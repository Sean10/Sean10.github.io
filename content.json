{"meta":{"title":"行路中.","subtitle":"脚踏实地","description":"笔记 随笔","author":"Sean10","url":"https://sean10.github.io"},"pages":[{"title":"关于&&留言板","date":"2018-02-24T09:15:33.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"about/index.html","permalink":"https://sean10.github.io/about/index.html","excerpt":"","text":"主要记录专业、反思、读书小结、影评。 mail: sean10reborn@gmail.com"},{"title":"categories","date":"2016-04-15T07:04:50.000Z","updated":"2020-04-24T01:27:29.000Z","comments":true,"path":"categories/index.html","permalink":"https://sean10.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2016-04-15T06:15:46.000Z","updated":"2020-04-24T01:27:29.000Z","comments":false,"path":"tags/index.html","permalink":"https://sean10.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"ceph之ansible理解","slug":"ceph之ansible理解","date":"2021-02-18T11:36:07.000Z","updated":"2021-02-18T11:15:29.900Z","comments":true,"path":"2021/02/18/ceph之ansible理解/","link":"","permalink":"https://sean10.github.io/2021/02/18/ceph之ansible理解/","excerpt":"","text":"理解 大家最受影响的就是一半时间开发, 一半时间运维的这个问题. 利用一个成熟的配置文件, 快速部署起自己需要的环境, 而不是一步步通过页面控制点击, 这是一个很省力的事情. 将运维中与部署相关的事情通过一些成熟的模板化的配置文件来提供, 最好不过了. ansible比较大的几个优点 由于是开源框架, 基于ansible的针对其他开源软件的配套代价较多 比如集成钉钉等 配置文件化管理部署成熟 可针对不同的环境, 使用不同的配置文件快速部署 可以使用开源插件快捷对接配置管理服务 因为 Ansible2.0以上的版本已经原生集成了consule: consul_module 不建议的操作 建议遵循unix思想, 一个工具只做该做的事情, ansible虽然提供了能力, 但是能由脚本来完成的事情, 没必要在ansible中进行处理 根据[^10]终于意识到我现在所处理的最别扭的地方在哪里了…这篇文章中说了下述几点. 在 ansible 中使用复杂的语法规则 更推荐直接封装成脚本, 由脚本来进行这些操作.但是脚本的粒度拆分, 什么应该让ansible来操作, 什么应该让脚本来处理, 是个边界. 明明几行 Shell 就可以搞定的事情，为什么一定要使用 Ansible 来做呢？ 明明一个 Shell 脚本就可以完成的环境监察，为什么一定要使用 Ansible Playbook 来做呢？要知道 Playbook 编写语法虽然是 YAML，但是使用起来并不简单，有很多特殊的语法需要去注意，完全没有必要花费精力去学习一个新的工具去完成。 &gt; * 如果脚本中存在较多判断，不宜使用 Playbook 实现逻辑 &gt; * 如果脚本中存在部分参数解析功能，不宜使用 Playbook 实现逻辑 &gt; * 不要过度拆分 task，保证每个 task 完整性 从个人使用上来说，Ansible 还是很好用的，至少它无需 Agent，SSH 连接等特性，使用起来很友好。 但是我们也不应该过分使用 Playbook，编写 Playbook 解析 json 花费了不少的时间，远不如直接在被执行脚本中完成的成本低。 tidb开发计划 deploy.yml 用来部署集群。执行 deploy 操作会自动将配置文件、binary 等分发到对应的节点上；如果是已经存在的集群，执行时会对比配置文件、binary 等信息，如果有变更就会覆盖原来的文件并且将原来的文件备份到 backup（默认） 目录。 start.yml 用来启动集群。注意：这个操作只是 start 集群，不会对配置等信息做任何更改 stop.yml 用来停止集群。与 start 一样，不会对配置等做任何修改。 rolling_update.yml 用来逐个更新集群内的节点。此操作会按 PD、TiKV、TiDB 的顺序以 1 并发对集群内的节点逐个做 stop → deploy → start 操作，其中对 PD 和 TiKV 操作时会先迁移掉 leader，将对集群的影响降到最低。一般用来对集群做配置更新或者升级。 rolling_update_monitor.yml 用来逐个更新监控组件，与 rolling_update.yml 功能一样，面向的组件有区别。 unsafe_cleanup.yml 用来清掉整个集群。这个操作会先将整个集群停掉服务，然后删除掉相关的目录，操作不可逆，需要谨慎。 unsafe_cleanup_data.yml 用来清理掉 PD、TiKV、TiDB 的数据。执行时会先将对应服务停止，然后再清理数据，操作不可逆，需要谨慎。这个操作不涉及监控。 \b并行任务引擎 作业编排：可以自由选择相应的原子化操作，编排和发布新的作业流程 可视化: 通过拖拽鼠标编排作业流程和参数表单，作业运行与任务的状态可视化 并行调度: 同一个作业中的任务支持并行执行，在很多场景下能极大的缩短执行时间 实时监控: 任务的运行状态在页面上实时更新 断点执行: 执行错误的任务在修复错误后可以继续执行，不需要重新执行整个作业 任务回滚: 遇到错误，可以支持回滚作业中已经执行过的任务，恢复执行环境 作业模板: 可定制作业模板，用模板创建作业实例，避免重复工作 任务组: 在作业模板中把任务分组，在创建任务实例时候可以动态的复制任务组，相似的作业使用同样的模板，但又不限制于模板 计算表达式: 使用表达式动态的计算任务的参数值，能够极大的简化重复参数的输入以及复杂参数的拼接 动态参数：前面任务的输出作为后续任务的输入参数 同类比较 fabric 快速入门使用 puppet C/S架构 大部分付费功能 Chef ansible 语义多层架构 基于ssh, push/pull均支持 cephadm是使用工具的配置语法进行部署后, 为了更强程度的自定义而进阶开发的产物. SaltStack 基于python的开源CM工具 CS架构 学习曲线低 cephadm之后有配套saltstack的 ceph/ceph-salt: Deploy Ceph clusters using cephadm Kolla-ansible? 应该是openstack用的 苏宁的产品化Hull思路 基于上面的, 设计标准的RESTAPI 定义Workflow 可视化安装 增加Data Center, cluster, region等逻辑概念, 更好的满足用户的部署需求. 最佳实践 重试逻辑 --start-at-task 这里采用的方案是自定义一个callback的插件, 将failed的task记录下来,见callback, 然后封装一个CLI, 在下次执行的时候增加--start-at-task {task_name}来进行调度. ### 优化方案 和一开始调研时的目的有点不一样, 现在发现的主要问题在于ansible做的预处理的逻辑太多了, 而且主要框架严重依赖单独的ssd和shell, 这样带来的问题你就是部署的性能较差. 需要找一些优化的方案 facts收集 关闭 设置缓存 增加并发 修改运行策略为free等. ssd长连接 开启pipelining. 原本的逻辑是将library,role等生成一个脚本, 复制到远程主机上, 再执行. 现在改为通过pipe直接传递给ssh会话. 开启accelerate模式, 是需要对面的远程服务, 预计是通过rpc类似? 通过poll设置一段时间后再来查询, 不阻塞着等待了. 插件开发 callback 主要目的是支持可以解析出当前失败的任务, 然后给另一个进行重试的接口进行使用. rolling upgrade什么意思 好像应该叫做rolling update模型, 哦,滚动升级 哦, 忽然明白为什么是loop结合delegate_to了, 因为要的不是并发,而是滚动操作. 继承的方法 v2_runner_on_failed runner_on_failed 这俩函数有什么区别呢? 目前看起来v2版本并没有加强多少? 那就随意使用了先. 理解开发方式 感觉[^3]这种插件的阅读方式能提供一些参考. python调用ansible python3.8 调用ansible 2.9.4 api | 经验分享&amp;服务器代维 ansible使用 调试方式 epdb -vvvvvv 虽然文档中只写了-vvv, 但是实际上代码里有一部分写了vvvvvv的函数. 设置ANSIBLE_KEEP_REMOTTE_FILES=1, 然后再运行Ansbile命令 ansible运行前生成的临时脚本就会保存下来, 不会被删除了. tower付费部分 workflow? workflow和任务队列的区别应该在于低代码吧? 还是说图形界面的任务的图形化操纵叫做workflow? 练习方式 chusiang/ansible-jupyter.dockerfile: Building the Docker image with Ansible and Jupyter. Ansible 用 Docker Compose 练习 Ansible_w3cschool 执行 通过playbook调度role的task, 来进行批量任务执行. ### workflow操作多个playbook是否有开源替代方案? 还是直接写playbook, 通过role控制. 目前来看, 不算特别关键. 语法 playbook 1234ansible-playbook -i &#123;inventory host&#125; add-osd.yml# checkansible-playbook foo.yml --check delegate_to 这里为什么看到和loop一起使用? delegate_to不支持直接指定组嘛?为什么要loop 这个的主要用途难道不是到一个只需要一个组内的一个节点执行的时候, 直接选中某一个吗? ansible解析参数的过程, 和delegate_to这种指定某个节点只执行一次的逻辑, 是哪个优先呢? 如果是后者, 那是否这个的目的是用来让这个组内只在第一个节点执行一次? 但是感觉有点像是后者 12delegate_to: \"&#123;&#123; item &#125;&#125;\"loop: \"&#123;&#123; xxx &#125;&#125;\" role 自定义模块, 内部包含具体的task 依赖管理 在 playbook 中存在多个 roles，且其中有相互依赖关系时，合理使用 meta 配置，填写其所依赖的 roles。注意，被依赖的 roles 会优先执行 ad-hoc 全节点临时执行的命令, 这个对于排查问题全节点查日志的时候还是用的比较多的. 1ansible 主机或组 -m command -a '模块参数' ansible参数 ceph-ansile [^2]里稍微解释了一部分. 问题 根据目前的调研结果来看, 存在两个问题 * osd层无法支持用于db,wal分区之后剩余空间创建osd * crush rule无法自由指定 * 不支持tier创建 * 不支持针对ec模式下的资源池,通过创建副本的元数据资源池进行创建rbd. 二次开发问题 开发环境到底怎么才能部署起来呢?如果不使用实机已经装好ceph和ceph-ansible的环境, 就没有办法了? 为什么看vagrant.yml.sample里, 都是从一个裸机开始呢?怎么里面就不能装好ceph依赖吗? 姑且按照[^5]先启动看看.` osism/ceph-ansible Tags - Docker Hub vagrant 启动失败了, 似乎我用的centos景象不太一样, 找个docker hub里的试试 Ceph — OSISM documentation 所以library其实完成的任务就是拼接command? AnsibleAPI 开发 - 简书 参考上面这篇文章基本可以说明怎么使用ansible提供的库 实践中的一些疑问 command和 debug冲突? 对应的是不同的Task, 因此的确会冲突 shell和command有没有区别? 一个是启动shell, 一个是启动sh 默认ansible使用的module 是 command，这个模块并不支持 shell 变量和管道等，若想使用shell 来执行模块，请使用-m 参数指定 shell 模块,但是值得注意的是普通的命令执行模块是通过python的ssh执行。 changed 是用来标记task的幂等性满足与否? 的确, 用来标记这个任务是否对环境产生了修改? groups保留字 属于ansible自身的保留字段 变量和inventory还是有点区别的, 虽然是这个主机组的, 但是单纯的变量其实没有主机组的概念的. 为什么ceph没有提供给ansible基于rados的接口呢? 是否是因为使用的是ssh等协议, 所以用Rados其实并不太方便? 并没有设计这个connection?如果要开发, 其实是开发一个connection机制吧? 主要用途是部署, 而在部署阶段, rados得在mon部署完毕后才能工作, 因此如果要切换connection, 还必须分阶段. 还不如直接ssh全套 You cannot register a variable, but you can set a fact (which in most use cases, including yours, will be equivalent to a variable): 12- set_fact: the_output: \"&#123;&#123; restdata.json.parameter[1] &#125;&#125;\" 要使用json_query , 需要安装jmespath ansible使用register就会被标记成changed? 为什么我用filter, 带上2个大括号就无法识别出对象了呢? 因为filter是jinja2语法, 外面需要先带上双引号. * You are using the debug: module with the option var: and this expects a variable, not a jinja2 template. 对于您的模块支持检查模式，您必须在实例化AnsibleModule对象时传递supports_check_mode = True。 当启用检查模式时，AnsibleModule.check_mode属性将计算为True。 对task进行检查模式 ### ansible的模块里打印大量内容, 即便他不显示,也会记录到warning里? 有垃圾产生? ansible的library不允许使用print, 居然就会报错. 没有日志, 需要之后再找怎么记录日志的方式 通过logging直接往其他文件, 或者通过Syslog协议等输出是一种方案. 或者可以记录到stderr中, ansible只检查stdout是否被污染, 然后报错. out不能是变量? 只能是字符串? 这个还需要找一下 通过debug可以打印出Ansible_facts, 但是直接引用就一直打印不出来, 忽然脑子过了一下, 想通了, ansible_facts应该是上层概念, 对于使用的应该直接填key就可以了, 然后的确拿出来了. 字符串输出转换, 坑 {} 会把字符串转换成object, 导致即便to_json了, 双引号也没了, 其他程序无法识别了. jinja2的语法问题 Double quotes are converted to single quotes on variable assignment if contents look like JSON · Issue #44897 · ansible/ansible Ansible - passing JSON string in environment to shell module - Stack Overflow ansibleSequence是什么东西? 字典的key索引不会被Jinja2解析, 这个真的是深坑 感觉看了下, 这个坑很大啊…一点都不方便debug 莫名其妙的module failure 没有提示的时候, 实际上问题就是在于你的模块里用了print… ansible 是只检测stdout是否被污染, 所以如果我把信息写到Stderr里是没问题的. python3支持问题 我们目前用的ansible 2.6, 我指望使用python3来进行操作, 避免一些问题. 按照[^13]里提到的来说, 理论上会按照从哪个python版本安装的ansible, 就从哪个版本启动的功能. 根据[^11]发现的问题就是, 我用的2.6通过ansible.cfg中的设置, 并没能生效, 而通过-e传入的参数倒是有效. 暂时通过上层传入来覆盖下层使用的解释器 group_vars的读取时间是什么时候嗯 只会在执行role的时候去读取对应的group_vars中的变量 怎么将当前读入的配置及收集到的facts配置导出呢 怎么执行Export呢? template - Templates a file out to a remote server copy content output from json and a variable is not idempotent under py3 · Issue #34595 · ansible/ansible 另外, 其实我并不需要ansible原生的gather_facts, 因为他能够给出来的ip, 现在我知道一些python的原生库获取, 重点在于, 我怎么把多个节点的数据给聚合到一个节点上. 通过set_fact去一起设置到一个字典里? 我通过vars聚合完了. 有个map(’extract’功能可以满足这套 12345678910111213141516171819- hosts: all vars: uuids: | &#123;%- set o=[] %&#125; &#123;%- for i in play_hosts %&#125; &#123;%- if o.append(hostvars[i].uuid) %&#125; &#123;%- endif %&#125; &#123;%- endfor %&#125; &#123;&#123; o &#125;&#125; tasks: - name: get uuids for existing cluster nodes shell: mysql -N -B -u &#123;&#123; db_user &#125;&#125; -p &#123;&#123; db_user_password &#125;&#125; -e \"SHOW GLOBAL STATUS LIKE 'wsrep_cluster_state_uuid';\" | sed 's/\\t/,/g' | cut -f2 -d',' register: maria_cluster_uuids - set_fact: uuid: \"&#123;&#123; maria_cluster_uuids.stdout &#125;&#125;\" - debug: var: uuids run_once: true delegate_to: 127.0.0.1 Is it possible combine remote results to local a register in Ansible? - Server Fault vars选项的运行时间是什么时候呢? 如果我采用task, 他能在我指定task前自动运行吗? vars的调用时间是什么时候呢? 写个代码模拟一下? 目前来看, 是当用到这个变量的时候, 才会去计算 有没有办法把list的tuple转成dict呢? Reference ceph-ansible 使用 | Bolog 干货｜基于Ansible的Ceph自动化部署解析_中兴开发者社区-CSDN博客 第八章: 扩展ansible_个人文章 - SegmentFault 思否 Full support for · Issue #2195 · ceph/ceph-ansible Easily deploy containerized Ceph daemons with Vagrant | Sébastien Han ansible debug模块学习笔记-行者之路-51CTO博客 一文搞懂 ansible 变量配置 - biglittleant - 博客园 Ansible 面向企业大规模使用探究 – IBM Developer 可能是最强网工ansible入门及深入教程之 ansible杂谈 - 知乎 Ansible最佳实践 | Yiran’s Blog ansible/python_3_support.rst at stable-2.6 · ansible/ansible Interpreter Discovery — Ansible Documentation Wrong python2 interpreter instead of python3 · Issue #69494 · ansible/ansible 一些小团队的自动化运维实践经验 | 程序猿DD How to Manage Multistage Environments with Ansible | DigitalOcean 基于Ansible自研的可视化和并行自动化运维引擎 - 知乎 Ansible 实现原理（源码分析） – Tiantian Gao ( gtt116 )","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"ansible","slug":"ansible","permalink":"https://sean10.github.io/tags/ansible/"}]},{"title":"vscode相关技巧","slug":"vscode相关技巧","date":"2021-01-31T08:32:59.000Z","updated":"2021-02-17T15:45:09.045Z","comments":true,"path":"2021/01/31/vscode相关技巧/","link":"","permalink":"https://sean10.github.io/2021/01/31/vscode相关技巧/","excerpt":"","text":"todo 目前vscode似乎还没有支持一个当前文件所有搜索项的列表显示的功能 暂时是通过左侧的全局搜索, 定位到当前文件来进行搜索的. 类似typora的所见即所得插件支持 即时渲染 有一些unote之类的web editor嵌入到vscode中打开, 这样的话也算是实现了一个所见即所得的编辑器, 不过不是基于Vscode的倒是了. 不过这种情况下有些vscode配置的快捷键应该还是可以用的. 同义词模糊搜索功能(fuzzy search) fzf fuzzy search 只能搜索文件名, 还是有点欠缺的 不知道这个模糊搜索能不能做到NLP的水平呢? 中文的似乎暂时没有, 别的都是直接基于fzf的 窗口之间的焦点切换 ctrl + M 使用tab键切换焦点模式tab move foucs ctrl + ~ 聚焦到TERMINAL(展开/收起TERMINAL) ctrl + 聚焦到editor Ctrl + Shift + E 资源视图和编辑视图的焦点切换 Ctrl + Shift + V 预览Markdown文件【编译后】 Ctrl + K v 在边栏打开渲染后的视图【新建】 vscode 插件资源占用排查 打开Help-&gt;Process Explorer, 这里会显示出每个窗口的CPU和内存的占用. 中文输入markdown时, 需要2次backspace才能删除掉在输入法中的字符 编辑器不会跟随同步删除. 根据[^2]来看,似乎是electron和chromium的问题. 但是我用的1.51的vscode还是存在这样的问题呀?为什么关闭了呢? 似乎我升级了下搜狗输入法就好了, 至少5.9.0.11685目前没什么问题. 快捷键 快速切换tab, Option+Cmd+左右方向键 中文分词[^4] 因为最近写文字记录比较多, 有时候词写错了, 想快点删的时候只能一个个删, 不像因为单词可以直接删, 就忽然意识到. 现在分词做的这么好了, 理论上这种插件应该已经有了. 果然, 搜到了这个CJK Word Handler - Visual Studio Marketplace, 试了下, 还挺好用. markdown的Cmd+B覆盖了vscode的outline打开和关闭. 被markdown覆盖掉了怎么办? 我暂时选择删除markdown的这个快捷键 Reference (2) vscode控制字符引起的问题以及解决思路_洞香春 - SegmentFault 思否 Backspace can not erase the last one character during Chinese/Japanese IME conversion (macOS) · Issue #24981 · microsoft/vscode Backspace can not erase the last one character during Japanese IME conversion (macOS) · Issue #9173 · electron/electron VSCode 中文分词插件：CJK Word Handler - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://sean10.github.io/tags/vscode/"}]},{"title":"openAPI初探","slug":"openAPI初探","date":"2021-01-31T07:29:57.000Z","updated":"2021-01-31T08:08:34.043Z","comments":true,"path":"2021/01/31/openAPI初探/","link":"","permalink":"https://sean10.github.io/2021/01/31/openAPI初探/","excerpt":"","text":"todo(未理解的问题) 既然作为一个规范文档, 那么引导的example肯定得提供吧? 提供了之后, 那为什么不能多几个example? 直接做成支持测试框架的呢? 虽然现在测试框架的确支持导入openAPI的文档, 但是这些测试框架中需要用的参数数据是另外填写的, 为什么openAPI不集成在里面呢? 一个初步的结论: OpenAPI只做规范特定领域的事情, 单元测试及更进一步的测试领域的功能, 应该由测试方面的工具来进行扩展,而不是一揽子全包含了. 也算是一个合理的解答了. 概念 OpenAPI是一种机器可读的接口文件的规范. 基于这个规范的文档可以提供的信息, 将原本需要开源人员处理的工作转移到工具上. 主要功能 基于规范 生成服务端Stub和客户端代码 构建自动Mock 生成可供开发人员你是用的API文档等 开发人员可以花更少的时间去了解API的底层细节, 只关心API的上层重点即可. 基于代码 对于已经有API实现的情况, 可以使用工具从代码中导出OpenAPI规范. 从而生成文档. 当代码版本较多等场景时, 能从对应的代码导出对应的API文档 让代码与文档产生联动关系. 扩展性 完全可以基于这套规范根据自己公司的需求进行扩展开发, 开发出对应的DSL.[^9] 配合postman, 自动化测试 参照下面这篇文章, 其实就可以做到我们想要的效果. 使用 Postman 测试你的 API_json 使用Jmeter和Jenkins自动化测试OpenAPI – 小工蚁 ET应该可以做到API 自动化测试：零代码自动化、数据驱动测试、自动生成报告 - Eolinker API 全生命周期管理这个的程度才对. CI 非常适合应用单元测试、应用代码覆盖以及做到daily build/tes Reference Open API测试畅想 - 阿里巴巴一个测试架构师 - 51Testing软件测试网 51Testing软件测试网-软件测试人的精神家园 使用 Postman 测试你的 API_json 使用Jmeter和Jenkins自动化测试OpenAPI – 小工蚁 OpenAPI Map OpenAPI：为传统机器构建智能API-InfoQ 使用OpenAPI构建更智能的API - EOLINEKR BLOG API 自动化测试 - 自动化测试 文档驱动开发模式在 AIMS 中的应用与实践 - InfoQ 写作平台 听说，阿里云给它的 OpenAPI 开发了一套编程语言 - InfoQ 写作平台 聊聊OpenAPI Specification（OAS） - InfoQ 写作平台","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"OpenAPI","slug":"OpenAPI","permalink":"https://sean10.github.io/tags/OpenAPI/"},{"name":"API","slug":"API","permalink":"https://sean10.github.io/tags/API/"},{"name":"SDK","slug":"SDK","permalink":"https://sean10.github.io/tags/SDK/"}]},{"title":"卡牌游戏之再玩ygocore.md","slug":"卡牌游戏之再玩ygocore-md","date":"2021-01-17T10:59:45.000Z","updated":"2021-01-17T17:56:13.054Z","comments":true,"path":"2021/01/17/卡牌游戏之再玩ygocore-md/","link":"","permalink":"https://sean10.github.io/2021/01/17/卡牌游戏之再玩ygocore-md/","excerpt":"","text":"背景 万智牌看着是不是跟D&amp;D有点关系?, 旅法师之类的. 看起来是集卡式游戏的始祖级别? 看大家的评论中, 这个的设计师考虑的比较好, 平衡性等都考虑的不错. 游戏王嘛, 动画, 漫画, 实体卡的宣传都非常广, 只不过实体卡等那部分不是官方, 而是盗版, 在国内的市场里占了很大一部分, 相当部分的人的童年基本上都看过游戏王, 至少我是这样的. 而万智牌我就到了大学才看到同学在玩, 才知道这个名词. 游戏王虽然宣传范畴上知道的人很多, 不过最大的诟病就是娱乐性较强, 平衡性较差吧, 新卡基本都非常强, 似乎是说每个时代的上位卡组基本都是一致的, 主流用户都玩同一套卡组, 只有玩娱乐场的时候大家能发散一点? 不过上面这都是大佬们为了整个游戏氛围的玩耍而考虑的. 对于我这种菜鸟来说, 光是很容易进行线上入门的ygo的整个社区就已经很好了. 暂时先从主流卡组入手之类的. 记得大学的时候搜到过, 当时好像应该移动端还没怎么有,当时至少还是ygopro一代的时代. 当时玩了两把, 连机器人都打不过(虽然现在也是). 在现在偏官方的网易的已经发布的现在, 至少我的个人感受是依旧是玩的远比那种闯关式要舒服的多的. 游戏 万智牌 emm. 似乎也没有线上服务, 也是需要收集实体卡的, 这样的话对于我这种就不太友好了. 暂时先不入门了. 游戏王 有ygocore等的在线任选卡的游戏, 相比其他的要好多的了. 基本上全平台都有ygopro2的游戏了, 安卓用ygomobile即可. 名词解释 禁卡 不允许使用的 限卡 有卡组内数量限制的 TCG 欧美发行正版卡 OCG 亚洲发行正版卡 OTK one turn kill 炉石 需要肝才能收集到想用的卡, 这样还是比较耗时间的. 游戏王规则[^3][^4][^5] 游戏王卡组[^2] 大佬推荐B站视频 和 闪刀姬Sky Striker 雷龙THUNDER DRAGON 自奏圣乐Orcust 英雄(幻影英雄) 电子龙 超魔导龙骑士真红眼龙骑士(单卡超模) 属性实在是太强了 新人随意搭配禁卡, 探索一下兴趣, 在卡牌编辑里搜了几个禁卡/限卡来用用. 发现在人机卡组里的这个龙骑士卡组默认版本稍微有一个问题 解决不了像是那个青蛙卡组, 他的特召之后效果能把免疫破坏效果的龙骑士给返回额外卡组. 我就暂时放弃随机抽卡, 找了个禁卡, 在我第一步就是用真红眼融合把龙骑士招出来之后, 发动, 把特召给禁了. 不过又出现一个时械神, 既不让破坏, 又不受伤害, 就跟我的在那边进入死循环了. 找了个手牌除外的卡, 趁他回到手牌的时候, 给清掉. 不过这个也太艰难了, 毕竟我都已经不洗牌了才能做到. 要是真启动. 不知道使用什么卡才能够解决掉他. Reference (4 条消息) 如何评价炉石、游戏王和万智牌这三款集换式卡牌游戏？ - 知乎 【图片】萌新的游戏王新手入门（缓更）【游戏王ygocore吧】_百度贴吧 Welcome to ocg-rule’s documentation! — ocg-rule 文档 2020年游戏王《完全规则书》更新规则 - 哔哩哔哩 游戏王集换纸牌游戏 | 遊戲王 Wiki | Fandom","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"游戏王","slug":"游戏王","permalink":"https://sean10.github.io/tags/游戏王/"},{"name":"ygo","slug":"ygo","permalink":"https://sean10.github.io/tags/ygo/"}]},{"title":"mac系统使用小记.md","slug":"mac系统使用小记-md","date":"2021-01-16T11:36:07.000Z","updated":"2021-02-17T04:09:28.558Z","comments":true,"path":"2021/01/16/mac系统使用小记-md/","link":"","permalink":"https://sean10.github.io/2021/01/16/mac系统使用小记-md/","excerpt":"","text":"Time Machine mac time machine限速 苹果官方直接就有给出解决方案，关闭限速即可 1sudo sysctl debug.lowpri_throttle_enabled=0 如果想要再开启，输入以下命令即可 1sudo sysctl debug.lowpri_throttle_enabled=1 查看time machine日志 12345678910111213141516171819202122232425262728293031323334353637383940414243444546sudo less +F \"/Volumes/MacBackup/Backups.backupdb/MacBook Pro/2020-08-05-163227.inProgress/.Backup.618330747.626060.log\"``` bash[macbook pro \\- Time Machine in the \"Cleaning Up\\.\\.\\.\" state forever \\- Ask Different](https://apple.stackexchange.com/questions/382772/time-machine-in-the-cleaning-up-state-forever)## time machine目录terminal无权限在Security * Privacy的Privacy中放开对Full Disk Access的Terminal权限.# 文件系统## APFS&gt; 稀疏文件、改进的 TRIM 操作，内建对扩展属性的支持&gt; 空间共享&gt; 数据加密&gt; 大小写敏感### Volume跟`lvm`那些的逻辑卷是不是差不多呢. 其中最大的亮点功能因为是不同卷组之间共享总体空间的功能了, 看上去应该是依托`COW`实现的. 但是具体机制不知道有没有哪篇文章提到.不知道`Container`和`Volume`两层分别是起什么样的作用呢?### firmlink跟``` bash ✗ cat /usr/share/firmlinks /AppleInternal AppleInternal/Applications Applications/Library Library/System/Library/Caches System/Library/Caches/System/Library/Assets System/Library/Assets/System/Library/PreinstalledAssets System/Library/PreinstalledAssets/System/Library/AssetsV2 System/Library/AssetsV2/System/Library/PreinstalledAssetsV2 System/Library/PreinstalledAssetsV2/System/Library/CoreServices/CoreTypes.bundle/Contents/Library System/Library/CoreServices/CoreTypes.bundle/Contents/Library/System/Library/Speech System/Library/Speech/Users Users/Volumes Volumes/cores cores/opt opt/private private/usr/local usr/local/usr/libexec/cups usr/libexec/cups/usr/share/snmp usr/share/snmp Mac journal extended 目录结构[^4] Mac 根目录下有以下几个文件夹： /System 文件夹，系统文件夹。与Windows 之中的 C:32 等文件夹类似。 Library 系统资料库，其中的 Caches 可以删除。 iOSSupport 提供了系统的 iOS 支持。 /Applications GUI软件文件夹，共享的所有软件包都存放在此。 /Library 应用资料库，包括了大部分非核心的系统组件。Caches 可删除。 /Users 文件夹，与 Linux 之中的 /home 文件夹功能类似。而mac 之中的 /home 只是为了与 Linux 兼容，一般不放任何东西。 /Network 和 /net 网络相关，空的。 /Volumes 与 /mnt 类似，其中挂载了全部硬盘、网络硬盘等。 /sbin，/bin，/usr /dev文件夹，与 Linux 基本一致。与 Linux 兼容。 /etc, /var /tmp 文件夹，是位于 /private 之中对应文件夹的软连接。存放系统配置、数据库、缓存等。用于与 Linux 文件结构兼容。 注意，/root, /procfs, /boot, /sysfs 等非必须文件夹均不存在。 遵照freeBSD的/bin,/etc,/lib目录都是不建议修改的, 所以所有程序都是装到/usr/local目录下 开发调试 clang相关 lldb lldb -c /cores/core.99415 这样就可以调试了,不需要指定可执行文件看起来 brew 包管理 brew使用 1234567891011#更新brew到最新版本brew update-reset# 显示这个包内安装的文件的路径。brew list redisbrew cleanup# 查包的依赖包brew deps --installed --tree# 卸载包及其依赖brew rmtree graphviz brew 运行详情 Unsupported special dependency :maximum_macos · Issue #38604 · Homebrew/homebrew-core macOS 使用 Homebrew 的经验分享 | HelloDog 没在文档里找到如何下显示brew update的进度，不然老是以为阻塞了，还好我想起来一般开源软件都用verbose，就试了一下，看了brew的写法也是相当不错的。 不过就是也只能显示到fetching的进度了，fetching快不快应该只能靠监控流量了。 字体[^5] fair code brew tap homebrew/cask-fonts brew cask install font-fira-code brew源配置 mkdir -p $(brew –repo homebrew/core) git -C “\\((brew --repo)&quot; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git git -C &quot;\\)(brew –repo homebrew/core)” remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git git -C “\\((brew --repo homebrew/cask)&quot; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.git git -C &quot;\\)(brew –repo homebrew/cask-fonts)” remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-fonts.git git -C “$(brew –repo homebrew/cask-drivers)” remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-drivers.git brew底层用的还是Git,git现在通过改host还是不怎么能提速，虽然现在用不了proxychains4，但是似乎可以直接用git config --global http.https://github.com.proxy socks5://127.0.0.1:1086直接用代理，唉，早知道这个就没那么多事情了。 奇怪好像找到我的cask和homebrew不正常的原因了, 不知道为什么, 我执行上面的这堆命令的结果, git和目录的对应都是错的. cask的目录里的git却是什么Font的. /usr/local/Homebrew/Library/Taps/homebrew 奇怪, 怎么好像这个目录下属的子目录里, 还是在brew那个仓库里呢… 是因为装的太早, 不是通过tap安装的? 看起来的确是这个问题, 新装的这个version目录没问题 brew tap homebrew/core brew tap homebrew/cask brew tap homebrew/cask-fonts brew tap homebrew/cask-drivers brew tap homebrew/cask-versions 暂时不配置源了, 用代理下载也挺快. 安装HomeBrew 失败的解决方案(Error: Fetching /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core failed!) - 子钦加油 - 博客园 老是报caskroom/homebrew-cask卡住 实际上不存在这个了, 已经改名成homebrew/homebrew-cask了. macos - Error: caskroom/cask was moved. Tap homebrew/cask-cask instead - Stack Overflow # 降频 机时以 sudo 运行 Turbo Boost Switcher，就不用来回输密码切换了。 如命令行输入：sudo /Applications/Turbo Boost Switcher.app/Contents/MacOS/Turbo Boost Switcher Turbo Boost Switcher 真香，试用了一天立刻买 Pro 了 - V2EX Spotlight 快捷键 Spotlight打开之后，输入单词，按command+b可以直接用浏览器搜索，用command+L可以直接跳到字典项进行查询。 购买+apple care+ 从官网买的时候, 听说官网不像渠道那边, 以开机联网开始激活, 而是以发货时间开始,如果发货到你收货就过了3天, 那就相当于你的保修期已经过了3天, 对于我想从淘宝加3天内的apple care+的需求来说, 这就导致我需要提前查询到序列号. 还好, 虽然大部分地方没提到,但是实际上只要进入发货阶段, 当你邮箱里收到发货信息之后, 序列号已经有了, 可以直接联系客服, 通过一些信息直接询问序列号. 根据客服当时说, 根据正常流程, 发票实际上会自动发出, 只是可能相比你直接去问要晚一点发送. 我问到序列号, 办完apple care+后的一天收到了发票. launchctl 如何通过launchctl控制进程呢?比如App 其实好像也只有pkill一条路. touchbar 一开始我以为必须按照他的提示来使用以前的那些功能按钮. 偶然按了fn的情况下去按touch bar上显示的f12, 发现也能成功调整音量. 所以如果知道原来这个按钮上对应的功能键, 其实还是可以用的. 关闭系统更新提示[^6] Paste this command in the Terminal window, then press Enter to execute it: sudo softwareupdate –ignore “macOS Catalina” Next, paste this in Terminal and press the Enter key to run the command: defaults delete com.apple.preferences.softwareupdate Lastly, execute the following command in Terminal: softwareupdate –list 休眠时, 你的前台程序会收到的信息 系统休眠过程中主要是IO超时中断,这部分做过滤处理就好了 CPU会被暂停, 所以可能一些程序如果没做IO超时处理,就会直接触发异常中断了. 的确很对, 像是一些视频网站打开后休眠再次打开, 缓存的连接都失效了, 一般需要刷新再操作了. Reference 当 Mac 升级到 Catalina 时，苹果在硬盘里施了点魔法 - 少数派 闲聊ReFS与APFS - 知乎 Apple新发布的APFS文件系统对用户意味着什么-InfoQ Layton’s Blog - 技术摘要| Mac OS 与 Linux 的目录结构比较 Programming Fonts - Test Drive Apple’s has brought back the nagging — you can no longer ignore major macOS updates","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"}]},{"title":"2020年终总结","slug":"2020年终总结","date":"2021-01-11T14:28:02.000Z","updated":"2021-01-11T14:28:52.471Z","comments":true,"path":"2021/01/11/2020年终总结/","link":"","permalink":"https://sean10.github.io/2021/01/11/2020年终总结/","excerpt":"","text":"今年主要的感触在项目中, 基本上就是一些沟通与落地方面是否双向澄清,全环节负责的人是否都已经理解需求及实现了. 人月神话中的沟通的代价, 想来过程中的人员澄清应该占用了一部分. 即便简单的项目, 也存在SE, DE, 开发者三人的环节. 这种常见的一般都会一个会议, 或直接在工位旁边完成澄清的过程. 而对于今年主要遇到的跨大部门的大型项目, 一个OR基本上就存在了2倍的人员对接. 每个环境都可能是由对应的责任人进行对接, 3人时最多出现的排列组合, 6次也足够了. 而对于6人时, 一旦某个环节的澄清中出现某个细节点未澄清, 最坏的情况, 可能就会出现6!的多次沟通(当然, 大部分情况应该就花个几次.). 在项目之外, 技术方面. 在年初时, 主要针对全链路追踪做了调研和demo的实现. 这个全链路追踪的思想在社区里查看, 针对java的果然还是比较成熟, 翻了翻综合安防平台的报告, 实际上他们的微服务的业务方面的开发框架, 基本上是集成了这部分功能的. 而针对嵌入式相关的编译时语言, 如果原先不是基于某套开发框架开发的背景下, 比如我们的代码大部分都是直接调用的syscall,这种情况下, 我们如果想做无感知的埋点, 就只能利用gcc或者clang方面编译器提供的pre的hook函数的支持--finstrument-functions来设置每个函数执行前后的回调之类的. 不过这个的性能代价相对来说较大, 因为源码文件中所有的函数均会被埋点. 当每个埋点都存在一个rpc通信时, 代价较大. 后续接触到ceph时, 对于pool,crush,pg,rados迅速有了一定的了解. 在这个过程中, 发现ceph基本上是应用了主流大部分的分布式技术方案. 然后, 逐渐意识到, 在分布式领域, 其实针对不同场景下的方案取舍, 存在很多种代价的组合. 在这其中发现虽然是称为分布式, 但是在程度上其实还是有差异的. 就目前的理解来说, mon等元数据管理机制其实都只是单点提供服务, 更多的管理节点完成的只是高可用(避免脑裂等问题). 而mon直接仍然存在单点性能的上限问题, 当然这个性能在一定规模下是不会成为瓶颈的. 比如, 假如说当管理的osd节点数量爆炸的高时, mon节点的性能的确开始成为瓶颈时, 是否就可以开始应用传统的垂直分割技术, 类似数据库垂直分表一般, 将传统技术在分布式领域的某些场景下再次应用, 就又可以突破一点. 诸如此类等等, 像是使用crush算法, 实际上算法始终存在分布不均匀问题.各公司在进行自研时, 是采用元数据管理服务器来提供分布来提供容量和性能, 还是为了让元数据管理服务器不成为功能上的瓶颈, 将选择节点过程迁移到客户端来进行, 暂时通过其他手段来解决crush带来的不均匀问题. 看起来都是根据自身的考量来说. 目前就目前的crush算法的限制, 以及个人的实验结果来看, 企业级产品, 目前可能这个资源占用的代价更愿意放到元数据管理服务器, 因为这个资源消耗相比性能的代价来看, 代价不如价值大. 但是, 对于社区来说, 前沿有意思的技术更有意思, 就像最初的ceph论文, 差异点主打的就是分布式. 且指不定忽然就出现了算法突破(比如可以通过配置不同的算法达成不同的虚节点分布, 一定程度上能够保障均衡), ceph的劣势一下子就不再是短板, 基本就完全碾压了基于元数据管理服务架构下的组件. 回到目前源码的学习中, 一个比较入门的感触, 就是目前组内调试, 可能并没有充分利用起社区提供的工具?主要还是只是增加日志重新运行等方式, 像是比如flame火焰图等排查分析函数调用工具, 甚至其中之前做的全链路追踪, ceph中就有使用用户态链路追踪的工具lttng, 基于这个额外提供了zipkin的埋点对接. ceph采用的方法是目前zipkin社区主要做的, 针对静态编译式语言, 由开发者人工在需要封装的函数位置调用宏tracepoint, 通过编译时宏来进行控制是否启动埋点检测, 预计对于帮助理解代码, 会有比较好的效果.感觉这个是接下来有必要做的事情, 将这种快速学习代码逻辑的工具充分利用起来. 总的来说, 今年在技术上发现了不少新的思路, 可扩展学习的方向希望早日能够打通ceph的整条路径中各节点的竞争方案 希望2021年能将ceph的rbd及下层的IO流程中角色打通~能够逐渐对设计IO路径中某个角色有所思考, 能糅合出较佳的一个方案","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"总结","slug":"总结","permalink":"https://sean10.github.io/tags/总结/"}]},{"title":"日志分析ELK部署","slug":"日志分析ELK部署","date":"2021-01-10T19:03:17.000Z","updated":"2021-01-10T19:03:47.722Z","comments":true,"path":"2021/01/11/日志分析ELK部署/","link":"","permalink":"https://sean10.github.io/2021/01/11/日志分析ELK部署/","excerpt":"","text":"部署 12345docker pull sebp/elkdocker run -p 5601:5601 -p 9200:9200 -p 5044:5044 \\ -v /Users/sean10/Code/docker-volume/elk:/var/lib/elasticsearch \\ -v /Users/sean10/Code/Algorithm_code/elk/logstash.conf:/etc/logstash/conf.d/logstash.conf\\ --name elk sebp/elk Filebeat 日志数据采集器 与logstash直接配置本地文件的读取是否存在差别呢? 把elk-logstash的证书[^6], 和这个证书对应的域名加到hosts里解析, 成功导入了宿主机里的日志. 不过这种不修改filter的逻辑的日志, 只是把log的每行都记录成message了, 其实索引没利用起来的感觉. 1234567891011121314output: logstash: enabled: true hosts: - elk:5044 timeout: 15 ssl: certificate_authorities: - /etc/certs/logstash-beats.crtfilebeat: inputs: paths: - \"/var/log/ceph/*.log\" 1docker run --name filebeat --user=root -v /Users/sean10/Code/ceph/ceph-14.2.9/src/out:/var/log/ceph -v /Users/sean10/Code/Algorithm_code/elk/logstash-beats.crt:/etc/certs/logstash-beats.crt -v /Users/sean10/Code/Algorithm_code/elk/filebeat.yml:/usr/share/filebeat/filebeat.yml -v /Users/sean10/Code/Algorithm_code/elk/hosts:/etc/hosts elastic/filebeat:7.10.1 logstash 配置 12345678910111213141516171819202122232425input file &#123; path =&gt; [&quot;/var/log/*.log&quot;, &quot;/var/log/message&quot;] type =&gt; &quot;system&quot; start_position =&gt; &quot;beginning&quot; &#125;&#125;filter &#123;# if [type] == &quot;cephlog&quot; &#123; grok &#123; # https://github.com/ceph/ceph/blob/master/src/log/Entry.h match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:stamp&#125;\\s%&#123;GREEDYDATA:msg&#125;&quot; &#125; match =&gt; &#123; &quot;message&quot; =&gt; &quot;(?m)%&#123;TIMESTAMP_ISO8601:stamp&#125;\\s%&#123;NOTSPACE:thread&#125;\\s*%&#123;INT:prio&#125;\\s(%&#123;WORD:subsys&#125;|):?\\s%&#123;GREEDYDATA:msg&#125;&quot; &#125; # https://github.com/ceph/ceph/blob/master/src/common/LogEntry.h match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:stamp&#125;\\s%&#123;NOTSPACE:name&#125;\\s%&#123;NOTSPACE:who_type&#125;\\s%&#123;NOTSPACE:who_addr&#125;\\s%&#123;INT:seq&#125;\\s:\\s%&#123;PROG:channel&#125;\\s\\[%&#123;WORD:prio&#125;\\]\\s%&#123;GREEDYDATA:msg&#125;&quot; &#125; &#125; date &#123; match =&gt; [ &quot;stamp&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSSSSS&quot;, &quot;ISO8601&quot; ] &#125;# &#125;&#125; 从ceph文档里找来的Filter, 不过好像匹配失败了, 可能跟版本有关系吧.版本太低? 用第一个,至少时间戳出来了. 实验 12/opt/logstash/bin/logstash --path.data /tmp/logstash/data \\ -e 'input &#123; stdin &#123; &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; [\"localhost\"] &#125; &#125;' 导入log 似乎要导入log, 默认的elk的配置不行, 需要修改logstash的配置, 增加一些属性. 一般流程 在日志存储服务器上安装filebeat filebeat将log存储目录下的所有log全部读取，发送到kafka logstash从kafka上读取日志，格式化后发送到elasticsearch elasticsearch正确索引后，response给logstash logstash更新kafka的offset，读取新的记录 一直循环以上步骤，直到所有的log都被写入到elasticsearch当中 可能的问题 索引过多, 导致elasticsearch 429 正确的处理大量历史数据的导入 不过很诧异，我很难在网络上搜到有人提过429的问题。仔细回想以下，一定是我的集群太low了。整个elasticsearch cluster的索引处理能力太弱鸡。。。所以，在你的集群比较弱鸡的情况下该怎么处理？ 当然，最直接的方法就是减少索引的量，比如，你要导入10月1号之前的所有log，你直接把索引的名字命名为platform-2017-10-1，而不是platform-%{+YYYY.MM.dd}。就算是只有一个eleasticsearch node，2C4G，亦能在5分钟之内把1G的log全部索引完。等索引完这些历史数据之后，你再把logstash上的output规则改为platform-%{+YYYY.MM.dd}。 elasticsearch 还是使用volume挂载 123path: data: /var/data/elasticsearch logs: /var/log/elasticsearch kibana 导入是导入成功了, 基本的搜索也有了, 但是显示出来的冗余内容有点多. Reference spujadas/elk-docker: Elasticsearch, Logstash, Kibana (ELK) Docker image elk-docker ELK生态：Logstash增量读取log文件数据，导入到Elasticsearch_alan_liuyue的博客-CSDN博客 用ELK导入历史log的正确姿势_点火三周的专栏-CSDN博客 手把手教你实战docker容器下的ELK环境搭建 - 知乎 fileBeat和Elk整合的问题_xinluke的专栏-CSDN博客","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"ELK","slug":"ELK","permalink":"https://sean10.github.io/tags/ELK/"}]},{"title":"arch体验","slug":"arch体验","date":"2021-01-02T15:03:56.000Z","updated":"2021-01-29T19:02:06.379Z","comments":true,"path":"2021/01/02/arch体验/","link":"","permalink":"https://sean10.github.io/2021/01/02/arch体验/","excerpt":"","text":"背景 有点用腻了mbp的mac os系统的感觉,想换arch了. 因为总觉得mac系统里好乱, 好多感知不到的空间管理. 而且终究只是unix, 并不是linux. 但是嘛, 都用了一段时间之后回来想想, 最近我比较倾向于arch的原因主要是最近工作所需一直在用linux规范下的systemd控制下的CentOS, 用的比较熟悉了, 对目录结构比较清楚了, 而对于自己非常不熟悉的freeBSD基础的mac, 有种不在自己控制内的感觉… 现在想了想, 这其实不就是舒适区的问题吗? 学习一下mac的目录结构和日志排查等, 其实也并不会有多费事, 也并不会增加我记忆unix生态的混淆程度. 哎,但是看笔记本的品控上来说,可能还是mac os让人比较省心了. 至少售后给的新笔记本不会像xps那样经常出问题… 硬件 XPS(arch推荐比较多的是这个,但是因为品控问题不推荐的也是这个) 什么电流音之类的,决定还是不选这个了. 虽然好像XPS 7590 15寸或者13寸的直接支持hdmi 2.0接口,不过品控还是太让人担心了. thinkpad x1c emm, 似乎还行,但是触控板的体验还是比不上mac的应该 matebook 好像散热不行, 键盘部分会烫? 听说bios不太行? 安装踩坑 manjaro踩坑 bootloader一直没能正常使用 参照[^3]这个带图片的安装过程终于安装成了. 发现我直接选择第三种systemd-boot的引导,最后是看不到进入系统的东西的,可能兼容性上有问题? 最后我额外安装了Refind这套引导,终于进入桌面了. arch安装 todo 大小写老师被自动切换了 似乎是vmware 15.5这个版本的缺陷 Temporary solution for Ubuntu guest which worked for me was just disabling the Caps Lock key all together with this setxkbmap -option caps:none setxkbmap -option caps:none # (disable the caps lock key) xdotool key Caps_Lock # (toggle caps lock) Caps Lock Issues With Upgrade - VMware Technology Network VMTN 禁用这个按钮倒也是个方案, 反正我基本也不用. 不过就怕他也影响宿主机, 那就很讨厌了. 为啥我安装的虚拟机鼠标放在Linux界面再挪出去，大小写键盘总是自动切换呢？用的vmware ubuntu.如图 为啥我安装的虚拟机鼠标放在Linux界面再挪出去，大小写键盘总_虚拟机吧_百度贴吧 VMware虚拟机中大小写不停切换的问题_helen2977的博客-CSDN博客 好像无解 重点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109# 这里fdisk分区时, 及时将类型修改为EFI类型# 否则会出现错误: cannot find a GRUB drive for mount /dev/mapper/VG_0-root /mntmkdir /mnt/bootmount /dev/sdb1 /mnt/bootswapon /dev/mapper/VG_0-swaptimedatectl set-ntp truevim /​etc/​pacman.d/​mirrorlistpacman -Syypacstrap /mnt base base-devel linux linux-firmware man-db man-pages iwd lvm2 dhcpcd vim systemdgenfstab -U /mnt &gt;&gt; /mnt/etc/fstab arch-chroot /mntln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime/etc/locale.conflocale-gen# 修改/etc/mkinitcpio.confHOOKS=(base systemd ... block sd-lvm2 filesystems)#Initramfsmkinitcpio -P# 安装grubgrub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=grub# 注意要挂载/boot/efi，见上面挂载boot分区那步grub-mkconfig -o /boot/grub/grub.cfg这次useradd -m -G wheel ccpasswd ccnano /etc/sudoers在 root ALL=(ALL) ALL 下面添加用户名 ALL=(ALL) ALL为你刚才创建的用户 添加sudo权限pacman -S xorg-serverpacman -S i3-wm# useradd的用户无法启动时, 安装一下这个, 创建一下自己这个用户的配置文件就好了.pacman -S xorg-xinit复制 /etc/X11/xinit/xinitrc 到～/.xinitrc。注释掉文件后面的最后的以下几行。twm &amp;xclock -geometry 50x50-1+1 &amp;xterm -geometry 80x50+494+51 &amp;xterm -geometry 80x20+494-0 &amp;exec xterm -geometry 80x66+0+0 -name login然后添加i3启动命令exec i3sudo pacman -S i3sudo pacman -S wqy-microhei adobe-source-code-pro-fonts# i3 Error: Status_command not found (exit 127) : linuxmint[\\(1\\) i3 Error: Status\\_command not found \\(exit 127\\) : linuxmint](https://www.reddit.com/r/linuxmint/comments/3f9k9s/i3_error_status_command_not_found_exit_127/)pacman -S i3status#HIDPI[HiDPI \\(简体中文\\) \\- ArchWiki](https://wiki.archlinux.org/index.php/HiDPI_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)#%E9%9D%9E%E6%95%B4%E6%95%B0%E5%80%8D%E7%BC%A9%E6%94%BE%E4%B8%8B%E7%9A%84Bug)Simplified appliance containg one one-linereval $(cvt 2220 1250 60 |sed 's/Modeline/xrandr --newmode /g'|sed -n '1!p')as a proper result resolution screen size aspect ratio might be afterwards reevaluated/adjusted, therefore find out the created resolution by xrand command - appended in the end of output,1) assign the resolution to a specific display -xrandr --addmode VGA-1 \"2224x1250_60.00\"2) output the desired resolution on the displayxrandr --output VGA-1 --mode \"2224x1250_60.00\"To list all installed shells, run:$ chsh -lAnd to set one as default for your user do:$ chsh -s full-path-to-shellif [[ ! $DISPLAY &amp;&amp; $XDG_VTNR -eq 1 ]]; then exec startxfiyay-git.gitmakepkg -si# 配置dhcpcd自动systemctl enable dhcpcd退出startx方式win+shift+e退出桌面, 这个方式好像会卡住, 输入不来哦东西. 按照这个终于过了. Arch Linux (UEFI with GPT) 安装 | 沈煜的博客 ArchLinux图形界面安装与美化：i3+polybar_盐焗咸鱼的博客-CSDN博客_archlinux安装i3桌面 ## 安装vmware VMware (简体中文)/Installing Arch as a guest (简体中文) - ArchWiki systemd-boot和 grub systemd-boot和EFISTUB - 知乎 ### boot manager可以看到有我新建的grub, 但是EFI似乎没法直接从硬盘启动? UEFI启动 /etc/locale.gen ### UEFI和 grub什么关系? 似乎我的/boot分区划分出问题了, efi无法找到s 并不是EFI分区, 导致bootctl无法识别了. bootctl status可以帮助判定 [SOLVED] EFI partition not detected / Installation / Arch Linux Forums grub-install –target=i386-pc /dev/sda 用legacy就尅引导了 用uefi的反而麻烦, 必须分区时gpt符合efi的 分区lvm Installation guide - ArchWiki lvm不能直接被引导? boot分区独立分区的意义? 创建出来之后, 从哪里复制内容过来, 好像这个文档里都没有提啊s Partitioning (简体中文) - ArchWiki /boot分区里的内容在哪里呢? 使用过grub-config来往里面生成内容? mkinitcpio -P 似乎也能生成新的initramfs grub-install –target=x86_64-efi –efi-directory=/boot –bootloader-id=grub grub-mkconfig -o /boot/grub/grub.cfg 将已经存在的archlinux迁移到lvm - 知乎 #### initramfs选择? LVM (简体中文) - ArchWiki archlinux安裝手记（Win10+Arch、GPT+UEFI、lvm） - 停止使用的账户 - 博客园 使用 源 123456789sudo pacman-mirrors -c Chinapacman -Syypacman -Syu好像说是命令是pacman -Syyupacman -Qi linuxpacman -Qs 在已安装中查询pacman -Ss 在仓库中查询pacman -R 卸载pacman -Ru 循环卸载系统里不依赖的东西 timeout [Solved] Connection time-out on installation (curl / iPv6 problem) / Installation / Arch Linux Forums 捣鼓了半天, 最后是因为我在Arch里默认开了代理, 代理好像有问题了. 内核异常 卡在loading initial ramdisk There was a kernel update, some element of your initramfs wasn’t successfully built and copied to your bootloader. Generally the output of mkinitcpio shows errors, chroot in and make it again. 执行 12mkinitcpio# 就会报出initramfs的错误. (1) Stuck on Loading initial ramdisk : archlinux 打开调试日志 123vim /boot/grub/grub.cfg# 去除quiet和设置log_level=7,rd.log=all# 奇怪,怎么没生效呢? 通过增加set debug=all和set ignore_log_level=all倒是生效了, 看到了一些代码的执行记录. 但是倒是没看到Error信息 General troubleshooting - ArchWiki 为其他不是当前正在运行的内核创建镜像，添加内核版本到命令行， 可以在/usr/lib/modules目录查看支持的内核版本. 12# mkinitcpio -p linux就会以当前安装的linux版本对/boot目录下的initramfs-linux.img进行再次生成了. 捣鼓了2天, 换了个稳定版的内核就正常开机了. 周期内核升级 1234567pacman -Sy linux-lts# 下面这个似乎只生成当前运行的内核的initramfs, 如果要生成指定, 需要指定preset mkinitcpio -P# 指定内核版本生成? grub-mkconfig -o /boot/grub/grub.cfg terminal i3-sensible-terminal 网络 systemd-networkd 禁用ipv6 net.ipv6.conf.all.disable_ipv6 = 1 输入法 kde最稳妥 可以和i3结合? bspwm 桌面:i3wm 毫无疑问,我主要感兴趣的点就是能够尽量完全使用键盘来控制的方式. $mod + Enter 启动虚拟终端 $mod + A 焦点转义到父窗口上 i3lock 歧义性好严重…没有看到输入密码的框, 原来是因为默认就处在接收密码的状态下, verifing和wrong的状态就是密码验证的结果… ### 登录桌面[deprecated] 最后因为vmware里似乎X11的直接配置没能配置生效, 导致sddm始终分辨率都是800x600, 我最后还是选择使用.xinitrc来调用xrandr修改分辨率 1234567891011pacman -S sddmsystemctl enable sddm #vim /etc/sddm.conf.d/hidpi.conf# 虽然我通过`pacman -Ql sddm`查到我装的位置是在`/usr/lib/sddm`里[Wayland]EnableHiDPI=true[X11]EnableHiDPI=true urxvt rxvt-unicode 不知道这个好不好用 (1) Which terminal simulator do you use with i3, and why? : i3wm urxvt 要支持hidpi, 还需要一些特殊配置. 先这样用吧. 已经挺好了. 图片和壁纸 feh feh feh –bg-scale new.jpg feh (简体中文) - ArchWiki HiDPI[^7] 看起来多屏高分屏支持有点费事, 暂时还是不捣鼓了. xrandr –output eDP-1 –auto –output DP-1 –auto –scale 2x2 这个的scale 和那个~/.Xresources的Xft.dpi=192区别? 是不是xrandr修改了dpi之后, 修改指定程序的字体大小就行了? xrandr --dpi这个好像是xft.dpi的更新的方案 这个设置了以后, 标题栏的确hidpi了, 但是应用程序并没有, 不管是Terminal还是chrome. .Xresources[^8] Xft.dpi: 141 xrdb ~/.Xresources xrdb -merge ~/.Xresources xrdb -query -all 最后成功版本[^9][^10] 最后其实还是按照wifi操作成功的. 我在 .xinitrc中添加xrandr –output Virtual-1 –mode 2560x1600 在.Xresources中添加 1234Xft.dpi: 256export GDK_SCALE=2export GDK_DPI_SCALE=0.5export QT_AUTO_SCREEN_SCALE_FACTOR=1 这次重启之后终于终端字体大小什么的都对了. 远程控制: x11远程和本地渲染不同? 我看到的窗口和颜色不太一样啊,vnc manjaro 先用i3试试. i3wm 使用 [^4]可以看. 不配置de还挺舒服的. 程序启动器 dmenu 和dmenu-manjaro冲突 Wayland仍未成熟 目前来看,虽然Wayland还是在逐渐开发, 不过Xorg的成熟度还是远比其成熟, Wayland存在的问题稍多. Sway 等价于i3wm的管理器,不过这个没能做到i3polybar的程度, 而且也始终是存在部分问题的. 所以如果要用arch, 还是继续Xorg下吧. 驱动 【openSUSE】软件源和软件搜索 --- 看了之后 受益匪浅 - 孙愚 - 博客园 Reference Installation guide - ArchWiki i3 (简体中文) - ArchWiki Manjaro-architect 安装指南_兴趣斗士的博客-CSDN博客_manjaro architect i3: i3 User’s Guide xps13(9370) Linux之路 · Kevin的笔记 screen lock / verifying : i3wm Linux 下， hipdi 高分屏外接显示器显示怎么整啊？ - V2EX 安装xdpyinfo在Linux Xresources中设置正确的屏幕DPI-教程-Linux系统学习 HiDPI - ArchWiki Fixing HIDPI on a bare i3 install (in Arch Linux btw)","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"arch","slug":"arch","permalink":"https://sean10.github.io/tags/arch/"},{"name":"laptop","slug":"laptop","permalink":"https://sean10.github.io/tags/laptop/"}]},{"title":"高铁站的技巧小记.md","slug":"高铁站的技巧小记-md","date":"2020-12-20T16:51:21.000Z","updated":"2020-12-20T17:11:07.182Z","comments":true,"path":"2020/12/21/高铁站的技巧小记-md/","link":"","permalink":"https://sean10.github.io/2020/12/21/高铁站的技巧小记-md/","excerpt":"","text":"背景 最近难得的出差去了一次杭州, 到了高铁站才用高德打车, 结果因为不知道该从什么地方去找师傅, 第一个打车的师傅说找不到这个地址, 只好取消, 换个试试能不能遇到对路线比较熟悉的师傅. 后来,稍微问了问这个比较熟悉录下你的师傅一些火车站的技巧. 顺便把以前常走的火车站的一些也给记录一下. 通用 要打车又不熟悉上车地点的时候, 可以提前预约, 接预约订单的师傅相比接马上上车的师傅要对火车站的路线要熟悉得多一般. 有时候晚上7点以后的火车没什么人, 但是目前还是没找到完全的规律, 这次同样也是晚上7点的火车, 但是人就坐满了. 上海虹桥 一般情况下, 检票口离1号检票口比较近的话, 坐地铁的时候可以直接坐到虹桥机场的地铁站下, 然后从这边往火车站方向走, 还可以有步道加速, 相比从火车站上楼再从25-26检票口走过去要省力一些. 北京南 地铁站下车直接上京沪快速进站口, 不用上出发层去候车了. 一般2分钟就可以从地铁出口上火车. 不过在非春运期间, 晚上6点就关门了. 另外疫情期间似乎也停止提供服务了, 不过我记得国庆的时候还是有提供服务的, 这块就不太懂了. 杭州东 出站往滨江方向打的车，一般推荐p5和p6停车场上车, 从火车出站口直接两边上楼，p5对应的是18号电梯，p6停车场是19号电梯，大部分司机都应该知道这两个停车场. 杭州东站的南广场和北广场都会有上车地点 北京到杭州飞机 延误 ，航空管制比较多，因为有会议导致航空管制 滨江到萧山机场倒是不会堵, 因为那个方向不会有什么人. 时间上从滨江去萧山机场和去杭州东火车站是一样的 滨江到火车站这条高架, 早上上班时间去滨江堵，下午回东站方向堵，跟工作时间一致 虽然有火车站到滨江的地铁直达，但是要从西湖边绕一圈，所以也要半小时以上 礼拜天滨江往市区(即火车站方向)走的高架会堵死，听说是下午2，3点过后开始会堵","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"高铁","slug":"高铁","permalink":"https://sean10.github.io/tags/高铁/"}]},{"title":"ceph之编译时python3.6m符号表错误","slug":"ceph之编译时python3-6m符号表错误","date":"2020-12-02T06:22:56.000Z","updated":"2020-12-02T17:19:09.026Z","comments":true,"path":"2020/12/02/ceph之编译时python3-6m符号表错误/","link":"","permalink":"https://sean10.github.io/2020/12/02/ceph之编译时python3-6m符号表错误/","excerpt":"","text":"今天在编译ceph时, 发生了libpython3.6m.a: could not read symbols: Bad value的问题, 在这附近有一个疑似相关的具体符号表的提示. 1/usr/binld: /usr/lib/python3.6/config-3.6m-x86_64-linux-gnu/libpython3.6m.a(abstract.o): relocation R_X86_64_32S against `_Py_NotImplementedStruct` can not be used when makeing a shared objectl recompile with -fPIC 第一感觉看上去的意思是ceph编译时尝试去链接的静态库的符号表没有通过-fPIC的方式生成,从而完成共享库代码段复用的功能. 但是回忆一下这个问题发生的背景, \b如果我用的是同一套yum源安装的依赖, 理论上python出现小版本不兼容的可能性较低. 那么, 就存在一个可能性, 这个报错链接找到的库并不是yum源里安装的, 可能是同事通过\b源码编译安装的python的库. 通过rpm -qf /usr/lib/python3.6/config-3.6m-x86_64-linux-gnu/libpython3.6m.a查到这个库并不是\b安装的, 验证了我的猜测. 而rpm -qf /usr/lib64/python3.6/config-3.6m-x86_64-linux-gnu则发现这里的文件才是python36-libs里提供的. 既然如此, 就将/usr/lib下的这个版本错误的库挪走, 重新编译, 这次报的是-lpython3.6m未找到. 查看/usr/lib64/libpython3.6m.so发现这个文件并不存在, 只有/usr/lib64/libpython3.6m.so.1.0存在,而软链并不存在. 通过rpm -ql python36-libs发现的确这个包中并不提供指向的链接. 根据目前对包管理的理解, 怀疑这个缺失的指向真实文件的软链很有可能在python36-devel包中, 安装后果然如此, 链接找到了. 执行编译, 毫无问题了~ 引申的疑问 因为目前出现的python3.6m.so这个库的疑问, python3-libs这个库里没有提供指向.so的链接, 而是在python3-devel包中存在 而python34则都是在python34-libs里. 但是python36应该是能够正常使用的吧? 那是不是其实可以作答哦这样一点, 如果编译时我指定了链接, 然后在符号表中, 他就能找到针对这个链接指向的真实路径 ,然后存起来. 到生产环境里, 如果这个路径中存在, 就不需要ldconfig的默认路径了呢? 会不会有这个选择呢? 还是说这个libpython3.6m.so这个库基本只会在编译C与python之间的库时使用,而且只编倾向于静态的? 然后这样编完到生产环境里就不需要了呢?","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"编译","slug":"编译","permalink":"https://sean10.github.io/tags/编译/"},{"name":"CentOS","slug":"CentOS","permalink":"https://sean10.github.io/tags/CentOS/"}]},{"title":"CLI转为http服务小探","slug":"CLI转为http服务小探","date":"2020-12-01T17:29:22.000Z","updated":"2020-12-01T17:29:49.976Z","comments":true,"path":"2020/12/02/CLI转为http服务小探/","link":"","permalink":"https://sean10.github.io/2020/12/02/CLI转为http服务小探/","excerpt":"","text":"背景 需要将现成的CLI转换为web服务的HTTP接口. 这个我记得之前看到哪篇文章推荐过, 但是一时想不起来了 想了想关键词 CLI command line http server web 终于把web这个带上之后, 用CLI to web server终于搜到一个相近的 w2c 这个python 程序 dongyx/c2w: convert CLI programs to Web services 然后用这个里的描述, google终于找到了相似语义的, 我少了program, 导致CLI应该被理解成了终端输入参数的web服务, 也就是常见的web服务… converts a CLI program to a Web service The Return of the CLI: CLIs Being Used by API-Related Companies | Nordic APIs | 初看没看懂 How can I convert my console application to a web service using visual studio 2013 - CodeProject hhh, 一个咨询解决方案的, 问题一致. 只不过我实现了一套, 现在想看看有没有更好的实现方案 adamkewley/jobson: A platform for transforming command-line applications into a job service. 这个东西似乎是转换成任务, 结果不知道有没有返回的地方 (1) [FOSS] Convert any command line tool/service into a asynchronous REST API. [Python] : linux 又拿到一个关键词, shell2http Eshaan7/Flask-Shell2HTTP: Execute shell commands via HTTP server (via flask’s endpoints). adnanh/webhook: webhook is a lightweight incoming webhook server to run shell commands 这个比较牛看起来, Star特别高, go实现 The Tech Feast: Expose Any Shell Command or Script as a Web API bash2http, 和上面的shell2http差不多 shell 2 http remote sh这个工具看起来也不错, 只是在页面填写bash 脚本, 然后指定服务器执行, 等同于web终端的感觉. command web server expose shell scripts as web services 又一个关键词 API lukasmartinelli/nigit: Web server that wraps around programs and shell scripts and exposes them as API wrap command to http API phonkee/goexpose: Expose shellscripts, postgres queries, redis commands and other as rest server endpoints 上一个开发者不维护了, 推荐用这个 Andreweweith/Web-Based-Remote-Command-Server: Web server and interface to remotely execute Linux shell commands and display the results 这个是C实现的一个http上输入命令底层执行,然后返回结果的那种. bytestream/Web-Server: During my time at the University of Miami whilst studying CSC524 - Computer Networks I was also asked to build a basic web server using pure C. The web server can be used to process GET and POST requests whereby GET requests will serve a static file and POST requests with the addition of POST data will execute the file as if it were CGI and pipe the output back to the client. Again for security reasons it only serves files in the current working directory, and will also only execute shell programs. 别人的一个大作业的成果.也是C实现的一个把shell通过API暴露. dotnet/command-line-api: Command line parsing, invocation, and rendering of terminal output. .Net实现的, 感觉我的实现架构比较贴近这个 wrap command to http API Soaplab2 看起来有点像需求的? Genivia - Getting Started with C/C++ XML Data Bindings and XML SOAP/REST Web Services gsoap使用总结 - 苦涩的茶 - 博客园 WebService服务基本概念：就是一个应用程序，它向外界暴露出一个可以通过web进行调用的API，是分布式的服务组件。本质上就是要以标准的形式实现企业内外各个不同服务系统之间的互调和集成。 所以以前其实这个实现形式叫做webservice. 只是我们不止是函数, 包括命令. 所以这里其实针对静态语言以前的思路是实现一个DSL, 然后基于编写的DSL生成可编译的代码, 然后再编译出可执行程序, 对, 针对静态语言,其实这也是个思路, 使用yacc等词法分析器? How to wrap a C library so that it can be called from a web service - Stack Overflow 这里也提到了soaplib mod-xmlrpc2 webservice command webservice c# - Consuming Web Service from C++/CLI - Stack Overflow emm. SyBooks Online proxy 忽然想到, proxy其实和wrap在这个场景里是同义词. 小结 所以根据上面的思路来看 流程 初始化 解析配置文件, 其中包含CLI或函数对应的API路由 \b\b\bdecoder\b解析http协议 dispatch根据路由转发, 路由注册 \b\b\b\b\b进入函数或传入命令参数进行执行 可能有前置处理参数逻辑, 一般定制性需要强一些 后置输出格式处理逻辑等 encoder协议拼装返回 思路 针对支持运行时元编程能力的语言(如python, go), 和我实现思路基本一致, 编写一套配置或叫做DSL, 运行时加载然后动态生成函数等. 针对不具有上述能力的语言, 有两种思路 参数传入, 核心调度逻辑的函数基本只有一个 如果是CLI, 则作为参数传入, 有一个统一system调用的函数封装 如果是前置和后置逻辑需要用函数处理, 则像下面一样用字符串找到符号表里的函数指针. 如果是函数, 我想的就是通过动态库的dlysm或者libeffi来根据配置中填写的函数名, 去进行调度. 编写一套DSL, 在进入编译前, 根据编写的DSL生成一套代码, 这样就支持各式各样的函数了, 就是定制性维护可能代码量膨胀的较快? gsoap和soaplib应该是这套思路吧, 好像有点像是10年前的思路, 看snmp代码的时候也是这种思路, 从mib生成代码. 这个的实现方式应该就多种多样了.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"CLI","slug":"CLI","permalink":"https://sean10.github.io/tags/CLI/"},{"name":"http","slug":"http","permalink":"https://sean10.github.io/tags/http/"},{"name":"system","slug":"system","permalink":"https://sean10.github.io/tags/system/"}]},{"title":"代码分支模式初探","slug":"代码分支模式初探","date":"2020-11-15T16:27:24.000Z","updated":"2020-11-15T16:27:43.399Z","comments":true,"path":"2020/11/16/代码分支模式初探/","link":"","permalink":"https://sean10.github.io/2020/11/16/代码分支模式初探/","excerpt":"","text":"背景 最近公司里多项目并行的时候, 发现在以前组管理的感觉比较混乱的分支方式(多个项目并行的时候, 同一个组件的代码需要维护多套分支)居然其实算是一个比较好的实现了… 这里的分支反而更加混乱. 索性梳理一下分支到底应该怎么管理, 才是最佳实现. 下面这部分是我目前的理解. 分支的场景 据我目前接触到和理解的, 会有以下几种常见的场景. 考虑到这里主要的障碍在于分支管理, 暂时假设一个组件的维护人员就是一人, 暂时跳过多人维护一个组件情况下的merge障碍问题(其实这块也比较要求模块设计的解耦, 多人改同一段代码这种情况本就不好合并, 我的理解是从设计上尽量避免对同一行冲突的修改). 根据[^6]中可知, 良好的模块化基本不会遇到代码分支带来的相同行修改的隔离问题. 一个分支对应一个项目, 包含多个组件的并行开发 多个分支对应多个并发项目面向不同业务场景, 同一套组件 一个项目对应多个组件分支, 各组件并行开发 多个组件对应多个主分支, 多个项目再各自开出对应的项目分支 上面几项中, 公共组件在多个项目中的使用 项目中只是用公共组件的发布版本 公共组件维护一个私源库, 每次迭代发布一个版本. 发布后的缺陷通过更新patch, 更新rpm包等形式, 如果各项目有涉及缺陷, 使用最新的组件包更新即可. 优点: 独立性强, 不需要因为业务项目拉出分支, 也进行项目拉出 缺点: 组件调试不便. git subtree 将一个目录自动提交到多个项目分支中的同一个组件目录下 个人只处理一个分支,但是实际上项目有多个分支. 这个感觉是一个比较好的处理手段. 独立分支维护 为了避免其他使用者对公共组件更新的感知不及时, 可以通过webhook等方式进行通知 依赖第三方组件如何管理问题 是单独维护一个分支用来记录使用的库及其版本的下载路径 还是直接把库提交到分支中. 版本发布模式 项目制发布模式: 项目制发布模式, 预先确定功能特性, 在所有功能开发完成后进行版本发布 发布火车模式: 大型套装分发类软件, 各部门之间互相依赖, 约定版本发布的时间 城际快线模式: 固定版本发布时间和质量维度, 时间较短 我理解, 项目制和发布火车模式有点相近. 都是约定一个集成时间, 开始各功能提交进行集成. 而城际快线就是高频集成的持续集成模式那种吧.敏捷开发?因为高频集成, 所以重构代码带来的代价也少, 这种比较贴合代码架构变更频繁的场景倒是. 分支管理的\b用途 一个长期稳定迭代的基线分支 这个分支只有当项目发布完毕时才合入代码. 项目进行中的不稳定的开发分支 这个分支在项目开启时,从基线拉出 项目发布后的缺陷修复所需提交的分支 定制项目的一些特殊需求无需合入基线. 潜在的问题 当一个项目开发中时, 开启了另一个项目, 需要用到目前正在第一个项目的分支中开发的功能 是否应该从项目分支再创建一个分支呢? 还是从基线拉出分支, 然后再从当前正在开发的分支合并功能代码过去呢? 根据现在的理解, 这个选择更合适, 分支统一从基线拉出, 这种分支流图更合理. 当一个功能即将开发完毕时, 但是由于对接方面的人时间计划来不及处理了,他的功能没有上车,这样的话, 对于我们的代码应该怎么处理呢? 我的理解是git的话可以在本地或是自己的一个branches里提交, 然后等到需要合并时, 再合入项目分支 或者可以通过stash暂存区来处理这个问题. 如果是svn, 是不是就只能注释这部分代码了呢? 似乎也可以像git一样, 创建一个自己的分支先提交, 但是这样的话, 如果每个人都有创建的分支的权限的话, 似乎就会比较混乱了把? 但是似乎这个也算是一个比较好的实现了. 毕竟不像git有约定的特性分支, 只能自己拉自己的特性分支了. 公司研发了一套svn插件, 导致通过git-svn来完成本地使用git这个逻辑不太可行. 代码合并的最大成本主要是在于工具吗? 并不是, 是在于开发时, 是否考虑过和基线的兼容性问题, 基线理论上除了缺陷, 不应该有其他的操作合入 通用思考 从主分支里拉了一个新分支出来，在合并回主分支之前，必须持续地把主分支的更改尽早尽快合并到新分支。新分支永远保持 最新主干代码+新模块代码 的状态。 其实的确是对的, 如果基线修改了, 那么就应该尽快把基线的一些修改合并到你当前的分支中去, 避免将来无法合并 因为你merge代码的时候，用BC除非没有冲突的文件，只要有add和delete操作的文件你都要逐个逐行进行处理啊，更别提有冲突的文件了。用git做merge无冲突文件且版本号高于master分支就自动帮你解决了，你只需要解决冲突就行； git合并分支容易的原因是，要经常和master分支merge，这样把冲突消灭在萌芽状态。 git可以合并commit到一个后来被修改过的文件&gt; Git可以修改和重构历史提交：使用Git本身的reset以及 rebase 命令可以修改或者重整/重构历史提交，非常灵活。使用强大的 stg 可以使得历史提交的重构更为简洁，如果您对 stg 或者 Hg/MQ 熟悉的话。 大厂文章 美团单周迭代 定期需求评审 多版本多需求并行开发(在需求分支内开发) 分支 release分支 立项时从stage分支拉出 成果物从这个分支构建. 发版后合入到Stage分支. 其他开发中的分支也合入该分支的最新代码 stage分支 承担稳定的代码功能的归档 通过jenkins job来完成分支的管理 git代码分支模型 git flow 基线分支只合稳定以后的功能 各项目的dev分支, 存放满足需求的feature的开发, 稳定后打tag, 合回基线 release分支, 从dev拉出, 包含所有功能, 处理发布所需, 完毕后打tag合回基线及dev分支 hotfix分支, 修复后, 合入到上述所有分支 优劣势 流程清晰 管理严格 长期分支的同步开销较大, 不适合快速发布 github flow 只有master分支, 只有部分管理员有提交权限, 其他人通过在自己分支完成功能后提交PR, 通过评审和自动化测试进行兜底 各feature及缺陷修复分支 优劣势 分支简单, 适合快速迭代 不适合多环境多版本项目并行产品 gitlab flow 似乎和git flow有点类似, 多出了production, release等分支? TBD flow(Trunk Based Develop) 开发及缺陷修复基于trunk, 只有快速发布, 完全没有分支管理 TBD++ flow 基于功能的主分支 trunk和feature分支需同步更新 trunk分支有自动化测试自动执行 基于发布的release分支 release分支发布后打Tag, 但依旧长期运行, 如果发现缺陷, 往这个分支及master分支合入缺陷修复, 这个发布分支打新的tag Reference Git代码分支管理模型 - 简书 (18 条消息) git合并分支，为什么会比svn容易？ - 知乎 一个 Git 分支协作模式的进化故事 – Gitee 官方博客 客户端单周发版下的多分支自动化管理与实践 - 美团技术团队 【读书笔记-017】持续交付2.0之集成分支策略 - 简书 Martin Fowler三万字解读源代码分支管理模式_ITPUB博客 (18 条消息) Git 相比 svn 和其他版本管理工具的核心优势有哪些？ - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"git","slug":"git","permalink":"https://sean10.github.io/tags/git/"},{"name":"版本管理","slug":"版本管理","permalink":"https://sean10.github.io/tags/版本管理/"},{"name":"svn","slug":"svn","permalink":"https://sean10.github.io/tags/svn/"}]},{"title":"文件系统概念初探","slug":"文件系统概念初探","date":"2020-10-18T13:38:26.000Z","updated":"2021-01-31T17:22:32.798Z","comments":true,"path":"2020/10/18/文件系统概念初探/","link":"","permalink":"https://sean10.github.io/2020/10/18/文件系统概念初探/","excerpt":"","text":"todo 为什么文件系统不默认提供每个目录的空间使用量呢? 多文件系统嵌套, 还是需要用户自己去df挂载的位置里去找所在目录在哪个分区里, 然后分区大小多少, 为什么不能直接显示出当前目录使用量及这个文件系统根的容量呢? subvolume btrfs子文件系统支持 说到这个,df默认为啥没有什么超时机制呢?卡在显示所有上? 可能df只提供基本查询, 自己有超时需求自己处理? 文件系统配额, 如果不开启的话, 怎么知道这个文件系统究竟有多少空间可以用呢? 文件系统写满时, 到底是哪层做的错误返回? 分配器提供的吧? 所以对于分布式块设备上建的文件系统, 得是支持扩容的文件系统? 文件系统\b\b中的原子事务如何实现? 幂等性如何保障 extent技术 隐藏的预留容量, 超级块 与块设备相比 问题原因 * 如何找到你想要的信息 * 如何保证一个用户不会读取另一个用户的数据 * 如何得知哪些块是空闲的, 等等 文件是上面这些问题的抽象解决. 文件系统概念[^3] 主要为存储设备提供一致的访问和管理方式. 数据以文件的形式存在 文件以树形目录进行组织. 较为复杂, 扩展性相比现在新增的对象存储较差一些.(各公司自研的应该还好) 文件系统的复杂性导致可扩展性未能跟上互联网的高速发展, 极大简化了的对象存储及时填补了空确. 不过因为对象存储缺乏树状结构, 也不支持原子重命名操作, 跟文件系统差异较大. 文件系统架构对比[^3] 多文件系统关联 挂载时 分配一个新的inode指向新的文件系统的data block. 挂载完成后，将在/proc/self/{mounts,mountstats,mountinfo}这三个文件中写入挂载记录和相关的挂载信息，并会将/proc/self/mounts中的信息同步到/etc/mtab文件中，当然，如果挂载时加了-n参数，将不会同步到/etc/mtab。[^3] FUSE 用户-内核通信协议 splice 零拷贝技术 内核FUSE队列 缓存写回 实现 文件系统布局 引导块 超级块 文件系统的大小 文件系统中的数据块数 指示文件系统状态的标志 分配组大小 空闲空间块 bitmap位图 bit vector 位向量 链表 #### 碎片 #### inode ### 分配 思想 有效利用文件空间 快速访问文件 #### 连续分配 CD-ROM 满的时候, 标记-1之类的. #### 链表分配 随机访问难 #### 使用内存表进行链表分配 引入索引的概念 FAT(File Application Table) 整个链表都在内存中, 表占用空间较大(1T盘 1KB的块, 需要至少3-4个字节的管理, 需要3GB左右的内存) 满的时候, 直接链表最后断开就行了. #### \binode 只有文件打开时, inode才在内存中, 解决FAT的问题 inode在初始化文件系统时就给定了, 多大的块设置一个inode. 128字节整数倍 /etc/mk2fs.conf inode_ratio, 多大的块分配一个inode号 ext4预留了inode用于比如/proc/, lost+found 问题: 文件知道自己的inode之后, inode存储了什么东西,可以让他找到对应的所有块? [^3] inode中保存了块的文件指针 ext2/ext3 最多15个指针, 前12个直接寻址, 第13-15个分别一级,二级,三级间接寻址 一个4K block可以放4096/4=1024个指针. 即1024^3+ 1024^2 + 1024^1+12 = 1.1G个块指针, * 4K= 4T左右的大小 ext4 使用了extent的方案 满的时候, 最后一个磁盘地址不指向数据块, 而是指向一个包含额外磁盘块地址的地址 ### 目录的实现 ### 共享文件 有向无环图 硬链接 软链接 问题: 复制时如果不对符号链接进行区分, 会带来重复写入问题 日志结构文件系统(Log structured File System, LFS) 性能问题 背景: 不断增长的内存 顺序I/O强于随机I/O 现有低效率的文件系统 文件系统不支持RAID(虚拟化) 由于Page cache存在, 读性能基本不是问题 数据结构 Inode Inode Map Segment Segment Usage Table ### 日志文件系统 防止掉电/崩溃问题 幂等性 引入原子事务 虚拟文件系统 VFS 对用户进程的上层接口POSIX接口 下层接口, 各文件系统提供的. vnode 文件系统的管理和优化 磁盘空间管理 分段管理 分页管理 #### 块大小 #### 记录空闲块 位图(bitmap) 磁盘块链表 问题 在内存中保留一个半满的指针块, 这样既处理文件的创建和删除, 又不会为空闲表进行磁盘IO 磁盘处理一些列临时文件, 不需要进行任何磁盘IO 磁盘配额 硬限制 软限制 用于实现警告和用户权限控制的计数 ### 文件系统备份 场景 从灾害中恢复 从错误的操作中恢复 删除-&gt;回收站 设计 备份整个文件系统还是只备份一部分文件 增量转储 压缩 备份过程中出错, 压缩文件是直接损坏还是可以纠正? 正在使用的文件系统如何备份 设置时间点? 瞬时快照 物理转储和逻辑转储 物理转储 全量备份 坏块转储 逻辑转储 维持一个inode为索引的bitmap, 修改过的文件被标记 空洞问题的处理 ### 文件系统的一致性 因为系统调用并不是原子事务的, 写操作复杂, 完全存在不一致可能性. fsck sfc(windows) 块的一致性检查 文件的一致性检查 空闲块和已使用的块的表的对照 块丢失(missing block) 块重复 空闲表中重复 直接标记就行 不同文件使用了这个块 分配一个磁盘快, 把他插入到文件里, 比如文本文件打开中, 出现掉电, 中间插入乱码是不是就是这个做法? 已使用和空闲表中均出现(就是删除过程只执行了一半) 应该也是优先分配一个新块, 插入到文件里 检查目录系统, 维护计数器表 检查inode数量与目录的关系 文件系统性能 高速缓存 block cache buffer cache 逻辑上属于磁盘, 实际通过内存来提供支持 页面置换算法 块提前读 考虑顺序读取, 进行预读取 好像在磁盘驱动那层也有这个设计? 所以其实多层都提供了这样的功能? 减少磁盘臂运动 块簇 以连续块簇来跟踪磁盘存储区. 分配时尽量分配在同一个柱面上 解决一个连续内容被分配在2个柱面上带来的寻道次数翻倍 读文件至少2次磁盘访问 访问inode 访问块 原本inode放在磁盘开始位置, 所以inode到块的平均距离是柱面组的一半 改到中间 磁盘碎片整理 删除文件, 回收磁盘块. defrag, 移动文件, 使空闲块连续分布 ext2/ext3选择磁盘块的方式, 导致不怎么需要处理磁盘碎片整理[^2] 日文件系统分配策略上并不完全连续分布 ext的延迟写入技术 主要是FAT 文件 文件命名 名字 unix 大小写敏感 MS-DOS 大小写不敏感 扩展名 unix 无感知 但是目前是不是也像window一样了 windows 能够在操作系统层面设置不同扩展名对应的程序 文件结构 目前都是字节序列, 用使用者自己进行定位. 这样的话其实和操作裸块也有点像吧? 的确 不知道有没有采用树等结构化关系的, 感觉更适合更上层的应用自己抉择. 文件类型 文件 由内核处理 目录 字符特殊文件 串行I/O设备 块特殊文件 由设备驱动程序处理 操作系统至少能识别自己的可执行文件. 所以文件系统和操作系统还是有一些绑定关系的? 文件访问 文件属性 文件操作 create delete open close read write append seed get attributes set attributes rename 目录 一级目录系统 根目录 层次文件目录 路径名 目录操作 create delete opendir closedir readdir rename link unlink FUSE支持 Reference 简直不要太硬了！一文带你彻底理解文件系统 - 程序员cxuan - 博客园 (80 条消息) 为什么NTFS系统容易产生碎片而ext系列则不会？ - 知乎 ext文件系统机制原理剖析 | 骏马金龙 分布式文件系统架构对比-InfoQ 分布式文件系统浅谈 - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"存储","slug":"存储","permalink":"https://sean10.github.io/tags/存储/"},{"name":"文件系统","slug":"文件系统","permalink":"https://sean10.github.io/tags/文件系统/"}]},{"title":"ceph之clion的cmake.md","slug":"ceph之clion的cmake-md","date":"2020-10-17T06:43:31.000Z","updated":"2021-01-03T09:13:59.521Z","comments":true,"path":"2020/10/17/ceph之clion的cmake-md/","link":"","permalink":"https://sean10.github.io/2020/10/17/ceph之clion的cmake-md/","excerpt":"","text":"调查 按照一般的编译过程, 是可以在CentOS或者Debian系的环境里直接执行do_cmake.sh然后自动安装install-deps.sh, 然后关闭一堆功能触发cmake的. 不过因为暂时没找到可以进行环境隔离比如通过在docker内编译ceph(初步尝试, deps中出现了systemd, 而docker内使用使用的一个fake-systemd, 这俩产生了冲突, 不知道有没有专门针对docker做的一个fake版本), 从而绕过弄坏OSX宿主机的依赖的风险的. 在这个安装依赖的脚本中是有针对freeBSD的pkg安装命令的, 但是和目前主流推荐的brew还是不一样的, pkg还是给服务端使用为主. 怕产生污染, 所以我暂时选择手动来处理这个依赖的问题. 当然, 如果有远程服务器, 可以利用remote develop, 通过服务器编译也能把成功建立索引. docker调试用运行 vstart.sh ceph/daemon[^9] 根据[^11]的image的build仓库来看, 这个docker也是可以来触发编译的? make CEPH_DEVEL=true FLAVORS=“luminous-12.2.13,centos,7” build 单看这个脚本, 看起来可以编出来的样子. make CEPH_DEVEL=true FLAVORS=“nautilus,centos,7” build 这里为什么这个版本的centos里装的是真实的systemd?, 我之前拿官方的centos的image就是fake-systemd呢… 搜了下, 用fakesystemd是为了cgroup与宿主机的隔离. 手动卸载再安装其实也是可以的. 不对, 这个镜像里是直接配置的yum install -y ceph-mon等…不是编译出来的… 自制Docker调试 1docker run -itd --name centos-test centos:centos7 opensuse ceph-dev-docker [^12], 这个是opensuse的. 123456789101112131415161718192021222324252627282930313233343536#src.rpm 12.2.13docker run -itd \\ -v /Users/sean10/Code/ceph/ceph-12.2.13:/ceph \\ -v /Users/sean10/Code/ceph/ceph-ccache-12.2.13:/root/.ccache \\ -v /Users/sean10/Code/ceph-dev-docker/shared:/shared \\ --net=host \\ --name=ceph-dev \\ --hostname=ceph-dev \\ --add-host=ceph-dev:127.0.0.1 \\ ceph-dev-docker# luminous版本docker run -itd \\ -v /Users/sean10/Code/ceph/ceph-14.2.9:/ceph \\ -v /Users/sean10/Code/ceph/ceph-ccache-14.2.9:/root/.ccache \\ -v /Users/sean10/Code/ceph-dev-docker/shared:/shared \\ --net=host \\ --name=ceph-dev \\ --hostname=ceph-dev \\ --add-host=ceph-dev:127.0.0.1 \\ ceph-dev-docker# nautilusdocker run -itd \\ -v /Users/sean10/Code/ceph/master/ceph:/ceph \\ -v /Users/sean10/Code/ceph/ceph-ccache-branch-luminous:/root/.ccache \\ -v /Users/sean10/Code/ceph-dev-docker/shared:/shared \\ --net=host \\ --name=ceph-dev \\ --hostname=ceph-dev \\ --add-host=ceph-dev:127.0.0.1 \\ ceph-dev-dockerdocker attach ceph-devNPROC=4 ./setup-ceph.shdocker exec -it ceph-dev /bin/zsh 通过传给cmake的CMAKE_BUILD_TYPE来确认编译出来的是否携带debuginfo.[^13] Release —— 不可以打断点调试，程序开发完成后发行使用的版本，占的体积小。 它对代码做了优化，因此速度会非常快， 在编译器中使用命令： -O3 -DNDEBUG 可选择此版本。 Debug ——调试的版本，体积大。 在编译器中使用命令： -g 可选择此版本。 MinSizeRel—— 最小体积版本 在编译器中使用命令：-Os -DNDEBUG可选择此版本。 RelWithDebInfo—— 既优化又能调试。 在编译器中使用命令：-O2 -g -DNDEBUG可选择此版本。 默认是RelWithDebInfo, 我给他传了俩参数-DWITH_LTTNG=ON -DDWITH_BABELTRACE=ON python-devel not found. 结论: 看上去是suse的tumbleweed现在的源里没python2的包了[^14]? 而这个仓库里的master分支如果编ceph还没去除python2的版本, 就会有问题. 根据这个来看Re: [opensuse-factory] Removal of Python2 from openSUSE Tumbleweed 高版本的suse把python2彻底抛弃了, 但是是不是也有办法加回来安装呢? 搜了一圈, 主流的思路是这种大版本迭代, 如果始终要考虑老版本兼容性, 始终去兼容python2, 对于开发的迭代并不利, 不如让开源软件去遵循这个规则, 统一进行大版本升级. 这种在商业产品里, 做法已经比较成熟了, 都是软件去适配系统. 只是linux系统在python以前可能没依赖性这么强的类似基础框架组件性质的部分, 所以对于彻底不兼容的软件会相对少一点. hhh, 说到这个, 这种换到公司里的代码开发, 就是为了兼容性, 当单元测试少时, 就不重构, 变成垃圾代码. 而开源的, \b就看开发者的能力了. 好像见到的一般都有大神在把控代码质量的~ 所以理论上其实ceph应该不完全依赖python2了. 我应该通过其他方式去判断是否要编python2相关. 根据不同版本的ceph的install-deps.sh和ceph.spec, 可知mimic和nautilus的版本还没有完全可以免去python2.7, 而Octopus里彻底去除了python2的编译. tmubleweed 的repo路径 Factory 和 Tumbleweed 合并了, 所以直接使用 factory 的源就好. 不过大多数镜像只提供了 repo-oss 和 repo-non-oss 这两个源 https://download.opensuse.org/repositories/openSUSE:Factory/standard/openSUSE:Factory.repo 搜出来显示这个,但是这个路径实际上已经不存在了…不知道怎么给他们提 Install package devel:languages:python:Factory / python Install package devel:languages:python / python-virtualenv openSUSE:Build Service 仓库详解 - openSUSE Wiki 看上去这上面源里的是src.rpm. 咋Search能看到, 就是提示转不上呢? 我先配置上面这个, 给装上去了. 某些疑似镜像源中似乎还有python2的库 Index of /pub/opensuse/tumbleweed/repo/oss/x86_64/ 但是下面这个源里明明也是oss, 但是却有呢? 稳定的Leap 15版本的nautilus编译 123456export NAME=ceph-dev-nautilusexport VERSION=nautilusexport CEPH=/Users/sean10/Code/ceph/ceph-14.2.9export CCACHE=/Users/sean10/Code/ceph/ceph-ccache-14.2.9cd /share/bin/nautilusbash -x ./setup.sh 这个倒是安装成功, 开始触发编译了. 不过中间dashboard的frontend在安装pip时报了点Input/Output Error, 暂时不是重点, 在setup-ceph.sh里设置-DWITH_MGR_DASHBOARD_FRONTEND=OFF, 就可以通过编译了. 就是本地编译有点慢… 12cd /ceph/srcOSD=3 MON=3 MGR=1 CEPH_BUILD_ROOT=/ceph/build bash -x ./vstart.sh -n ccache make -j8 ceph-mon [ 97%] Building CXX object src/mon/CMakeFiles/mon.dir/AuthMonitor.cc.o c++: internal compiler error: Killed (program cc1plus) Please submit a full bug report, with preprocessed source if appropriate. See https://bugs.opensuse.org/ for instructions. make[3]: *** [src/mon/CMakeFiles/mon.dir/build.make:351: src/mon/CMakeFiles/mon.dir/MonmapMonitor.cc.o] Error 4 看着跟OOM的表现有点像. 根据linux - make -j 8 g++: internal compiler error: Killed (program cc1plus) - Stack Overflow这篇说的, 可能是我开的线程太多, 给他分配的内存又没那么多引起的? 我试试 降低以后的确编过了. vstart.sh erasure-code load dlopen(/ceph/build/lib/erasure-code/libec_jerasure.so): /ceph/build/lib/erasure-code/libec_jerasure.so: cannot open shared object file: No such file or directory 123╭─root@ceph-dev-nautilus /ceph ╰─# cat src/vstart.sh | grep erasure-code [ -z \"$EC_PATH\" ] &amp;&amp; EC_PATH=$CEPH_LIB/erasure-code 暂时没找到怎么只是make , 生成到build/lib/erasure-code目录下的功能. vstart.sh ERROR: error creating empty object store in /data/ceph/build/dev/osd0: (22) Invalid argument 根据Support #23433: Ceph cluster doesn’t start - ERROR: error creating empty object store in /data/ceph/build/dev/osd0: (22) Invalid argument - bluestore - Ceph这里的回复, 看起来这个是因为毕竟是虚拟化的, 所以指向的/dev/目录下的内容并不是块设备引起的吧? 实践 采用官方给的关闭的大部分配置文件的方案[^1], 可以避过大部分坑, 至少Luminous版本做到了. Docker编译 根据[^7], 还有有参考价值的. 官方CI[^10] \b似乎这里主要运行test和image, 那个dev的镜像看起来是给调试镜像版本用的, 并不是直接提供运行vstart.sh来调试编译版本的. Luminous 最后按照下述方案处理好软链和安装包之后的cmake选项 1-DCMAKE_C_COMPILER=/usr/bin/clang -DCMAKE_CXX_COMPILER=/usr/bin/clang++ -DCMAKE_EXE_LINKER_FLAGS=&quot;-L/usr/local/opt/llvm/lib&quot; -DENABLE_GIT_VERSION=OFF -DSNAPPY_ROOT_DIR=/usr/local/Cellar/snappy/1.1.7_1 -DWITH_BABELTRACE=OFF -DWITH_BLUESTORE=OFF -DWITH_CCACHE=OFF -DWITH_CEPHFS=OFF -DWITH_KRBD=OFF -DWITH_LIBCEPHFS=OFF -DWITH_LTTNG=OFF -DWITH_LZ4=OFF -DWITH_MANPAGE=ON -DWITH_MGR=OFF -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DWITH_RADOSGW=OFF -DWITH_RDMA=OFF -DWITH_SPDK=OFF -DWITH_SYSTEMD=OFF -DWITH_TESTS=OFF -DWITH_XFS=OFF -DPYTHON_LIBRARY=$(python-config --prefix)/lib/libpython2.7.dylib -DPYTHON_INCLUDE_DIR=$(python-config --prefix)/include/python2.7 -DPYTHON3_LIBRARY=$(python3-config --prefix)/lib/libpython3.6.dylib -DPYTHON3_INCLUDE_DIR=$(python3-config --prefix)/include/python3.6m -DOPENSSL_ROOT_DIR=/usr/local/Cellar/openssl/1.0.2o_1/ 官方文档方案 brew install llvm brew install snappy ccache cmake pkg-config pip install cython pip3 install cython brew cask install osxfuse mkdir build cd build export PKG_CONFIG_PATH=/usr/local/Cellar/nss/3.48/lib/pkgconfig:/usr/local/Cellar/openssl/1.0.2t/lib/pkgconfig cmake .. -DBOOST_J=4 -DCMAKE_C_COMPILER=/usr/local/opt/llvm/bin/clang -DCMAKE_CXX_COMPILER=/usr/local/opt/llvm/bin/clang++ -DCMAKE_EXE_LINKER_FLAGS=“-L/usr/local/opt/llvm/lib” -DENABLE_GIT_VERSION=OFF -DSNAPPY_ROOT_DIR=/usr/local/Cellar/snappy/1.1.7_1 -DWITH_BABELTRACE=OFF -DWITH_BLUESTORE=OFF -DWITH_CCACHE=OFF -DWITH_CEPHFS=OFF -DWITH_KRBD=OFF -DWITH_LIBCEPHFS=OFF -DWITH_LTTNG=OFF -DWITH_LZ4=OFF -DWITH_MANPAGE=ON -DWITH_MGR=OFF -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DWITH_RADOSGW=OFF -DWITH_RDMA=OFF -DWITH_SPDK=OFF -DWITH_SYSTEMD=OFF -DWITH_TESTS=OFF -DWITH_XFS=OFF 由于我的主要目的是在CLion中使用, 所以我在Perference-&gt;Build,Execution,Deployment-&gt;Cmake-&gt;Cmake Options中添加的是上面的配置的单行形式. 出现的报错 BUILD NSS_INCLUDE_DIRS: NSS_INCLUDE_DIR-NOTFOUND 查看find_package(NSS)中调用的其实是pkg-config来查找nss.pc, 使用pkg-config --cflags --libs nss报不存在, 所以说明pkg-config的扫描路径中没有上面这个pc文件. 通过brew list nss查找到nss.pc文件所在, 通过pkg-config --variable pc_path pkg-config找到pc的默认搜索路径, 有两种方案 1. 做个软链到pkg-config的默认搜索路径中 1ln -s /usr/local/Cellar/nss/3.35/lib/pkgconfig/nss.pc /usr/local/lib/pkgconfig/nss.pc pkg_config使用的搜索环境变量PKG_CONFIG_PATH中导入 1export PKG_CONFIG_PATH=/usr/local/Cellar/nss/3.48/lib/pkgconfig:/usr/local/Cellar/ 我采用的第一种方案. 同理,还会出现nspr等需要这样处理的库. NOT find PythonLibs: Found unsuitable version “2.7.10”, but required[^3] 在CMake选项中增加指定下述的python库和头文件路径 1-DPYTHON_LIBRARY=$(python-config --prefix)/lib/libpython2.7.dylib -DPYTHON_INCLUDE_DIR=$(python-config --prefix)/include/python2.7 TestBigEndian.cmake:49 (message): no suitable type found 暂时看到的资料都是说需要看测试代码和修改cmake文件的样子, 我并不需要编译, 只是需要建立索引, 所以我暂时注释了这部分的检查[^4,5,6] Nautilus 采用同样的方案, 暂时未去推进. 遇到的问题 findboost unknown compiler: AppleClang 报了一个暂时没去尝试解决的错误, 识别不了clang? 调试增加选项 1./configure CFLAGS=&apos;-g3 -O0&apos; CXXFLAGS=&apos;-g3 -O0&apos;. todo 问题并不是真正的CMakeLists.txt. CLion解析了cmake中引用的所有源文件,以启用大多数功能(导航,code-completion,重构).根据我的经验,索引大型项目可以花费几分钟(十分钟). 减轻这个问题的一种方法是标记项目的“第三方”目录:右键单击您的common目录和Mark directory as… &gt; Libraries.如果需要,您甚至可以将目录排除在项目之外. 还请注意,CLion索引的结果被缓存:在初始索引之后,即使在重新启动项目时,只应修复经修改的文件(注意,修改CMakeLists中的构建选项可能触发完整的reindex) 索引代码理论上只需要选择这些代码文件就可以, 但是实际上像ceph如果我cmake工程没能成功编译,他也是并没有把函数的调用关系给分析出来的. 哎, 静态分析功能还是得依赖clang. 根据CI里的log来看, 的确只是yum install ceph这种形式直接安装成果物构造image. 那src.rpm编译出成果物是在哪个jenkins里做的呢? Reference build on MacOS — Ceph Documentation pkg-config 路径问题 - 采男孩的小蘑菇 - 博客园 CMake finding Python library and Python interpreter mismatch during pybind11 build · Issue #99 · pybind/pybind11 Re: Weird CMake failures building 10.4 on MacOS High Sierra (10.13) TestBigEndian.cmake:51 (messag no suitable type found (#16283) · Issues · CMake / CMake · GitLab windows - CMake internal error (TEST_BIG_ENDIAN) - Stack Overflow dockerize ceph集群和shell脚本编程 - 知乎 CEPH CRUSH algorithm source code analysis ceph/daemon - Docker Hub Quay Container Registry · Quay ceph/ceph-container: Docker files and images to run Ceph in containers ricardoasmarques/ceph-dev-docker Build Ceph — Ceph Documentation TUMBLEWEED Cant install python-lxml Opensuse Tumbleweed ceph luminous版本编译及部署 | itocm.com","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"编译","slug":"编译","permalink":"https://sean10.github.io/tags/编译/"}]},{"title":"diff与merge实践初探","slug":"diff与merge实践初探","date":"2020-10-08T14:14:57.000Z","updated":"2020-10-08T14:15:28.000Z","comments":true,"path":"2020/10/08/diff与merge实践初探/","link":"","permalink":"https://sean10.github.io/2020/10/08/diff与merge实践初探/","excerpt":"概念 diff和merge是一回事吗? 实际上是两回事. 如果可以通过已知的规则, 比如同时保留双方不一致内容, 自动merge, 那属于diff可以做到的内容. 但是如果想要手动merge, 比如展示开来, 然后一行行比较人工决定使用哪份, 这个就不属于diff提供的功能了, 需要一个展示diff结果然后保存回原始文件中的工具, 这个就属于编辑器的范畴了. 像beyond compare这种更像是一个集成了差异比较功能的编辑器了.","text":"概念 diff和merge是一回事吗? 实际上是两回事. 如果可以通过已知的规则, 比如同时保留双方不一致内容, 自动merge, 那属于diff可以做到的内容. 但是如果想要手动merge, 比如展示开来, 然后一行行比较人工决定使用哪份, 这个就不属于diff提供的功能了, 需要一个展示diff结果然后保存回原始文件中的工具, 这个就属于编辑器的范畴了. 像beyond compare这种更像是一个集成了差异比较功能的编辑器了. diff和patch和RCS版本控制关系? unified输出的diff就是一个patch, 然后通过patch命令打入. 基于上面的开发出了Source Code Control System和Revision Control System(RCS).RCS新增了lock的功能, 防止文件被其他人checkout之后修改了. 123456789ci a.txt #lockci -l a.txt # checkinci -u a.txt# 查看日志rlog a.txt# 获取patchrcsdiff -u -r1.1 -r1.2 a.txt 执行上面的命令就能把文件纳入版本控制, 会在当前目录生成对应文件的管理. CVS和Subvision的诞生 中心化版本控制系统 都是通过保存diff原型的changeset来保存作为日志. 另外增加了branch, trunk这些概念. Git和Mercurial 分布式版本控制系统 \b基本操作单位从上面的changeset变成了blob(压缩保存的完整文件). 所以在查询diff时是当前做的比较,而不是直接输出结果, git log --patch. diff 支持格式 命令模式(normal) ed命令模式 RCS(Revision Control System) 上下文模式(context) 我们目前默认用的diff和patch用的基本都是这个模式的样子. unified模式 简化了上下文模式同时显示2个文件的操作, 只显示第一个文件的那些行及要做的操作 命令 12345diff -e a.txt b.txt &gt; c.ed# 输出ed脚本, 可以让a文件和b文件一致.diff -n a.txt b.txt &gt; c.rcs# 输出RCS格式的脚本 merge[^5] sdiff和diff3之类的支持merge的操作. diff自身也支持一定的if-then-else的merge操作 样例文件 a.txt 1234567891011The Way that can be told of is not the eternal Way;The name that can be named is not the eternal name.The Nameless is the origin of Heaven and Earth;The Named is the mother of all things.Therefore let there always be non-being, so we may see their subtlety,And let there always be being, so we may see their outcome.The two are the same,But after they are produced, they have different names. b.txt 12345678910111213The Nameless is the origin of Heaven and Earth;The named is the mother of all things.Therefore let there always be non-being, so we may see their subtlety,And let there always be being, so we may see their outcome.The two are the same,But after they are produced, they have different names.They both may be called deep and profound.Deeper and more profound,The door of all subtleties! 自带的配合C语言的 1diff -DTWO a.txt b.txt 等价于下面这段,这段等后面的自定义掌握之后比较好看懂. 1234567891011--old-group-format='#ifndef name%&lt;#endif /* ! name */' \\--new-group-format='#ifdef name%&gt;#endif /* name */' \\--unchanged-group-format='%=' \\--changed-group-format='#ifndef name%&lt;#else /* name */%&gt;#endif /* name */' 输出得到的是以第二个文件为基础的ifndef之类的分支. 12345678910111213141516171819202122232425#ifndef TWOThe Way that can be told of is not the eternal Way;The name that can be named is not the eternal name.#endif /* ! TWO */The Nameless is the origin of Heaven and Earth;#ifndef TWOThe Named is the mother of all things.#else /* TWO */The named is the mother of all things.#endif /* TWO */Therefore let there always be non-being, so we may see their subtlety,And let there always be being, so we may see their outcome.The two are the same,But after they are produced,#ifndef TWO they have different names.#else /* TWO */ they have different names.They both may be called deep and profound.Deeper and more profound,The door of all subtleties!#endif /* TWO */ group line format (GFMT GTYPE) 基本上这里的区分主要就是多行匹配和单行匹配的区别了. 和LFMT同时运行的时候, 匹配了单行之后, 多行匹配也会触发一次. 具体暂时不知道运行时是先按多行还是单行扫, 总之看到的结果是两项修改均会触发. 主要会有以下几种结果. * –old-group-format=format * –new-group-format=format * –changed-group-format=format * 目前来看,如果配置了这条, 则--new-group-format基本上会被替换成这个. * 只有当这条没设置的时候, 可以让new生效. * –unchanged-group-format=format 1234567891011121314151617181920212223242526diff \\ --old-group-format='\\begin&#123;old&#125;%&lt;\\end&#123;old&#125;' \\ --new-group-format='\\begin&#123;bf&#125;%&gt;\\end&#123;bf&#125;' \\--unchanged-group-format='%=' \\ --changed-group-format='\\begin&#123;em&#125;%&lt;\\end&#123;em&#125;\\begin&#123;bf&#125;%&gt;\\end&#123;bf&#125;' \\ a.txt b.txt diff \\ --unchanged-group-format='%%' \\ --old-group-format='-------- %dn line%(n=1?:s) deleted at %df:%&lt;' \\ --new-group-format='-------- %dN line%(N=1?:s) added after %de:%&gt;' \\ --changed-group-format='-------- %dn line%(n=1?:s) changed at %df:%&lt;-------- to:%&gt;' \\ a.txt b.txt &gt; output.4 上面这段的%(n=1?:s)一开始一点都不理解是啥意思, 突然才反应过来是line和lines的区别…还以为这个N是和前面的%dn有关的… 格式符 ‘%&lt;’ stands for the lines from the first file, including the trailing newline. Each line is formatted according to the old line format (see Line Formats). ‘%&gt;’ stands for the lines from the second file, including the trailing newline. Each line is formatted according to the new line format. ‘%=’ stands for the lines common to both files, including the trailing newline. Each line is formatted according to the unchanged line format. 上面这几个, 分别代表旧文件, 新文件, 两个文件中相同的内容. ‘Fn’ where F is a printf conversion specification and n is one of the following letters, stands for n’s value formatted with F. ‘e’ The line number of the line just before the group in the old file. ‘f’ The line number of the first line in the group in the old file; equals e + 1. ‘l’ The line number of the last line in the group in the old file. ‘m’ The line number of the line just after the group in the old file; equals l + 1. ‘n’ The number of lines in the group in the old file; equals l - f + 1. ‘E, F, L, M, N’ Likewise, for lines in the new file. ‘(A=B?T:E)’ If A equals B then T else E. A and B are each either a decimal constant or a single letter interpreted as above. This format spec is equivalent to T if A’s value equals B’s; otherwise it is equivalent to E. For example, ‘%(N=0?no:%dN) line%(N=1?:s)’ is equivalent to ‘no lines’ if N (the number of lines in the group in the new file) is 0, to ‘1 line’ if N is 1, and to ‘%dN lines’ otherwise. 单纯格式符和行号这部分, 基本按照printf的使用方式就可以了. 输出 123456789101112131415161718192021222324252627\\begin&#123;old&#125;The Way that can be told of is not the eternal Way;The name that can be named is not the eternal name.\\end&#123;old&#125;The Nameless is the origin of Heaven and Earth;\\begin&#123;old&#125;The Named is the mother of all things.\\end&#123;old&#125;\\begin&#123;bf&#125;The named is the mother of all things.\\end&#123;bf&#125;Therefore let there always be non-being, so we may see their subtlety,And let there always be being, so we may see their outcome.The two are the same,But after they are produced,\\begin&#123;old&#125; they have different names.\\end&#123;old&#125;\\begin&#123;bf&#125; they have different names.They both may be called deep and profound.Deeper and more profound,The door of all subtleties!\\end&#123;bf&#125; Line Format (LFMT LTYPE) 主要做差异有这几种结果. * –old-line-format=format * –new-line-format=format * –unchanged-line-format=format 1234567891011121314diff \\ --old-line-format='&lt; %l' \\ --new-line-format='&gt; %l' \\ --old-group-format='%df%(f=l?:,%dl)d%dE%&lt;' \\ --new-group-format='%dea%dF%(F=L?:,%dL)%&gt;' \\ --changed-group-format='%df%(f=l?:,%dl)c%dF%(F=L?:,%dL)%&lt;---%&gt;' \\ --unchanged-group-format='' \\ a.txt b.txt 使用这个的时候,发生这样一个问题, 只能看到触发了--old-group-format和--changed-group-format, 没变化的那种倒是没发现 输出 1234567891011121314151,2d0&lt; The Way that can be told of is not the eternal Way;&lt; The name that can be named is not the eternal name.4c2,3&lt; The Named is the mother of all things.---&gt; The named is the mother of all things.&gt; 11c10,13&lt; they have different names.---&gt; they have different names.&gt; They both may be called deep and profound.&gt; Deeper and more profound,&gt; The door of all subtleties! 格式符 In a line format, ordinary characters represent themselves; conversion specifications start with ‘%’ and have one of the following forms. ‘%l’ stands for the contents of the line, not counting its trailing newline (if any). This format ignores whether the line is incomplete; See Incomplete Lines. ‘%L’ stands for the contents of the line, including its trailing newline (if any). If a line is incomplete, this format preserves its incompleteness. ‘%%’ stands for ‘%’. ‘%c’C’’ where C is a single character, stands for C. C may not be a backslash or an apostrophe. For example, ‘%c’:’’ stands for a colon. ‘%c’’’ where O is a string of 1, 2, or 3 octal digits, stands for the character with octal code O. For example, ‘%c’\\0’’ stands for a null character. ‘Fn’ where F is a printf conversion specification, stands for the line number formatted with F. For example, ‘%.5dn’ prints the line number using the printf format “%.5d”. See Line Group Formats, for more about printf conversion specifications. 自定义需求 合并两个文件, 比如跨平台编辑笔记时, 多个文本都出现了新增内容, 同步盘创建了Conflict文件的时候 1diff --old-line-format=%L --new-line-format=%L a.txt b.txt 直接双向合并就行了. Reference man diff linux - Manually merge two files using diff - Stack Overflow 用Diff和Patch工具维护源码 版本控制 — Unix 即集成开发环境 1.0 文档 If-then-else (Comparing and Merging Files)","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"diff","slug":"diff","permalink":"https://sean10.github.io/tags/diff/"},{"name":"merge","slug":"merge","permalink":"https://sean10.github.io/tags/merge/"},{"name":"git","slug":"git","permalink":"https://sean10.github.io/tags/git/"}]},{"title":"vscode之增加quote实现","slug":"vscode之增加quote实现","date":"2020-09-12T08:30:13.000Z","updated":"2021-01-17T08:33:29.645Z","comments":true,"path":"2020/09/12/vscode之增加quote实现/","link":"","permalink":"https://sean10.github.io/2020/09/12/vscode之增加quote实现/","excerpt":"","text":"增加quote功能 主要有整理笔记时, 有些内容需要注意引用的需求, 在给[^2]提交PR后很可惜作者一直没有上线, 就去提交给了markdown all in one, 在大佬们的讨论中, 发现这样一个场景, markdown的语法中对于引用只要求&gt;符号即可, 但是在各渲染及自动补充的实现中, 追加空格是个优雅的习惯. 然后在[^3]的review中, 大佬发现针对是否增加空格, 针对多级列表, github的markdown渲染的表现还不一致. 这就导致这套实现存在局限性了, 轻易引入存在较大bug风险了. 所以这个插件暂时主要用于下述需求的场景, 对于需要对多级列表等进行引用的场景, 还没有一个比较好的方案. 自己先单独封装了一个来使用. 场景 当cursor在某个位置, 未选中任何内容 需求: 该行行首增加&gt;即可 当选中了单行中的部分文本 该文本所在行首增加&gt; 当选中了多行文本 每行选中文本的行首增加&gt;即可. 或者根据每行行首绝对如何反转,是增加还是删除 不对,根据我个人的需求, 应该是三种状态, 如果存在未补全的, 则补全. 如果全部补全了才需要进行反转. 针对一些非标准格式的quote是否需要支持修改? 增加一个修正吧. 只要是匹配规则的, 都进行修正. 主要只针对缩进的吧. 实现 1. 找一下该插件中提供文本内容的显示的接口 123let editor = window.activeTextEditor;let lineIndex = editor.selection.active.line;let lineText = editor.document.lineAt(lineIndex).text; 上面的接口似乎满足了第一需求 2. 寻找如何根据获取选中内容部分的当前行内容的行首指针. 这个通过获取到start所在line的Start就可以了. 3. 针对第三种需求的三种状态切换 进行简化 场景一和场景二的最终动作都是在该行增加&gt; 场景一和场景二? 增加一个循环, 一开始获取到selection的时候就可以设置为循环, 最后处理为循环内每行遍历. 如果是场景一和场景二那就是处理当行 都是根据遍历后的状态进行处理. 首先一开始,场景一可以提取为场景二, 获取到指针所在行的全部内容, 场景三, 由于我们不关心尾部内容,因此其实也就是场景二的状态,只需要处理start所在指针的内容.(PS, 后来发现如果不关心尾部内容,也是存在问题的, 插入内容的时候直接导致尾部的文字会被替换一部分)","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://sean10.github.io/tags/vscode/"},{"name":"typescript","slug":"typescript","permalink":"https://sean10.github.io/tags/typescript/"}]},{"title":"mac远程桌面踩坑","slug":"mac远程桌面踩坑","date":"2020-07-11T04:12:23.000Z","updated":"2020-09-19T10:07:05.000Z","comments":true,"path":"2020/07/11/mac远程桌面踩坑/","link":"","permalink":"https://sean10.github.io/2020/07/11/mac远程桌面踩坑/","excerpt":"","text":"背景 最近要做痔疮手术, 术后有一段时间估计是还不能坐着的. 台式机就没有办法用上了, 但是笔记本的性能还是有点差,内存也不太够. \b工具 主要有以下以及更多的访问方式 vnc的一系统访问方式 Apple Remote Desktop VNC等工具 封装了vnc协议的类似xrdp的工具 Jump Desktop 踩坑实验记录 vnc直接修改分辨率 一开始我直接用的\b\b自带的finder里的vnc访问的, 效果还可以.不过因为笔记本只有13寸,访问3840*2160的台式机, 分辨率用系统配置的display最低也只能设计成拟合1920*1080的, 相比我一般设置成2560*1440拟合1280*720的笔记本的字实在是小太多了. 据我所知, windows的rdp是可以做到让渲染在客户端设备执行的逻辑的, 这样就无所谓我目标设备分辨率到底是多少了. 然而,很可惜, 经过调查, mac端主要也就上面这几种工具. apple remote desktop主要也只是基于vnc进行的封装,而vnc的渲染主要是在服务端进行的, 客户端只是直接显示的效果. 对于基于这种协议的远程访问工具只能直接修改服务端设备的分辨率来适应客户端, linux端至少看到的一般的解决方式都是这样的. 原生设置能够控制的分辨率还是有限, 最后我用了SwitchResX来进行的分辨率修改, 修改成拟合1440*900在客户端上用的. 无显示器操作方案[^2] 偶然看到好像有人提到没有接显示器的mac mini, 有人试着远程连接直接修改分辨率. 看到针对没有显示器连接的时候, 分辨率也能够修改. 我就试验了下SwitchResx, 发现居然的确显示了一个Virtual Desktop,可以修改的分辨率基本上都是客户端\b\b\b的分辨率. 基本上达到我的目的了. 无显示器竖屏方案[^3] 12345678910111213141516171819202122232425262728293031323334353637383940414243#displayplacer➜ ~ displayplacer listPersistent screen id: FFFFFFFF-FFFF-FFFF-FFFF-FFFFFFFFFFFFContextual screen id: 1104977160Type: MacBook built in screenResolution: 1440x900Hertz: 60Color Depth: 4Scaling:onOrigin: (0,0) - main displayRotation: 0 - rotate internal screen example (may crash computer, but will be rotated after rebooting): `displayplacer \"id:FFFFFFFF-FFFF-FFFF-FFFF-FFFFFFFFFFFF degree:90\"`Resolutions for rotation 0: mode 0: res:1x1 hz:60 color_depth:4 mode 1: res:800x600 hz:60 color_depth:4 mode 2: res:1024x768 hz:60 color_depth:4 mode 3: res:1280x720 hz:60 color_depth:4 mode 4: res:1280x1024 hz:60 color_depth:4 mode 5: res:1440x900 hz:60 color_depth:4 mode 6: res:1680x1050 hz:60 color_depth:4 mode 7: res:1920x1080 hz:60 color_depth:4 mode 8: res:2560x1440 hz:60 color_depth:4 mode 9: res:2560x1600 hz:60 color_depth:4 mode 10: res:3840x2160 hz:60 color_depth:4 mode 11: res:1024x640 hz:60 color_depth:4 scaling:on mode 12: res:1152x720 hz:60 color_depth:4 scaling:on mode 13: res:1152x800 hz:60 color_depth:4 scaling:on mode 14: res:1440x900 hz:60 color_depth:4 scaling:on &lt;-- current mode mode 15: res:1680x1050 hz:60 color_depth:4 scaling:on mode 16: res:1920x1200 hz:60 color_depth:4 scaling:on mode 17: res:1504x846 hz:60 color_depth:4 scaling:on mode 18: res:1920x1080 hz:60 color_depth:4 scaling:on mode 19: res:2048x1152 hz:60 color_depth:4 scaling:on mode 20: res:2304x1296 hz:60 color_depth:4 scaling:on mode 21: res:2560x1440 hz:60 color_depth:4 scaling:on mode 22: res:3008x1692 hz:60 color_depth:4 scaling:on mode 23: res:3360x1890 hz:60 color_depth:4 scaling:on mode 24: res:3840x2160 hz:60 color_depth:4 scaling:on mode 25: res:4096x2160 hz:60 color_depth:4 scaling:on mode 26: res:1280x1024 hz:60 color_depth:4Execute the command below to set your screens to the current arrangement:displayplacer \"id:FFFFFFFF-FFFF-FFFF-FFFF-FFFFFFFFFFFF res:1440x900 hz:60 color_depth:4 scaling:on origin:(0,0) degree:0\" 1234#Example:displayplacer &quot;id:18173D22-3EC6-E735-EEB4-B003BF681F30+F466F621-B5FA-04A0-0800-CFA6C258DECD res:1440x900 scaling:on origin:(0,0) degree:0&quot;displayplacer &quot;id:FFFFFFFF-FFFF-FFFF-FFFF-FFFFFFFFFFFF res:1440x900 scaling:on origin:(0,0) degree:90&quot; fb-rotate 1fb-rotate -l 方案 最后总结的方案主要就是下述两种了. 1. 基于SwitchResX直接修改服务端的分辨率 2. 拔掉服务端连接的显示器,这个时候用SwitchResX基本上就可以设置成客户端的分辨率了. 目前我主要用的就是第二套方案了. Reference Apple Remote Desktop 真是垃圾中的战斗机 - V2EX Force the resolution on a headless mac mini server - Ask Different jakehilborn/displayplacer: macOS command line utility to configure multi-display resolutions and arrangements. Essentially XRandR for macOS. CdLbB/fb-rotate: A Unix utility to rotate the display on any Mac and switch the primary display back and forth between displays.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"},{"name":"rdp","slug":"rdp","permalink":"https://sean10.github.io/tags/rdp/"},{"name":"vnc","slug":"vnc","permalink":"https://sean10.github.io/tags/vnc/"}]},{"title":"ceph之Nautilus版本引入的Perf统计","slug":"ceph之Nautilus版本引入的Perf统计","date":"2020-07-05T16:15:48.000Z","updated":"2020-07-05T16:20:01.000Z","comments":true,"path":"2020/07/06/ceph之Nautilus版本引入的Perf统计/","link":"","permalink":"https://sean10.github.io/2020/07/06/ceph之Nautilus版本引入的Perf统计/","excerpt":"","text":"背景 Nautilus在OSD和MGR中合并了通用的度量收集框架，以提供内置的监视，并且在该框架之上构建了新的RBD性能监视工具，以将各个RADOS对象度量转换为针对IOPS，吞吐量和性能的聚合RBD镜像度量。这些指标都是在Ceph集群本身内部生成和处理的，因此无需访问客户端节点即可获取指标。 源码阅读过程 新增接口 12rbd perf image iostat rbd perf image iotop 根据这里v14.2.9 Nautilus — Ceph Documentation New rbd perf image iotop and rbd perf image iostat commands provide an iotop- and iostat-like IO monitor for all RBD images. The ceph-mgr Prometheus exporter now optionally includes an IO monitor for all RBD images. 应该是在14.2.0的发布里完成的，那这次大版本包含了什么？小版本更新会包含pr和issue链接 14版本还增加了ceph config全局配置修改的功能。 ceph14支持pg数减小和pg数根据pool容量自动调整 ceph telemetry命令用ceph mgr module enable telemetry启用，但是对telemetry不了解也跳过了。 这个应该就是我要看到的openTelemetry Ceph v12.2.13 Luminous released - Ceph 这个应该是12版本最后一次补丁升级吧 这个里不包含大版本开发的代码 rbd: implement new ‘rbd perf image iostat/iotop’ commands by dillaman · Pull Request #26133 · ceph/ceph 就这个提交来看，大部分代码都在处理上下文的接口适配,增加选项，假如说这套代码里只是使用已经增加的接口，那么代码里就应该有调用的API 这个问题怎么才能验证? src/toos/rbd/action/Perf.cc这个新增文件，依赖的是rbd perf image stats。 然后rbd perf image stats也是这次commit里增加的，是继承MgrModule使用API实现的，看看这里面用的哪些api. 应该就是这里拿的了 register_osd_perf_queries好像有点像了。 这里使用了mgr_module.py提供的add_osd_perf_query 从这里拿到了osd层面的ops,write_ops, read_ops, bytes, write_bytes, latency这些内容 拿到osd的结果，怎么计算出rbd层的？ 他这里只查appplication_metadata里有rbd这个的资源池，然后拿到资源池的osd_map user_query变量里，QUERY_POOL_ID_MAP拿到了 在PerfHandler里进行的周期查询perf数据。 在这里周期获取数据时又调用了mgr-module的get_osd_perf_counters。emm，这个函数在12版本我们的代码里还没有，不过单论这部分呼出，其实我们可以。这个函数在14版本里，prometheus也调用了这个，那就有意思了，prometheus刚好在这个版本支持了rbd performance monitor, ceph-export输出了这部分数据。那是不是就是从这里拿到的呢？（osd_perf_query_support 在这里ceph-mgr里面的_ceph_get_osd_perf_counters的内容。这个函数就是Cython的封装了。 get_osd_perf_counters这个封装，好像还是在ceph-mgr里提供的，果然。 在ActivePyModules.cc里又封装了一层，这里应该是从DaemonServer.cc里封装的实际逻辑了。 果然，在ActivePyModules里实例化了DaemonServer这个对象， 这里调用osd_perf_metric_collector的get_counters。OSDPerfMetricCollector这个类，应该是12版本之后给mgr好好梳理时更新出来的。 在OSDPerfMetricSubKeyDescriptor这个struct里，封装了支持的类型 卧槽，好像这里全覆盖了,在下面这里做的扩充。从Client，牛皮 osd: support more dynamic perf query subkey types by trociny · Pull Request #25371 · ceph/ceph 那OSDPerfMetricCollector呢，是在这个PR里增加的？ mgr: create shell OSD performance query class by trociny · Pull Request #24117 · ceph/ceph 在下面这里提到了，开启这个收集功能之后，这套功能会遇到rbd images数据过于庞大的问题， osd: collect client perf stats when query is enabled by trociny · Pull Request #24265 · ceph/ceph 再在这个类下面继续探究就有点难的感觉了。下面就越来越细，估计需要实机环境验证了。 Prior to Red Hat Storage 4, Ceph storage administrators have not had access to built-in RBD performance monitoring and metrics gathering tools. Ceph Storage 4 now incorporates a generic metrics gathering framework within the OSDs and MGRs to provide built-in monitoring, and new RBD performance monitoring tools are built on top of this framework to translate individual RADOS object metrics into aggregated RBD image metrics for Input/Output Operations per Second (IOPS), throughput, and latency. 好像在这篇文章里要解释到底是怎么计算的了。哦，没解释 eph ceph mgr module enable rbd_support Noisy Neighbors and QoS看到好几次，。 到底这部分是怎么计算出来的呢？ß Ceph Block Performance Monitoring the OSD-based statistical stats are the end solution since that can never provide the latencies that the client is actually experiencing. 这篇里提到这个链接，有点意思？ Live Performance Probes - Ceph - Ceph mgr, rbd: report rbd images perf stats to mgr by Yan-waller · Pull Request #16071 · ceph/ceph (看这篇) 目前的怀疑点是在Nautilus的版本里在osd那层新增了不少埋点数据收集 这里提到了SLA（服务等级协议service level agreement) （提问题的人说到了想要这种客户端级别的IOPSjiankong ） As we know, one perfcounter metric was created in ImageCtx when we opened a rbd image , but these metrics data is scattered and reside in kinds of clients, furthermore, a rbd image could be opened simultaneously by more than one client. report these information (especially ops, bytes, latency ) to MGR may be useful. Ultimately, I still expect that operational indicators that we send up to mgr will mostly get reported onwards to something else (nagios, zabbix, snmp, etc), so for O(clients) monitoring jobs we should consider skipping the middleman. 这个@jcsp大佬推荐是在mgr的插件层完成这个监控的操作，然后实际上好像也的确完成了。support-rbd啊，osd-perf-count啊，都是基于ceph-mgr的插件。 monitoring that gives them per-client throughput, latency and op type breakdown, I’m not sure how strong the push would be to implement the separate monitoring path to go get the client’s view of the same set of stats. 待看mgr/prometheus: provide RBD stats via osd dynamic perf counters by trociny · Pull Request #25358 · ceph/ceph 在module.py里通过OSD_PERF_QUERY_COUNTERS_INDICES这个来把一个counter按照我们要的key导出数据。 extract_pool_key是用来提取像pool1/image0这样的spec字符串里的pool name的， user_queries到底是放了什么内容？ OSDPerfMetricCollectorListener这个应该是才是真实被Ceph-mgr实例化的内容。、 12class OSDPerfMetricCollectorListener : public OSDPerfMetricCollector::Listener 在DaemonServer初始化的时候 12345678910111213141516171819202122232425262728293031323334osd_perf_metric_collector_listener(this), osd_perf_metric_collector(osd_perf_metric_collector_listener)typedef int OSDPerfMetricQueryID;typedef std::pair&lt;uint64_t,uint64_t&gt; PerformanceCounter;typedef std::vector&lt;PerformanceCounter&gt; PerformanceCounters;struct PerformanceCounterDescriptor &#123; case PerformanceCounterType::OPS: case PerformanceCounterType::WRITE_OPS: case PerformanceCounterType::READ_OPS: case PerformanceCounterType::BYTES: case PerformanceCounterType::WRITE_BYTES: case PerformanceCounterType::READ_BYTES: case PerformanceCounterType::LATENCY: case PerformanceCounterType::WRITE_LATENCY: case PerformanceCounterType::READ_LATENCY:typedef std::vector&lt;std::string&gt; OSDPerfMetricSubKey; // array of regex matchtypedef std::vector&lt;OSDPerfMetricSubKey&gt; OSDPerfMetricKey;enum class OSDPerfMetricSubKeyType : uint8_t &#123; CLIENT_ID = 0, CLIENT_ADDRESS = 1, POOL_ID = 2, NAMESPACE = 3, OSD_ID = 4, PG_ID = 5, OBJECT_NAME = 6, SNAP_ID = 7,&#125;; 根据这里来看，果然是在Nautuil版本里，给ceph-mgr里增加了很多功能。 123456789 typedef std::map&lt;OSDPerfMetricQueryID, std::map&lt;OSDPerfMetricKey, PerformanceCounters&gt;&gt; Counters;int OSDPerfMetricCollector::get_counters( OSDPerfMetricQueryID query_id, std::map&lt;OSDPerfMetricKey, PerformanceCounters&gt; *c) &#123;int DaemonServer::get_osd_perf_counters( 这里调用到get_counter.这个接口被封装进pybind里了。 这里面的数据都是从哪里手机的呢？这个collector只是作为一个接口层提供收集的函数，手机的内容是通过指针穿进去的。还是存在了DaemonServer这个类里。 这里面到底调用了什么接口来收集osd？ OSDPerfMetricQueryID OSDPerfMetricCollector::add_query( 在这个函数里添加的到底是任务，还是收集的值呢？应该是任务吧？ 12typedef std::map&lt;OSDPerfMetricQuery, std::map&lt;OSDPerfMetricQueryID, OptionalLimit&gt;&gt; Queries; 这个和queries有什么关系呢？ 123456789101112131415161718192021222324252627 typedef std::optional&lt;OSDPerfMetricLimit&gt; OptionalLimit; typedef std::map&lt;OSDPerfMetricQuery, std::map&lt;OSDPerfMetricQueryID, OptionalLimit&gt;&gt; Queries; typedef std::map&lt;OSDPerfMetricQueryID, std::map&lt;OSDPerfMetricKey, PerformanceCounters&gt;&gt; Counters; struct OSDPerfMetricLimit &#123; PerformanceCounterDescriptor order_by; uint64_t max_count = 0;``` 在`bool DaemonServer::handle_report(MMgrReport *m)`这个里` osd_perf_metric_collector.process_reports(m-&gt;osd_perf_metric_reports);```` c++ class OSDPerfMetricCollectorListener : public OSDPerfMetricCollector::Listener &#123; public: OSDPerfMetricCollectorListener(DaemonServer *server) : server(server) &#123; &#125; void handle_query_updated() override &#123; server-&gt;handle_osd_perf_metric_query_updated(); &#125; 这里继承了Listener里的虚函数接口 1234567891011121314151617181920212223void DaemonServer::handle_osd_perf_metric_query_updated()&#123; dout(10) &lt;&lt; dendl; // Send a fresh MMgrConfigure to all clients, so that they can follow // the new policy for transmitting stats finisher.queue(new FunctionContext([this](int r) &#123; std::lock_guard l(lock); for (auto &amp;c : daemon_connections) &#123; if (c-&gt;peer_is_osd()) &#123; _send_configure(c); &#125; &#125; &#125;));&#125;/** * This message is sent from ceph-mgr to MgrClient, instructing it * it about what data to send back to ceph-mgr at what frequency. */class MMgrConfigure : public MessageInstance&lt;MMgrConfigure&gt; &#123; mgr: update MMgrConfigure message to include optional OSD perf queries by colletj · Pull Request #24180 · ceph/ceph 可能数据是从MgrClient里来的？嗯，忘了之前看过, 现在也才意识到mgr其实分成了Server和client， osd和pg都看到了，但是其他的呢？如果只有这两个数据，那其他的rados那些是怎么算出来的？ set_perf_queries_cb(m-&gt;osd_perf_metric_queries); Ceph Manager Overview 这篇里主要讲的mgr的代码 以osd daemon为例，在启动过程中，会发送消息MMgrOpen，mgr收到后，会回复MMgrConfigure消息，主要是返回一个period时间，后续osd就根据设定的period， 定期将状态信息上报给mgr，即消息MMgrReport和MPGStats: 本以为这段代码里不涉及image的信息了 但是下面这段查询到的数据里显然带上了rbd的image信息 12345res = self.module.get_osd_perf_counters(query_id)for counter in res['counters']: raw_image[0] = None if not raw_image[0]: raw_image[0] = [now_ts, [int(x[0]) for x in counter['c']]] mgr: templatize metrics collection interface by vshankar · Pull Request #29214 · ceph/ceph 这里做了一层封装模板化 blame Daemon里的这个函数get_osd_perf_counters是下面这条里加的 mgr: make dynamic osd perf counters accessible from modules · vshankar/ceph@b8362d9 get_counters这个实际工作的方法呢？ mgr: store osd perf counters received in osd reports · vshankar/ceph@438a3f7 又没头绪了 还是回到prometheus这里使用上看看阿布 mgr/prometheus: provide RBD stats via osd dynamic perf counters by trociny · Pull Request #25358 · ceph/ceph 12345678910111213141516171819202122232425262728293031# Per RBD image stats is collected by registering a dynamic osd perf # stats query that tells OSDs to group stats for requests associated # with RBD objects by pool, namespace, and image id, which are # extracted from the request object names or other attributes. # The RBD object names have the following prefixes: # - rbd_data.&#123;image_id&#125;. (data stored in the same pool as metadata) # - rbd_data.&#123;pool_id&#125;.&#123;image_id&#125;. (data stored in a dedicated data pool) # - journal_data.&#123;pool_id&#125;.&#123;image_id&#125;. (journal if journaling is enabled) # The pool_id in the object name is the id of the pool with the image # metdata, and should be used in the image spec. If there is no pool_id # in the object name, the image pool is the pool where the object is # located. if 'query_id' not in self.rbd_stats: query = &#123; 'key_descriptor': [ &#123;'type': 'pool_id', 'regex': pool_id_regex&#125;, &#123;'type': 'namespace', 'regex': namespace_regex&#125;, &#123;'type': 'object_name', 'regex': '^(?:rbd|journal)_data\\.(?:([0-9]+)\\.)?([^.]+)\\.'&#125;, ], 'performance_counter_descriptors': list(counters_info), &#125; query_id = self.add_osd_perf_query(query) if query_id is None: self.log.error('failed to add query %s' % query) return self.rbd_stats['query'] = query self.rbd_stats['query_id'] = query_id res = self.get_osd_perf_counters(self.rbd_stats['query_id']) 这段注释写的是真的好 所以其实还是这个借口的功能，类似mon_command，提供了根据传入的数据进行收集的操作。 这里也的确用上赋值逻辑 queryID到底是怎么期作用的？ 来自add_osd_perf_query OSDPerfMetricQueryID DaemonServer::add_osd_perf_query( 1234567891011121314151617181920212223242526272829303132333435 query = &#123; 'key_descriptor': [ &#123;'type': 'pool_id', 'regex': pool_id_regex&#125;, &#123;'type': 'namespace', 'regex': namespace_regex&#125;, &#123;'type': 'object_name', 'regex': '^(?:rbd|journal)_data\\.(?:([0-9]+)\\.)?([^.]+)\\.'&#125;, ], 'performance_counter_descriptors': list(counters_info), &#125; query_id = self.add_osd_perf_query(query)``` 使用上[mgr: create shell OSD performance query class · vshankar/ceph@a6c3390](https://github.com/vshankar/ceph/commit/a6c3390834759e3f953962d46cc7c840c9970046)这个`add_osd_perf_query`是在这里加的add_query也是他家的。``` c++static PyObject*ceph_add_osd_perf_query(BaseMgrModule *self, PyObject *args)&#123; static const std::string NAME_KEY_DESCRIPTOR = \"key_descriptor\"; static const std::string NAME_COUNTERS_DESCRIPTORS = \"performance_counter_descriptors\"; static const std::string NAME_LIMIT = \"limit\"; static const std::string NAME_SUB_KEY_TYPE = \"type\"; static const std::string NAME_SUB_KEY_REGEX = \"regex\"; static const std::string NAME_LIMIT_ORDER_BY = \"order_by\"; static const std::string NAME_LIMIT_MAX_COUNT = \"max_count\";``` 在封装python这里做的参数解析``` C++auto query_id = self-&gt;py_modules-&gt;add_osd_perf_query(query, limit); 所有属性都传到了limit里 在_send_configure的时候，把limit里的任务传给了MgrClient 1234567891011121314151617181920212223242526struct OSDPerfMetricLimit &#123; PerformanceCounterDescriptor order_by; uint64_t max_count = 0; OSDPerfMetricLimit() &#123; &#125; OSDPerfMetricLimit(const PerformanceCounterDescriptor &amp;order_by, uint64_t max_count) : order_by(order_by), max_count(max_count) &#123; &#125; bool operator&lt;(const OSDPerfMetricLimit &amp;other) const &#123; if (order_by != other.order_by) &#123; return order_by &lt; other.order_by; &#125; return max_count &lt; other.max_count; &#125; DENC(OSDPerfMetricLimit, v, p) &#123; DENC_START(1, 1, p); denc(v.order_by, p); denc(v.max_count, p); DENC_FINISH(p); &#125;&#125;; 传过去的应该是这个OptionalLimit吧，这个有啥用？ 里面有个order_by里申明是哪种type,是pg还是rados了好像 encode之后发送到mgrclient 看看怎么解码 std::function&lt;void(const std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; &amp;)&gt; set_perf_queries_cb; 在这个MgrClient.cc里居然有2个set_perf_queries_cb 一个是封装的MgrClient对外暴露的函数，就是用来赋值的？ 一个是private的值，与mgr的Daemon沟通时进行调用。 但是这里好像只看到了osd.cc触发啊 这个被osd.cc里调用了 12void OSD::set_perf_queries( const std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; &amp;queries) &#123; 怎么看上去osd.cc里不止负责普通的osd信息收集 在12版本里，这个OSD.cc里也有mgrc 在14版本里， std::list m_perf_queries;属于OSD这个class 123456789101112131415161718192021222324private: void set_perf_queries( const std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; &amp;queries); void get_perf_reports( std::map&lt;OSDPerfMetricQuery, OSDPerfMetricReport&gt; *reports); Mutex m_perf_queries_lock = &#123;\"OSD::m_perf_queries_lock\"&#125;; std::list&lt;OSDPerfMetricQuery&gt; m_perf_queries; std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; m_perf_limits; void get_perf_reports( std::map&lt;OSDPerfMetricQuery, OSDPerfMetricReport&gt; *reports); mgrc.set_pgstats_cb([this]()&#123; return collect_pg_stats(); &#125;); mgrc.set_perf_metric_query_cb( [this](const std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; &amp;queries) &#123; set_perf_queries(queries); &#125;, [this](std::map&lt;OSDPerfMetricQuery, OSDPerfMetricReport&gt; *reports) &#123; get_perf_reports(reports); &#125;); mgrc.init(); osd把收集pg信息的回调函数设置到mgrc里,接下来应该是由mgrc来调用了把 在void MgrClient::_send_report()这里会触发调用. 理论上应该是 1234567891011121314151617181920void OSD::get_perf_reports( std::map&lt;OSDPerfMetricQuery, OSDPerfMetricReport&gt; *reports) &#123; std::vector&lt;PGRef&gt; pgs; _get_pgs(&amp;pgs); DynamicPerfStats dps; for (auto&amp; pg : pgs) &#123; // m_perf_queries can be modified only in set_perf_queries by mgr client // request, and it is protected by by mgr client's lock, which is held // when set_perf_queries/get_perf_reports are called, so we may not hold // m_perf_queries_lock here. DynamicPerfStats pg_dps(m_perf_queries); pg-&gt;lock(); pg-&gt;get_dynamic_perf_stats(&amp;pg_dps); pg-&gt;unlock(); dps.merge(pg_dps); &#125; dps.add_to_reports(m_perf_limits, reports); dout(20) &lt;&lt; \"reports for \" &lt;&lt; reports-&gt;size() &lt;&lt; \" queries\" &lt;&lt; dendl;&#125; void add_to_reports( 下面这个数据在primary_log的里 12345678class PrimaryLogPG : public PG, public PGBackend::Listener &#123; DynamicPerfStats m_dynamic_perf_stats;void PrimaryLogPG::get_dynamic_perf_stats(DynamicPerfStats *stats) std::swap(m_dynamic_perf_stats, *stats); 而这个value在下面这里更新的 123void PrimaryLogPG::log_op_stats(const OpRequest&amp; op, m_dynamic_perf_stats.add(osd, info, op, inb, outb, latency); 差别可能真在这?在12版本的这个log_op_stats函数里,没有记录perf信息的. 123456789101112131415161718192021222324252627282930 auto m = static_cast&lt;const MOSDOp*&gt;(op.get_req());std::string match_string; switch(d.type) &#123; case OSDPerfMetricSubKeyType::CLIENT_ID: match_string = stringify(m-&gt;get_reqid().name); break; case OSDPerfMetricSubKeyType::CLIENT_ADDRESS: match_string = stringify(m-&gt;get_connection()-&gt;get_peer_addr()); break; case OSDPerfMetricSubKeyType::POOL_ID: match_string = stringify(m-&gt;get_spg().pool()); break; case OSDPerfMetricSubKeyType::NAMESPACE: match_string = m-&gt;get_hobj().nspace; break; case OSDPerfMetricSubKeyType::OSD_ID: match_string = stringify(osd-&gt;get_nodeid()); break; case OSDPerfMetricSubKeyType::PG_ID: match_string = stringify(pg_info.pgid); break; case OSDPerfMetricSubKeyType::OBJECT_NAME: match_string = m-&gt;get_oid().name; break; case OSDPerfMetricSubKeyType::SNAP_ID: match_string = stringify(m-&gt;get_snapid()); break; default: ceph_abort_msg(\"unknown counter type\"); &#125; 的确是在这个add这里加的,奇怪了.这里的m是怎么拿到所谓的snapobject这些信息的呢? 1234567891011121314151617181920212223 auto m = static_cast&lt;const MOSDOp*&gt;(op.get_req());Requests are MOSDOp messages. Replies are MOSDOpReply messages.An object request is targeted at an hobject_t, which includes a pool,hash value, object name, placement key (usually empty), and snapid.The hash value is a 32-bit hash value, normally generated by hashingthe object name. The hobject_t can be arbitrarily constructed,though, with any hash value and name. Note that in the MOSDOp thesecomponents are spread across several fields and not logicallyassembled in an actual hobject_t member (mainly historical reasons).A request can also target a PG. In this case, the *ps* value matchesa specific PG, the object name is empty, and (hopefully) the ops inthe request are PG ops.Either way, the request ultimately targets a PG, either by using theexplicit pgid or by folding the hash value onto the current number ofpgs in the pool. The client sends the request to the primary for theassociated PG.Each request is assigned a unique tid. 原来这里是osd的落盘请求链路,这里能通过req() 12345class MOSDOp : public MessageInstance&lt;MOSDOp, MOSDFastDispatchOp&gt; &#123; std::map&lt;OSDPerfMetricQuery, std::map&lt;OSDPerfMetricKey, PerformanceCounters&gt;&gt; data; osd: collect client perf stats when query is enabled by trociny · Pull Request #24265 · ceph/ceph 找到了,是在这个pr里增加的数据收集, 又是trociny这个大佬提交的. ceph tell mgr osd perf query add simple the mgr starts to receive perf report, writing to the log: 简单点说原理是在osd的最下层通过request的MOSDop这个类,查到这次request各层的名字,然后在对应的计数器数加一 123void PrimaryLogPG::log_op_stats(const OpRequest&amp; op, const uint64_t inb, const uint64_t outb) 在这的时候传入的op. 这个DynamicPerfStats.h的文件是在osd目录里. dps.merge(pg_dps);","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"源码","slug":"源码","permalink":"https://sean10.github.io/tags/源码/"},{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"rbd","slug":"rbd","permalink":"https://sean10.github.io/tags/rbd/"},{"name":"perf","slug":"perf","permalink":"https://sean10.github.io/tags/perf/"}]},{"title":"ceph之tier数据源码初探","slug":"ceph之tier数据源码初探","date":"2020-07-04T13:07:29.000Z","updated":"2020-12-18T14:48:24.789Z","comments":true,"path":"2020/07/04/ceph之tier数据源码初探/","link":"","permalink":"https://sean10.github.io/2020/07/04/ceph之tier数据源码初探/","excerpt":"","text":"分析关键点 埋点统计接口 123456# tier_flush\\tier_promote等数据ceph daemon osd.&#123;id&#125; perf dump | grep tier# num_write\\num_read\\num_promote等数据ceph pg dump_json tier主要触发任务 数据迁移 下面的flush和evict动作主要根据热度命中集和当前空间占用的ratio有关. * flush * evict * promote(感觉只和这个有关系了) IO操作 根据flush_mode和evict_mode状态判断触发下面的may_read,can_proxy_write等操作的成功与否. 下面的每一个操作好像都是may或者can的, 看上去像是有开关之类的. write_back 读: 缓存不存在 read proxy(osd层的proxy_read怎么转换到pg层上?) read forward(会redirct, 统计数据应该是直接记录到base pool上的pg层的read_num上) 这两个是怎么选择的呢? 缓存命中 (cache pool的read) 写 缓存不命中 write_proxy(proxy_write) promote_object 缓存命中 (cache pool的write) 源码阅读过程 tier_proxy_read数据来源 tier_proxy_read这个数据是哪里统计增加的?是在finish_proxy_read里增加的,那么同理 osd: tiering: add proxy read support · ceph/ceph@70d3d08 这次提交好像是个核心开发者的提交,当时不是走的github的pr? 看了下代码,这里好像没有计数器,inc 虽然是在ceph daemon osd.x perf dump里拿到的数据,但实际上还是pg层的,只是这个数据pg那边的接口暂时没找到能直接打印出来的方式.不对,这里虽然是PG类里的,但是数据记在了这个pg所属的osd上. osd: add proxy write perf counter · ceph/ceph@b9ec7e6 Revision b9ec7e64 - osd: add proxy write perf counter Signed-off-by: Zhiqiang Wang &lt;zhiqiang.wan... - Ceph - Ceph tracker单里咋也啥都没有呢?那他们怎么决定的呢? 在这个提交里增加的计数器.这个是直接提交在master分支里的了…哎 int PrimaryLogPG::do_osd_ops(OpContext *ctx, vector&amp; ops) write这边是尝试写,或者跟tier有关的都会进行计数 而read这边则是读一些元数据信息会触发读计数 这样的话,write和read数据就没有那么准确了. pg的counter好像不够实时, 有一个类似pg map的同步周期的样子,待核对. rmw_flags flags这个是判断到底要不要promote,和may_proxy_write的结果判断的 bool can_proxy_write = get_osdmap()-&gt;get_up_osd_features() &amp; CEPH_FEATURE_OSD_PROXY_WRITE_FEATURES; uint64_t OSDMap::get_up_osd_features() const { return cached_up_osd_features; } void OSDMap::_calc_up_osd_features() 在这个函数里做的赋值, osd/OSDMap: cache get_up_osd_features · Mirantis/ceph@e0e765f 在这次提交里做的改名,改成cached_up_osd_features,之前叫uint64_t OSDMap::get_up_osd_features() const, 每次都是重新查. osd/OSDMap: get_up_osd_features() · Mirantis/ceph@1d8429d age Weil authored and Yan, Zheng committed on Dec 29, 2013 struct osd_xinfo_t { 变量在osdMap这个class里 mempool::osdmap::vector osd_xinfo; pg stats pool stat方向 dump时用的iops_wr和iops_rd int64_t iops_wr = pos_delta 是从pg_sum_delta来的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596 mempool::pgmap::list&lt; pair&lt;pool_stat_t, utime_t&gt; &gt; pg_sum_deltas;void PGMap::update_global_delta(CephContext *cct, const utime_t ts, const pool_stat_t&amp; pg_sum_old)&#123; update_delta(cct, ts, pg_sum_old, &amp;stamp, pg_sum, &amp;pg_sum_delta, &amp;stamp_delta, &amp;pg_sum_deltas);&#125; /* Aggregate current delta, and take out the last seen delta (if any) to * average it out. * Skip calculating delta while sum was not synchronized. */ if(!old_pool_sum.stats.sum.is_zero()) &#123; delta_avg_list-&gt;push_back(make_pair(d,delta_t)); *result_ts_delta += delta_t; result_pool_delta-&gt;stats.add(d.stats); &#125; size_t s = cct ? cct-&gt;_conf-&gt;get_val&lt;uint64_t&gt;(\"mon_stat_smooth_intervals\") : 1; if (delta_avg_list-&gt;size() &gt; s) &#123; result_pool_delta-&gt;stats.sub(delta_avg_list-&gt;front().first.stats); *result_ts_delta -= delta_avg_list-&gt;front().second; delta_avg_list-&gt;pop_front(); &#125;//这里add,实际对应的就是底层对每个num_write之类的变量做加减. mempool::pgmap::list&lt;pair&lt;pool_stat_t,utime_t&gt; &gt; *delta_avg_list)//这里的减,减去的是上一次收集的数据? auto ts = per_pool_sum_deltas_stamps.find(p-&gt;first); assert(ts != per_pool_sum_deltas_stamps.end()); client_io_rate_summary(f, out, p-&gt;second.first, ts-&gt;second);//这里应该是pgmap维持那张pg_sum_deltas list里的stamp if (!stamp.is_zero() &amp;&amp; !pg_sum_old.stats.sum.is_zero()) &#123; utime_t delta_t; delta_t = inc.stamp; delta_t -= stamp; // calculate a delta, and average over the last 2 deltas. pool_stat_t d = pg_sum; d.stats.sub(pg_sum_old.stats); pg_sum_deltas.push_back(make_pair(d, delta_t)); stamp_delta += delta_t;//这里的inc.stamp是什么东西? list&lt;Incremental*&gt; inc; Incremental::generate_test_instances(inc); class Incremental &#123; public: MEMPOOL_CLASS_HELPERS(); version_t version; mempool::pgmap::map&lt;pg_t,pg_stat_t&gt; pg_stat_updates; epoch_t osdmap_epoch; epoch_t pg_scan; // osdmap epoch mempool::pgmap::set&lt;pg_t&gt; pg_remove; float full_ratio; float nearfull_ratio; utime_t stamp; pool_stat_t d = pg_sum;void PGMapDigest::decode(bufferlist::iterator&amp; p)void ClusterState::update_delta_stats()&#123; pending_inc.stamp = ceph_clock_now(); pending_inc.version = pg_map.version + 1; // to make apply_incremental happy dout(10) &lt;&lt; \" v\" &lt;&lt; pending_inc.version &lt;&lt; dendl; dout(30) &lt;&lt; \" pg_map before:\\n\"; JSONFormatter jf(true); jf.dump_object(\"pg_map\", pg_map); jf.flush(*_dout); *_dout &lt;&lt; dendl; dout(30) &lt;&lt; \" incremental:\\n\"; JSONFormatter jf(true); jf.dump_object(\"pending_inc\", pending_inc); jf.flush(*_dout); *_dout &lt;&lt; dendl; pg_map.apply_incremental(g_ceph_context, pending_inc); pending_inc = PGMap::Incremental();&#125; 所以pool_stat数据的更新,基本上就是和这个pg_sum数据的更新一致的. 这里的stamp周期到底是多长呢? PGMap::apply_incremental 像是在这merge的数据? 在PGMonitor::tick里会更新这个delta的数据. 理论 因为太多人不推荐这个方案了, 所以看看有没有推荐的. 推荐ssd用于WAL, 然后剩下的根据热数据大小控制缓存分层的大小[^3] 所以理论上控制好, 还是有用的? 下刷 flush_target evict_target PrimaryLogPG.cc:13468 cache_target_full_ratio_micro uint64_t flush_target = pool.info.cache_target_dirty_ratio_micro; uint64_t flush_high_target = pool.info.cache_target_dirty_high_ratio_micro; uint64_t flush_slop = (float) flush_target * cct-&gt;_conf-&gt;osd_agent_slop; uint64_t evict_target = pool.info.cache_target_full_ratio_micro; uint64_t evict_slop = (float) evict_target * cct-&gt;_conf-&gt;osd_agent_slop; agent_choose_mode 这次新增了flush_high &gt; commit 8f6056aebbabcbe236d332f546d075e06a14c0ca &gt; Author: MingXin Liu mingxin.liu@kylin-cloud.com &gt; Date: Thu May 28 14:33:10 2015 +0800 &gt; &gt; Osd: revise agent_choose_mode() to track the flush mode &gt; &gt; Signed-off-by: Mingxin Liu mingxinliu@ubuntukylin.com &gt; Reviewed-by: Li Wang liwang@ubuntukylin.com &gt; Suggested-by: Nick Fisk nick@fisk.me.uk commit c9daf8e5ea401f5bc2aafd4025991fb4903ffcd4 Author: Sage Weil sage@inktank.com Date: Mon Jan 27 17:57:53 2014 -0800 osd/ReplicatedPG: add slop to agent mode selection We want to avoid a situation where the agent clicks on and off when the system hovers around a utilization threshold. Particularly for trim, the system can expend a lot of energy doing a minimal amount of work when the effort level is low. To avoid this, enable when we are some amount above the threshold, and do not turn off until we are the same amount below the target. Signed-off-by: Sage Weil &lt;sage@inktank.com&gt; 理解 该值需要根据缓存池的容量大小以及副本个数来设置，以三副本为例，target_max_bytes 不应该超过容量的 1/3，如果实际的负载使得存储池中的数据大小达到了容量的 1/3，后续的 IO 将被阻塞，所以需要设置别的参数来避免池中的数据到达该阈值。 为什么是1/3? 该类参数的设计目的： 作为刷回淘汰操作的触发条件，避免 OSD 被数据撑满。 为什么不直接使用存储池的容量作为该参数，是为了考虑另外一种场景，存在多个缓存池，使用相同的磁盘。 flush 逻辑[^5] Agent will be always in idle state if target_max_bytes or target_max_objects not set on the pool irrespective of other tiering params set in the pool. dirty_micro and full_micro will not be calculated if those two params are zero which is by default I guess. Now, flush will be activated if dirty_micro is &gt; flush_target. My understanding is, once it is activated it will iterate through all the dirty objects and flush all the dirty objects which is &gt; cache_min_flush_age. Am I right ? The cache_min_flush_age will only be applicable if the flush is triggered after crossing the dirty_threshold, right ? If dirty_threshold is not breached, the flush age param is never checked. evict逻辑 I saw the cache_min_evict_age is not been used anywhere, am I missing anything ? It’s possible. The min params are a bit dangerous because they can potentially confuse the cache agent (e.g., what if all objects are under the min? How/when do we decide to ignore the min, or, how/when do we give up trying to find an older object?). blocked 时间 1234uint64_t over = full_micro - evict_target;uint64_t span = 1000000 - evict_target;evict_effort = MAX(over * 1000000 / span, (unsigned) (1000000.0 * cct-&gt;_conf-&gt;osd_agent_min_evict_effort)); 123full_micro = num_user_objects * avg_size * 1000000 / MAX(pool.info.target_max_bytes / divisor, 1) 根据目前的理解, 当full_ratio达到1000000时, 根据上文, 也就是只有当达到target_max_bytes的时候才会彻底阻塞, 在这之前都是不会停止写io的. evict_effort与实际速度的计算 根据默认配置可知, osd_agent_min_evict_effort默认值为0.1,即默认的evict_effort为0.1. osd_agent_quantize_effort默认值同样为0.1 1234567uint64_t inc = cct-&gt;_conf-&gt;osd_agent_quantize_effort * 1000000; assert(inc &gt; 0); uint64_t was = evict_effort; evict_effort -= evict_effort % inc; if (evict_effort &lt; inc) evict_effort = inc; assert(evict_effort &gt;= inc &amp;&amp; evict_effort &lt;= 1000000); 看起来这段只是在凑0.1-1以0.1为单元. if (full_micro &gt; evict_target), the mode is set as TierAgentState::EVICT_MODE_SOME. In this scenario evict_effort is calculated and based on hit_set and temp calculation some clean objects are evicted. My question is , can we quantify this value ? For ex, if the target_full_ratio = 50%, once the eviction is triggered, what %objects will be evicted ? The effort is calculated based on how far between target_full and 100% we are. This is mapped onto the estimation of atime. We generate a histogram of age for the objects we have examined, so after the agent has run a bit we’ll have a reasonable idea how the current object’s age compares to others and can decide whether this is older or newer than the others; based on that we decide what to do. maybe_handle_cache see maybe_handle_cache(). That’s not strictly agent behavior per se. Also, there is now a readforward mode that doesn’t promote on read ever, based on our discussion about the performance of flash on read. 调用链 agent_choose_mode OSDService::agent_entry() PrimaryLogPG::agent_work PG::agent_work(int max, int agent_flush_quota) = 0 PG::agent_work(int max) = 0 agent_maybe_evict agent_maybe_flush Todo write_full? pg counter有类似pg map的同步周期? 计算什么时候会达到平衡的时候, 预计应该是会与tier的flush速度+evict速度 是否等同于上层下发的写io速度相平衡? 也就是我们需要得到evict速度的增长曲线, 得到evict与容量占比的计算公式, 然后计算上flush的计算速度与osd, 盘性能的相关性, 再计算一下业务的压力, 就可以得到到底设置多大的上水线可以让这个缓存池满足使用了. TierAgentState Reference Ceph 学习——OSD读写流程与源码分析（一）_SEU_PAN的博客-CSDN博客_primarylogpg openstack - What is the best size for cache tier in Ceph? - Stack Overflow Ceph Tiring Cache 调优 | Elvis Zhang Re: [ceph-users] Regarding cache tier understanding","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"源码","slug":"源码","permalink":"https://sean10.github.io/tags/源码/"},{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"tier","slug":"tier","permalink":"https://sean10.github.io/tags/tier/"}]},{"title":"ceph之tier效果收集","slug":"ceph之tier效果收集","date":"2020-06-29T06:01:18.000Z","updated":"2020-06-29T08:09:44.000Z","comments":true,"path":"2020/06/29/ceph之tier效果收集/","link":"","permalink":"https://sean10.github.io/2020/06/29/ceph之tier效果收集/","excerpt":"","text":"数据整理 写入效果统计 \\[ \\frac{num\\_write_{cache}}{num\\_write_{cache} + num\\_write_{base}} \\] 读取效果统计 \\[ \\frac{num\\_read_{cache}}{num\\_read_{cache} + num\\_read_{base}} \\] 数据收集 osd daemon tier perf 实际还是pg的数据, 只是没有在pg那里直接对外暴露 123456789101112131415161718192021222324252627282930&#123; \"cache\": &#123; \"tier_whiteout\": 0, \"tier_try_flush_fail\": 0, \"tier_proxy_read\": 0, \"tier_dirty\": 2, \"tier_promote\": 3, \"tier_clean\": 0, \"tier_delay\": 0, \"tier_flush_fail\": 0, \"tier_flush\": 0, \"tier_try_flush\": 0, \"tier_evict\": 0, \"tier_proxy_write\": 3 &#125;, \"base\": &#123; \"tier_whiteout\": 0, \"tier_try_flush_fail\": 0, \"tier_proxy_read\": 0, \"tier_dirty\": 3, \"tier_promote\": 0, \"tier_clean\": 0, \"tier_delay\": 0, \"tier_flush_fail\": 0, \"tier_flush\": 0, \"tier_try_flush\": 0, \"tier_evict\": 0, \"tier_proxy_write\": 3 &#125;&#125; pg perf 12345678910111213141516171819202122232425262728293031323334353637383940&#123; \"cache\": &#123; \"num_write_kb\": 3, \"num_evict_mode_full\": 0, \"num_write\": 8, \"num_bytes_hit_set_archive\": 83, \"num_promote\": 3, \"num_whiteouts\": -1, \"num_bytes\": 6991, \"num_read_kb\": 53, \"num_flush_kb\": 0, \"num_evict\": 0, \"num_flush\": 0, \"num_evict_kb\": 0, \"num_read\": 61, \"num_objects_hit_set_archive\": 1, \"num_flush_mode_high\": 0, \"num_flush_mode_low\": 0, \"num_objects_dirty\": 2 &#125;, \"base\": &#123; \"num_write_kb\": 8, \"num_evict_mode_full\": 0, \"num_write\": 3, \"num_bytes_hit_set_archive\": 0, \"num_promote\": 0, \"num_whiteouts\": 0, \"num_bytes\": 6890, \"num_read_kb\": 1, \"num_flush_kb\": 0, \"num_evict\": 0, \"num_flush\": 0, \"num_evict_kb\": 0, \"num_read\": 5, \"num_objects_hit_set_archive\": 0, \"num_flush_mode_high\": 0, \"num_flush_mode_low\": 0, \"num_objects_dirty\": 3 &#125;&#125; 统计指标所在场景 根据上面这张图以及&lt;ceph源码分析&gt;可知, 主要的最后执行任务场景如下 read cache pool read op -&gt; num_read(cache)+ do_proxy_read -&gt; tier_proxy_read(cache) + num_read(base)+ num_read(cache)+ do_cache_redirect -&gt; num_read(base) + promote_object -&gt; num_promote(cache) + num_read(base)+ num_read(cache)+ write wait_queue(block) -&gt; 重新进入下面3个逻辑 promote_object -&gt; num_promote+ num_write(base)+ num_write(cache)+ num_read(base)+ num_write(cache)+ do_cache_redirect num_write(base)+ num_read(base)+ num_read(write)+ do_proxy_write tier_proxy_write(cache)+ num_write(base)+ num_write(cache)+ num_read(base)+ num_read(cache)+ 汇总 可知, promote和proxy并不是强相关的,只有实际的op的read和write存在强相关性. 只是由于read类型和write类型,可知元数据的读写也被统计了. 不过在总体上来说, 每个对象相关的元数据是存在正比关系(理论上应该是), 所以这个比值应该也是可靠的. num_read计数OP类型 1234567891011121314151617181920case CEPH_OSD_OP_CMPEXT:case CEPH_OSD_OP_READ:case CEPH_OSD_OP_CHECKSUM:case CEPH_OSD_OP_MAPEXT:case CEPH_OSD_OP_CALL:case CEPH_OSD_OP_ISDIRTY:case CEPH_OSD_OP_GETXATTR:case CEPH_OSD_OP_GETXATTRS:case CEPH_OSD_OP_CMPXATTR:case CEPH_OSD_OP_ASSERT_VER:case CEPH_OSD_OP_LIST_WATCHERS:case CEPH_OSD_OP_LIST_SNAPS:case CEPH_OSD_OP_NOTIFY:case CEPH_OSD_OP_NOTIFY_ACK:case CEPH_OSD_OP_OMAPGETKEYS:case CEPH_OSD_OP_OMAPGETVALS:case CEPH_OSD_OP_OMAPGETHEADER:case CEPH_OSD_OP_OMAPGETVALSBYKEYS:case CEPH_OSD_OP_OMAP_CMP:case CEPH_OSD_OP_COPY_GET: num_write计数OP类型 1234567891011121314151617181920212223242526case CEPH_OSD_OP_UNDIRTY:case CEPH_OSD_OP_CACHE_TRY_FLUSH:case CEPH_OSD_OP_CACHE_FLUSH:case CEPH_OSD_OP_CACHE_EVICT:case CEPH_OSD_OP_SETALLOCHINT:case CEPH_OSD_OP_WRITE:case CEPH_OSD_OP_WRITEFULL:case CEPH_OSD_OP_WRITESAME:case CEPH_OSD_OP_ROLLBACK :case CEPH_OSD_OP_ZERO:case CEPH_OSD_OP_CREATE:case CEPH_OSD_OP_TRUNCATE:case CEPH_OSD_OP_DELETE:case CEPH_OSD_OP_WATCH:case CEPH_OSD_OP_CACHE_PIN:case CEPH_OSD_OP_CACHE_UNPIN:case CEPH_OSD_OP_SET_REDIRECT:case CEPH_OSD_OP_SETXATTR:case CEPH_OSD_OP_RMXATTR:case CEPH_OSD_OP_TMAPUP:case CEPH_OSD_OP_TMAP2OMAP:case CEPH_OSD_OP_OMAPSETVALS:case CEPH_OSD_OP_OMAPSETHEADER:case CEPH_OSD_OP_OMAPCLEAR:case CEPH_OSD_OP_OMAPRMKEYS:case CEPH_OSD_OP_COPY_FROM: Todo问题 针对当cache资源池满的时候,write的请求会进入block_write_on_full_cache, 等到不满以后,再调用requeue_ops重新加入,因此对于num_write和num_read是体现不出这里的block的过程的. 可能需要增加一个latency的数据展示. 该统计方式, 需要分场景独立统计后使用 cache为空时的写入 cache上数据写入始终在cache_target_dirty_ratio下 cache上数据写入始终在cache_target_dirty_high_ratio下 cache上数据写入始终在cache_target_full_ratio下 超过cache_target_full_ratio时,主要只有延时需要关注了应该 Reference","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"源码","slug":"源码","permalink":"https://sean10.github.io/tags/源码/"},{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"tier","slug":"tier","permalink":"https://sean10.github.io/tags/tier/"}]},{"title":"hexo开启atom订阅","slug":"hexo开启atom订阅","date":"2020-06-27T14:45:43.000Z","updated":"2020-07-05T11:59:56.000Z","comments":true,"path":"2020/06/27/hexo开启atom订阅/","link":"","permalink":"https://sean10.github.io/2020/06/27/hexo开启atom订阅/","excerpt":"","text":"最近想起来, 收藏的博客都没怎么看, 最近全靠公众号在提供一些有意思的内容,但是这个渠道还是太单薄了. 想起来之前用inoreader订阅过一些频道, 现在把最近一段时间收藏的博客再给补充进去, 顺便把自己博客的atom源也给打开. PS. 扫了一遍,好多用自定义域名的博客都已经不再维护, 这些不怎么常见的域名像是被专门去买别人未续费的域名机构给收集了,跳转到了一些做SEO. 还是github这种基本有几乎永久保障的二级域名好,. 123456# npm install hexo-generator-feed --savefeed: type: atom path: atom.xml limit: 0 在打开生成的atom.xml时输出这样一个错误PCDATA invalid Char value 8, 最后发现是md文件中多出了^H这个符号, vs code暂时不展示这种字符. 暂时也不知道是在什么情况下被添加进来的. 总之, 按照[^1]通过vim找到并删除之后就可以了. vs code render 按照有些大佬说的,设置Render Whitespace成all可以看到一些字符了,但是这个里还是只显示space和tab,似乎并不能显示换行符及像上面这种^H符号. 遇到问题 本来想着常开这个,至少能起到看我有没有在某些文件里错用tab,发现这个功能在markdown文件编写标题时,会出现和输入法重复的问题, 会出现下述这种效果. Refernence Hexo 的 RSS 生成错误 - ouyangsong - 博客园","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"}]},{"title":"异常处理实践初探","slug":"异常处理实践初探","date":"2020-06-24T16:26:46.000Z","updated":"2020-06-26T07:53:02.000Z","comments":true,"path":"2020/06/25/异常处理实践初探/","link":"","permalink":"https://sean10.github.io/2020/06/25/异常处理实践初探/","excerpt":"","text":"背景 在用异常的时候,会有这么几个疑问 * 异常是直接raise,让程序退出,还是捕获记录到日志中后继续运行 * 异常的代码影响到了代码的可读性, 有没有更合适的解决方式? 异常的使用场景 详见if-else与try-catch初理解 Todo:异常的代码可读性 像是如果一个业务逻辑里要执行多种封装的接口调用 123456789try: # code 1except CustomException: passtry: # code 2except CustomException2: pass 这种应该是有些类似装饰器,阅读代码中 捕获异常记录到日志里 一直有一个疑问，究竟是捕获异常,然后按照约定的接口输出错误信息，还是直接抛出,让程序直接退出呢? 根据目前写的比较多的几种场景的程序来看 * 守护程序, 进程间通信运作 * 接口程序,执行完即退出 无论是上面哪种场景,按照接口交互的开发标准来说,已知的异常都应该按照拟定的接口格式,错误时输出约定的错误码及信息,而不应该直接将exception直接抛出, 这样对其他调用解析你的接口的人来说,会产生未知错误. 只不过,这里的封装只在最上层封装, 然后在内部依旧可以使用raise,便于直接从底层快速将问题抛到上层的try...except处.(这里主要是相比return, 能快速退出多层接口调用) 注意点 PS. 虽然直接把异常抛到上层是很便捷的做法,但是对于一个公有库来说,最好还是在自己的抽象层定义自己的异常, 一个层次只处理他调用的层次的异常,而不是直接向上暴露底层异常. 当然,这里封装的异常同样也是已知异常,对于未知异常,只能尽可能靠单元测试来发现并捕捉,不然就只能抛到最上层捕获记录到日志里,修缺陷时再进行补全捕获了. 单元测试不可疏忽 而对于未知的错误, 肯定就是直接抛出了,但是这部分是需要在单元测试中尽可能覆盖完全来避免出现的. 样例 那么,怎么才能把traceback栈信息记录到日志里呢? 目前我用的比较多的是python3.6, 这个版本的logging.log提供了exc_info的选项 123456try: # coode in hereexcept Exception as e: logging.error(e, exc_info=True) # or logging.exception(e) 接口拟定正常 直接抛出Exception打断运行 正常来说,我们提供接口时,会约定一套返回值及内容格式,以及这个接口执行出现问题时的反应,如抛出什么异常,来让调用者捕获.这是Python的推荐做法. exception作为返回值 但是我看到[^4]这样一篇文章,里面提到了将Exception作为返回值,并且还存在一套针对这种用法的比较完备的库returns. 就仿佛静态类型里的非0值 单纯就这个做法来说,可能不是比较Pythonic的,但是按照readme来看,比较贴合目前python对静态类型的青睐?因为可以完全利用上类型标注的检查效果. 对于遗漏的异常返回值检查,可以做到很好的效果. 而且这样,又不会丢失Exception饱含的错误信息. 但是,又有一个问题,程序调用栈可能就会被破坏了,就像下面说的. 我调用一个库要一个int类型的结果,结果这个库里的接口在失败时并不会直接抛出,打断运行,而是返回一个Exception,我必须增加额外的判断检查,才能使用,否则一定会让调用者出错,这样其实也是违背了静态类型的接口设计的吧. 谁的问题应该由谁抛出更合适吧. 不捕获异常,上层也不做捕获,直接抛出 但是又看到一种说法[^5],有人说是由于python底层针对各种语句,存在各式各样的异常,基本不可能捕获,这个语言就是这么脆弱,捕获异常也只能做到非常有限的效果的话, 直接让程序出错直接退出就好了,如果这个场景没有考虑到的话. 但是按照我的理解, 如果底层的异常太多没处理好,其实就说明底层就开始有问题吧,应该一层层逐渐封装异常,最上层的使用不应该直接接触底层异常,而是下层逻辑的抽象异常才对. 这本就属于业务异常要考虑的逻辑. 这里python之父居然参与讨论了,回答了问题了. Let me draw a line in the sand. The PEP will not support any form of exception checking. The only thing possibly under discussion here is whether there is some other use of stubs (maybe an IDE suggesting a raise or try/except) that might benefit from declaring exceptions. But so far everything brought up has just been about the relative advantages of checked exceptions, and on that issue is close. We won’t do it. The PEP doesn’t mandate any particular behavior from a type checker, so I’m not prohibiting you from doing something you find useful. Whether it is actually useful may well depend on the codebase you are checking. I just don’t want to have to put anything in the PEP that would seem to make checked exceptions part of the signature of a function. Maybe as a compromise we can just say in the PEP that a conformant type checker should not interpret the body of functions in stubs, and you can have a non-conformant option that interprets raise statements in stub function bodies. PEP里是不是没有这样的讨论? Never throw an exception of my own Always catch any possible exception that might be thrown by a library I’m using on the same line as it is thrown and deal with it immediately. It’s all well and good that exceptions are widely used in core Python constructs, but why is a different question. Reference python - Log exception with traceback - Stack Overflow logging — Logging facility for Python — Python 3.8.3 documentation Python 工匠： 异常处理的三个好习惯 - 掘金 Python exceptions considered an anti-pattern - DEV declaring exceptions in stubs · Issue #71 · python/typing","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"编程范式","slug":"编程范式","permalink":"https://sean10.github.io/tags/编程范式/"},{"name":"code","slug":"code","permalink":"https://sean10.github.io/tags/code/"},{"name":"paradigm","slug":"paradigm","permalink":"https://sean10.github.io/tags/paradigm/"},{"name":"exception","slug":"exception","permalink":"https://sean10.github.io/tags/exception/"}]},{"title":"静态类型检查价值初认识","slug":"静态类型检查价值初认识","date":"2020-06-23T17:09:40.000Z","updated":"2020-06-27T14:41:44.000Z","comments":true,"path":"2020/06/24/静态类型检查价值初认识/","link":"","permalink":"https://sean10.github.io/2020/06/24/静态类型检查价值初认识/","excerpt":"","text":"现在接触了一些类型和风格的代码之后，稍稍发现，其实以前讨厌的静态类型风格才是大势所趋，以前最喜欢的灵活的python依旧喜欢，但是作为工程代码时，也希望对接的人也利用起最新的类型标注等特性开发。 以前python编写接口时, 只能在用类型注释或者注释来告知使用的人,这套接口的入参. 现在python3.6开始可以用typing的类型标注功能了. 简单举个例子, 返回的是什么样的generator都可以定义了,利用mypy可以在IDE中编写时直接做检查了.虽然还是不能做到运行时强制检查. 12345def function(a: str, b: int) -&gt; Generator[ptional[str, int]]: c: list = [a, b] for k in c: yield k 对于愈发庞大的代码来说,静态类型声明带来的直观的类型阅读及清晰的调用逻辑,在后续维护时带来的好处非常大. 当然,即便原先没有这种类型标注,对于一套良好的动态类型代码,也是会说明清楚所有的类型的, 只是因为不像静态语言编译时会自动检查, 因为当时还没有类型标注这样的标准,开发自动检查的插件的难度也非常庞大, 这种情况下全靠开发者自觉. 对于一套大型代码, 最主要的是不能依赖开发者的个人素质, 要通过各式各样的检查工具,来提高开发者们的下限水平. 所以, 相比于依赖注释,这个只能靠认为review或不标准的检查工具的形式, 标准支持的类型标注的价值要大得多了. 再之后,对于类型检查,准备在防御式编程初探中讨论. Reference typing — Support for type hints — Python 3.8.3 documentation Python 有必要自己写类型判断吗？ - V2EX","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"编程范式","slug":"编程范式","permalink":"https://sean10.github.io/tags/编程范式/"},{"name":"code","slug":"code","permalink":"https://sean10.github.io/tags/code/"},{"name":"paradigm","slug":"paradigm","permalink":"https://sean10.github.io/tags/paradigm/"}]},{"title":"if...else(LBYL)与try...catch(EAFP)初理解","slug":"if-else与try-catch初理解","date":"2020-06-23T17:00:36.000Z","updated":"2020-06-27T14:44:16.000Z","comments":true,"path":"2020/06/24/if-else与try-catch初理解/","link":"","permalink":"https://sean10.github.io/2020/06/24/if-else与try-catch初理解/","excerpt":"","text":"这两种其实在python里属于防御性编程下属的两种风格 if…else属于LBYL(Look before you leap) try…catch属于EAFP(easier to ask for forgiveness than permission) 就目前的理解上来说，主要的差异点好像在于以下 EAFP 一旦出现异常，存在性能上较差的问题，但是如果在正常逻辑，倒是没有固定成本 业务逻辑会非常顺畅，所有的异常判断全部在业务逻辑外 这里应该有一点前提，业务逻辑封装的足够合适，否则每行做异常封装的话，看上去也并不美观 LBYL 固定的检查耗时成本，但是其实消耗不大，因为if是最适合编译器和处理器做分支预测优化的部分了*。 存在race condition的潜在问题 参数检查会混杂在业务逻辑中 不过这里也有一个疑惑点，如果封装的恰当，应该很多逻辑都是在入参检查处，这样的话倒也不会影响到业务逻辑部分的阅读。 所以，针对不同类型的业务代码，其实是根据场景都适用的。 当业务逻辑中，异常场景不少见的时候，用LBYL处理更合适 当业务逻辑中，大部分场景是走的正常分支，只有少部分时候由于环境、网络波动等因素出现异常时，用EAFP更合适。 python官方是更推荐EAFP的 也有人更推荐LBYL[^5] Todo 需要考虑的场景 * 如果是EAFP，因为未进行各种检查引起的问题，是否会需要回滚？ * 还是说，如果拆分的足够合适，做了基本的入参检查之后，代码中在调用其他函数时，进行异常处理就可以了？是否需要捕捉，然后抛出一个自定义的未知异常呢？ 静态分析Exception 好像在mypy里支持了静态分析异常? Reference Python Tips - 防御性编程风格 EAFP vs LBYL - 知乎 (11 封私信 / 1 条消息) 如何理解 EAFP 和 LBYL 两种编程风格的区别？ - 知乎 方式 1 和方式 2 的却别到底在哪里？ - V2EX Write Cleaner Python: Use Exceptions 13 – Joel on Software","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"编程范式","slug":"编程范式","permalink":"https://sean10.github.io/tags/编程范式/"},{"name":"code","slug":"code","permalink":"https://sean10.github.io/tags/code/"},{"name":"paradigm","slug":"paradigm","permalink":"https://sean10.github.io/tags/paradigm/"}]},{"title":"hexo结合PasteImage使用相对路径图片","slug":"hexo结合PasteImage使用本地图片","date":"2020-06-23T16:46:35.000Z","updated":"2020-06-23T16:59:10.000Z","comments":true,"path":"2020/06/24/hexo结合PasteImage使用本地图片/","link":"","permalink":"https://sean10.github.io/2020/06/24/hexo结合PasteImage使用本地图片/","excerpt":"","text":"背景 最近发现用外部OSS图床，在本地处理归档文件资源时，不是那么的方便。且自己用的腾讯云COS的上传插件没做对剪切板中图片上传的功能，导致每次粘贴图片都得多一步去获取文件的绝对路径或者选中文件。 然后发现vs code有个Paste Image的插件可以做到直接将剪切板的图片放到本地指定相对路径的功能。 但是对于发布到github page上的文章呢，图片资源怎么才能使用相对路径呢？ 就发现hexo 3提供了一部分功能（即便现在4了，好像也暂时没有更进一步优化的计划，relative path没怎么搜到有人提PR了）。 按照hexo的意思是不使用标准markdown语法，而是使用下面这种提供的外部语法来处理…… 123&#123;% asset_path slug %&#125;&#123;% asset_img slug [title] %&#125;&#123;% asset_link slug [title] %&#125; 不太能接受，然后发现配合一个好多年前的插件hexo-asset-image就可以做到对于用户可以无感知的使用相对路径的图片了。 hexo配置 hexo版本大于3，node版本不知道有没有影响（我本地14.4版本无法正常工作，9.5可以） _config.yaml中post_assets_folder设置为true npm install hexo-asset-image vim node_modules/hexo-asset-image/index.js 按照[^2]修改代码 原因在于作者不再维护了，npm源里一直没有重新打包的内容 12- var endPos = link.lastIndexOf('.');+ var endPos = link.length-1; 原始的md文件中的图片路径依旧可以用正常的相对路径![](hexo结合PasteImage使用本地图片/hexo结合PasteImage使用本地图片_2020-06-24-00-47-39.png)， 在hexo g时生成的文件中的图片资源路径会被这个插件自动转换成url后静态文件相对于静态文件根目录的绝对路径。 PasteImage配置 1234567&#123; \"pasteImage.namePrefix\": \"$&#123;currentFileNameWithoutExt&#125;_\", \"pasteImage.defaultName\": \"YMMDDHHmmss\", \"pasteImage.path\": \"$&#123;currentFileDir&#125;/$&#123;currentFileNameWithoutExt&#125;\", \"pasteImage.basePath\": \"$&#123;currentFileDir&#125;\", \"pasteImage.forceUnixStyleSeparator\": true,&#125; 图示配置如下 Reference Hexo开启post_asset_folder后, 安装hexo-asset-image,不起作用的问题 | Tomtan’s Blog 域名是xxx.io的情况下，图片路径会从原本/xxx.jpg变成 /.io/xxx.jpg · Issue #47 · xcodebuild/hexo-asset-image","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"},{"name":"vs code","slug":"vs-code","permalink":"https://sean10.github.io/tags/vs-code/"}]},{"title":"python单元测试mock和stub小记","slug":"python单元测试mock","date":"2020-06-23T13:06:11.000Z","updated":"2021-02-10T14:27:22.759Z","comments":true,"path":"2020/06/23/python单元测试mock/","link":"","permalink":"https://sean10.github.io/2020/06/23/python单元测试mock/","excerpt":"","text":"背景 单测主要遇到需要mock数据的场景目前遇到比较多的是两类 * HTTP接口 * 对底层业务逻辑API HTTP接口相关的mock工具非常多了，暂时就不具体说了。这篇主要记录的是针对依赖的API的mock。 在python单元测试数据mock有两座山，一个是unittest.mock，一个是pytest的mockeypatch。当然，还有一些easymock之类的库，但是没去研究，暂时搁置。 很多文章里提到Test Double at XUnitPatterns.com，好像TDD开发中的概念，这里做了非常详细的划分。 不过，主体上其实对数据的模拟主要是2点。 * mock * stub mock与stub mock主要用于测试对象的行为验证 stub主要用于提供模拟数据 mock使用 虽然上面的理论上是这样说，但是对于python的unittest库里，并没有按照这两个来分开实现，统一都是叫做mock.patch。 不过使用的方法上的确有差异 123456# mockmock_instance.assert_called_with# stubmock_instance.return_value = &apos;xxx&apos;mock_instance.side_effect = &#123;&apos;a&apos;: &apos;xxx&apos;&#125; mock应该主要指的是检查函数的调用、异常的触发情况，而stub主要就负责提供我们要的模拟数据 具体使用方式 主要使用的是pytest及pytest-mock，pytest-mock提供了一个mocker的fixture。 PS. fixture是pytest的一个封装，将一个函数封装，作为全局参数使用，在被写入某些函数的参数时，这些被封装的函数会执行一遍（对于像patch这类修改运行时的操作，能够保留） patch基本使用 12 patch调用封装的接口 a使用b模块中提供的接口，而单元测试脚本patch掉b模块，手动封装b模块会提供的数据 123456789101112131415161718192021222324252627# a.pyfrom b import Bclass A: def output(self): b = B() print(b.get_data())# b.pyclass B: def __init__(self): pass def get_data(self): return \"B\"# test_a.pyfrom pytest_mock import mockerdef test_A_output(mocker): # Important!!这里要注意，你要patch掉的内容是在这个模块被导入的地方，而不是这个模块定义的地方 inst = mocker.patch(\"a.B\") inst.get_data().return_value = \"A\" a = A() a.output() # A 上面要注意的地方，原因主要在于模块使用时的运行时上下文，在这个模块被导入前，这个模块是不存在于代码的运行时中，只有当这个模块被导入了，这个模块才存在于运行时，patch的操作才能生效。除非是在你的当前文件中，这样定义和导入默认都已经完成了，就不会遇到这个问题了。 样例 return_value 下面所有的mock都可以用上面提到的mocker替换 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# mymodule.py#!/usr/bin/env python# -*- coding: utf-8 -*-import osimport os.pathclass RemovalService(object): \"\"\"A service for removing objects from the filesystem.\"\"\" def rm(filename): if os.path.isfile(filename): os.remove(filename) return True return False# test_mymodule.pyfrom mymodule import RemovalServiceimport mockimport unittestclass RemovalServiceTestCase(unittest.TestCase): @mock.patch('mymodule.os.path') @mock.patch('mymodule.os') def test_rm(self, mock_os, mock_path): # instantiate our service reference = RemovalService() # set up the mock mock_path.isfile.return_value = False ret = reference.rm(\"any path\") assert ret == False # test that the remove call was NOT called. self.assertFalse(mock_os.remove.called, \"Failed to not remove the file if not present.\") # make the file 'exist' mock_path.isfile.return_value = True ret = reference.rm(\"any path\") mock_os.remove.assert_called_with(\"any path\") assert ret == True side_effect 根据入参返回不同的结果 1234567891011121314151617181920def my_side_effect(*args, **kwargs): if args[0] == 42: return \"Called with 42\" elif args[0] == 43: return \"Called with 43\" elif kwargs['foo'] == 7: return \"Foo is seven\"temp = mock.patch(\"myModule.mod\")temp.get_value.side_effect = my_side_effectprint(temp.get_value(42))# 或者直接用匿名函数my_side_dict = &#123; \"42\": \"Called with 42\", \"43\": \"Called with 43\"&#125;temp = mock.patch(\"myModule.mod\")temp.get_value.side_effect = lambda x: my_side_dict[x]print(temp.get_value(42)) 测试是否返回异常 123myMethod = Mock(side_effect=KeyError('whatever'))with self.assertRaises(KeyError): myMethod() Reference 浅谈mock和stub | 忆桐之家的博客 unittest.mock — mock object library — Python 3.8.3 documentation Monkeypatching/mocking modules and environments — pytest documentation Python Mocking: A Guide to Better Unit Tests | Toptal 简述软件开发中的单元测试 | 无人之岛","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"mock","slug":"mock","permalink":"https://sean10.github.io/tags/mock/"},{"name":"unittest","slug":"unittest","permalink":"https://sean10.github.io/tags/unittest/"}]},{"title":"python常用调试","slug":"python常用调试","date":"2020-06-23T12:17:08.000Z","updated":"2020-06-23T16:36:21.000Z","comments":true,"path":"2020/06/23/python常用调试/","link":"","permalink":"https://sean10.github.io/2020/06/23/python常用调试/","excerpt":"","text":"Python常用调试方式 pdb 1python3 -m pdb xxx.py break 或 b 设置断点 设置断点 continue 或 c 继续执行程序 list 或 l 查看当前行的代码段 step 或 s 进入函数 return 或 r 执行代码直到从当前函数返回 exit 或 q 中止并退出 next 或 n 执行下一行 pp 打印变量的值 help 帮助 批量执行输出 123456(Pdb) commands 1(com) p some_variable(com) p another(com) end(Pdb) c# 会打印出some_variable和another 侵入式断点 断点 12import pdbpdb.set_trace() 条件断点 1234while a &gt; 0: if a == 15: print(a) pdb.set_trace() 条件断点 12# b(reak) [([filename:]lineno | function) [, condition]]b temp.py:13, a == 15 多线程调试 pdb原生不支持多线程调试，但是基于这个开发的不少第三方库支持, 可能rpdb？详见下述 PythonDebuggingTools - Python Wiki 稍后讲下pycharm多线程调试 pycharm常用 条件断点 多线程调试 pycharm是开发了pydevd这个插件来完成的远程调试、多线程调试的功能 健壮的logging机制 对于代码量一大，手动gdb肯定不方便，又不像二进制程序会出现coredump，所以gdb的backtrace经常需要用来排查段错误。 日志才是最主要的排查手段，通过等级控制，打开debug日志复现一次，日志足够详细就能直接定位到问题行。如果不够详细，就需要补充了。 Example 123456789101112131415import loggingfrom logging.handlers import RotatingFileHandlerlog_path = \"./res/a.log\"logger = logging.getLogger(\"a\")logger.setLevel(logging.DEBUG)fh = RotatingFileHandler(log_path, maxBytes=200000, backupCount=7, encoding=\"utf-8\")fh.setLevel(logging.INFO)console = logging.StreamHandler()console.setLevel(logging.DEBUG)fomatter = logging.Formatter('%(asctime)s\\t%(module)s\\t%(message)s', '%Y-%m-%d %H:%M:%S')fh.setFormatter(fomatter)console.setFormatter(fomatter)logger.addHandler(fh)logger.addHandler(console) 远程同步 vscode: sftp pycharm: deployment vscode:sftp Example 1234567891011&#123; \"name\": \"Profile Name\", \"host\": \"name_of_remote_host\", \"protocol\": \"ftp\", \"port\": 21, \"secure\": true, \"username\": \"username\", \"remotePath\": \"/public_html/project\", \"password\": \"password\", \"uploadOnSave\": true&#125; 基于pycharm的deployment 配置 参考文档 pdb — The Python Debugger — Python 3.8.3 documentation","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"debug","slug":"debug","permalink":"https://sean10.github.io/tags/debug/"}]},{"title":"ceph之SafeTimer定时器受系统时钟跳变影响","slug":"ceph之SafeTimer定时器受系统时钟跳变影响","date":"2020-06-21T16:18:28.000Z","updated":"2020-11-30T14:33:48.093Z","comments":true,"path":"2020/06/22/ceph之SafeTimer定时器受系统时钟跳变影响/","link":"","permalink":"https://sean10.github.io/2020/06/22/ceph之SafeTimer定时器受系统时钟跳变影响/","excerpt":"最近遇到这样一个情况，ceph运行环境里时间被修改到以前的时间之后，ceph -s和ceph df都看不到在这之后创建的资源池了。 在大佬的带领下，得知了这部分数据来源于ceph-mgr的pgmap例行同步。时间出现变化之后，debug日志里也的确不再出现pgmap的同步日志了。从这个方向找到了入手点。","text":"最近遇到这样一个情况，ceph运行环境里时间被修改到以前的时间之后，ceph -s和ceph df都看不到在这之后创建的资源池了。 在大佬的带领下，得知了这部分数据来源于ceph-mgr的pgmap例行同步。时间出现变化之后，debug日志里也的确不再出现pgmap的同步日志了。从这个方向找到了入手点。 ceph-mgr pgmap日志代码溯源（基于Luminous版本） 根据打开调试信息后, 看到的日志中大量的pgmap v137057: 565 pgs: 576 active+clean 搜索日志pgmap v，是在DaemonServer.cc中调用的send_report 自底向上 MgrStandby和Mgr是组合关系，MgrStandby里实例化了一个active的Mgr 在触发一次tick之后，还会记录一个事件，好像让下一次触发timer.add_event_adter(g_conf-&gt;get_val&lt;int64_t&gt;(&quot;mgr_tick_period&quot;) new FunctionContext([this](int r))){ tick();}的逻辑 对，在MgrStandby启动时调用init,触发第一次tick。之后应该就是这个计时器在工作。 这个mgr_tick_period的功能，看看咋工作的，好像只是std::chrono::seconds的封装。 这个mgr_tick_period应该只是个配置文件，记录多久同步的吧，果然，ceph daemon里可以看到是2s一次。 timer.add_event_after应该才是重头戏，这里居然是设置的根据时间戳来调用add_event_at添加回调的任务……当timer_thread执行到ceph_clock_now，用gettimeofday拿到系统时间，如果当前时间大于设置的时间，就是永远不会触发了? 所以这里存在一个潜在问题，是不是所有使用这个计时器的地方都存在会直接受到这个时钟往回调影响的问题。目前来看定时器应该只有这一个。 SafeTimer理解 12345678910111213141516171819202122232425262728class SafeTimer&#123; CephContext *cct; Mutex&amp; lock; Cond cond; bool safe_callbacks; // 是否是safe_callbacks friend class SafeTimerThread; SafeTimerThread *thread; //定时器执行线程 void timer_thread(); //本函数一次检查scheduler中的任务是否到期，其循环检查任务是否到期执行。 void _shutdown(); std::multimap&lt;utime_t, Context*&gt; schedule; //目标时间和定时任务执行函数Context std::map&lt;Context*, std::multimap&lt;utime_t, Context*&gt;::iterator&gt; events; //定时任务&lt;--&gt;定时任务在shedule中的位置映射 bool stopping; //是否停止// 下面这个应该才是真实在后台不停刷新检查定时器任务的线程class SafeTimerThread : public Thread &#123; SafeTimer *parent;public: explicit SafeTimerThread(SafeTimer *s) : parent(s) &#123;&#125; void *entry() override &#123; parent-&gt;timer_thread(); return NULL; &#125;&#125;; 以ceph-mgr为例，调用顺序是这样的。 ceph_mgr.cc里实例化MgrStandby，MgrStandby实例化SafeTimer,然后ceph_mgr.cc调用mgr.init，里面调用SafeTimer实例的init，在这里 12thread = new SafeTimerThread(this);thread-&gt;create(\"safe_timer\"); mgr的定时器任务就开始周期执行了。根据safe_callbacks这把锁的状态决定是否要申请到锁阻塞式执行任务，还是非阻塞式。 时间的触发基于cond.WaitUnitl(lock, schedule.begin()-&gt;first这个的实现。这个中主要依赖的应该是pthread_cond_timedwait这个超时等待接口。似乎有些库里的sleep就是通过这个实现的。 pthread_cond_timedwait()函数阻塞住调用该函数的线程，等待由cond指定的条件被触发（pthread_cond_broadcast() or pthread_cond_signal()）。如果超时了，就可以作为定时器使用。这里传入的是当前的abstime。 是否可能使用monotonic运行时间，而不是绝对时间？ 但是这块我好像看到，这个函数其实是支持传入monotonic时钟的，这个时钟开机开始计数，不受外部影响。 根据 123456789101112131415#man 3 pthread_condattrDESCRIPTION Condition attribute objects are used to specify parameters to the pthread_cond_init(3) function. The pthread_condattr_init() function initializes a condition attribute object with the default attributes and the pthread_condattr_destroy() function destroys a condition attribute object. The pthread_condattr_getclock() function shall obtain the value of the clock attributes object referenced by attr. The pthread_condattr_setclock() function sets the system clock to be used for time comparisons to the one specified in clock. Valid clock values are **CLOCK_MONOTONIC** and **CLOCK_REALTIME** (the default). The pthread_condattr_getpshared() function shall obtain the value of the process-shared attribute from the attributes object referenced by attr. The pthread_condattr_setpshared() function shall set the process-shared attribute in an initialized attributes object referenced by attr. 可见应该是支持的，但是这个时钟不知道在分布式环境，能不能保证多节点内及时被chrony或者ntp协调一致。根据这个[^5]来看，应该是能通过ntp服务来保障长时间稳定一致的。 ceph社区是否存在相关思路的方案 根据[^6]的结果来说，mds是应用上了这套，也向下移植到了Luminous版本。 根据[^7]，在bluestore的perf上也用上了这个时钟来进行latency延时统计。在Nautilus版本里增加的功能。 在Luminous版本里，我也搜到了这个在[^7]里使用的coarse_mono_clock::now()时钟。 根据[^8]，在Mimic版本里，好像mon也迁移了部分。 根据[^10]，在Mimic版本里，rados bench也开始使用这个时钟。 所以都只是部分组件已支持, 只是mgr没有支持, 目前来看也没有统一迁移到支持的计划. Reference 《Ceph源码分析》 ceph中的SafeTimer类详解_turou3442的博客-CSDN博客_ceph mds 定时器safe_timer线程cpu占用率高 ceph中的SafeTimer 用法和分析_jason的笔记-CSDN博客_safe_timer linux多线程编程，你还在用sleep么？用pthread_cond_timedwait吧 - shzwork的个人空间 - OSCHINA linux - What is the difference between CLOCK_MONOTONIC &amp; CLOCK_MONOTONIC_RAW? - Stack Overflow Bug #26959: mds: use monotonic clock for beacon message timekeeping - fs - Ceph os/bluestore: use the monotonic clock for perf counters latencies by mogeb · Pull Request #22121 · ceph/ceph Ceph v14.2.0 Nautilus released - Ceph mon: a few conversions to monotonic clock by batrick · Pull Request #18595 · ceph/ceph tools/rados: use the monotonic clock in rados bench by mogeb · Pull Request #18588 · ceph/ceph 附录 123456789101112131415161718192021digraph G &#123; splines=&quot;FALSE&quot;; // rankdir=&quot;BT&quot;; node [shape=&quot;cds&quot;, color=&quot;#dddddd&quot;, penwidth=&quot;1&quot;,style=&quot;filled&quot;, height=0.5, fontname=&quot;Futura&quot;, fontsize=10] /* Relationships */ &quot;ceph_mgr.cc&quot; -&gt; &quot;ceph_mgr.cc:MgrStandby mgr&quot; &quot;ceph_mgr.cc&quot; -&gt; &quot;ceph_mgr.cc:mgr.init()&quot; -&gt; &quot;MgrStandby.cc:MgrStandby::init()&quot; &quot;ceph_mgr.cc:MgrStandby mgr&quot; -&gt; &quot;MgrStandby.cc:MgrStandby::MgrStandby()&quot; &quot;MgrStandby.cc:MgrStandby::init()&quot; -&gt; &quot;timer.init();&quot; &quot;timer.init();&quot; -&gt; &quot;thread = new SafeTimerThread(this);&quot; -&gt; &quot;parent-&gt;timer_thread();&quot; -&gt; &quot;cond.WaitUntil(lock, schedule.begin()-&gt;first);&quot; -&gt; t_c t_c [label=&quot;pthread_cond_timedwait(&amp;_c, &amp;mutex._m, &amp;ts)&quot;, color=&quot;#dfc1c1&quot;] &quot;MgrStandby.cc:MgrStandby::init()&quot; -&gt; &quot;MgrStandby.cc:MgrStandby::handle_mgr_map(MMgrMap* mmap)&quot; &quot;MgrStandby.cc:MgrStandby::init()&quot; -&gt; &quot;tick();&quot; &quot;tick();&quot; -&gt; &quot;add_event_adter(g_conf-&gt;get_val&lt;int64_t&gt;(\\&quot;mgr_tick_period\\&quot;) new FunctionContext([this](int r)))&#123;tick();&quot; -&gt; &quot;SafeTimer::add_event_after&quot; -&gt; &quot;add_event_at(when, callback);&quot; &quot;SafeTimer::add_event_after&quot; -&gt; &quot;utime_t when = ceph_clock_now(); when += seconds;&quot; -&gt; &quot;gettimeofday(&amp;tv, NULL);&quot; &quot;MgrStandby.cc:MgrStandby::handle_mgr_map(MMgrMap* mmap)&quot; -&gt; &quot;active_mgr.reset(new Mgr...&quot; [label = &quot;组合,实例化&quot;]; &quot;add_event_adter(g_conf-&gt;get_val&lt;int64_t&gt;(\\&quot;mgr_tick_period\\&quot;) new FunctionContext([this](int r)))&#123;tick();&quot; -&gt; &quot;Mgr.cc:Mgr::tick()&quot;-&gt; &quot;DaemonServer.cc:void DaemonServer::send_report()&quot;&#125;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"源码","slug":"源码","permalink":"https://sean10.github.io/tags/源码/"},{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"定时器","slug":"定时器","permalink":"https://sean10.github.io/tags/定时器/"}]},{"title":"使用reveal-md将markdown转slides","slug":"使用reveal-md将markdown转slides","date":"2020-06-21T08:57:16.000Z","updated":"2020-06-23T13:03:23.000Z","comments":true,"path":"2020/06/21/使用reveal-md将markdown转slides/","link":"","permalink":"https://sean10.github.io/2020/06/21/使用reveal-md将markdown转slides/","excerpt":"","text":"前段时间看到了vue-mark-display这套功能，直接基于markdown生成slides，都不用去专门学习beamer那套，直接就能基于现有的markdown生成，感觉相当不错。 不过在折腾这套工具的时候，遇到一个问题，自己展示的时候用html没有问题，但是归档发布给其他人的时候，当然最好还是以pdf的形式嘛。这套工具不知道是以为没适配高分屏还是什么原因，通过Chrome和decktype导出pdf时，文字布局一定会与页面上看到的不一致。 具体也没细看了，这套工具终究是个人使用为主，可能开发者的使用场景不怎么需要导出，比如纯外网或内网部署了自己的静态网站之类的情况下。 考虑到这套工具偏个性化，于是去找找适用性较广，功能做的比较完善的这类产品。 发现了reveal.js这套目前来看star数应该是最多的，也支持所有我需要的功能，如markdown。还有人基于这套，做了一个一键使用的reveal-md，更加满足我的需求了。 这篇文章主要讲的就是针对我的几个痛点，我怎么使用这套工具了。 emm，发现几个问题，看看remark和remark-slide和spectacle这俩star更多的有没有解决这个问题呢？reveal-md作者没兴趣修这些问题…… 指定主题 1234# 指定官方提供的reveal-md slides.md --theme solarized# 自定义scssreveal-md slides.md --theme theme/my-custom.css 文件内嵌yaml输出参数 12345678910111213141516---title: temptheme: solarizedrevealOptions: transition: 'fade'---## slide 1slide ---## slide 2这种效果 输出pdf（不建议使用，不支持mathjax） 1reveal-md slides.md --print slides.pdf html看到的公式和图片都是正常的。但是基于Puppeteer导出的时候，公式无法加载。按照reveal.js里说的，是已经支持了部分版本的mathjax了的，所以只能从这个工具使用的导出方式上来怀疑了。 可能因为headless浏览器那边加载的问题？没加载指定的js之类的？导致无法解析出mathjax公式。可能是这个reveal-md里对puppeteer的使用上存在一些问题？因为看decktape底层应该也是基于puppeteer来做的。 使用reveal.js的print-pdf（推荐使用） emm，有人说reveal.js原生的?print-pdf已经修复了这些问题，但是reveal-md，怎么像是css不加载？ 123reveal-md temp.md --static staticpython3 -m http.server#然后在打开的页面里按下面增加print-pdf，保存成pdf 要在html后的#前增加?print-pdf，在#后面加是没用的……总算是意识到了 1http://localhost:8000/index.html?print-pdf#/ 遇到因为文件头部的yaml导致生成的html都无法使用的问题 奇怪，前两天操作的时候怎么好像没遇到这个问题呢？ node版本的问题嘛？不像啊 12是因为我去掉了水平Separator的设置，但是保留了下面这个verticalSeparator: &lt;!--v--&gt; 通过Decktape输出pdf(支持mathjax，但暂时存在标题与图片间隙过大问题未修复，pinned状态) 使用reveal-md提供的生成Static文件的方式，再通过decktape将静态网页转成pdf。 12reveal-md temp.md --static staticdecktape index.html new.pdf 根据下面[^2]里提到的问题，目前找到的有两种解决方式 1. 使用screenshots输出，再写个脚本拼接成pdf，可能会丢失一些动态效果？如果尺寸比图片小，也会丢失下面的内容……不过这个和html是表现一致的，所以如果图片在html有问题，还可以调整。 2. 使用增加size的方式，直到找到可以正确显示的方式。但是这样的size针对不同的图片大小，还需要手动调整…… 3. 使用1.0.0版本的decktape，这个版本还在使用phantomjs，但是我发现在高分屏幕环境，似乎存在一点问题.只能显示一部分，原本的中间的内容跑到了右下角去了。 4. 使用原生的print-pdf，但是好像我这边生成的好像怎么都加载不了css，位置始终在左侧. 常用尺寸： * 2048x1536 * 1920x1080 * 2560x1440(screenshots) 存在图片和标题间距过大问题[^2] 绕过方式如下: A workaround seems to be increasing (very much) the size. For example using –size=‘2048x1536’ instead of –size=‘1024x768’ works for me. 但是这个存在一个问题，因为图片分辨率一旦超过设置的宽度，他这边就会无法显示了。 可能相比之下还不如刚才那样直接输出。如果使用screenshots输出倒是没有一点问题。 备注 在markdown文件每页中增加Note:，这页的剩下的部分就都会显示在注释中，打开本地web端访问slides后，按s会弹出注释页面，放到其他屏幕上就可以了。然后分别按Cmd+Ctrl+f全屏即可了。[^5] 只不过这种只适合多屏幕场景了吧，不过对于投屏来说，的确就是多屏幕 生成的目录结构 本以为Reveal.js生成的slides是顺序的，但是发现实际是具有上下左右四个方向的…… 本以为直接是按照目录结构保证的，但是实际上来看，和我写的目录结构并不是完全匹配的。 还得具体了解一下。 横向的幻灯片代表一章, 纵向的幻灯片代表一章中的一节。那么横向的幻灯片在播放时是左右切换的, 而纵向的幻灯片是上下切换的。 Reveal.js 里页面有两种页面类型，横向的一级页面、纵向的子页面。后者务必嵌套在前者里面。所谓的纵横比较好理解，键盘上的左右箭头控制一级页面，上下键移动子页面。 说是这么说的.根据[^7]也是有人直接改了，让可以在section切换时，能够直接进入下一个section的开头，而不是按Esc看到的布局的右侧位置。 又仔细翻了下文档，其实是由开关控制，决定是否要继承当前所在的section下属的纵向index的，关闭navigationMode就可以了。[^8]的Navigation Mode有提开关,既然有空格可以工作，暂时就不动这个了。 还是暂时使用空格顺序切换吧。 scss编写 123cd reveal.jsyarnyarn run build -- css-themes 在调试过程中，发现主要痛点在于默认主题的标题全部被强制大写了，导致看上去不是很符合我的预期，找了下可以在英文外增加代码符号```来完成绕过。 Reference webpro/reveal-md: reveal.js on steroids! Get beautiful reveal.js presentations from any Markdown file weird spacing with reveal · Issue #151 · astefanutti/decktape astefanutti/decktape: PDF exporter for HTML presentations remark vs remark-slide vs reveal-md vs reveal.js vs spectacle | npm trends Presenter mode · Issue #404 · hakimel/reveal.js Reveal.js：把你的 Markdown 文稿变成 PPT - 少数派 Forces left/right to go to top of previous/next section · Issue #2504 · hakimel/reveal.js Vertical Slides | reveal.js","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://sean10.github.io/tags/工具/"},{"name":"node-js","slug":"node-js","permalink":"https://sean10.github.io/tags/node-js/"},{"name":"markdown","slug":"markdown","permalink":"https://sean10.github.io/tags/markdown/"},{"name":"pdf","slug":"pdf","permalink":"https://sean10.github.io/tags/pdf/"}]},{"title":"python单元测试框架比较","slug":"python单元测试框架比较","date":"2020-06-02T07:00:38.000Z","updated":"2020-06-02T07:01:28.000Z","comments":true,"path":"2020/06/02/python单元测试框架比较/","link":"","permalink":"https://sean10.github.io/2020/06/02/python单元测试框架比较/","excerpt":"旧文简单整理","text":"旧文简单整理 ## 背景 主要测试框架: unittest，和在unittest基础上开发而来的pytest和nose2 定位 pytest The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries. nose2 It’s unittest with plugins. nose2’s purpose is to extend unittest to make testing nicer and easier to understand. nose2的主要目的是扩展Python的标准单元测试库unittest，因此它的定位是“带插件的unittest”。 nose2 vs pytest nose2 may or may not be a good fit for your project. If you are new to python testing, we encourage you to also consider pytest, a popular testing framework. 官方对于\b\b新使用单元测试的更推荐使用pytest。 上一个大版本功能 nose（已进入维护阶段，不再开发新功能） 功能 共同点 都是基于unittest原生库开发而来。 差异点 详见[转]Python测试框架对比----unittest, pytest, nose, robot framework对比 - bonelee - 博客园[^5] 基于测试功能上来说，均具有。 总体来说，pytest入门、扩展性最强，nose2比较要求写单元测试的功底的样子？ 社区生态 pytest 6K+的star数量，518个贡献者。 名字中含有pytest的python库 5308个 nose2 625个star, 58个贡献者。 nose[已进入维护阶段，不再开发新功能] 1.3K的star, 70个贡献者 名字中含有nose的python库，707个。 结论 毫无疑问，用py.test就完事了。 Reference pytest-dev/pytest: The pytest framework makes it easy to write small tests, yet scales to support complex functional testing nose-devs/nose2: The successor to nose, based on unittest2 三种最流行的Python测试框架，我该用哪一个？ - 知乎 【pytest】（二） pytest与unittest的比较 - 知乎 [转]Python测试框架对比----unittest, pytest, nose, robot framework对比 - bonelee - 博客园 pytest vs nose detailed comparison as of 2020 - Slant","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"pytest","slug":"pytest","permalink":"https://sean10.github.io/tags/pytest/"}]},{"title":"上海新版社保卡办理因支付宝被迫踩坑","slug":"上海新版社保卡办理因支付宝被迫踩坑","date":"2020-05-30T04:46:26.000Z","updated":"2020-06-01T04:22:19.000Z","comments":true,"path":"2020/05/30/上海新版社保卡办理因支付宝被迫踩坑/","link":"","permalink":"https://sean10.github.io/2020/05/30/上海新版社保卡办理因支付宝被迫踩坑/","excerpt":"背景 网上申办上海新版社保卡，设备小米 8，支付宝一直提示此设备不支持刷脸，请更换设备后再试。官方没有任何其他的可以不使用支付宝的办理方式。","text":"背景 网上申办上海新版社保卡，设备小米 8，支付宝一直提示此设备不支持刷脸，请更换设备后再试。官方没有任何其他的可以不使用支付宝的办理方式。 更新 主任信箱回复了 尝试 搜了半天，有说支付宝这么报是因为下述等原因 * 设备root了 （我这台已经没root了，不过以前root过，直接移机的） * 设备上存在了xposed之类的软件，被判断不安全，不让刷脸 （的确以前root的时候装过，现在卸了也不行，难道支付宝的匹配规则这么严格？） * 就是设备不支持（小米8都不支持的话，这能线上办理的设备得多新啊） * 账户黑了（支付宝连政务办理都给卡？） 我是不能理解为什么小米8支持红外人脸识别（支持不支持3D人脸识别，是足够用在大部分非支付级别的人脸识别上了的）且没有root的设备也不能使用刷脸的。 这个刷脸只是这个办理的第一步，就直接被卡死了。 根据官网的说明（下图） 15813162114102da1db5c-aeb3-42d8-abd2-420399d9f3b4.jpg (600×3318) 网页开通，全都是让用支付宝进行刷脸认证。 https://www.962222.net/ 不管是网站还是”上海社保卡“APP第一步就是打开支付宝，然后支付宝直接给我打回了…… 短时间内肯定是不会回上海的，线下办理完全不现实。 也暂时没有按支付宝说的，换手机的想法。 以前学信网那些都能允许笔记本摄像头验证，现在的业务办理必须走人脸了？ 成功方式 最后，有个大佬回复说用工行的app可以办理，我照着做成功了，这个阶段里根本没有用到人脸识别，只需要提交照片就可以了。看来社保负责的部门只提供了一个由银行申办的通道，至于银行有没有提供线上功能，根本不关心…… 头疼点 唉，这还只是新版社保卡的办理，要不是有银行的通道，我肯定是最后只能线下去处理这个事。要是以后别的身份证之类的事情也是这类全部用了支付宝之类的接口，然后这些接口的使用上做了限制，部分人始终没办法使用可怎么办呢…… 猜测吧，支付宝这个刷脸接口做成通用功能了，导致自家支付程序要求严格的安全，金融级别嘛，不够安全的设备不用，这个属于正常。毕竟只是额外功能，刷脸支付可以不用。 但是这个接口如果同时也开给了政府部门，对于不要求金融级别的安全的情况下，却必须先满足这个级别的条件，才能使用政府提供的功能，那这种场景是不能接受的吧。毕竟我这种还算年轻的人都没有找到刷脸过不了的情况下的其他办理手段，那年纪更大的人呢？岂不是反而给很多人带来办理的负担了？ 论人群来说，刷脸支付占全国比例，和使用政府提供的线上功能的人的比例，是存在绝对差距的（毕竟，政府功能除了线下没有其他通道了）。但是又没有渠道反馈这样的情况……试试962222这个官网提供的热线吧 尝试反馈 962222，联通提示号码不存在 猜测是因为手机号是外地的，需要加区号021. 962222， 电话拨号中，只有咨询选项，没有信息反馈选项 尝试主任信箱 https://www.962222.net/pages/cms/zrxx.html 发送了一封上面写的总结，不知道能不能收到反馈。 主任信箱回复 回复：您好！非常抱歉给您带来了不便，我们已将您反应的情况提交至相关部门，如有不便，敬请谅解。有关新版社保卡办理相关事宜，您也可以拨打我们的服务热线962222。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://sean10.github.io/tags/生活/"},{"name":"支付宝","slug":"支付宝","permalink":"https://sean10.github.io/tags/支付宝/"}]},{"title":"C语言的magic宏定义","slug":"C语言的magic宏定义","date":"2020-05-28T17:07:01.000Z","updated":"2020-05-28T17:10:13.000Z","comments":true,"path":"2020/05/29/C语言的magic宏定义/","link":"","permalink":"https://sean10.github.io/2020/05/29/C语言的magic宏定义/","excerpt":"可变参…和 ##__VA_ARGS 基本使用方式如下，我主要用来记日志了","text":"可变参…和 ##__VA_ARGS 基本使用方式如下，我主要用来记日志了 12345678910111213141516171819202122232425262728#include &lt;syslog.h&gt;#include &lt;stdarg.h&gt;#include &lt;stdio.h&gt;#define BUFF_LEN_O 1024#define LOGGER(priority, format, ...) do&#123; \\ logger(priority, format, __FUNCTION__, __LINE__, ##__VA_ARGS__); \\ &#125;while(0)#define PRINT(x, a) printf(\"\\n\")static void logger(int priority, const char *format, ...)&#123; openlog(\"test_log\", LOG_PID | LOG_NDELAY, LOG_LOCAL0); va_list ap; char buff[BUFF_LEN_O] = &#123;0&#125;; char placeholder[] = \"function&#123;%s&#125;,line&#123;%d&#125;\"; va_start(ap, format); snprintf(buff, sizeof(buff) - 1, \"%s %s\", placeholder, format); vsyslog(priority, buff, ap); va_end(ap);&#125;int main()&#123; LOGGER(LOG_INFO, \"hello world %s\", \"123\"); LOGGER(LOG_ERR, \"new\"); logger(LOG_INFO, \"hello world %s\", __FUNCTION__, __LINE__, \"123\"); return 0;&#125; #字符串化 会直接把表达式按照字符串输出，并过滤掉注释部分以及前后的空白。 12345678#include &lt;stdio.h&gt;#define PRINT(x) do &#123;printf(\"\\n\"#x\"\\n\");&#125;while(0)int main()&#123; PRINT(print(\"hello world\")/*new*/); return 0;&#125; ##Token拼接符号[^4] 这个就比较有意思了，可以通过这个结合gcc的typeof模拟出不少泛型的方式，在编译前预处理时扩展出不少函数或变量定义。参考[^4]文章的大佬用宏扩展出了弱图灵完备的函数。 按照大佬说的，这个库Cloak/cloak.h at master · pfultz2/Cloak非常多的例子 延迟展开 123456789#define EXPAND(...) __VA_ARGS__#define EMPTY()#define DEFER(id) id EMPTY()#define FOO() printf(\"macro\\n\");DEFER(FOO)() /*这个解到最后就是FOO()*/// DEFER(FOO)();EXPAND(DEFER(FOO)()); /*这个最后输出macro*/ _Generic[^6] 使用方式，_Generic((var), type1 : ..., type2 : ..., ……, default : ...)，感觉果然和大佬们说的一样，比较像是对基本类型进行switch。 比起这个，可能gcc内建的像typeof这些关键字用起来更具有扩展性。 12345678910111213141516171819202122232425262728293031323334353637#include &lt;stdio.h&gt;#include &lt;complex.h&gt; #define CUSTOM_GENERIC(_var_) _Generic((_var_), \\/*signed char*/ signed char : printf(\"type signed char, var:%d\\n\", _var_), \\/*signed short*/ signed short : printf(\"type signed short, var:%hd\\n\", _var_), \\/*signed int*/ signed int : printf(\"type signed int, var:%d\\n\", _var_), \\/*signed long int */ signed long int : printf(\"type signed long int, var:%ld\\n\", _var_), \\/*signed long long int*/ signed long long int : printf(\"type signed long long int, var:%lld\\n\", _var_), \\/*unsigned char*/ unsigned char : printf(\"type unsigned char, var:%c\\n\", _var_), \\/*unsigned short*/ unsigned short : printf(\"type unsigned short, var:%hu\\n\", _var_), \\/*unsigned int*/ unsigned int : printf(\"type unsigned int, var:%u\\n\", _var_), \\/*unsigned long int*/ unsigned long int : printf(\"type unsigned long int, var:%lu\\n\", _var_), \\/*unsigned long long int*/ unsigned long long int : printf(\"type unsigned long long int, var:%llu\\n\", _var_), \\/*float*/ float : printf(\"type float, var:%f\\n\", _var_), \\/*double*/ double : printf(\"type double, var:%lf\\n\", _var_), \\/*long double*/ long double : printf(\"type long double, var:%llf\\n\", _var_), \\/*_Bool*/ _Bool : printf(\"type _Bool, var:%d\\n\", _var_), \\/*float _Complex*/ float _Complex : printf(\"type float _Complex, var:%f+%fi\\n\", crealf(_var_), cimagf(_var_)), \\/*double _Complex*/ double _Complex : printf(\"type double _Complex, var:%f+%fi\\n\", creal(_var_), cimag(_var_)), \\/*long double _Complex*/ long double _Complex : printf(\"type long double _Complex, var:%lf+%lfi\\n\", creall(_var_), cimagl(_var_)), \\/*default*/ default : printf(\"type default!\") \\) int main(void)&#123; int a = 10; float f = 100.0f; float _Complex fCex = 100.0f + 1.0if; CUSTOM_GENERIC(a); //type signed int, var:10 CUSTOM_GENERIC(f); //type float, var:100.000000 CUSTOM_GENERIC(fCex); //type float _Complex, var:100.000000+1.000000i CUSTOM_GENERIC(12); //type signed int, var:12 return 0;&#125; Reference 宏定义的黑魔法 - 宏菜鸟起飞手册 C preprocessor - Wikipedia C11新增关键字：_Generic(泛型)_c/c++_南雨兮-CSDN博客 宏定义黑魔法-从入门到奇技淫巧 (3) | Feng.Zone","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"macro","slug":"macro","permalink":"https://sean10.github.io/tags/macro/"}]},{"title":"黑苹果AMD显卡风扇降速","slug":"黑苹果AMD显卡风扇降速","date":"2020-05-28T15:14:10.000Z","updated":"2020-05-28T15:14:43.000Z","comments":true,"path":"2020/05/28/黑苹果AMD显卡风扇降速/","link":"","permalink":"https://sean10.github.io/2020/05/28/黑苹果AMD显卡风扇降速/","excerpt":"旧文补发 在第一次尝试黑苹果的时候，按照大佬们的经验之谈，配置一个A卡，这样配置核显做硬解就能充分利用起显卡的性能来了。 但是很可惜的是，在做教程的时候，这些大佬们没提到关于温控的问题。","text":"旧文补发 在第一次尝试黑苹果的时候，按照大佬们的经验之谈，配置一个A卡，这样配置核显做硬解就能充分利用起显卡的性能来了。 但是很可惜的是，在做教程的时候，这些大佬们没提到关于温控的问题。 方案1 对于黑苹果来说，A卡独显的风扇默认是无法通过软件控制到的，即便注入了驱动，也只能控制机箱风扇。 对于A卡的风扇来说，需要单独定制操作。翻遍黑锅论坛，发现有大佬开发了针对AMD Vega64显卡风扇的温控操作。而rx系列就没有了…… 在搜索过程中，发现除了直接软件接管控制之外，似乎还有一种直接写入到驱动的方法，不过这个难度可能稍大，也可能挺费时间…… 我姑且选择了拔掉独显，单纯使用集显驱动了。但是方案姑且记录在这里吧。 方案2 如果你在 Windows 下使用过 AMD 显卡驱动程序，则你一定对于 AMD Watt Man 有印象。这是随驱动程序安装的用于用户自定义性能模式的工具。你可以调整风扇转速方案，设定核心和内存频率以及电压。其实质就是生成一个自定义的 Power Table 供 GPU 加载使用以控制其行为模式。如果我们可以将这个 Power Table 设定好并抽取出来，然后注入到 macOS 对于该显卡的驱动当中，就可以完成对于显卡行为的自定义控制。[^2] embed the Soft Power Table in the kext. 上面两句是关键，根据上面两句来看，我之前构思的，能够切换到win10把显卡的bios里设置的参数改了，用北极星编辑器和flash工具刷进去，然后切回mac来使用的思路，是不是不太可行呢。因为从上面来看，这些参数可能实际是在驱动加载的时候生效的，而不是在硬件上。但是从刷bios这一个动作来看，应该也是存在于bios中的。可能这是2种方式吧。根据[^3]来看，的确是有2种方式了。 Reference MacOS – AMD’s Radeon Adrenalin Software | GPU, Monitor &amp; Peripherals Knock me down, and I’ll keep getting back up - 知乎 [【心得】MSI ARMOR RX580 8G 降壓降頻心得 @電腦應用綜合討論 哈啦板 \\- 巴哈姆特](https://forum.gamer.com.tw/C.php?bsn=60030&amp;snA=511548)","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"hacintosh","slug":"hacintosh","permalink":"https://sean10.github.io/tags/hacintosh/"},{"name":"AMD","slug":"AMD","permalink":"https://sean10.github.io/tags/AMD/"}]},{"title":"ceph之df的MAX AVAIL","slug":"ceph之df的MAX-AVAIL","date":"2020-05-28T10:50:05.000Z","updated":"2020-06-02T07:20:01.000Z","comments":true,"path":"2020/05/28/ceph之df的MAX-AVAIL/","link":"","permalink":"https://sean10.github.io/2020/05/28/ceph之df的MAX-AVAIL/","excerpt":"ceph df输出的统计数据的计算法昂是比我一眼以为的要复杂一些。 尤其是MAX AVAIL这个值。目前遇到的问题是发现在L版本,当osd out了之后，ceph df拿到的MAX AVAIL始终没有变化。","text":"ceph df输出的统计数据的计算法昂是比我一眼以为的要复杂一些。 尤其是MAX AVAIL这个值。目前遇到的问题是发现在L版本,当osd out了之后，ceph df拿到的MAX AVAIL始终没有变化。 这样对于使用者来说是存在问题的，当出现降级的情况时，若业务层使用这个接口看到资源池仍有可用空间，但实际上依旧up的osd并不能提供这些空间，是会导致业务人员出现误判……直接导致业务数据写不下去的情况的。 代码里是这样写了，但是是否上面的想法只是我们理解错误产生的误用呢？ 向上追溯一下这段关键计算的提交记录吧，看看有没有相关场景。 先搜索主要代码 12// PGMap.ccint64_t proj = (int64_t)(avail / (double)p-&gt;second); 利用blame查找每行的记录，还是不错的。 Bug #10257: Ceph df doesn’t report MAX AVAIL correctly when using rulesets and OSD in ruleset is down and out - Ceph - Ceph 这篇里只加了跳过kb=0的选项 mon: incorrect MAX AVAIL in “ceph df” by liuchang0812 · Pull Request #17513 · ceph/ceph 这篇里好像是之前漏了/raw_used_rate这个副本size mon/PGMap: factor mon_osd_full_ratio into MAX AVAIL calc by liewegas · Pull Request #12923 · ceph/ceph 这个操作引入的full_ratio参数到MAX AVAIL计算中 mon/PGMap: Fix %USED calculation bug. · ceph/ceph@d10c6c2 修复%USED（raw的应该) 没有乘以副本数的问题。 osd,os,mon: extend ‘ceph df’ report to provide both USED and RAW_USED · ceph/ceph@7ca25df 这个应该是在L之后的版本，在这次commit中引入Statfs这个中间结构用来存储total、avail，免于直接接触kb mon/PGMap: GLOBAL -&gt; RAW STORAGE in ‘df’ output · ceph/ceph@738789b 这个也是L之后的版本，把ceph df输出的GLOBAL改成了RAW，防止错误理解 get_rule_weight_osd_map这个函数的新增并没有看出有立刻被用在计算资源池容量这里。 应该可以从这个接口被调用的地方来分析，新增的人是否没考虑过osd异常的场景？ mon/PGMap: move summary information into parent PGMapDigest object · ceph/ceph@8f25216 这里被重构，挪了一下位置…… mon/PGMap: factor mon_osd_full_ratio into MAX AVAIL calc · ceph/ceph@f223ac9 这里又被做了格式化，哎 mon: move “df” dump code from PGMonitor to PGMap · ceph/ceph@519a01d 这里又重构了…… 在这次提交以前这部分代码在src/mon/PGMonitor.cc mon/pgmonitor: use appropriate forced conversions in get_rule_avail · ceph/ceph@024caa7 哎，这次对这行改了下显式类型转换，从float改成double Bug #10257: Ceph df doesn’t report MAX AVAIL correctly when using rulesets and OSD in ruleset is down and out - Ceph - Ceph 这个看起来和OSD out相关，但很可惜，只处理了错误计算为0的问题，并没有考虑正常场景？ mon: include ‘max avail’ in df output · ceph/ceph@7a9652b 终于找到了引入的地方,这里增加的max avail的值。 PGMonitor: fix bug in caculating pool avail space · ceph/ceph@04d0526 这里处理的那个osd_map 提交 在最新的分支里，也没有相关信息。看起来得提个ISSUE看看有没有答复了。 12345678910111213Environment: Luminous 12.2.12I have a question about the pool's `MAX AVAIL` of `ceph df`.When i out a osd, the `MAX AVAIL` doesn't change. Only when i remove the osd from the crush map of the pool, the `MAX AVAIL` decrese.For example, I have a pool with 10 osd. When 9 osds out, `ceph df` still output the MAX AVAIL with 10 osds, not the remained 1 osd. Only when i remove the out osds from the crush map, the MAX AVAIL changed to the remained size. But in my understanding, when the osd out, the recovery begin. When the recovery begins, the out osd has no use for the pool. If `MAX AVAIL` doesn't change, It may provide error avail size for the users.The calculate logic is in `PGMap::get_rules_avail`. Maybe after called `get_rule_weight_osd_map`, we could recalculate the weight map to remove the osd which `osd_info.kb` is zero. Or could modify the `get_rule_weight_osd_map`, but i don't know whether there is some other impact. 新建了这个issue, 希望能得到回复吧。 Bug #45809: When out a osd, the `MAX AVAIL` doesn’t change. - Ceph - Ceph","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"}]},{"title":"windows terminal1.0暂时还无法替代tmux","slug":"windows-terminal1-0暂时还无法替代tmux","date":"2020-05-25T05:57:05.000Z","updated":"2020-05-25T06:26:02.000Z","comments":true,"path":"2020/05/25/windows-terminal1-0暂时还无法替代tmux/","link":"","permalink":"https://sean10.github.io/2020/05/25/windows-terminal1-0暂时还无法替代tmux/","excerpt":"前段时间, windows Terminal 1.0发布了，其实我知道这个的时候，还是非常期待的。毕竟公司的开发机是windows，需要一直连接着linux设备做开发。","text":"前段时间, windows Terminal 1.0发布了，其实我知道这个的时候，还是非常期待的。毕竟公司的开发机是windows，需要一直连接着linux设备做开发。 我之前的方案是自己搭了个本地虚拟机做跳板，这个虚拟机里装了tmux，然后我通过windows上可以ssh的工具ssh上去使用tmux， 再开多个panessh开发机。 tmux通过快捷键切换、创建、分割、临时全屏化pane来操作还是非常便捷的。 目前我是使用的putty作为ssh工具。之前使用过cygwin（MSYS)，不过在这些环境下启动tmux，当时是在创建切换pane上有些或多或少的问题。听说MSYS2之前也已经出了，似乎已经比较成熟了，大佬们也可以试试。 我最近已经比较图稳定了，之前遇到的或多或少的问题有比如我需要显示编码从UTF-8临时切换到GBK，在这个时候有些工具会把分隔栏变成错误字符。还有我需要简洁的全屏，只需要通过tmux来控制和切换窗口，像xshell和CRT等工具对我来说就有些功能过冗余了。当然，像能和这两个工具结合在一起的文件传输插件还是挺不错的，不过也可以通过samba和IDE的remote devetop的sync功能将就将就，对于偶尔才会有代码以外的文件需要替换时，winscp足够使用了。 去年好像windows 10 开始官方提供OpenSSH支持，我立马也就升级了。不过很可惜在powershell和cmd环境中，像Ctrl+C等快捷键会直接被powershell给捕获，导致即便用这两个窗口ssh到了设备上，表现也并不是那么好。另外powershell和cmd的默认字体和高亮的美观度也不是很喜欢…… 根据windows terminal的文档[^2]中所说的快捷键使用，基本上我用到的tmux功能都可以修改windows terminal的profile来模拟一致。且针对windows上需要临时复制单pane的内容时，这个相比putty能够不用单独全屏化窗口再复制，算是一个优势。 不过现在唯一的不足就在于，在这个版本暂时没有临时zoom全屏化单个pane的功能，根据[^1]中说的，#996暂时也没有纳入1.x的计划中，在2.0中才会发布。这就有点可惜了，只能再期待了。 Reference Scenario: Add support for panes · Issue #1000 · microsoft/terminal Windows Terminal Key Bindings | Microsoft Docs","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"windows","slug":"windows","permalink":"https://sean10.github.io/tags/windows/"},{"name":"terminal","slug":"terminal","permalink":"https://sean10.github.io/tags/terminal/"},{"name":"tmux","slug":"tmux","permalink":"https://sean10.github.io/tags/tmux/"}]},{"title":"ceph之df原理","slug":"ceph之df原理","date":"2020-05-24T12:04:33.000Z","updated":"2020-12-28T11:36:03.206Z","comments":true,"path":"2020/05/24/ceph之df原理/","link":"","permalink":"https://sean10.github.io/2020/05/24/ceph之df原理/","excerpt":"ceph df主要得到的是global以及每个pool的used以及max_available.","text":"ceph df主要得到的是global以及每个pool的used以及max_available. 123#Montor.cc文件入口ceph dfpgservice-&gt;dump_fs_stats(&amp;ds, f.get(), verbose);pgservice-&gt;dump_pool_stats(osdmon()-&gt;osdmap, &amp;ds, f.get(), verbose); global FileStore ceph上个版本使用filestore时，计算是基于osd的所在磁盘的statfs来计算的。因此，rbd层面的大的稀疏文件，在落到osd层上之后实际就并不占用那么多了。 12345678# 主体函数PGMapDigest::dump_fs_stats osd_sumPGMap::calc_stats osd_sum = osd_stat_t();OSDService::update_osd_statKStore::statfs BlueStore 1234567891011PGMapDigest::dump_fs_stats osd_sumPGMap::calc_stats osd_sum = osd_stat_t();#疑似现在只有这个函数会刷新数据了OSD::tick_without_osd_lock()OSDService::set_statfsBlueStore::statfs（找不到怎么那边怎么调用到bluestore的，直接来找同名函数了，理论上应该是继承的接口吧？）BlueFS::get_freebluefs这块还不太理解…… pool 是否可以理解为，如果不使用ceph df提供的接口，手动去计算可用pg的容量，就可以直接代表可用容量？ FileStore 1234PGMapDigest::dump_pool_stats_fullPGMapDigest::dump_object_stat_sum疑似是在osd写入时做的更新？PrimaryLogPG::write_update_size_and_usage BlueStore 待阅读 12345678PGMapDigest::dump_pool_stats_full PGMap.cc: pool_raw_used_ratePGMapDigest::dump_object_stat_sum 这里似乎计算的是去除降级后的？仅在MgrStatMonitor::preprocess_statfs中出现了PGMapDigest::get_statfs（这个像是已经deprecated?) PGMapDiest::get_pool_free_space Nautilus变化 根据[^5]可以知道 ceph df [detail] output (POOLS section) has been modified in json format: ‘bytes used’ column renamed to ‘stored’. Represents amount of data stored by the user. ‘raw bytes used’ column renamed to “stored_raw”. Totals of user data over all OSD excluding degraded. new ‘bytes_used’ column now represent amount of space allocated by all OSD nodes. ‘kb_used’ column - the same as ‘bytes_used’ but in KB. new column ‘compress_bytes_used’ - amount of space allocated for compressed data. I.e. comrpessed data plus all the allocation, replication and erasure coding overhead. new column ‘compress_under_bytes’ amount of data passed through compression (summed over all replicas) and beneficial enough to be stored in a compressed form. 所以在这个版本中将之前版本中存在的多种容量统计给分类了. pool级别分为 * stored(old bytes used) 逻辑空间占用量, 主要针对的是写入多少, 不考虑由于COW引起的实际占用量较小 * store_nromalized = pool_stat.get_user_bytes(raw_used_rate, per_pool) * store_stats.data_stored / raw_used_rate * Bluestore.cc * res_statfs-&gt;data_stored += l.length * 传统模式 stats.sum.num_bytes + stats.sum.num_bytes_hit_set_archive; * 12版本好像没加命中集归档的容量 * 12版本这里直接拿的sum.num_bytes * 通过ceph report可以看到资源池的这个统计 * stored_raw(old raw bytes used) 用户使用的总容量, 包含所有osd除去降级的(这个应该是带副本的吧) * pool_stat.get_user_bytes(1.0, per_pool) * 这里应该是统计store_stats.data_stored的时候一些down的osd就不统计了, 所以为1.0的raw_used_rate. * new bytes used 实际这个资源池里的OSD分配的空间大小(这里应该是不包含其他资源池因为复用osd占用的空间吧?) * pool_stat.get_allocated_bytes * store_stats.allocated; * compress_bytes_used compress的数据 , 分配的空间大小(包含副本/EC的开销), 也就是说除去副本数就是用户数据实际在设备里存储吧 * statfs.data_compressed_allocated * comprress_under_bytes compress的用户数据大小? * statfs.compressed_original 123456789diagraph calltrace &#123; Monitor::handle_command -&gt; mgrstatmon()-&gt;dump_cluster_stats Monitor::handle_command -&gt; mgrstatmon()-&gt;dump_pool_stats -&gt; PGMapDigest::dump_pool_stats_full -&gt; pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; pool_stat.get_allocated_bytes pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; store_nromalized = pool_stat.get_user_bytes(raw_used_rate, per_pool) pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; pool_stat.get_used_bytes(1.0, per_pool) pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; statfs.data_compressed_allocated pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; statfs.compressed_original&#125; 12345struct pool_stat_t &#123; object_stat_collection_t stats; store_statfs_t store_stats; ...&#125; 变量解释 raw_used_rate num_object_copies num_object_degraded per_pool osd_sum.num_osds == osd_sum.num_per_pool_osds mon: use per-pool stats only when all OSDs are reporting · ceph/ceph@5dcb6d8 osd: per-pool osd stats collection by ifed01 · Pull Request #19454 · ceph/ceph 这里应该是引入点, 为了解决压缩率统计的问题? Backport #37565: luminous: OSD compression: incorrect display of the used disk space - bluestore - Ceph Luminous无法被backport. 哎 data_stored num_bytes 这个还是在PrimaryLogPG.cc里进行统计 PG::_update_calc_stats OSD::send_pg_stats todo 问题: * 资源池显示的使用量实际上并不是osd上实际分配和占用的, 那为什么资源池显示已用满了基本上就不让用了呢? 还是说这两个基本上是一致的? * 按照bluestore这层应该也是和FileStore时一样, 实际上是有洞的,这种情况下, 为什么不默认提供更多的空间呢? 是怕出问题吧? 只有当压缩的时候, 才提供? * compressed的容量是否 * used和 objects数量是否有关呢 * 像是rbd上层4K随机写, 在rados层看到的就是写了2W5的对象以后就100G了, rados还是按照4M对象创建了… * 按照之前我们看pg的op, 理论上应该和objects数量无关才对. * pg处理的是Rados层的请求, 所以其实问题在于rbd层的4k 是怎么转换到4M的. * 问题其实是写了这些对象以后, df看到的容量就满了, 而实际上osd还没满. * mon如何打印出他当前收集的容量信息呢? * ### Luminous pool可用量计算 在代码中，在计算max_avail容量时，在PGMap::get_rules_avail函数中，mon会去迭代所有的资源池，根据pool_id拿到pool的如使用的ruleno的rule id、类型和size信息。拿到上述信息后，使用ruleno找到crush map信息，在这里建立一张基于crush map对各级bucket及osd进行广度优先搜索查找到的map&lt;int, float&gt;的id为key,crush weight为value的表，并进行归一化，让key更新为weight/sum的值。 然后在计算资源池整体可用时，使用上面拿到的osd的kb_avail除以此处拿到的表中osd id对应的归一化结果，取得资源池原始的最大可用空间。 现在要根据当前配置的副本数来获得对于资源池来说可用的空间，在PGMapDigest::dump_pool_stats_full函数中副本数变量为raw_used_rate。 针对Replicated类型，直接赋为资源池size 针对Erasure类型，从erasure_code_profile中获取到k和m，赋为\\((k+m)/k\\) 最后直接得到资源池可用空间\\(\\frac{max_avail}{raw_used_rate}\\) pool使用量计算 在PGMapDigest的成员变量mempool::pgmap::unordered_map&lt;int32_t,pool_stat_t&gt; pg_pool_sum中保存着pool的pg的对应资源池中的使用量num_bytes的和。该数据在ceph df detail中进行汇总 可以用下面这个命令看到这些统计 1ceph report 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455struct pool_stat_t &#123; object_stat_collection_t stats; ...&#125;;struct object_stat_collection_t &#123; /************************************************************************** * WARNING: be sure to update the operator== when adding/removing fields! * **************************************************************************/ object_stat_sum_t sum; ...&#125;;struct object_stat_sum_t &#123; /************************************************************************** * WARNING: be sure to update operator==, floor, and split when * adding/removing fields! **************************************************************************/ int64_t num_bytes; // in bytes int64_t num_objects; int64_t num_object_clones; int64_t num_object_copies; // num_objects * num_replicas int64_t num_objects_missing_on_primary; int64_t num_objects_degraded; int64_t num_objects_unfound; int64_t num_rd; int64_t num_rd_kb; int64_t num_wr; int64_t num_wr_kb; int64_t num_scrub_errors; // total deep and shallow scrub errors int64_t num_objects_recovered; int64_t num_bytes_recovered; int64_t num_keys_recovered; int64_t num_shallow_scrub_errors; int64_t num_deep_scrub_errors; int64_t num_objects_dirty; int64_t num_whiteouts; int64_t num_objects_omap; int64_t num_objects_hit_set_archive; int64_t num_objects_misplaced; int64_t num_bytes_hit_set_archive; int64_t num_flush; int64_t num_flush_kb; int64_t num_evict; int64_t num_evict_kb; int64_t num_promote; int32_t num_flush_mode_high; // 1 when in high flush mode, otherwise 0 int32_t num_flush_mode_low; // 1 when in low flush mode, otherwise 0 int32_t num_evict_mode_some; // 1 when in evict some mode, otherwise 0 int32_t num_evict_mode_full; // 1 when in evict full mode, otherwise 0 int64_t num_objects_pinned; int64_t num_objects_missing; int64_t num_legacy_snapsets; ///&lt; upper bound on pre-luminous-style SnapSets int64_t num_large_omap_objects = 0;&#125; osd使用的空间 12.2.13这部分函数似乎被重构了, update_osd_stat没有入参了. 123456void OSD::heartbeat()-&gt;void OSDService::update_osd_stat(vector&lt;int&gt;&amp; hb_peers)-&gt; int BlueStore::statfs(struct store_statfs_t *buf)这里通过指针设置了`Compress`和`compress_origin`的变量. 这里有个available, 为什么压缩后, 这里显示的减去之后获取到的容量还是实际使用了compress_origin的空间? 1struct store_statfs_t 这里的available是什么时候计算的? 1ceph daemon osd.1 pref dump | grep bluestore bluestore_allocated bluestore_stored bluestore_compressed bluestore_compressed_allocated bluestore_compressed_original 这里的容量分别是什么意思? 11.76-9.89=1.86g 这个compressed容量只有在占用正式结束了才会统计? 在流式使用空间的过程中, osd_used在逐渐增加, 但是这个compress一直没变. 似乎这里把struct store_statfs_t stbuf拿到的stbuf给通过OSDService::set_osd_stat给传过去了, 然后这里的值就是osd_stat的计数器里的值了. 稍后就直接传给mon了. 好像初始化的时候, osd默认就占用1.01G空间? num_bytes似乎和osd_stat里的used和available没什么关系?目前看到的现象是ceph osd df里看到的osd的used只有18.8G, 但是ceph df看到的资源池的使用量是61.6G, 3个osd, 2副本. 而我真实写入的文件大小是用/dev/zero生成的21G文件+ 一堆之前的, ceph df看到的是用户的操作 我关闭Compress之后, osd的used增加大概是3个G, 差不多欸, 我写的是10G对象, 拆到每个osd上. 理论上应该有7个G左右. 而那几个开了compress的大概是增加1个G. sum.num_bytes在哪里计算的呢? PGMapDigest下的public成员变量mempoool::pgmap::unordered_map&lt;int32_t,pool_stat_t&gt; pg_pool_sum. 应该是这里更新的. auto it2 = pg_pool_sum.find(it.first)-&gt;const pool_stat_t *pstat-&gt;const object_stat_sum_t&amp; sum void PGMap::update_pool_deltas(这个有点像, 不过这里计算的应该是差值吧? pg_pool_sum里的差值有哪些?应该不是 尝试搜索num_bytes =, 搜了下, 没有, 那应该意味着是通过聚合性质的做的计算, 按照C++的限制,应该是会通过字符串作为key的列表, 转换成对应的变量. emm, 只找到dump时的字符串与原始计数器 和 一个mon这里的pcb.add_u64(的任务, 这里的这个mon的东西是全局统计, 通过PGMonitor::update_logger这里更新. 啊, 忘了, 应该搜num_bytes +=, 在PrimaryLogPG.cc里出现了osd的统计ctx-&gt;delta_stats-&gt;num_bytes, 在osd_types.cc里也出现了操作符重载的void object_stat_sum_t::add的操作. 然后publish_stats_to_osd pg_info_t -&gt; pg_stat_t -&gt; pg_stats_publish -&gt; osd_stat_updated = true -&gt; send_pg_stats -&gt; m-&gt;pg_stat[pg-&gt;info.pgid.pgid] = pg-&gt;pg_stats_publish; 这里会将变化的pg的stat_queue_item入队到pg_stat_queue中。然后设置osd_stat_updated为True。入队之后，由tick_timer在C_Tick_WithoutOSDLock这个ctx中通过send_pg_stats()将PG的状态发送给Monitor。这样Monitor就可以知道pg的的变化了。 mon哪里处理这个接收到的最新的pg数据呢? 搜索这个msg结构体中的.pg_stat, 看到个下面这个, 是不是ClusterState::ingest_pgstats呢, 的确是这个, 在DaemonServer::ms_dispatch中调用这个更新的数据 在ClusterState中定义了PGMap::Incremental pending_inc;这里填充的pg_stat_updates 在比如PGMap::apply_incremental的好多地方都直接处理了这个更新的数据. 这样我就不好找到底把df的内容存哪去了. 最后应该是存到了PGMap里的`mempool::pgmap::unordered_map&lt;pg_t,pg_stat_t&gt; pg_stat里. 这个pgmap应该是哪里实例化的呢? PGMonitor ? 这个的初始化的Monitor在ceph_mon.cc里, 似乎初始化ceph-mon的时候只读取了version_t v = store-&gt;get(&quot;monmap&quot;, &quot;last_committed&quot;);? 那数据难道还是在osd上? 而且mon数据丢失似乎是可以恢复过来的. 通过ceph pg dump –format json-pretty是可以导出num_bytes的, 而daemon osd.x perf dump反而拿不到. 通过ceph-objectstore-tool可以拿到OSD里存的pg的信息 ceph-objectstore-tool查看OSD数据库中bluestore pg信息 如何解密然后修改呢 export pg信息似乎走的是RadosDump 欸,如果我要修改某个值, 要停掉这个pg所在的所有osd? ObjectStoreTool::do_export get_log PGLog::IndexedLog 这个为啥不能用pg_log_t解码呢? 根据[^9这个来看,其实还是遵守了kv数据结构的,只是好像在哪层被过滤掉了? 试了下, get-bytes拿到的是对象的内容 那么是否说明其实也是计算, 而不是累加的呢? info这个数据似乎无从修改, 只有pg的元数据可以修改的样子? 这个疑似PGLog::IndexedLog, 不知道怎么改 按照现在看到的objects的问题, 是不是这个pg提供的objects指标全都是负数,所以上层统计的也都是 但是现在在数据库里list, list不出这个pg, 是代表什么呢? 我应该只能从代码到底是怎么list, 用的什么接口然后查不到这个pg来看吧? 用rados ls -p data02, 因为这个资源池理论上其实不应该有任何object, 所以应该也是查不到东西, 但是实际存在了几个对象信息为负数的object. 以osd级别来显示object, 看看带不带pg的信息. pg上面统计的信息, 感觉像是以object为单位处理的啊. 假如说真是以pg自己来存储自己的信息, 那么object和pg之间就存在歧义性了. ceph pg dump显示的pg id不完整, 被坑了. scrub是一个方案, 看看能不能修复他, 根据EC 现在pg的指标是负数, 还有什么信息能够用来处理呢?object无法查到 rados ls 卡住,无论哪个, 可能受影响了 ceph-objectstore-tool 查询这个pg, list也是空的 ceph pg repair pg.$id 居然就修复了. 所以repair过程发生了什么 todo pgid居然是As1 librados: wait_for_osdmap done waiting 是否代表某个客户端占用了这个吧所? 打开–debug_objecter 40 –debug_rados 40看到的内容就是上述的. objecter给出的信息更多一点, 看着 这中间慢在哪里呢?ms_dispatch ceph osd df SIZE 没问题 USE 是上面的store呢还是allocated? AVAIL 又是哪种呢? 在正常情况下ceph osd df 看到的osd的used是跟ceph df看到的stored一致的, 但是这个数据是在osd这里实际存储的, 而ceph df却并不是 这里看到的osd的容量是 pgs-&gt;get_osd_sum().kb PGStatService *pgs PGMapStatService get_osd_sum() return pgmap.osd_sum; pgmap怎么更新? 指向的是ClusterState中的pg_map mgr ClusterState::ingest_pgstats ClusterState::notify_osdmap mon tick() send_report() 根据[^8]里可以看到这个MonPGStatService是\b\b\b\b\bceph-mon把内容转嫁到ceph-mgr的中间层. pool使用的空间 used 所以根据上面来看, 这边的容量并不是根据osd_stat汇总的了, 而是pg这层自己维护的? 根据[^7] bytes used 逻辑空间占用量, 主要针对的是写入多少, 不考虑由于COW引起的实际占用量较小 12版本这里直接拿的sum.num_bytes 通过ceph report可以看到资源池的这个统计 raw bytes used 用户使用的总容量, 包含所有osd除去降级的(这个应该是带副本的吧) pool_stat.get_user_bytes(1.0, per_pool) compress_bytes_used compress的数据 , 分配的空间大小(包含副本/EC的开销), 也就是说除去副本数就是用户数据实际在设备里存储吧 statfs.data_compressed_allocated 12版本还在osd里 comprress_under_bytes compress的用户数据大小? statfs.compressed_original sum.num_bytes属于pool_stat_t里的object_stat_collection_t stats, 这个东西怎么从pg_map里得到的? 在PGMap::calc_stats里似乎pg_sum = pool_stat_t(), 但是这个pool_stat_t的构造函数里只是构造并初始化为0, emm, 只在decode的时候被调用, 倒是的确没什么影响. cephfs使用的空间 cephfs上删除太多文件, 出现了ceph df看到的used为EiB的情况, 通过json打印出来, 看到实际上统计的bytes为负数, 引起的. 根据[^6], 好像说是和cephfs文件系统有关系? osd特殊场景 在osd out之后，该osd在2.4.1中提到的kb_avail会变成0，因此可用容量不需要计算 max_avaible 单pool计算公式 资源池容量计算，主要在osd容量的基础上，遵循下述公式进行 \\[max.avail = min(\\frac{osd\\_avail_0}{\\frac{weight_0}{\\sum_{i=0}^nweight_i}}, \\frac{osd\\_avail_1}{\\frac{weight_1}{\\sum_{i=0}^nweight_i}}, \\dots, \\frac{osd\\_avail_j}{\\frac{weight_j}{\\sum_{i=0}^nweight_i}})/pool.size\\] max_avail: 该资源池最大可用空间 min: 取括号范围内的最小值 osd_avail: 表示某个编号osd对应的可用空间 weight: 表示对应某个编号osd对应的crush weight pool_size: 表示pool对应副本数(或纠删码经计算后的数值) rbd rbd du 需要开启object-map fast-diff功能之后统计拿到的数据才是正确的，否则就会出现每层快照占用的容量都会比原始数据要大 根据[^4], 好像rbd的discard选项, 影响这个容量的问题. rbd diff 1rbd diff rbd/zp | awk '&#123; SUM += $2 &#125; END &#123; print SUM/1024/1024 \" MB\" &#125;' 异常情况 osd down 对容量无影响 ### osd out 在未达到min size阶段可继续使用的pool，只有osd正式out了，容量才会变更。 仅当被从crush中挪走或不存在in的osd，才会真的容量变化。 Reference Ceph df分析_运维_weixin_44389885的博客-CSDN博客 ceph全局GLOBAL容量和POOLS级别容量计算_awk_pansaky的博客-CSDN博客$$ Ceph中的容量计算与管理 - gold叠 - 博客园 kubernetes - How to explain Ceph space usage - Stack Overflow osd: per-pool osd stats collection by ifed01 · Pull Request #19454 · ceph/ceph Bug #16671: “ceph df”object num is negative - Ceph - Ceph Ceph中的容量计算与管理 - gold叠 - 博客园 https://runsisi.com/2019-02-27/ceph-pg-stat pglog出错导致osd启动失败的解决办法 - 简书","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"存储","slug":"存储","permalink":"https://sean10.github.io/tags/存储/"}]},{"title":"ceph之librados使用","slug":"ceph之librados使用","date":"2020-05-20T19:43:44.000Z","updated":"2021-01-02T14:34:06.088Z","comments":true,"path":"2020/05/21/ceph之librados使用/","link":"","permalink":"https://sean10.github.io/2020/05/21/ceph之librados使用/","excerpt":"librados是ceph各组件对外暴露的模块，藉由librados接口，可以高效的使用ceph内的组件进行CRUD等操作。","text":"librados是ceph各组件对外暴露的模块，藉由librados接口，可以高效的使用ceph内的组件进行CRUD等操作。 12345import radoscluster = rados.Rados(conffile = 'ceph.conf', conf = dict (keyring = '/path/to/keyring'))cluster.connect()cmd = json.dumps(&#123;\"prefix\": \"osd safe-to-destroy\", \"ids\": [\"2\"], \"format\": \"json\"&#125;)c.mon_command(cmd, b'') 这里的conf=keyring主要用于当打开了cephx等认证措施时，ceph.conf中又没有记录认证所用到的keyring文件路径时，进行额外设置使用。 最近我在参照python的librados使用，调用C的接口时，就一直遇到cephx认证打开之后，无法成功rados_connect的情况，具体原理还得细看，但应该和cephx及这个keyring存在强相关性是可以确认的了。 连接成功之后，主要使用下属这几个接口来查询pool,osd,pg等一些信息。 1234Rados.mon_command(self, cmd, inbuf, timeout=0, target=None)Rados.osd_command(self, osdid, cmd, inbuf, timeout=0)Rados.mgr_command(self, cmd, inbuf, timeout=0, target=None)Rados.pg_command(self, pgid, cmd, inbuf, timeout=0) 就目前而言，我在抓取IO等指标时，用的比较多的接口是mon_command和mgr_command，使用这几个接口能进行的操作，都有提供cli和rest接口。我主要是在使用cli熟悉接口之后，会去代码中的MonCommands.h和MgrCommands.h文件中去找相近的prefix，然后参照着使用。 但是偶尔也是会遇到像ceph osd pool stats和ceph pg ls-by-pools这类没怎么能找到相关prefix的情况。这个时候可以充分利用起ceph这个cli入口其实是个python文本的功能了。 python -m pgd /bin/ceph osd pool stats执行，在new_style_command函数内的json_command处打断点，进入后，打印cmddict就可以看到cli发送出去的prefix拼接出来是什么样子的了，然后再拿着这个去代码里搜就好了。 开发者模式[^2] make vstart async模式 mon_command_async 好像RadosClient.cc里有这个异步下发任务, 但是似乎并没有对外提供成librados的接口. 之后有空应该是可以利用这个封装出来使用的应该. radosstripper理解 rados连接过程 似乎有加载client name. parse_config_files似乎还有指定不读取任何配置文件的时候, 即便是默认配置文件 global_pre_init里调用的似乎就是这个. “cdef class Rados(object):”-&gt;“name = ‘client.admin’” 默认name client.admin context 是什么? rados_create2 rados_create_cct() librados::RadosClient::connect理解 monclient.init() 源码 RadosClient IoctxImpl AioCompletionImpl osdc Reference Librados (Python) — Ceph Documentation 深入理解ceph crush(2)—-手动编译ceph集群并使用librados读写文件 · Dovefi never stop Ceph学习——Librados与Osdc实现源码解析_SEU_PAN的博客-CSDN博客","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"rados","slug":"rados","permalink":"https://sean10.github.io/tags/rados/"},{"name":"存储","slug":"存储","permalink":"https://sean10.github.io/tags/存储/"}]},{"title":"正则表达式BRE/ERE/PRE","slug":"正则表达式BRE-ERE-PRE","date":"2020-05-16T15:53:18.000Z","updated":"2020-05-16T15:57:21.000Z","comments":true,"path":"2020/05/16/正则表达式BRE-ERE-PRE/","link":"","permalink":"https://sean10.github.io/2020/05/16/正则表达式BRE-ERE-PRE/","excerpt":"概述 在开发过程中，经验遇到使用不同语言不同工具时，正则表达式无法直接复用的问题。主要原因在于不同语言使用的正则表达式的标准也是不一样的。","text":"概述 在开发过程中，经验遇到使用不同语言不同工具时，正则表达式无法直接复用的问题。主要原因在于不同语言使用的正则表达式的标准也是不一样的。 Basic Regular Expression Extended Regular Expression Perl Regular Expression 主要区别[^1] 流派 说明 BRE () {} + ? |都必须转义使用 ERE 元字符不必转义, + ? ( ) { } |可以直接使用 PRE 除了ERE支持的之外，还支持, BRE、ERE可以使用POSIX字符集来操作 使用支持 grep 支持BRE，通过参数控制，默认BRE, -P开启PRE, -E开启ERE sed 支持BRE，默认BRE，-r开启ERE awk 支持ERE，默认ERE。 C c语言的regex根据man 3 regex看到的内容来看，支持BRE和ERE. 另外由于C语言字符串处理的性质，一般使用元字符时，需要额外的转义符，如\\s Python python使用的是PRE，所以处理起来要相对C要简单不少 Reference 正则表达式基础知识|Jerkwin","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"re","slug":"re","permalink":"https://sean10.github.io/tags/re/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://sean10.github.io/tags/正则表达式/"}]},{"title":"C可变参数","slug":"C可变参数","date":"2020-04-28T17:29:14.000Z","updated":"2020-05-03T07:05:37.000Z","comments":true,"path":"2020/04/29/C可变参数/","link":"","permalink":"https://sean10.github.io/2020/04/29/C可变参数/","excerpt":"旧笔记整理后发布","text":"旧笔记整理后发布 C99编译器允许可变参数宏(variadic macros), GCC默认使用的标准是GNU89/90标准，这个标准在C89的基础上增加了一些C99的功能（就比如这个Variadic macro）[^3]。 123456man gcc... gnu90 gnu89 GNU dialect of ISO C90 (including some C99 features). This is the default for C code. 查看gcc版本 1gcc -E -dM - &lt;/dev/null | grep \"STDC_VERSION\" 1234567891011#include &lt;stdio.h&gt;int main(void) &#123;#ifdef __STDC__ printf(\"%s\\n\", \"stardard c\");#endif#ifdef __STDC_VERSION__ printf(\"%d\\n\", __STDC_VERSION__);#endif return 0;&#125; 在这个版本中增加的宏__VA_ARGS__前增加##可以完成对逗号的处理，在没有传入额外参数时，gcc对代码进行预处理时，识别到##会将逗号给去除。如果不加入这个，那在不传入额外参数时，就会编译错误。[^4] example 1234567891011121314151617181920212223242526#include &lt;syslog.h&gt;#include &lt;stdarg.h&gt;#include &lt;stdio.h&gt;#define BUFF_LEN_O 1024#define LOGGER(priority, format, ...) logger(priority, format, __FUNCTION__, __LINE__, ##__VA_ARGS__)static void logger(int priority, const char *format, ...)&#123; openlog(\"test_log\", LOG_PID | LOG_NDELAY, LOG_LOCAL0); va_list ap; char buff[BUFF_LEN_O] = &#123;0&#125;; char placeholder[] = \"function&#123;%s&#125;,line&#123;%d&#125;\"; va_start(ap, format); snprintf(buff, sizeof(buff) - 1, \"%s %s\", placeholder, format); vsyslog(priority, buff, ap); va_end(ap);&#125;int main()&#123; printf(\"%s %d\\n\", __FUNCTION__, __LINE__); LOGGER(LOG_INFO, \"hello world %s\", \"123\"); LOGGER(LOG_ERR, \"new\"); logger(LOG_INFO, \"hello world %s\", __FUNCTION__, __LINE__, \"123\"); return 0;&#125; Reference C99 open-std.org/JTC1/SC22/WG14/www/docs/n897.pdf C11 ISO/IEC 9899:201x C Extensions - Using the GNU Compiler Collection (GCC) Variadic Macros - Using the GNU Compiler Collection (GCC)","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"C","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"gcc","slug":"gcc","permalink":"https://sean10.github.io/tags/gcc/"}]},{"title":"C++远程开发&&跨平台Sourcetrail","slug":"C-远程开发-跨平台Sourcetrail","date":"2020-04-24T02:28:13.000Z","updated":"2020-08-01T18:10:16.000Z","comments":true,"path":"2020/04/24/C-远程开发-跨平台Sourcetrail/","link":"","permalink":"https://sean10.github.io/2020/04/24/C-远程开发-跨平台Sourcetrail/","excerpt":"Clion配置 Clion支持基于cmake的远程开发，最近用来在windows上开发linux程序时的高亮、提示、补全。相对以前开发时很多unix特定的头文件无法提示出来，现在要好得多了。 基本配置方式就是在perference-&gt;Build\\Execution\\Deployment-&gt;toolchains里添加remote debug环境，也可以配置gdb server做远程调试。 如果新引入了动态库，需要重新让clion去下载一下依赖的库建立索引的时候，点击Tools-&gt;Resync with Remote Hosts重新同步就可以了。","text":"Clion配置 Clion支持基于cmake的远程开发，最近用来在windows上开发linux程序时的高亮、提示、补全。相对以前开发时很多unix特定的头文件无法提示出来，现在要好得多了。 基本配置方式就是在perference-&gt;Build\\Execution\\Deployment-&gt;toolchains里添加remote debug环境，也可以配置gdb server做远程调试。 如果新引入了动态库，需要重新让clion去下载一下依赖的库建立索引的时候，点击Tools-&gt;Resync with Remote Hosts重新同步就可以了。 Sourcetrail阅读代码 另外，配合去年开源的Sourcetrail来看代码感觉也不错，调用图索引的也还可以。而且sourcetrail在建立C/C++的索引的时候，也可以使用cmake导出的一个cdb成果物。 1cmake -DCMAKE_EXPORT_COMPILE_COMMANDS .. 编译时增加上述选项就可以导出compile_commands.json这个文件，包含代码src路径和include路径、编译选项等等，用这种方式建立索引的时候就不会报错了。但是好像大部分时候看代码时也不是那么需要某些头文件的提示，缺失也影响不大。 跨平台sourcetrail建立索引[^2] 但是在开发的时候大部分代码其实主要还是linux环境偏多，并不兼容MinGW的时候，就容易出现错误文件数量过多，影响阅读的时候。针对这种情况，issue里也给出了一个方法，suorcetrail提供了command line功能，可以在编译环境中， 完成索引，然后再把生成的数据库文件拖回本机打开工程，就能直接看到代码了。 可以用图形界面直接创建一个sourcetrail工程(得到.srctrlprj文件)，然后将在编译环境中的源码路径或者是上面提到过的compile_commands.json的路径给填上。 把这个srctrlprj文件放到编译环境中，在编译环境中执行Sourcetrail index &lt;path/to/your/project.srctrlprj&gt; 把生成的srctrldb文件拖回本地srctrlprj文件所在目录，用Sourcetrail打开即可。 还是太卡了 OpenGrok + Universal CTags understand Reference Support CMake files for project setup · Issue #35 · CoatiSoftware/Sourcetrail Remote indexing · Issue #134 · CoatiSoftware/Sourcetrail","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"Clion","slug":"Clion","permalink":"https://sean10.github.io/tags/Clion/"},{"name":"Sourcetrail","slug":"Sourcetrail","permalink":"https://sean10.github.io/tags/Sourcetrail/"},{"name":"Index","slug":"Index","permalink":"https://sean10.github.io/tags/Index/"}]},{"title":"小黑的故事梳理","slug":"小黑的故事梳理","date":"2019-10-05T14:24:48.000Z","updated":"2020-04-24T01:27:29.000Z","comments":true,"path":"2019/10/05/小黑的故事梳理/","link":"","permalink":"https://sean10.github.io/2019/10/05/小黑的故事梳理/","excerpt":"剧透预警","text":"剧透预警 故事发展 与小黑相关的主要人物线 罗小黑战记剧场版-c369f14a-ac8d-4fd8-9ab2-629b6b257034 小黑 小黑虽然是本片的主角，故事围绕着他发展，是本片营造的矛盾的中心，但主要出于一个提供矛盾点的作用。 在片中，在风息和无限两个阵营中处于一个阵营切换的地位。他在片中的成长点主要在于对于好坏的认知，逐步从狭义到广义，再到是相对的概念。 * 谁对我好，谁是好人（风息的第一次接触、无限的陪伴过程） * 好人的概念是不是广义绝对的？（无限回答为何抓风息，风息在整体上做了什么） * 好人是有立场的（最后决战完，风息失败了，从他理解风息的角度，风息还是个好人） 风息 风息的理念主要是人妖平等，指的是妖与人的互不侵犯的平等，根据本片来看，风息的目的主要是实现妖不用再流浪。 风息曾提到人与妖的过去曾经是人不知道妖的存在、人将妖看作为神、到如今人已不知晓妖，妖的生存空间（自然）在逐渐被开发。可以看到，从风息的立场来说，妖是处于受害者的位置的。 然后，从本片开场风息控制人类、无限来抓风息来看，风息应该是仇视人类，甚至是有伤害人类的行为的。开场时，风息就已经不像会馆里人认知的那样，是为了妖的整体考虑的了，已经是为了自己、为了大部分的妖了，从这时，风息已经为了实现妖有自己不变的家园，可以接受自己承担路上伤害无辜者的罪孽这点了。后面所做的，小黑等等，已经不在他心中不可伤害了。 无限 无限的立场是会馆中的人类，是处于人妖均衡的立场的。从我们的认知来看，会馆当前维持的局面是，大众不知晓妖的存在，从而实现的和谐相处下的均衡关系（当前应该是高层可以知晓的）。从未来发展的角度猜测，会馆应该是有在向可以让大众知晓的情况下，人与妖还能和谐发展的均衡关系发展的。 所以无限开场，试图捕获风息，让风息去会馆冷静一下这点没有任何问题。至于抓错了小黑，在找不到风息时，将小黑顺便送回会馆是一个顺便的事情。在带回去的过程中，和小黑培养感情（这个的节奏就有些缓慢，也有TV版治愈的感觉了）。在带回去的过程中，小黑被抓走，甚至被抢走领域而生命垂危，这就是无限个人情感上不可接受的点了，无限冲入被风息控制的灵质空间也就有原因了。 最终，制止了风息，小黑救回来，然后抵达神秘的会馆。小黑因与无限的羁绊确立师徒关系算是一个圆满。 作为电影 就像上面列的3个角色的发展那样，故事的发展应该主要围绕着双方立场和行为矛盾点展开。其外的内容比例一般应该是有所控制。但是电影中有一点虽然作为粉丝看着很开心，作为非观众的话，可能觉得节奏有问题的一部分，无限带小黑回会馆的这部分日常的故事这段，占用篇幅过长。因为从推进故事的角度来看，应该是没有那么重要。可以用于扩充其他角色的角度来阐述更多的背景或是矛盾点，可能会显得更好。不过这样小黑的出场可能就少了些许。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/动漫/"},{"name":"罗小黑战记","slug":"罗小黑战记","permalink":"https://sean10.github.io/tags/罗小黑战记/"}]},{"title":"hexo主题自定义--修改indigo tag显示","slug":"hexo主题自定义","date":"2019-01-17T12:57:48.000Z","updated":"2021-01-16T13:57:48.000Z","comments":true,"path":"2019/01/17/hexo主题自定义/","link":"","permalink":"https://sean10.github.io/2019/01/17/hexo主题自定义/","excerpt":"","text":"更换hexo-theme-indigo的时候，发现作者也是个简约主义啊，功能足够就行了，不需要更新，hhh。 增加引用 首先，将next主题中一直用的addthis统计与分享功能引入。 官网上很简单，就是一行html和js，不过似乎在我使用时，可能排版上与js中携带的addthis模块排版冲突了，导致没能显示出来 修改tag显示 主要的问题在于, 当写的Tag总计多了时, 观察不到哪些tag的文章比较多 当时初步想的是hexo-tag-cloud或者是雷达图效果. 不过想了下, 这方面如果更换, 可能css也得换, 修改较多. 试试看能不能直接在tag名字后面加一个统计数字. 这个API里理论上应该有提供 翻了下代码, 感觉layout/tags.ejs有点像显示的代码, 翻到个函数is_tag, 全局没搜到, 那应该代表着这里的一些信息是从hexo或者hexo的插件里获取到的. 的确,根据Helpers | Hexo, 在这里找到了这个函数. 对, 和页面上的id, class比对了下, 的确这里是正文中的tag和post显示的位置. 123456789101112131415161718192021222324252627&lt;% if(is_tag()) &#123; %&gt; &lt;div class=\"waterfall\"&gt; &lt;% page.posts.each(function(post)&#123; %&gt; &lt;%- partial('_partial/archive', &#123;post: post, date_format: config.date_format&#125;) %&gt; &lt;% &#125;) %&gt; &lt;/div&gt; &lt;% &#125; else &#123; site.tags.each(function(tag)&#123; if(tag.length)&#123; %&gt; &lt;h3 class=\"archive-separator\" id=\"tag-&lt;%=tag.name %&gt;\"&gt;&lt;%=tag.name %&gt;&lt;/h3&gt; &lt;div class=\"waterfall\"&gt; &lt;% tag.posts.each(function(post)&#123; %&gt; &lt;%- partial('_partial/archive', &#123;post: post, date_format: config.date_format&#125;) %&gt; &lt;% &#125;) %&gt; &lt;/div&gt; &lt;% &#125; &#125;) &#125; %&gt; 开启debug模式, hexo s --debug 实验了下, 还是header处增加统计数字更明显一些. tags-bar.ejs文件 增加tag统计角标 1&lt;a href=\"&lt;%- url_for(tag.path) %&gt;\" style=\"-webkit-order:&lt;%= order%&gt;;order:&lt;%= order%&gt;\" class=\"tags-list-item waves-effect waves-button waves-light&lt;% if(is_current(tag.path))&#123;%&gt; active&lt;%&#125;%&gt;\"&gt;&lt;%-tag.name%&gt;&lt;/a&gt; 增加了sup选项, 加了个角标,看起来还可以 1&lt;a href=\"&lt;%- url_for(tag.path) %&gt;\" style=\"-webkit-order:&lt;%= order%&gt;;order:&lt;%= order%&gt;\" class=\"tags-list-item waves-effect waves-button waves-light&lt;% if(is_current(tag.path))&#123;%&gt; active&lt;%&#125;%&gt;\"&gt;&lt;%-tag.name%&gt;&lt;sup&gt;&lt;%-tag.length%&gt;&lt;/sup&gt;&lt;/a&gt; 增加排序(未完成) 相对来说, 还是不太直观. 看下面这段代码, 看起来是在指定Tag在这个顺序中的位置. 123456789101112131415161718192021222324252627var options = []; (type === 'tags' ? site.tags : site.categories).each(function(o) &#123; if(o.posts.length) &#123; options.push(o) &#125; &#125;) var index = _.findIndex(options, function(o) &#123; return is_current(o.path) &#125;) var len = options.length var order = 0 options.forEach(function(tag, i)&#123; if(index &lt;= 1) &#123; order = i &#125; else &#123; if( i &lt; index - 1) &#123; order = len - (index - 1) + i &#125; else &#123; order = i - (index - 1) &#125; &#125; %&gt; webkit-order的作用是什么呢… 理解错了, 这个其实还是为了布局用的. 问题 hexo渲染时, Markdown文本中如果出现\\{\\{\\}\\}, 又没有被转义, 是会转义失败, 报下面的错误的. 1Template render error: (unknown path) [Line 208, Column 5]","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"},{"name":"js","slug":"js","permalink":"https://sean10.github.io/tags/js/"}]},{"title":"Python脚本常用模块记录","slug":"Python分享","date":"2018-11-19T14:41:31.000Z","updated":"2018-11-21T14:47:47.000Z","comments":true,"path":"2018/11/19/Python分享/","link":"","permalink":"https://sean10.github.io/2018/11/19/Python分享/","excerpt":"","text":"最近老是写脚本，感觉主要用Python的动力就在于Python存在大量造好的轮子，开箱即用，性能和全面性又能比自己现造的轮子要好。 计数 首先就拿Counter类个例子 12345678910111213141516171819a = [10, 8, 6, 7, 2, 8, 4, 10, 3, 7, 8, 4, 5, 7, 2, 2, 3, 8, 8, 9, 6, 2, 2, 7, 8, 7, 4, 8, 5, 2] e = dict() for item in a: if item in e: e[item] += 1 else: e[item] = 1 b = [] for item in set(a): b.append((item, a.count(item))) c = defaultdict(int) for i in a: c[i] += 1 d = Counter(a) 有4种方式，逐渐演变出来，内建函数就支持了计数功能 性能优化 1234567891011121314151617181920212223242526272829303132333435363738import cProfileimport timeitfrom collections import Counter, defaultdicta = [10, 8, 6, 7, 2, 8, 4, 10, 3, 7, 8, 4, 5, 7, 2, 2, 3, 8, 8, 9, 6, 2, 2, 7, 8, 7, 4, 8, 5, 2]def count1(): e = dict() for item in a: if item in e: e[item] += 1 else: e[item] = 1def count2(): b = &#123;item: a.count(item) for item in set(a)&#125;def count3(): c = defaultdict(int) for i in a: c[i] += 1def count4(): d = Counter(a)def main(): count1() count2() count3() count4()if __name__ == '__main__': cProfile.run(\"main()\") # timeit.timeit(\"main()\", number=1) 像这样就不需要再像下面这样手动写了 123456start = time.time()....stop = time.time()total = stop - start 内存监控 memory_profiler 123456789from memory_profiler import profile@profiledef main(): xxxif __name__ == '__main__': main() 解析配置文件 123456789101112131415161718192021import configparsercf = configparser.ConfigParser()cf.read('conf.ini')secs = cf.sections()print('sections:', secs, type(secs))opts = cf.options('baseconf')print(\"opts\", opts, type(opts))host = cf.get('baseconf', 'host')print(host)for sec in cf.sections(): for opt in cf.options(sec): print(cf.get(sec, opt))cf.set('baseconf', 'host', '0.0.0.0')cf.write(open('temp.conf', 'w')) 读取无section名的常用linux conf文件 12345678910import configparserwith open('temp.conf', 'r') as f: config_string = '[dummy_section]\\n' + f.read()cf = configparser.ConfigParser()cf.read_string(config_string)for sec in cf.sections(): for opt in cf.options(sec): print(cf.get(sec, opt)) 读写xml 1234567891011with open('temp.xml', 'r') as f: doc = xmltodict.parse(f.read())import jsonprint(json.dumps(doc, indent=4))print(doc['domain'])print(doc['domain']['cpu']['@mode'])doc['domain']['cpu']['@mode'] = 123print(doc['domain']['memory']['#text'])doc['domain']['memory']['#text'] = \"1111111\"with open('out.xml', 'w') as f: f.write(xmltodict.unparse(doc, pretty=True)) 读写json 12345678import jsonwith open('temp.json', 'r') as f: content = f.read() jsonData = json.loads(content)print(jsonData)print(json.dumps(jsonData, indent=2)) 起一个简单的http接口服务 12345678910from flask import Flaskapp = Flask(__name__)@app.route('/')def index(): return \"hello world\"if __name__ == '__main__': app.run(host=\"0.0.0.0\", port=80) RPC接口 相比http性能更好 Pipe管道 Python默认是前缀语法，是下面这么多个括号嵌套 1sum(select(where(take_while(fib(), lambda x: x &lt; 1000000) lambda x: x % 2), lambda x: x * x)) 这种的，而不是下面这样的中缀语法，类似这样链式调用 123456from pipe import *fib() | take_while(lambda x: x &lt; 1000000) \\ | where(lambda x: x % 2) \\ | select(lambda x: x * x) \\ | sum()","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sean10.github.io/tags/Python/"},{"name":"script","slug":"script","permalink":"https://sean10.github.io/tags/script/"}]},{"title":"「译」sqlite为什么autoincrement不推荐使用","slug":"为什么autoincrement不推荐使用","date":"2018-09-15T14:51:18.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/09/15/为什么autoincrement不推荐使用/","link":"","permalink":"https://sean10.github.io/2018/09/15/为什么autoincrement不推荐使用/","excerpt":"在使用sqlite3写一个建议订单系统的时候，没设置主键，默认将第一个条属性设置成了主键，而这条属性并不具有唯一性，导致经常出现插入失败的问题。 在这个背景下，我考虑设置一个数据库里的自增主键，之后这部分就可以自动生成了。 但是在我使用的ORM_LITE中没有提供这样的属性，那么是不是这个属性不推荐使用呢？ 找到了下面这篇文章SQLite AUTOINCREMENT : Why You Should Avoid Using It","text":"在使用sqlite3写一个建议订单系统的时候，没设置主键，默认将第一个条属性设置成了主键，而这条属性并不具有唯一性，导致经常出现插入失败的问题。 在这个背景下，我考虑设置一个数据库里的自增主键，之后这部分就可以自动生成了。 但是在我使用的ORM_LITE中没有提供这样的属性，那么是不是这个属性不推荐使用呢？ 找到了下面这篇文章SQLite AUTOINCREMENT : Why You Should Avoid Using It 下文是这篇的翻译。 SQLite ROWID表简介 无论何时，创建表时不指定WITHOUT ROWID选项，都会得到一个名为rowid的隐式自动增量列。 rowid列存储64位有符号整型，用于唯一标识表中的行。 我们来看下面的例子。 首先，创建一个包含两列first_name, last_name的新表people: 1234CREATE TABLE people ( first_name text NOT NULL, last_name text NOT NULL); Try it 其次，用以下INSERT语句插入people一行: 123INSERT INTO people (first_name, last_name)VALUES ('John', 'Doe'); Try it 第三，用以下SELECT语句从people中查询数据 123456SELECT rowid, first_name, last_nameFROM people; Try it 所以，SQLite会自动创建一个名为rowid的隐式列，并 在您插入新行时自动分配一个整数值。 可以通过rowid的两个别名_rowid_和oid来使用它 如果创建具有INTEGER PRIMARY KEY列的表，则该列指向rowid列。 以下语句删除people表并重新创建它，不过这一次，我们添加另一列带有INTEGER PRIMARY KEY属性的名为person_id的列。 1234567DROP TABLE people; CREATE TABLE people ( person_id INTEGER PRIMARY KEY, first_name text NOT NULL, last_name text NOT NULL); Try it 现在person_id列实际上就是rowid列。 那么，Sqlite如何分配一个整型值给rowid列呢？ 如果插入一个新行时，你没有指定一个rowid值或者使用NULL值， Sqlite会分配一个比表中最大的rowid大1的整型。 当还没有插入任何行时， rowid是1。 首先，插入带有最大值的一行插入people表。 1234567891011INSERT INTO people ( person_id, first_name, last_name)VALUES ( 9223372036854775807, 'Johnathan', 'Smith' ); Try it 第二，插入不指定person_id的另一行 123456789 INSERT INTO people ( first_name, last_name)VALUES ( 'William', 'Gate' ); Try it SQLite AUTOINCREMENT 属性 SQLite 推荐你不应该使用AUTOCREMENT属性，因为: The AUTOINCREMENT keyword imposes extra CPU, memory, disk space, and disk I/O overhead and should be avoided if not strictly needed. It is usually not needed. \bAUTOINCREMENT关键字会产生额外的CPU,内存,磁盘空间和磁盘I/O开销，如果不是严格需求，应该避免使用。通常不是必须的。 此外，SQLite为AUTOCREMENT列分配值的方式与rowid列的使用方式略有不同。 请参阅以下示例。 首先，再次删除并重新创建人员表。这次，我们使用AUTOINCREMENT属性。 1234567DROP TABLE people; CREATE TABLE people ( person_id INTEGER PRIMARY KEY AUTOINCREMENT, first_name text NOT NULL, last_name text NOT NULL); Try it 其次，将具有最大行id值的行添加到people表中。 1234567891011INSERT INTO people ( person_id, first_name, last_name)VALUES ( 9223372036854775807, 'Johnathan', 'Smith' ); Try it 第三，在people表中插入另一行 123456789INSERT INTO people ( first_name, last_name)VALUES ( 'John', 'Smith' ); Try it 这次，SQLite发出了一条错误消息： 1[Err] 13 - database or disk is full 因为它不会重新使用未被使用数字。 AUTOCREMENT这个属性的主要目的是防止SQLite复用还未使用的值或者使用先前删除的行 如果还没有任何像这样的需求，那么你就不应该在主键中使用SQLite AUTOINCREMENT属性。 在这篇教程中，你已经学习到AUTOINCREMENT属性如何运作的，以及它如何影响SQLite分配值给主键的方式。 # Reference 1. SQLite AUTOINCREMENT : Why You Should Avoid Using It","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"Qt","slug":"Qt","permalink":"https://sean10.github.io/tags/Qt/"},{"name":"sqlite3","slug":"sqlite3","permalink":"https://sean10.github.io/tags/sqlite3/"}]},{"title":"高层火灾应对方式","slug":"高层火灾应对方式","date":"2018-08-25T16:53:55.000Z","updated":"2020-10-18T07:58:49.000Z","comments":true,"path":"2018/08/26/高层火灾应对方式/","link":"","permalink":"https://sean10.github.io/2018/08/26/高层火灾应对方式/","excerpt":"今天学姐提起了这个话题，现在住在高层19层，我们遇到火灾时，应该有哪些逃生方式。","text":"今天学姐提起了这个话题，现在住在高层19层，我们遇到火灾时，应该有哪些逃生方式。 众所周知，小学的时候都有讲过湿毛巾捂笔过滤有毒气体。还有一些摸墙跑，下层走不了就上楼之类的各种常识。不过具体问起发生火灾时，我们应该怎么判断，自己该怎么行动，这个流程倒是没有那么清晰了。 下面来捋捋这个流程。 根据知乎大佬们所说，理论上，我们能做到的自救方式，就是冷静，并能向下冲就冲，一旦被困，就只有祈祷高层防火措施完善，自动喷淋装置等能够加快消防员们灭火的措施齐全。一旦公寓防火有不完善的操作，被困就很难人力突破了。 我们实地考察了以下，大约以下几点 * 屋外走廊是否有自动喷淋装置 * 屋外走廊是否有灭火器等防火措施 * 每层的防火通道是否有2个，并且是否独立不连通 所幸这几点这个屋子都是具备的，让我心里踏实了不少。 Reference 发生火灾后，住在高层有哪些可行的逃生措施？","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"火灾","slug":"火灾","permalink":"https://sean10.github.io/tags/火灾/"},{"name":"高层","slug":"高层","permalink":"https://sean10.github.io/tags/高层/"}]},{"title":"KVM宿主机与虚拟机交互","slug":"KVM宿主机与虚拟机交互","date":"2018-08-16T12:08:01.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/08/16/KVM宿主机与虚拟机交互/","link":"","permalink":"https://sean10.github.io/2018/08/16/KVM宿主机与虚拟机交互/","excerpt":"环境背景 使用libvirt管理kvm， 需要在不知道虚拟机ip的情况下，与虚拟机进行交互。 翻了翻，qemu有提供一个qemu-guest-agent的工具，在虚拟机内安装后就可以让宿主机获取虚拟机内的信息了。","text":"环境背景 使用libvirt管理kvm， 需要在不知道虚拟机ip的情况下，与虚拟机进行交互。 翻了翻，qemu有提供一个qemu-guest-agent的工具，在虚拟机内安装后就可以让宿主机获取虚拟机内的信息了。 操作引导 根据redhat的指导[1], 在rhel7的系统的虚拟机xml里插入以下内容 123&lt;channel type=&apos;unix&apos;&gt; &lt;target type=&apos;virtio&apos; name=&apos;org.qemu.guest_agent.0&apos;/&gt;&lt;/channel&gt; 原理上，上面这部分为虚拟机添加了一个叫做org.qemu.guest_agent.0的串口，而在宿主机上则是在路径/var/lib/libvirt/qemu/channel/target/&lt;domain-6-kvm01&gt;/org.qemu.guest_agent.0创建了一个unix socket。 不过为什么要在虚拟机内建立的是串口呢？而不是和宿主机一样的unix socket呢？ 虚拟机内安装这个包之后，启动这个服务就可以了。 123yum install qemu-guest-agentsystemctl start qemu-guest-agentsystemctl enable qemu-guest-agent 这里需要注意，默认安装的qga的service文件中的串口名都是默认的guest_agent.0，如果在指定时修改了这个，手动指定了bind socket路径和target，那么虚拟机内的服务文件就需要替换这些默认名。并且，宿主机就监听不到我们所使用的端口了，需要手动使用下面的socat命令监听了。 然后宿主机，有3种 1. 执行socat /var/lib/libvirt/qemu/channel/target/&lt;domain-6-kvm01&gt;/org.qemu.guest_agent.0 readline，在这里交互式输入json格式的命令可以得到结果 2. virsh qemu-agent-command kvm_instance ‘{“execute”:“guest-network-get-interfaces”}’ 3. 也可以通过qemu-guest-agent提供的api执行命令，不过似乎要添加他的so包，没尝试 常用命令 123456789101112&#123;&quot;execute&quot;: &quot;guest-info&quot;&#125;通过下述3个命令在虚拟机内写信息到文件内&#123;&quot;execute&quot;:&quot;guest-file-open&quot;, &quot;arguments&quot;:&#123;&quot;path&quot;:&quot;/home/testqga&quot;,&quot;mode&quot;:&quot;w+&quot;&#125;&#125;&#123;&quot;execute&quot;:&quot;guest-file-write&quot;,&quot;arguments&quot;:&#123;&quot;handle&quot;:0,&quot;buf-b64&quot;:&quot;aGVsbG8gd29ybGQhCg==&quot;&#125;&#125;# 注意这个handle是返回的句柄&#123;&quot;execute&quot;:&quot;guest-file-close&quot;, &quot;arguments&quot;:&#123;&quot;handle&quot;:0&#125;&#125;# 获取虚拟机网络信息ip&#123;&quot;execute&quot;:&quot;guest-network-get-interfaces&quot;&#125; 接口扩展 如果想要在虚拟机内执行没有默认提供的命令，就需要编辑qga源码，自己添加了。当时还以为是提供的一个类似配置文件的方式进行扩展，然后实际上是自己修改源码，扩展。 去github上svn checkout https://github.com/qemu/qemu/trunk/qga拉下这个文件夹，参考[4]操作编译就好了。 在虚拟机内执行命令 如果只是需要执行shell脚本的话，参照[3],似乎可以通过上面的方法写入到fsfreeze-hook.d中，然后fsfreeze-hook来执行。 12virsh qemu-agent-command instance &apos;&#123;&quot;execute&quot;:&quot;guest-fsfreeze-freeze&quot;&#125;&apos;virsh qemu-agent-command instance &apos;&#123;&quot;execute&quot;:&quot;guest-fsfreeze-thaw&quot;&#125;&apos; 不过也可以通过上面的network interface得到ip之后通过socket或者rpc等等自己定制接口来执行就是了。 Reference How to enable QEMU guest agent in KVM qemu-guest-agent api openstack通过qemu-guest-agent在物理机上操作虚拟机","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://sean10.github.io/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://sean10.github.io/tags/虚拟化/"}]},{"title":"frp远程桌面尝试","slug":"frp远程桌面尝试","date":"2018-08-09T15:11:43.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/08/09/frp远程桌面尝试/","link":"","permalink":"https://sean10.github.io/2018/08/09/frp远程桌面尝试/","excerpt":"迫于公司访问外网使用的机器性能以及对外网访问的各种路由、权限限制，尝试远程到家里的电脑来进行访问。","text":"迫于公司访问外网使用的机器性能以及对外网访问的各种路由、权限限制，尝试远程到家里的电脑来进行访问。 历程 偶然间看到带我的导师用的anydesk连的家里的电脑，推动了我马上开始捣鼓远程桌面。 在学校内网时，主要直接使用RDP来访问，现在都被NAT过了，那么就只有一些通过服务器来中转的软件可以使用了，第一反应就是teamviewer,不过经过这个月的摸索，公司对http请求都会ban掉，对于一些存在过风险的软件恐怕更加会ban了，果不其然，teamviewer的请求都是被拒绝了的。 简单了解，anydesk基本功能等同teamviewer，简单安装尝试，效果很棒，第一天从第一次连接到晚上下班，连接一直都没有断开。 只是第二天就是噩梦的来临，anydesk连接的持续时间不足5分钟就会断开，当时曾以为是公司网络的限制，回到家后同样如此，那么猜测可能是个人License的区别了，官网看了下，个人使用版本年费79刀，才能保证session。唉，只好选择其他方式了。 那么，就回归看上去最费事的frp穿透了。 frp穿透+rdp远程桌面 配置说简单也简单，但是在像公司网络限制的地方，就难以确定可能出现的问题原因究竟是配置问题还是网络问题了。 123wget https://github.com/fatedier/frp/releases/download/v0.20.0/frp_0.20.0_linux_amd64.tar.gztar -zxvf frp_0.20.0_linux_amd64.tar.gzcd frp_0.20.0_linux_amd64/ 服务端基本可以不改配置，直接启动./frps -c ./frps.ini也行 123# frps.ini[common]bind_port = 7000 客户端，按照需求从full.ini中选取需要的就可以了，比如rdp,启动方式同上 12345678910# frpc.ini[common]server_addr = X.X.X.Xserver_port = 7000[RDP]type = tcplocal_ip = 0.0.0.0local_port = 3389remote_port = 6000 两个都连上以后就可以看到start proxy success的成功信息。 不过成功连上以后，性能却不甚理想……远比anydesk使用时卡顿的多，看来还需要探索其他方式。 如果不是使用rdp，只需要ssh，可能还是非常不错的。 需要后台的话，使用systemd管理的方式的，在/lib/systemd/system/里添加一个service文件 123456789[Unit]Description=frps daemon[Service]ExecStart=/root/frp_0.20.0_linux_amd64/frps -c /root/frp_0.20.0_linux_amd64/frps.iniRestart=always[Install]WantedBy=multi-user.target 上面这样基本就可以了，注意执行命令必须都是绝对路径 systemd的基本控制命令如下 123systemctl daemon-reloadsystemctl restart frps systemctl enable frps # 将frps作为开机启动项","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"frp","slug":"frp","permalink":"https://sean10.github.io/tags/frp/"},{"name":"rdp","slug":"rdp","permalink":"https://sean10.github.io/tags/rdp/"}]},{"title":"rsyslog & journald日志系统结构","slug":"rsyslog-journald日志系统结构","date":"2018-08-01T17:45:01.000Z","updated":"2020-10-18T08:00:24.000Z","comments":true,"path":"2018/08/02/rsyslog-journald日志系统结构/","link":"","permalink":"https://sean10.github.io/2018/08/02/rsyslog-journald日志系统结构/","excerpt":"之前在公司服务器上验证了好多次流程图，结果是被改过代码了可能，运行结果与原生CentOS镜像结果不同。被迫混淆了好久。","text":"之前在公司服务器上验证了好多次流程图，结果是被改过代码了可能，运行结果与原生CentOS镜像结果不同。被迫混淆了好久。 基本背景 实验环境 Centos 7.4 rsyslog 8.24 systemd环境 rsyslog与systemd-journald日志流向 目前来看，lsof只能查看该进程监听的socket,不显示它发送的socket。通过strace追踪，RecMsg会显示发送方的进程pid，从那里可以看到是哪个进程发送到自己监听的socket的信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# rsyslog[root@localhost ~]# strace -T -ttt -f -p 35341strace: Process 35341 attached with 3 threads[pid 35343] 1532962871.699907 futex(0x559329e6e2ac, FUTEX_WAIT_PRIVATE, 23, NULL &lt;unfinished ...&gt;[pid 35342] 1532962871.699926 select(4, [3], NULL, NULL, NULL &lt;unfinished ...&gt;[pid 35341] 1532962871.699940 select(1, NULL, NULL, NULL, &#123;367, 871364&#125; &lt;unfinished ...&gt;[pid 35342] 1532962894.732966 &lt;... select resumed&gt; ) = 1 (in [3]) &lt;23.033022&gt;[pid 35342] 1532962894.733015 recvmsg(3, &#123;msg_name(0)=NULL, msg_iov(1)=[&#123;\"&lt;13&gt;Jul 30 11:01:34 root: newer\", 8096&#125;], msg_controllen=64, [&#123;cmsg_len=32, cmsg_level=SOL_SOCKET, cmsg_type=0x1d /* SCM_??? */&#125;, &#123;cmsg_len=28, cmsg_level=SOL_SOCKET, cmsg_type=SCM_CREDENTIALS, &#123;pid=10247, uid=0, gid=0&#125;&#125;], msg_flags=0&#125;, MSG_DONTWAIT) = 31 &lt;0.000008&gt;[pid 35342] 1532962894.733070 futex(0x559329e6e2ac, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x559329e6e2a8, &#123;FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1&#125; &lt;unfinished ...&gt;[pid 35343] 1532962894.733094 &lt;... futex resumed&gt; ) = 0 &lt;23.033169&gt;[pid 35342] 1532962894.733098 &lt;... futex resumed&gt; ) = 1 &lt;0.000018&gt;[pid 35343] 1532962894.733110 futex(0x559329e6e0b0, FUTEX_WAIT_PRIVATE, 2, NULL &lt;unfinished ...&gt;[pid 35342] 1532962894.733116 futex(0x559329e6e0b0, FUTEX_WAKE_PRIVATE, 1 &lt;unfinished ...&gt;[pid 35343] 1532962894.733128 &lt;... futex resumed&gt; ) = -1 EAGAIN (Resource temporarily unavailable) &lt;0.000012&gt;[pid 35342] 1532962894.733140 &lt;... futex resumed&gt; ) = 0 &lt;0.000021&gt;[pid 35343] 1532962894.733154 futex(0x559329e6e0b0, FUTEX_WAKE_PRIVATE, 1 &lt;unfinished ...&gt;[pid 35342] 1532962894.733160 select(4, [3], NULL, NULL, NULL &lt;unfinished ...&gt;[pid 35343] 1532962894.733175 &lt;... futex resumed&gt; ) = 0 &lt;0.000016&gt;[pid 35343] 1532962894.733194 write(5, \"Jul 30 11:01:34 localhost root: \"..., 38) = 38 &lt;0.000020&gt;[pid 35343] 1532962894.733234 futex(0x559329e6e2ac, FUTEX_WAIT_PRIVATE, 25, NULL# systemd-journald[root@localhost ~]# strace -ttt -f -p 10247strace: Process 10247 attached1532962887.731909 epoll_wait(7, [&#123;EPOLLIN, &#123;u32=3876856720, u64=94080840508304&#125;&#125;], 10, -1) = 11532962894.732687 clock_gettime(CLOCK_BOOTTIME, &#123;246287, 470494988&#125;) = 01532962894.732723 ioctl(5, FIONREAD, [31]) = 01532962894.732755 recvmsg(5, &#123;msg_name(0)=0x7ffc9785fab0, msg_iov(1)=[&#123;\"&lt;13&gt;Jul 30 11:01:34 root: newer\", 24575&#125;], msg_controllen=136, [&#123;cmsg_len=32, cmsg_level=SOL_SOCKET, cmsg_type=0x1d /* SCM_??? */&#125;, &#123;cmsg_len=28, cmsg_level=SOL_SOCKET, cmsg_type=SCM_CREDENTIALS, &#123;pid=35455, uid=0, gid=0&#125;&#125;, &#123;cmsg_len=70, cmsg_level=SOL_SOCKET, cmsg_type=SCM_SECURITY, \"unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023\\0\"&#125;], msg_flags=MSG_CMSG_CLOEXEC&#125;, MSG_DONTWAIT|MSG_CMSG_CLOEXEC) = 311532962894.732825 sendmsg(5, &#123;msg_name(29)=&#123;sa_family=AF_LOCAL, sun_path=\"/run/systemd/journal/syslog\"&#125;, msg_iov(1)=[&#123;\"&lt;13&gt;Jul 30 11:01:34 root: newer\", 31&#125;], msg_controllen=28, [&#123;cmsg_len=28, cmsg_level=SOL_SOCKET, cmsg_type=SCM_CREDENTIALS, &#123;pid=35455, uid=0, gid=0&#125;&#125;], msg_flags=0&#125;, MSG_NOSIGNAL) = -1 ESRCH (No such process)1532962894.732870 sendmsg(5, &#123;msg_name(29)=&#123;sa_family=AF_LOCAL, sun_path=\"/run/systemd/journal/syslog\"&#125;, msg_iov(1)=[&#123;\"&lt;13&gt;Jul 30 11:01:34 root: newer\", 31&#125;], msg_controllen=28, [&#123;cmsg_len=28, cmsg_level=SOL_SOCKET, cmsg_type=SCM_CREDENTIALS, &#123;pid=10247, uid=0, gid=0&#125;&#125;], msg_flags=0&#125;, MSG_NOSIGNAL) = 311532962894.733261 open(\"/proc/35455/cgroup\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733307 open(\"/proc/35455/comm\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733331 readlinkat(AT_FDCWD, \"/proc/35455/exe\", 0x5590e71435b0, 99) = -1 ENOENT (No such file or directory)1532962894.733872 open(\"/proc/35455/cmdline\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733923 open(\"/proc/35455/status\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733946 open(\"/proc/35455/sessionid\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733988 open(\"/proc/35455/loginuid\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.734014 open(\"/proc/35455/cgroup\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.734050 fstat(14, &#123;st_mode=S_IFREG|0640, st_size=8388608, ...&#125;) = 01532962894.734146 ftruncate(14, 8388608) = 0这里可以看到，35455是logger发送时建立的进程pid[root@localhost ~]# journalctl | grep 35455Jul 30 10:31:18 localhost.localdomain root[35455]: 123Jul 30 10:32:35 localhost.localdomain root[35455]: 123Jul 30 10:34:03 localhost.localdomain root[35455]: 123Jul 30 10:35:30 localhost.localdomain root[35455]: 123Jul 30 11:01:34 localhost.localdomain root[35455]: newer 常见问题 日志重复 见上图，可知默认rsyslog.conf中启动了imuxsock与imjournal两个模块，分别会通过不同的渠道获得syslog日志，因此会导致重复。配置方法详见下章配置信息对应项。 日志丢失 由于日志频次丢失 rsyslog的imjournal模块读取数据库有一个频率上限设置，而systemd-journald也有一个数据库读取频率上限设置。满足rsyslog频率上限，messages中就会drop日志；满足systemd-journald上限，journald就会miss日志。配置方法详见下章配置信息对应项。 123rsyslogd: imjournal: 84667 messages lost due to rate-limitingsystemd-journal[1770]: Missed 1427 kernel messages journal正常，rsyslog停止记录日志 当前测试似乎是在/var/log/messages被移动或者被删除或者被轮转了导致的这个问题 在logrotate那里执行了达到100M就轮转的功能，会删除.1文件然后备份 但是这边的现象还是有点怪，在我关闭那个特别高频的日志写入之后，就会更新最新的了，但这是为什么呢？ 这里的messages是在/b_iscsi/log/messages里的，这块的设置倒是和我没太大关系，不过原因还是得测试一下，在自己的53.31的/var/log/messages里测试是没什么问题的。 通过lsof，并且从logrotate那里删除自动备份的操作，结果发现，rsyslog还是会出现被删除的情况，但是没找到哪里触发的， logrotate会在100M时删除 sys_space这个进程会在messages达到110M时删除 Aug 29 17:02:28 localhost syslog: [do_record_log_t:1013] get log info error 目前更换回/var/log/messages，没有出现被删的情况，但是每满130M会出现一次rsyslog不再读取journal的问题,需要移除那个快速写入的程序才能接着更新 看了下卡死的那个时候，rsyslog的lsof显示并不是像我之前想的那样，读取的全都是Deleted文件，反而有些是正常的文件。 刚才试了一下，top里可以看到rsyslog卡死之后读取了30M缓存。 欸，但是命名rsyslog是直接读取systemd-journald数据库啊，哪里有缓存的位置 测试journald数据库性能上限 数据库文件大小上限设置为2T,在尚未抵达文件大小上限时，出现了间歇的丢失日志 123456789101112131415161718192021222324252627282930Aug 7 15:53:23 localhost journal: Missed 68 kernel messagesAug 7 15:53:23 localhost journal: Missed 770 kernel messagesAug 7 15:53:23 localhost journal: Missed 16 kernel messagesAug 7 15:53:23 localhost journal: Missed 95 kernel messagesAug 7 15:53:23 localhost journal: Missed 77 kernel messagesAug 7 15:53:23 localhost journal: Missed 65 kernel messagesAug 7 15:53:23 localhost journal: Missed 71 kernel messagesAug 7 15:53:23 localhost journal: Missed 92 kernel messagesAug 7 15:53:23 localhost journal: Missed 110 kernel messagesAug 7 15:53:23 localhost journal: Missed 89 kernel messagesAug 7 15:53:23 localhost journal: Missed 206 kernel messagesAug 7 15:53:23 localhost journal: Missed 5 kernel messagesAug 7 15:53:23 localhost journal: Missed 485 kernel messagesAug 7 15:53:23 localhost journal: Missed 243 kernel messagesAug 7 15:53:23 localhost journal: Missed 105 kernel messagesAug 7 15:53:23 localhost journal: Missed 893 kernel messagesAug 7 15:53:23 localhost journal: Missed 947 kernel messagesAug 7 15:53:23 localhost journal: Missed 837 kernel messagesAug 7 15:53:23 localhost journal: Missed 890 kernel messagesAug 7 15:53:23 localhost journal: Missed 892 kernel messagesAug 7 15:53:23 localhost journal: Missed 914 kernel messagesAug 7 15:53:23 localhost journal: Missed 894 kernel messagesAug 7 15:53:23 localhost journal: Missed 896 kernel messagesAug 7 15:53:23 localhost journal: Missed 888 kernel messagesAug 7 15:53:23 localhost journal: Missed 901 kernel messagesAug 7 15:53:23 localhost journal: Missed 928 kernel messagesAug 7 15:53:23 localhost journal: Missed 887 kernel messagesAug 7 15:53:23 localhost journal: Missed 884 kernel messagesAug 7 15:53:23 localhost journal: Missed 905 kernel messages: 测试再persistent与volatile状态下，数据库停止记录条件 目前在设置了日志上限的情况下，并没有出现数据库卡死，都是在覆写之前的日志。 在公司镜像上测试，发现，在volatile状态下的日志，和在persistent状态下，同样会自动覆写之前的日志。 仅当journald日志大小达到该分区上限时，目前测试为当RunMaxUse大于分区可用空间时，会导致日志卡死。 imjournald journal reloaded问题 这个问题在[7]中被提到，主要时由于systemd-journald正在轮转数据库文件，因此导致数据库文件变动，所以会出现这个reload日志。 根据[8]中添加的这个日志信息，可以看到是为了在journald切换文件位置时，为了不用重启rsyslog而添加的自动切换。 经过测试，journal日志每被切割一次，都会产生一个reloaded信息（日志level是info，不是Error，所以可以忽视） /dev/log 丢失 参照[11]，这个socket似乎在systemd设备上，是由systemd-journald.socket提供， 如果是单独的rsyslog的日志管理下，则是由imuxsock插件创建， Normally, with rsyslogd, the imuxsock module will create the /dev/log socket on its own, unlinking the previous entry before creating it. When rsyslogd is stopped (possibly because restart which fails because of faulty configuration), rsyslogd removes /dev/log. However, the rsyslog supplied with RHEL7 is expected to be used in conjunction with systemd, and the imuxsock module will actually open and remove /run/systemd/journal/syslog socket. Meanwhile, the /dev/log device is created by the system service-file systemd-journald.socket which triggers journald. 在systemd-journald.socket这个服务的Unit文件里是这么写的 123456789101112131415161718192021222324252627[root@localhost ~]# less /lib/systemd/system/systemd-journald.socket # This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.[Unit]Description=Journal SocketDocumentation=man:systemd-journald.service(8) man:journald.conf(5)DefaultDependencies=noBefore=sockets.target# Mount and swap units need this. If this socket unit is removed by an# isolate request the mount and swap units would be removed too,# hence let&apos;s exclude this from isolate requests.IgnoreOnIsolate=yes[Socket]ListenStream=/run/systemd/journal/stdoutListenDatagram=/run/systemd/journal/socketListenDatagram=/dev/logSocketMode=0666PassCredentials=yesPassSecurity=yesReceiveBuffer=8M 这里可以看到监听的/dev/log端口创建是由这个服务管理的。 /var/log/messages 时间存在跳变，乱序 暂时无法复现 journal input/output Error 理论上来说，应该是journald连接写入到数据库被阻断了，数据库无法访问导致的问题。 不过应该仅针对journalctl读取时的问题 将/var/log/journal目录做了软链接后，指向路径是被挂载的盘，在系统启动尚未挂载上时，会导致日志不合并，会丢失 欸，我试下了，挂载上后，新的日志就看不到了，而卸载掉后，这次启动的日志文件还是在的。 在测试中，新挂载的盘中与systemd-journal并没有建立连接，在lsof中看到的该路径下的文件是现在已经被隐藏了的目录，通过stat查看了文件inode，的确如此。 12345678910111213141516171819202122systemd-j 432 root 17u REG 8,1 8388608 531238 /root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal[root@thor ~]# stat /root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal File: 鈥root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal鈥 Size: 8388608 Blocks: 16384 IO Block: 4096 regular fileDevice: 811h/2065d Inode: 42729475 Links: 1Access: (0640/-rw-r-----) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2018-08-22 14:31:18.865335001 +0800Modify: 2018-08-22 14:27:43.244195482 +0800Change: 2018-08-22 14:27:43.244195482 +0800 Birth: -[root@thor ~]# umount /dev/sdc1[root@thor ~]# stat /root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal File: 鈥root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal鈥 Size: 8388608 Blocks: 16408 IO Block: 4096 regular fileDevice: 801h/2049d Inode: 531238 Links: 1Access: (0640/-rw-r-----) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2018-08-22 14:34:01.246346582 +0800Modify: 2018-08-22 14:39:01.133367970 +0800Change: 2018-08-22 14:39:01.133367970 +0800 Birth: - 配置信息 /etc/rsyslog.conf $ModLoad imuxsock 该模块导入监听本机syslog socket的功能，从syslog中接收日志,该配置项依赖systemd-journald.conf中的ForwardToSyslog=Yes $OmitLocalLogging 与 $SystemLogSocketName 该配置信息测试结果与官网有所区别，测试中指定socketName为/dev/log(可修改)，系统默认指向socket为/run/systemd/journal/syslog。使用详见下表。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# 显式关闭 OmitLocalLog,未指定socketName || 非显式关闭，未指定socketName[root@localhost ~]# lsof -c rsyslogCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 1713 root cwd DIR 253,0 224 64 /rsyslogd 1713 root rtd DIR 253,0 224 64 /rsyslogd 1713 root txt REG 253,0 663960 961 /usr/sbin/rsyslogdrsyslogd 1713 root mem REG 253,0 38128 9671 /usr/lib64/rsyslog/imuxsock.sorsyslogd 1713 root mem REG 253,0 24520 9672 /usr/lib64/rsyslog/lmnet.sorsyslogd 1713 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sorsyslogd 1713 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1rsyslogd 1713 root mem REG 253,0 20040 87327 /usr/lib64/libuuid.so.1.3.0rsyslogd 1713 root mem REG 253,0 40824 322855 /usr/lib64/libfastjson.so.4.0.0rsyslogd 1713 root mem REG 253,0 15424 322847 /usr/lib64/libestr.so.0.0.0rsyslogd 1713 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sorsyslogd 1713 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sorsyslogd 1713 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sorsyslogd 1713 root mem REG 253,0 90664 87310 /usr/lib64/libz.so.1.2.7rsyslogd 1713 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sorsyslogd 1713 root 0r CHR 1,3 0t0 5423 /dev/nullrsyslogd 1713 root 1w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1713 root 2w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1713 root 3u unix 0xffff880037064800 0t0 29648 /run/systemd/journal/syslog# 显式打开OmitLocalLog 并 指定socketName || 并不指定socketName[root@localhost ~]# lsof -c rsyslogCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 1765 root cwd DIR 253,0 224 64 /rsyslogd 1765 root rtd DIR 253,0 224 64 /rsyslogd 1765 root txt REG 253,0 663960 961 /usr/sbin/rsyslogdrsyslogd 1765 root mem REG 253,0 38128 9671 /usr/lib64/rsyslog/imuxsock.sorsyslogd 1765 root mem REG 253,0 24520 9672 /usr/lib64/rsyslog/lmnet.sorsyslogd 1765 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sorsyslogd 1765 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1rsyslogd 1765 root mem REG 253,0 20040 87327 /usr/lib64/libuuid.so.1.3.0rsyslogd 1765 root mem REG 253,0 40824 322855 /usr/lib64/libfastjson.so.4.0.0rsyslogd 1765 root mem REG 253,0 15424 322847 /usr/lib64/libestr.so.0.0.0rsyslogd 1765 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sorsyslogd 1765 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sorsyslogd 1765 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sorsyslogd 1765 root mem REG 253,0 90664 87310 /usr/lib64/libz.so.1.2.7rsyslogd 1765 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sorsyslogd 1765 root 0r CHR 1,3 0t0 5423 /dev/nullrsyslogd 1765 root 1w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1765 root 2w CHR 1,3 0t0 5423 /dev/null# 非显式开启OmitLocalLog ，指定socketName || 显式关闭OmitLocalLog, 并指定SocketName[root@localhost ~]# lsof -c rsyslogCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 1779 root cwd DIR 253,0 224 64 /rsyslogd 1779 root rtd DIR 253,0 224 64 /rsyslogd 1779 root txt REG 253,0 663960 961 /usr/sbin/rsyslogdrsyslogd 1779 root mem REG 253,0 38128 9671 /usr/lib64/rsyslog/imuxsock.sorsyslogd 1779 root mem REG 253,0 24520 9672 /usr/lib64/rsyslog/lmnet.sorsyslogd 1779 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sorsyslogd 1779 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1rsyslogd 1779 root mem REG 253,0 20040 87327 /usr/lib64/libuuid.so.1.3.0rsyslogd 1779 root mem REG 253,0 40824 322855 /usr/lib64/libfastjson.so.4.0.0rsyslogd 1779 root mem REG 253,0 15424 322847 /usr/lib64/libestr.so.0.0.0rsyslogd 1779 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sorsyslogd 1779 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sorsyslogd 1779 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sorsyslogd 1779 root mem REG 253,0 90664 87310 /usr/lib64/libz.so.1.2.7rsyslogd 1779 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sorsyslogd 1779 root 0r CHR 1,3 0t0 5423 /dev/nullrsyslogd 1779 root 1w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1779 root 2w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1779 root 3u unix 0xffff88003b564800 0t0 30441 /dev/logrsyslogd 1779 root 4u unix 0xffff88003b560800 0t0 30443 socketrsyslogd 1779 root 5w REG 253,0 754001 17131680 /var/log/messagesrsyslogd 1779 root 6w REG 253,0 24654 17131681 /var/log/secure 由上述可知，在不同情况下，rsyslog实际监听的socket如下 x 显式开启 显式关闭 非显式开启 指定socket null /dev/log /dev/log 不指定socket null /run/systemd/journal/syslog /run/systemd/journal/syslog $ModLoad imjournal 该模块导入直接读取systemd-journald数据库的功能，可直接从journald数据库中读取syslog日志、内核日志以及服务stdout。 imjournal在lsof中可以看到，直接读取的数据库 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889[root@localhost ~]# lsof /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsystemd-j 10247 root mem REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalsystemd-j 10247 root 12u REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalrsyslogd 10255 root mem REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalrsyslogd 10255 root 5r REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journal[root@localhost ~]# lsof -c systemd-journalCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsystemd-j 10247 root cwd DIR 253,0 224 64 /systemd-j 10247 root rtd DIR 253,0 224 64 /systemd-j 10247 root txt REG 253,0 274752 16874824 /usr/lib/systemd/systemd-journaldsystemd-j 10247 root mem REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalsystemd-j 10247 root mem REG 253,0 19888 87389 /usr/lib64/libattr.so.1.1.0systemd-j 10247 root mem REG 253,0 402384 87259 /usr/lib64/libpcre.so.1.2.0systemd-j 10247 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sosystemd-j 10247 root mem REG 253,0 19384 87371 /usr/lib64/libgpg-error.so.0.10.0systemd-j 10247 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sosystemd-j 10247 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sosystemd-j 10247 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1systemd-j 10247 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sosystemd-j 10247 root mem REG 253,0 37056 87391 /usr/lib64/libacl.so.1.1.0systemd-j 10247 root mem REG 253,0 155744 87307 /usr/lib64/libselinux.so.1systemd-j 10247 root mem REG 253,0 535064 87381 /usr/lib64/libgcrypt.so.11.8.2systemd-j 10247 root mem REG 253,0 157424 87316 /usr/lib64/liblzma.so.5.2.2systemd-j 10247 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sosystemd-j 10247 root mem REG 0,19 8 7972 /run/systemd/journal/kernel-seqnumsystemd-j 10247 root 0r CHR 1,3 0t0 5423 /dev/nullsystemd-j 10247 root 1w CHR 1,3 0t0 5423 /dev/nullsystemd-j 10247 root 2w CHR 1,3 0t0 5423 /dev/nullsystemd-j 10247 root 3u unix 0xffff880037e83000 0t0 42542 /run/systemd/journal/stdoutsystemd-j 10247 root 4u unix 0xffff880037e81400 0t0 42544 /run/systemd/journal/socketsystemd-j 10247 root 5u unix 0xffff880037e80800 0t0 42546 /dev/logsystemd-j 10247 root 6w CHR 1,11 0t0 5429 /dev/kmsgsystemd-j 10247 root 7u a_inode 0,9 0 5419 [eventpoll]systemd-j 10247 root 8u a_inode 0,9 0 5419 [timerfd]systemd-j 10247 root 9u CHR 1,11 0t0 5429 /dev/kmsgsystemd-j 10247 root 10r REG 0,3 0 7973 /proc/sys/kernel/hostnamesystemd-j 10247 root 11u a_inode 0,9 0 5419 [signalfd]systemd-j 10247 root 12u REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalsystemd-j 10247 root 13u a_inode 0,9 0 5419 [timerfd][root@localhost ~]# lsof -c rsyslogCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 10255 root cwd DIR 253,0 224 64 /rsyslogd 10255 root rtd DIR 253,0 224 64 /rsyslogd 10255 root txt REG 253,0 663960 961 /usr/sbin/rsyslogdrsyslogd 10255 root mem REG 0,19 25165824 307917 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-0000000000000f6d-0005722d8a52e79b.journalrsyslogd 10255 root mem REG 0,19 25165824 2282729 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-00000000000074f5-0005722d9bdab060.journalrsyslogd 10255 root mem REG 0,19 25165824 4612418 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-000000000000dcd4-0005722db4fed7dd.journalrsyslogd 10255 root mem REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalrsyslogd 10255 root mem REG 0,19 6455296 7976 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-0000000000000001-000571ff63cd3044.journalrsyslogd 10255 root mem REG 253,0 68192 87353 /usr/lib64/libbz2.so.1.0.6rsyslogd 10255 root mem REG 253,0 99944 87368 /usr/lib64/libelf-0.168.sorsyslogd 10255 root mem REG 253,0 402384 87259 /usr/lib64/libpcre.so.1.2.0rsyslogd 10255 root mem REG 253,0 19888 87389 /usr/lib64/libattr.so.1.1.0rsyslogd 10255 root mem REG 253,0 297328 115274 /usr/lib64/libdw-0.168.sorsyslogd 10255 root mem REG 253,0 111080 72708 /usr/lib64/libresolv-2.17.sorsyslogd 10255 root mem REG 253,0 19384 87371 /usr/lib64/libgpg-error.so.0.10.0rsyslogd 10255 root mem REG 253,0 535064 87381 /usr/lib64/libgcrypt.so.11.8.2rsyslogd 10255 root mem REG 253,0 157424 87316 /usr/lib64/liblzma.so.5.2.2rsyslogd 10255 root mem REG 253,0 155744 87307 /usr/lib64/libselinux.so.1rsyslogd 10255 root mem REG 253,0 1139680 61008 /usr/lib64/libm-2.17.sorsyslogd 10255 root mem REG 253,0 20032 87393 /usr/lib64/libcap.so.2.22rsyslogd 10255 root mem REG 253,0 25072 9665 /usr/lib64/rsyslog/imjournal.sorsyslogd 10255 root mem REG 253,0 24520 9672 /usr/lib64/rsyslog/lmnet.sorsyslogd 10255 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sorsyslogd 10255 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1rsyslogd 10255 root mem REG 253,0 20040 87327 /usr/lib64/libuuid.so.1.3.0rsyslogd 10255 root mem REG 253,0 40824 322855 /usr/lib64/libfastjson.so.4.0.0rsyslogd 10255 root mem REG 253,0 15424 322847 /usr/lib64/libestr.so.0.0.0rsyslogd 10255 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sorsyslogd 10255 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sorsyslogd 10255 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sorsyslogd 10255 root mem REG 253,0 90664 87310 /usr/lib64/libz.so.1.2.7rsyslogd 10255 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sorsyslogd 10255 root mem REG 253,0 162560 237027 /usr/lib64/libsystemd.so.0.6.0rsyslogd 10255 root 0r CHR 1,3 0t0 5423 /dev/nullrsyslogd 10255 root 1w CHR 1,3 0t0 5423 /dev/nullrsyslogd 10255 root 2w CHR 1,3 0t0 5423 /dev/nullrsyslogd 10255 root 3r a_inode 0,9 0 5419 inotifyrsyslogd 10255 root 4u unix 0xffff880037338800 0t0 9404081 socketrsyslogd 10255 root 5r REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalrsyslogd 10255 root 6r REG 0,19 25165824 4612418 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-000000000000dcd4-0005722db4fed7dd.journalrsyslogd 10255 root 7r REG 0,19 25165824 2282729 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-00000000000074f5-0005722d9bdab060.journalrsyslogd 10255 root 8r REG 0,19 25165824 307917 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-0000000000000f6d-0005722d8a52e79b.journalrsyslogd 10255 root 9r REG 0,19 6455296 7976 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-0000000000000001-000571ff63cd3044.journalrsyslogd 10255 root 10w REG 253,0 49250519 17152683 /var/log/messagesrsyslogd 10255 root 11w REG 253,0 4634 17152684 /var/log/secure $imjournalRatelimitInterval 0 该属性设置为5s,代表以5s为一个间隙统计日志频次，达到下一条配置设置的频次，即放弃读取journald数据库信息(待验证是读取前放弃，还是读取后丢弃)。 $imjournalRatelimitBurst 0 该属性设置为上一条设置的间隙期间读取日志条数上限，如5s内读取1000条，达到该频次即停止。与上一条同时设置为0，即关闭该上限 Note that it is not recommended to turn of ratelimiting, except that you know for sure journal database entries will never be corrupted. Without ratelimiting, a corrupted systemd journal database may cause a kind of denial of service (we are stressing this point as multiple users have reported us such problems with the journal database - information current as of June 2013). 但是官方并不建议关闭该上限，可能会导致数据库阻塞等问题导致其他服务出现异常。 $ModLoad imklog 该模块导入直接从平台内核中读取内核日志的功能，可以避过journald数据库读写性能瓶颈。 $ModLoad imkmsg 该模块通过/dev/kmsg设备，获取结构化日志 $ModLoad imudp 导入该模块，并打开防火墙放行，可远程访问该主机获取日志信息 $ModLoad imtcp 导入该模块，并打开防火墙放行，可远程访问该主机获取日志信息 转发规则 rhel7系统中，一般log默认保存在下述目录，/var/log 目录保管由rsyslog维护的各种特定于系统和服务的日志文件。 /var/log/messages大多数系统日志消息记录在此。例外是与身份验证，电子邮件处理相关的定期运行作业的消息以及纯粹与调试相关的信息。 /var/log/secure安全和身份验证相关的消息和错误的日志文件。 /var/log/maillog与邮件服务器相关的日志文件。 /var/log/cron crond计划任务的日志 /var/log/boot.log与系统启动相关的消息记录在此。 建议不直接修改rsyslog.conf的规则，在这个目录$IncludeConfig /etc/rsyslog.d/*.conf下存放自定义的转发规则 1234567891011121314151617181920212223242526272829303132333435:msg, contains, \"of user root\" ~ &amp; ~:msg, contains, \"Removed session\" ~ &amp; ~:msg, contains, \"please try to use systemctl\" ~&amp; ~ # Log all kernel messages to the console.# Logging much else clutters up the screen.#kern.* /dev/console# Log anything (except mail) of level info or higher.# Don't log private authentication messages!*.info;mail.none;authpriv.none;cron.none /var/log/messages# The authpriv file has restricted access.authpriv.* /var/log/secure# Log all the mail messages in one place.mail.* -/var/log/maillog# Log cron stuffcron.* /var/log/cron# Everybody gets emergency messages*.emerg :omusrmsg:*# Save news errors of level crit and higher in a special file.uucp,news.crit /var/log/spooler# Save boot messages also to boot.loglocal7.* /var/log/boot.log 转发过滤规则，见文档 begin forwarding rule 暂未使用的远程访问日志配置信息，语法见Legacy Action-Specific Configuration Statements /etc/systemd/journald.conf systemd-journald主要获得以下信息 * Kernel log messages, via kmsg * Simple system log messages, via the libc syslog(3) call * Structured system log messages via the native Journal API, see sd_journal_print(4) * Standard output and standard error of service units. For further details see below. * Audit records, originating from the kernel audit subsystem RateLimitInterval=30s 频率间隙为30s RateLimitBurst=1000 每个间隙频次上限为1000，直到下个间隙不会接收日志 Storage=auto 该配置选项控制journald日志的存储位置，以下4个选项“volatile”, “persistent”, “auto” and “none”，对应/run/log/journal,/var/log/journal,根据/var/log/journal目录建立与否判断，收到即drop,但转发forward还是生效的(如imjournal等读取数据库文件等方式无效)。 RuntimeMaxUse= 设置内存中journald文件上限，一旦达到该上限，journald数据库就会阻塞住。 RuntimeKeepFree= RuntimeKeepFree表示需要保留的内存空间，剩余空间不足其设置，journald数据库同样会阻塞住。 SystemMaxUse= 与 RuntimeMaxUse= 的默认值是10%空间与4G空间两者中的较小者； SystemKeepFree= 与 RuntimeKeepFree= 的默认值是15%空间与4G空间两者中的较大者； 如果在 systemd-journald 启动时， 文件系统即将被填满并且已经超越了 SystemKeepFree= 或 RuntimeKeepFree= 的限制，那么日志记录将被暂停。 也就是说，如果在创建日志文件时，文件系统有充足的空闲空间， 但是后来文件系统被其他非日志文件过多占用， 那么 systemd-journald 只会立即暂停日志记录， 但不会删除已经存在的日志文件。 RuntimeMaxFileSize= SystemMaxFileSize= 与 RuntimeMaxFileSize= 限制单个日志文件的最大体积， 到达此限制后日志文件将会自动滚动。 默认值是对应的 SystemMaxUse= 与 RuntimeMaxUse= 值的1/8 ， 这也意味着日志滚动默认保留7个历史文件。 日志大小的值可以使用以1024为基数的 K, M, G, T, P, E 后缀， 分别对应于 1024, 1024², … 字节。 ForwardToSyslog=yes 转发syslog日志到syslog socket，从而使rsyslog调用imuxsock从该socket接收日志 该选项可被内核引导选项覆盖systemd.journald.forward_to_syslog=, systemd.journald.forward_to_kmsg=, systemd.journald.forward_to_console=, systemd.journald.forward_to_wall=，允许/禁止将收集到的日志： 转发到传统的 syslog 守护进程, 转发到内核日志缓冲区, 转发到系统控制台, 作为wall警告信息转发给所有已登录的用户 MaxLevelStore=debug MaxLevelSyslog=debug MaxLevelKMsg=notice MaxLevelConsole=info MaxLevelWall=emerg 以上配置控制在数据库上存储以及转发的最大日志等级。 日志等级一共分为“emerg”, “alert”, “crit”, “err”, “warning”, “notice”,“info”, “debug” /lib/systemd/system/systemd-journald.service StandardOutput=null 设置进程的标准输出(STDOUT)。 可设为 inherit, null, tty, journal, syslog, kmsg, journal+console, syslog+console, kmsg+console, socket, fd 之一。 inherit 表示使用 StandardInput= 设置的值。 null 表示 /dev/null ， 也就是所有写入都会被丢弃。 tty 表示 TTY(由 TTYPath= 设置)， 如果仅用于输出， 那么进程将无需取得终端的控制权， 亦无需等待其他进程释放终端控制权。 journal 表示 systemd 日志服务(通过 journalctl(1) 访问)。 注意，所有发到 syslog 或 kmsg 的日志都会 隐含的复制一份到 journal 中。 syslog 表示 syslog(3) 日志服务。 注意，此时所有日志都会隐含的复制一份到 journal 中。 kmsg 表示内核日志缓冲区(通过 dmesg(1) 访问)。 注意，此时所有日志都会隐含的复制一份到 journal 中。 journal+console, syslog+console, kmsg+console 与上面三个值类似， 不同之处在于所有日志都会再复制一份到系统的控制台上。 socket 的解释与 StandardInput= 中的解释完全相同。 fd 表示将标准输出(STDOUT)连接到一个由 socket 单元提供的文件描述符。 可以通过 “fd:foobar” 格式 明确指定文件描述符的名称。 描述符名称的默认值为 “stdout” ，也就是 “fd” 等价于 “fd:stdout” 。 必须明确使用 Sockets= 选项 提供至少一个定义了文件描述符名称的 socket 单元。 注意，文件描述符的名称不一定和定义它的 socket 单元的名称一致。 如果出现了多个匹配，那么以第一个为准， 详见 systemd.socket(5) 手册对 FileDescriptorName= 选项的讲解。 如果单元的标准输出(StandardOutput=)或标准错误(StandardError=)中含有 journal, syslog, kmsg 之一， 那么该单元将会自动隐含的获得 After=systemd-journald.socket 依赖(见上文)。 /etc/logrotate.conf 仅对持久化后的/var/log/journal有效 journald持久化 持久化保存journal的日志，默认保存一个月的日志 直接修改journald.conf中的storage为persistent就切换到var路径下了，切换到volatile就自动回/run/log了。 12systemctl restart systemd-journald.servicesystemctl restart systemd-journald.socket 如果出现了切换到persistent状态下，日志已经存到了/var/log/journal，但是/run/log/journal路径依旧存在的状况的话，可能是自动切换有些不同。就手动将volatile修改成auto,手动mkdir /var/log/journal，这样再重启比较适合防丢日志。 在切换前，为了防止journal数据库文件大小刚好超过设置的上限，然后由于重启了服务，没能及时自动清理掉超过的部分，从而导致数据库假死，建议使用journalctl --vacuumm-size=250M，可以清除日志直到满足这个大小限制。不过这个要求sytemd版本318及以上才支持这个选项。 如果版本不支持的话，那就还是rm -rf掉这些日志或者手动删掉一些数据库文件吧，升级systemd的版本似乎带来的风险相比这些日志的价值要大得多。[12] 调试方法 检验rsyslog配置信息 1234# 可以让rsyslogd 进入 Debug模式[root@localhost ~]# rsyslogd -N6rsyslogd: version 8.24.0, config validation run (level 6), master config /etc/rsyslog.confrsyslogd: invalid or yet-unknown config file command 'IMJournalStateFile' - have you forgotten to load a module? [v8.24.0 try http://www.rsyslog.com/e/3003 ] strace -p pid追踪进程 参考资料 imjournal: Systemd Journal Input Module rsyslog-logger-message-duplicated systemd service 单元语法 Filter Conditions imuxsock: Unix Socket Input Module man journald.conf rsyslog daemon have unkown log entries “rsyslogd:imjournal: journal reloaded” from time to time switching to persistent journal possible without rsyslog restart Journal is reloaded and duplicate messages are output into log file 关于Rsyslogd 的一些配置 (高性能、高可用 rsyslogd) How do I restore /dev/log in systemd+rsyslog host? How would I upgrade systemd? Is systemd-journald a syslog implementation?","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"rsyslog","slug":"rsyslog","permalink":"https://sean10.github.io/tags/rsyslog/"},{"name":"systemd","slug":"systemd","permalink":"https://sean10.github.io/tags/systemd/"}]},{"title":"RMBP_me865换屏小记","slug":"RMBP-me865换屏小记","date":"2018-07-28T03:08:55.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/07/28/RMBP-me865换屏小记/","link":"","permalink":"https://sean10.github.io/2018/07/28/RMBP-me865换屏小记/","excerpt":"这个屏幕在去年冬天坏的，大概1月份左右，当时考虑长期就在学校肝毕设，加上屏幕当时只黑了右侧总计1/4，还能用，所以就买了块比较便宜的显示器，1080p 21.5寸，在宿舍床上用着，还是挺不错的。","text":"这个屏幕在去年冬天坏的，大概1月份左右，当时考虑长期就在学校肝毕设，加上屏幕当时只黑了右侧总计1/4，还能用，所以就买了块比较便宜的显示器，1080p 21.5寸，在宿舍床上用着，还是挺不错的。 它挺过了我搬家的时候，没料到在偶然一天，合盖的时候可能被后侧的数据线卡到的，外屏裂痕扩大，内屏也多黑了1/4，这下，真没办法使用了。 首先，考虑到维修水深，转眼可能就会偷换零件，或者修坏什么，因此首选是有淘宝店的实体维修店。然而，结果很可惜，在上海的时候看到的评论比较真实的好评店铺，定位在北京以后，搜到的几近所有好评店铺，报价在1800以下的，咨询后给出的地址都是中关村…… 既然这样，那就咨询以下v站大佬，看看有没有什么好消息。在apple分区发了2天，只有一个大佬回复了，经搜索得到的结果有些可惜，报价2200up，其他几家越是名声好的，都报价在2000+。 最后，只好进行第3个选择，自己买材料，更换。由于事前有搜到过有大佬自己更换过屏幕总成，这种不仅是内屏损坏的只有一条路，直接更换总成，这样的技术要求反而更低，很适合个人自己操作。 这条选择一波三折，公司前辈说有工具，然后都没有5角梅花的螺丝头，哎，迫于快速修理的急切心情，下楼找了个修理店借了波工具，结果螺丝刀头磨损太严重，特别费事。花了2个半小时，换完总成，结果老板下班了收走了合盖用的螺丝刀。走的时候一手手机，一手换下来的屏幕，恰恰忘了还没装上的小螺丝。 用胶带撑到了第二天小米的如风达螺丝刀抵达，一大早顶着被楼下8点的炮竹惊醒的困顿，去店里取回螺丝，成功装好。 总的来说，1400二手屏幕+100小米螺丝刀+2个半小时，还是挺不错的。 使用上，颜色稍稍感觉和以前有些差异，在外接屏幕时，似乎被系统也识别成外接的了，不能像原来那样单独修改一个屏幕的分辨率了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"硬件","slug":"硬件","permalink":"https://sean10.github.io/tags/硬件/"},{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"}]},{"title":"KVM虚拟机镜像压缩","slug":"KVM虚拟机镜像压缩","date":"2018-07-09T13:39:49.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/07/09/KVM虚拟机镜像压缩/","link":"","permalink":"https://sean10.github.io/2018/07/09/KVM虚拟机镜像压缩/","excerpt":"最近刚入职，做的还比较简单，熟悉libvirt，把KVM镜像给压缩一下。","text":"最近刚入职，做的还比较简单，熟悉libvirt，把KVM镜像给压缩一下。 KVM主要硬盘镜像有qcow2和raw两种类型。 qcow2格式是copy on write的，使用时才占用硬盘空间，而raw则是创建时即分配了。 使用ll -h和du -h可以看到实际分配的和磁盘占用的大小。 1qemu-img convert -f qcow2 -c -O qcow2 xx.qcow2 xx_compressed.qcow2 通过上述命令可以实现qcow2格式的压缩，但是无法更改硬盘初始创建时上限的大小。只有raw格式可以减小上限，一开始以为只有上限压缩了以后，才能把这样的镜像放到较小的硬盘分区里。 首先尝试了 123qemu-img convert -f qcow2 -O raw xxx.qcow2 xxx.rawqemu-img resize -f raw xxx.raw -10Gqemu-img convert -f raw -O qcow2 xxx.raw xxx.qcow2 但，的确就和其他博客里说的一样，这样会由于raw内部分区并不是顺序，而不是稀疏的，会导致破坏文件系统，如windows启动时就会导致蓝屏。 如果要这样做，就需要首先让系统分区进行压缩，如使用win7的磁盘管理进行压缩卷操作，亦或是使用gparted、libguestfs进行处理。 这里有个问题，qcow2格式用qemu-img info看到的大小是3.7G，用raw格式也仅有7.8G左右，而在win7内部磁盘管理看到的空间占用却是11.2G。这里的不对称是因为文件系统格式的原因吗？ 一开始一直在尝试安装libguestfs，因为似乎virt-resize可以做到压缩上限，但是很可惜，内网环境yum安装依赖实在是太艰难了，在将CentOS安装包的iso镜像挂载上作本地源之后，还是存在一些依赖问题。折腾了快有2天时间，在supermin5上还是没能搞定。 最后，在看qcow2压缩的博客时，发现没有人提到过要修改这个上限的问题，qcow2本身就是写时分配空间，，那么其实，是不是无关紧要呢？我分配了一个4G的硬盘，将3.7G压缩后的镜像移动到这块硬盘再启动，windows启动一点没有问题，在系统内部的文件分区显示依旧是11.2G左右。 哎，尝试了好多，最后还是回到了原点。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://sean10.github.io/tags/KVM/"},{"name":"libvirt","slug":"libvirt","permalink":"https://sean10.github.io/tags/libvirt/"}]},{"title":"第一次下厨","slug":"第一次下厨","date":"2018-06-19T05:30:45.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/06/19/第一次下厨/","link":"","permalink":"https://sean10.github.io/2018/06/19/第一次下厨/","excerpt":"","text":"西红柿炒蛋 按照食谱来做，没想到还是有很多细节上没有提到的东西，想当然了，导致最终的成品出现了大大的错误。 番茄是切块，而不是切片 由于新手手速慢，油烧热以后将火调小，再倒入菜 黄瓜炒蒜肠 没有红肠，只好先买个蒜肠，还好最后味道也还能吃。 黄瓜没能入味，虽然菜谱上说一起放进去炒，但是由于需要入味，但是单独先给黄瓜加点盐炒为好。 Reference 下厨房 番茄炒蛋 下厨房 黄瓜炒火腿 感谢豆豆儿大大的指点。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"下厨","slug":"下厨","permalink":"https://sean10.github.io/tags/下厨/"}]},{"title":"租房布置搭配","slug":"租房布置搭配","date":"2018-06-02T11:48:01.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/06/02/租房布置搭配/","link":"","permalink":"https://sean10.github.io/2018/06/02/租房布置搭配/","excerpt":"","text":"终于确定了租房问题，房间虽然有点小，不过目前看大小，2.53的大小，放一个单人床之外，还是可以放的下一个稍大的桌子的。计划是最少要买个1.50.8*0.75左右的书桌，这样桌子就可以放的下显示器，又能做做笔记什么的了。不过暂时等入住以后再详细调整。 细节记录 墙壁 看情况吧？墙壁如果没问题那就没事了，要是有点脏那到时候再咨询房东能不能贴了。 桌子 简约的似乎直接用淘宝的就行，不用在意非要实木，毕竟我并不是有多个显示器外接的大佬。预算可以不用达到600了，300以内应该可以。 椅子 目前来看，不太喜欢那种椅子带滚轮的，价格低的情况下，办公椅似乎由于零部件太多容易出问题，宜家几十块的椅子带椅背就可以了 床上三件套 网购或是实体店，到时候逛逛 灯光 我台灯从高一用到大四，7年时间，关节处已经撑不住了。 宜家，爆款落地灯79，mark。 垃圾桶 必选 置物架(可选) 宜家优先，不过我不确定我有哪些需要用这个 Reference 四次租房经验，告诉你如何提高出租房的格调","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"租房","slug":"租房","permalink":"https://sean10.github.io/tags/租房/"}]},{"title":"部署Moin_wiki记录","slug":"部署beibq-wiki","date":"2018-05-30T15:16:46.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/05/30/部署beibq-wiki/","link":"","permalink":"https://sean10.github.io/2018/05/30/部署beibq-wiki/","excerpt":"之前一直想写一个论坛或者wiki，不过最近感觉想先部署着，以后慢慢改了。","text":"之前一直想写一个论坛或者wiki，不过最近感觉想先部署着，以后慢慢改了。 安装Moinmoin 1234567curl http://static.moinmo.in/files/moin-1.9.9.tar.gz -o moin-1.9.9.tar.gzpython2.7 wikiserver.py# 开放端口iptables -A INPUT -p tcp --dport 18082 -j ACCEPT/etc/rc.d/init.d/iptables save/etc/init.d/iptables restart 安装Mysql(虽然最后这个框架没用到) 1234567891011121314151617181920212223wget https://dev.mysql.com/get/mysql80-community-release-el6-1.noarch.rpmyum localinstall mysql80-community-release-el6-1.noarch.rpmyum repolist enabled | grep &quot;mysql.*-community.*&quot;sudo yum install mysql-community-serverservice mysqld startsudo grep &apos;temporary password&apos; /var/log/mysqld.log# passwd: 5!iozIn&amp;t;Vwmysql -uroot -pALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;fighton&apos;;# executingpip3.6 install -r requirements.txt# 缺少mysql_configyum install mysql-develpython3 manage.py runserver -h 0.0.0.0 reference Installing MySQL on Linux Using the MySQL Yum Repository","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"wiki","slug":"wiki","permalink":"https://sean10.github.io/tags/wiki/"},{"name":"centos","slug":"centos","permalink":"https://sean10.github.io/tags/centos/"}]},{"title":"zotero使用记录","slug":"zotero使用记录","date":"2018-05-16T06:52:06.000Z","updated":"2020-11-15T17:11:48.523Z","comments":true,"path":"2018/05/16/zotero使用记录/","link":"","permalink":"https://sean10.github.io/2018/05/16/zotero使用记录/","excerpt":"为了管理论文文献，方便引用导出等等，要用zotero,但是单纯这个导出的bibtex又无法直接给xelatex使用，就试着使用一下jabref这个工具","text":"为了管理论文文献，方便引用导出等等，要用zotero,但是单纯这个导出的bibtex又无法直接给xelatex使用，就试着使用一下jabref这个工具 问题集锦 xelatex导出bib参考文献，格式不正确，输出有些混乱[2] 使用zotero导出的bib中，文献类型同样是学位论文，但是bib中是phdThesis,而我本科的模板上是MasterThesis,暂时没找到如何让zotero修改这个的方法，倒是找到了在JabRef上修正这个的方法，看来暂时只能用JabRef了. 不过在LaTex的bst格式文件中也找到了phdthesis的输出样式，所以错误原因究竟是什么呢？ 经过一个个与模板bib文件比照，发现是由于缺少了language={Chinese}这行设置，补充后即可输出了，搞定。 由于JabRef的无法正常运行，又去了解了下zotero的强大，经过检索，发现还是zotero也是可以自己配置一些可选field之后导出bib的，在language位置设置为chinese，搞定。 Zotero中文文献作者只显示姓[1] 根据知乎上作者所说，是在抓取网页解析的语法出现了问题，所以按照知乎所说修改解析方法，全部防止到姓中即可 &gt;1. 首选项-高级-文件和文件夹-打开数据文件夹。 &gt;找到translators文件夹，找到里面的CNKI.js，打开 &gt;2. 注释掉189和190两行，在后面加上一行 creator.firstName = “”; &gt;3. 刷新文献所在页面，重新获取条目，创建者即为作者全名。 &gt;4. 文件重命名规则可使用%a JabRef 在打开finder时，经常进入 not responding状态 按照issue里说的换成4.3 beta版本就可以正常使用了,唔，在新建entry的时候还是和issue一样Freeze了。 使用Zotfile进行pdf提取到独立目录 根据[^4]这篇文章操作了下, 现在在一个独立目录里有所有的pdf了, 至少可以跨平台阅读了. 但是这样就出现了一个新的问题, 删除文献时, 是无法把已经被rename出去的pdf也给删掉的. 不过这个倒是挺适合我的暂时, 我倒是不怎么有删文献的需求. 使用共享盘里设置软链 根据[^3]的说法? 设置软链也是个方案? 其实我一开始就是这么用的, 为了避免300MB官方空间用完, 但是这样不就回到最初的状态了, 我就是因为用ipad访问同步盘的时候, zotero的storage目录结构不好找, 根本找不到想看的文献, 所以才引入zotfile的方案的呀? 使用scite-zotero-plugin进行分析文献 Reference Zotero 作者按西文的方式显示，如何调整为中式？ 参考文献管理工具zotero的使用经验分享 ZotFile + 同步盘，实现Zotero文献跨平台同步！ 在 iPad 上优雅地看文献：Zotero + ZotFile + 坚果云","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"zotero","slug":"zotero","permalink":"https://sean10.github.io/tags/zotero/"},{"name":"jabref","slug":"jabref","permalink":"https://sean10.github.io/tags/jabref/"}]},{"title":"档案迁移问题","slug":"档案迁移问题","date":"2018-05-16T06:38:01.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/05/16/档案迁移问题/","link":"","permalink":"https://sean10.github.io/2018/05/16/档案迁移问题/","excerpt":"现在毕业了，关于走流程方面有了很多问题，档案迁移需要提交什么样的表格，等等","text":"现在毕业了，关于走流程方面有了很多问题，档案迁移需要提交什么样的表格，等等 据现在知道的信息要遵守户档不分离的原则，那么户口和档案就都是回到上海，现在学校发了一张二分材料。 网上查到的上海的派遣地址存在3种可能性（上海人力资源和社会保障局、上海市各区县就业促进中心、上海市各区县人才服务中心），但是实际上现在2018年只有就业促进中心负责接收上海生源地毕业生档案，这个部分折腾了我很久，去找了些上海的大学的派遣方案里，发现写的很清楚，上海生源派遣回户口所在区县的就业促进中心就行。 确定了派遣地址： * 上海市浦东新区就业促进中心 * 上海市浦东新区浦东南路3995号309室 * 200126 * 58740409 不过又了解了一下，户档不分离的主要出处是北京毕业生集体户口迁出，既然如此，没有迁户口进入学校的情况似乎是可以不遵循户档不分离原则，是可以将档案迁移到单位所在地的。不过据别人论坛经验之谈，各省市政策不同。所以就姑且按照上面那样做吧。 派遣证信息要确保准确，就业去向为就业，签订三方协议的，需将三方协议由用人单位盖章后返回至学校，在就业信息网登记就业信息，并加盖就业指导中心公章，就业指导中心将根据毕业生在就业信息网上登记的就业信息进行派遣，其中单位名称为解决户口和档案的准确的单位名称（不能是简称），也有部分没有独立人事权的单位，需将单位名称写为放置户档的人才机构名称，一定要与用人单位确认后再上报！单位地址为解决户口的地址，（一般落实到市、区一级，如：北京市海淀区，陕西省西安市）。 Reference 毕业生就业手续办理流程","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"档案","slug":"档案","permalink":"https://sean10.github.io/tags/档案/"}]},{"title":"第一次租房记录","slug":"第一次租房记录","date":"2018-05-12T06:32:18.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/05/12/第一次租房记录/","link":"","permalink":"https://sean10.github.io/2018/05/12/第一次租房记录/","excerpt":"终于把大一遗留下来的课给清考掉了，不用担心会被留级了。是时候准备租房了。 最后选了学长转租的那个，小区物业什么的似乎稍好一些，房间也够放个大桌子，那就行了。 搜房工具 用的几个工具是有人做好的 http://bj.yurixu.com/manage/beijing.php https://woyaozufang.live 这个是开源的","text":"终于把大一遗留下来的课给清考掉了，不用担心会被留级了。是时候准备租房了。 最后选了学长转租的那个，小区物业什么的似乎稍好一些，房间也够放个大桌子，那就行了。 搜房工具 用的几个工具是有人做好的 http://bj.yurixu.com/manage/beijing.php https://woyaozufang.live 这个是开源的 公司附近辐射 步行 金域华府 据说是商品房 有学长出租2500 [https://bbs.byr.cn/#!article/Home/110715] 2000(由于太小，砍到1900了) 8平米https://bbs.byr.cn/#!article/Home/111715 融泽嘉园 据说是回迁房 学长出租2700 (无）1900 10平米 [https://www.douban.com/group/topic/117535918/] （客厅有隔断，唉）1850 [https://www.douban.com/group/topic/117830495/] 蓝天嘉园 1700 中介 [https://www.douban.com/group/topic/117714288/] (无)2150 [https://www.douban.com/group/topic/116591899/] 回龙观新村中区 拆迁？(路过看着也很好，可惜没联系上) 1800 [https://www.douban.com/group/topic/117733687/] 2100 [https://www.douban.com/group/topic/117347155/] 回龙观村西区 1700 有隔断 [https://www.douban.com/group/topic/117699317/] 2050 [https://www.douban.com/group/topic/117511027/] 北京人家，2KM 2000, 学长[https://bbs.byr.cn/#!article/Home/111694] 2000 [https://www.douban.com/group/topic/117073185/] 龙兴园-西区 自行车 5km范围 北店嘉园 2000 [https://www.douban.com/group/topic/117734045/] 龙锦苑东二区 2200 [https://www.douban.com/group/topic/117699317/] 风雅园三区 2000 [风雅园三区] 地铁13号线或8号线 租房要点: 下述这些最后都没用上……因为学长很省事，连押金都没要…… 看房要点 周围环境、物业安保、交通状况、配套设施等是否适宜。 看房东或者合租者是否好相处。 租房房源信息核实 所租房屋的产权证书、房东的身份证明等，确定出租房有权利出租该房屋。 看清房屋细节 *看清房屋角角落落。 主要的项目有房租、水电费、煤气费、电话费、有线电视费、垃圾清理费是否缴清 房屋内设备的数量、成新度等情况； 在租房前要仔细检查水电、马桶等日常设施是否良好；把家电都试用一遍以检查插头是否漏电，煤气是否泄漏等。一定要当面和房东把房内的设施、家具家电等核实清楚，该添置的一定要事先跟他讲明，如有问题，价格上还有商议的余地，确认无误后再决定是否签订合同。 只租过自如的房子，说下关于租自如的经验： 1. 不要租新装修的，特别是那种“首次出租” 2. 中途转租需要扣至少50%的押金，就是半个月房租，如果是退租的话需要扣80%+好像 如果公司和自如有合作的话，服务费可以打88折，并且一年有一次免费换租的机会（可以趁12月淡季的时候换一个便宜点性价比高点的） 3. 合租最好租3居室，自如的房子都是原有的n居室+1个隔断，4居往上公共空间会很挤（厕所厨房冰箱啥的，水电费还容易超阶梯），2居室一般都没有客厅，只有一个窄窄的过道 4. 最好是租13层左右的，一般都是30+的高楼，10几层正好在中间，光照好不怕遮挡并且夏天不会太热冬天不会太冷 5. 看房子的时候问下正在租的租户，水电费每个月大概是多少钱，是不是商用水电（超过阶梯价格用起来会很可怕，一个月水电费可能要150） 6. 检查下卫生间有没有返味，房间的隔音如何 7. 避免租房东打算卖房的，虽然到时候会赔你一个月房租，但经常会带人来看房子，而且到时候还得费事去找新房子 8. 尽量租在公司附近，减少不必要的通勤时间，走路就可以上班就最好啦，当然如果和对象一起租还是商量一下吧 9. 实在不行也要尽量离地铁站近一些，小区周边的配套设施也很影响生活质量（超市、小饭店、早餐店、水果店等等） 10. 第一次签约大概要准备5个月的租金（1个月押金+3个月季付+1个月服务费），要准备好预算 11. 总的来说我觉得租自如就是省事一点吧，找起房源来没那么麻烦，但也相对没那么划算，建议最好找同学或者同事一起合租一个 以上~（两年搬了四次家的感想。。[1] 租房的地点离单位近一点，要是可以步行上下班最好了，特别是如果单位有食堂管早晚餐的话，简直幸福感爆棚； 有精力尽量找个人房源，在58或者赶集上找找，这样优点是省去了和中介或者二房东讨价还价的精力和时间，缺点是不容易找到合适的，需要不停的打电话联系看房； 签合同之前要看房东的房产证和身份证，物业、水电、燃气、取暖谁交，物品损坏谁掏钱维修要讲清楚，如果提前中止合同的话，押金和房租能不能退、退多少都要在合同里写明白，能想到的就是这些。 沙发说的很棒，补充一些吧 无论价格多低都不要租隔断，隔音什么的都在其次，住了一半被赶出去的经历估计谁都不想有 如果是合租，重点考虑朝向、隔音效果、是否带独立阳台和独立卫生间，如果是整租，还要考虑是否南北通透，如非迫不得已，不要租不向阳的房子（东南西南这种斜向的勉强可以接受） 楼层低的话要注意暖气是否够热，在室内还冻手冻脚的感觉还是挺闹心的，有条件的话尽量在冬天租房子 考虑是否有小区围墙，是否有门卫，楼道是否有门禁等，那种全开放式的楼房体验是很恐怖的，楼道和电梯里全部都是小广告，平时贴小广告的、送外卖的串来串去，安全隐患很大 离公司距离越近越好，步行上下班能极大的提升幸福感，不要想着省钱住远一点，每天坐地铁公交时间长了会把意志力都磨没的 租房需要搞清楚哪些事情？ 1.交通、生活便利性。计算一下通勤的距离和费时，一共多少站，换乘几次，走到地铁站公交站要多久？附近共享单车好不好找？超市菜市场医院饭馆离得远不远？自己开车的话，早晚高峰附近的路堵不堵？ 2.物业费、取暖费。怎么交？谁来交？物业费和集中供暖的房子取暖费一般都是房东交，自采暖的房子通常是租户自己交，这些租房的时候都要问清楚。 3.水、电、燃气、网络、有线电视费。水、电、燃气都有计数表，搬进去的时候抄一下底数，拍照留存，等搬出的时候一对比就知道你用了多少，要问清楚是水电燃气的费率是民用标准还是商用标准，两者差别还是很大的。网络要问清楚小区通了哪些运营商的网络，如果你之前办过包年的网络还没用完，新的住处也有同样的运营商的话，可以联系运营商办理迁移，如果是房东提供的网络，要问清楚还剩多少时长，有没有流量限制，剩下的时长是需要交费还是赠送。有线电视费同网费。 4.周边有无污染源噪音源。周边如有长期污染源和噪音源，看房的时候短时间内很难察觉，一定要问清楚，必要的时候可以跟小区的保安或大叔大妈打听一下，比如我有朋友之前住过的小区后面有一个混凝土厂，导致小区那个水质比较差，水垢很多，之前不知道，住进去以后就感觉被坑了。（原文来自微信公众号：我在北京租租房子） 5.小区安全性。小区门禁是否严格？保安是否24小时值守？摄像头有没有覆盖？晚间有无巡逻？小租前不久电动车停在楼下就被撬了，心累。除了保障财产安全，还有人身安全，所以必要的小区安保是必须的。如果觉得问房东和中介得不到实话，可以问问小区的大爷大妈或者住过该小区的朋友。 6.家具家电是否齐全？损耗情况如何？损坏赔偿等说明。住进去之前仔细检查家具家电是否完好，如果有损坏的，签合同的时候就要说明，可以拍照留记录，避免还房的时候因为一些损耗损毁归责不明起争执，还有约定好如果东西坏了怎么赔偿，哪些东西价格比较高，使用的时候需要尤其注意。ps女生很容易弄脏床垫，有的房东床很贵，最好自己平常注意垫上垫子，淘宝上卖的姨妈垫几十块一个并不贵，一旦弄脏了，不管是赔偿还是请人专门清洗床垫都不便宜，就不太划算啦。 7.朝向、采光、楼层和冬暖夏凉情况。一般来说朝东和朝南的房子采光好一些，东向的房子是早上的阳光，在我们北半球南向的房子一整天光线都比较充足，也不会太晒，朝西的房子夕晒，下午光线强烈，夏天会很热，朝北的房子跟朝南的相反， 一整天光线都一般，冬天会偏冷，其他不是正中朝向的房子，自己推断一下就知道啦。除了朝向，附近建筑物遮挡也会影响采光，都需要提前观察好。小租还去看过一个全是平房的公寓，屋顶虽说放了遮阳板，但是夏天阳光直射还是非常晒，感觉夏天不会很愉快。楼层高的房子通常都比楼层低的采光好，但是也会增加一些不便，比如一旦电梯坏了就很崩溃了，一楼通常会潮一些，而且私密性相对差，要么整天拉着窗帘，要么路过的人都能看到屋里在干吗，这些都要自己权衡。 8.能否养宠物。很多房东都不让养宠物，主要是怕挠坏真皮家具或者让屋里有异味，如果有宠物要跟房东协商好，双方接收并且约定好规则即可。 9.隔音情况。有的房子隔音效果不好，住起来也会有困扰，一般来说正常的小区房子之间的外墙隔音还不错，内墙稍次，隔断就基本不要指望隔音了。有的公寓用料不好不实，外墙隔音也有问题，高档的装修甚至会把墙壁刷成墙面凹凸的，有吸音的效果，这里面差别就很大了。 10.房租押几付几。通常情况下都是押一付三，现在有的公寓和芝麻信用合作可以免押金，也蛮不错的，有的房东如果屋内家具家电贵重也会要求押二付三，这些就看大家自己衡量啦。（原文来自微信公众号：我在北京租租房子） 11.停车位。如果有车，要问清楚房子带不带停车位？小区有没有长租停车位？管理是否安全？费用怎么交？ 12.仔细看合同条款，有无其他限制，如合租人数，是否允许转租，退租是否提前说明等。有的房东会明确限制长住人数不超过几人，或者不允许转租，退租需要提前多久说明等等，合同一定要仔细看！合同一定要仔细看！合同一定要仔细看！否则签了什么霸王条款，到时候吃亏哭都没地方哭。小租被无赖二房东扣押金那次，最后找警察叔叔来一条条对合同，我没有任何违反合同条款的地方，无赖二房东也不得不退了我大半的押金，所以说，不管什么时候发生了纠纷，合同都是你最后一道保护伞，一定要看清楚记清楚。 搬家篇 现在搬家公司也很多啦，自如搬家、蓝犀牛、58、货拉拉、或者豆瓣租房小组直接找搬家师傅等等，多看看评价，比比价，选一个合适的即可。注意有的搬家会自带箱子，能省去部分自己打包的困扰，这些都要了解清楚。还有的搬家会看有无电梯，无电梯的房子会加收楼层费，都需要注意。（原文来自微信公众号：我在北京租租房子） 入住篇 租好了房子以后，一般建议换个门锁，以免中介或者房东留了钥匙，仍然可以随时出入你的家门，就很尴尬了。另外出门多熟悉熟悉周边环境，地铁站公交站、超市菜市场、物业位置和电话、附近医院药店、派出所、邮局、快递等等都去踩踩点，必要的时候不会两眼一抹黑。还有，记得修改网购、外卖默认地址！我就干过不止一次搬走了东西寄到原来住的地方的蠢事儿，还得回去取，肥肠麻烦的说。 最好将地址告知家人和朋友也留存一下，万一有什么事儿他们能及时找到你。容易丢钥匙或忘带钥匙的人，可以在靠谱亲友那里放一把钥匙，这样不会把自己关外面死活进不去。（原文来自微信公众号：我在北京租租房子） 防止被坑 一个在北京从事租房领域创业项目多年创业者，积累的防黑中介坑骗的重要经验与建议： 我是宋增建，根据我之前在北京进行的一个租房领域创业项目大量真实经验与数据，分享给大家，减少大家租房时，被黑中介坑骗的概率。 其实，通过网上的58、赶集等租房平台，完全可以找到大量的房东，而且其中中介公司的出租房源中，很大比例的房东，也都在58、赶集上个人登出来了，你完全可以找到他们。真正的风险，是租房过程中，被冒充房东的黑中介所坑骗，造成很大损失。这里将我之前做这方面创业时，通过大量实战，探索积累的很多经验、技巧与心得，和大家交流分享一下：1、在网上找房源，看到贴子里面的文字介绍，只有空格，而没有逗号、句号等标点时，要小心一些，这种贴子，大多是中介发的。2、主要的网上找房东个人房源的平台，就是58、赶集两个网站，其次是搜房网，别的就量很少了。在这些网站上，注意在房源中选择个人房源，但要注意，这些网站上登的个人房源，里面也有一定的比例是中介，甚至是黑中介，现有的手段，并不能完全保证对方真伪，还需要租房者自已去亲身验证。 现在一般58、赶集，都引导大家通过手机app，才可以看到房东的手机号，就可以和这套网上房源的房东联系了。3、打过去电话，可以先停顿一下不说话，静静地听对方的背景音，有时你可以听到中介公司那种很多人在打电话谈租房的交流声，这就可以判断是中介公司了。 同时，一般的房东，会主动先出声和你交流，你可以听其声音，判断其年龄、修养、气质等情况，再去聊。而如果打通后，对方很久不出声，想听你的声音，是中介的可能性较大。4、要把判断对方是否是中介作为最首要的一件事情。 在没有判断清楚时，避免说出过多个人信息，以及租房需求等。要等判断清楚了，比较自信了，再说更多个人情况。 很多中介公司会有一个系统，第一个和你通话的中介，会把你的手机号、个人信息和租房需求等录入进系统，这样其它人帮你租成了拿佣金，录入者也有业绩与分成。所以如果对方是中介，录入系统，全北京这家中介的各个分店都可以看到，并主动打电话给你，会比较烦，但作为租户，被电话骚扰的数量不会太多。你明确向对方说不用中介后，给你打电话的中介，也会把你的这个回复，录入系统中，其它中介会看到。5、在打电话前，详细记清租房贴子中的一些照片、房子情况等细节，比如地板什么样，电视什么样，楼层是多高，面积有多大，房东姓什么，租金，等等。最好打电话之前，提前记在电脑或纸上，列出这些问题与细节清单。 然后打电话时，用这些细节去验证，看房东是不是会记错与出现矛盾之处。 在刚打通电话时，注意不要自已主动说出你看到的小区的名字、几室几厅、多少租金等信息，而是先问一句：“您有房子出租吗？”，然后装作记不清小区、租金、甚至是对方姓氏等，主动去套对方的话，比如“不好意思，刚才网上看了几套，给您打电话时，手机上看不到相关信息了，想详细问您一下，我是个人租房者，想多了解了解。” 然后，将很多刚才记下的细节，一一去问，注意有时要故意用误导式提问，比如：明明照片上看到是木地板，却问其地面磁砖的颜色；或明明看到是绿色的沙发，问其蓝色的沙发是否干净等等。如果对方能及时纠正你故意说错之处，说明对方对房子情况非常了解，更可能是个人房东。而中介，有时登出很多套假的房源，是记不清这么多细节的，让你问多了，就会矛盾与错误百出，明显与网上登的细节不符。6、电话里，大量、详细地问很多东西、交流很多东西。 一般真实的房东，也会怕遇到黑中介冒充个人来租房，最后租下打隔断出租毁了房子，所以，你这样问的特别详细，真正的房东，也会对你更加信任，而中介，往往就会不耐烦。所以，就大量细节去问房东，可以偶尔加一点解释，就是强调自已是个人，所以也想找真实的个人房东，多问一点请别介意。真实的房东，也愿意多了解求租者个人信息，一般都愿意和你多交流，而中介往往受不了这么麻烦的问来问去。这是很重要的区别，两种人的出发点与目的不同。7、除了问房子情况之外，很重要的一点，是多聊聊房东是做什么工作的，最好还可以问出是哪一家公司或单位。 可以结合房东说自已的工作领域，聊一些你所知道的这个行业的一些人、事、公司等等，一方面，房东可以加深对你的赞叹与信任，另一方面，你也可以通过这些话题去验证对方真伪。 而且这里面，还可以故意说一些“陷阱性的问题”，去试探对方。比如明明你知道一个这个行业的事情，你说一个假的，或是相反的，或说一个你乱编的这行业公司的名字，看对方的反应，如果对方说是对的，顺着你说，没有纠正错误，而不是说不知道，或是对方对这个行业与领域根本说不上什么来，表现得很不耐烦或粗鲁，往往就暴露对方是中介。 如果你问对方工作，如果是中介，一般他们会说自已是做行政工作、市场营销等人们最常见的，但不会说具体的行业，中介很难说得出很具体的一些行业以及工作细节，这个就太难为他们了。所以具体到这个行业哪一家公司，或是深聊一些这个行业的一些东西，中介假冒房东，往往就会暴露。这样，你就不用白跑一趟了。8、注意对方的电话开头号段： 一般139的，或是186开头的，可信度比较高。当然这不是绝对的，而一些如155、156、131、132、133、185等开头的，是中介可能性相对较高。但这些只是相对的，不是绝对的。 现在实名制了，但中介仍然有办法找一些临时的号去发贴子，冒充房东，而139这种号的成本很高，而且这种号，往往不能多次在网上发贴，否则会被标记为经纪人，而且，过多用此号，也会被标注为经纪人，因为中介往往需要不断换号。9、在搜索引擎，去搜索看到的房东手机号，看是否被多人标注为经纪人： 安卓手机有一个功能，就是很多人标注上一个手机号是中介后，你打去时就可以看到。所以，可以找一个安装有腾迅手机管家、360手机管家等这类安卓手机打过去，这可以显示被多少人标注为中介。 还有一种方法，就是在百度、搜狗、360这三个搜索引擎中，搜索你看到的房东的手机号，这些网站与BAT出的手机安全类app是绑定的，在手机上被这些app标注的，也会在这些搜索引擎中展示出来此号被多少人标注为中介。 PC或手机浏览器上的搜索引擎，百度对应的是“百度手机卫士”app,搜狗对应的是“腾迅手机管家”app，360搜索对应的是“360手机卫士”app，这样在浏览器里用这些搜索引擎去搜索房东手机号，效果是一样的，看其标注情况，我说过，中介会经常大量换新号，这种方法只是一种辅助手段。10、看贴子、以及配的文字，感受房东是一个怎样的人。 如果是黑中介，只是希望把你骗来。所以看房子的介绍，感觉就比较粗糙，或是别处抄来的文字，就是黑中介。而如果是真正的房东，往往在照片、写的东西上面，会很用心，尤其是你一打电话，对方会对你的身份、工作、几个人住、什么关系等，希望多了解你，而这些情况，中介一般是没有兴趣过多问细节的。 通过声音，去感受到对方的气质、学识、修养、心理等很多细节，这需要你用心去感受，多注意自已的直觉，综合判断是不是黑中介，毕竟在黑中介里，有文化与修养、气质的人，还是比例很少的。 不过，很多时候，有些房东也只发布那种几乎就一句话说明的租房贴，特别简单，也没有图片，而中介有时也经常发布这种贴子，从这种很简单无图的贴子中，就很难判断。11、听电话或微信语音中的口音，判断对方身份与地域： 我管这种电话里的语气，叫“菜音”，就是听上去比较粗俗、浅薄、没多少文化、有时带有一种粗鲁，或是刻意装出来的一种有文化与文雅的感觉。 我个人，对各个地方的人，没有偏见，但整体上说，北京黑中介里面，东北口音偏多一些，还有中原地带也有少量，但南方口音，或是北京口音，并不一定就不是黑中介，只是概率小很多。 同时，从事黑中介的，绝大多数是20岁到30岁左右的年轻人，年龄大的要少很多，听年龄，也可以做出一定判断，如果对方听着50多岁，温文尔雅很有文化，那是黑中介的可能性就会很低，而毕竟，大多真实的个人房东，年龄并不轻了。 有时中介会找一些人来共同演戏，骗租房者上当。但这里面，有文化修养与高雅气质，就是大家在好的写字楼、好的公司，经常遇到的那种受到良好教育、有好的工作积淀与修养，这种气质的人，在黑中介中，比例还是很少的，但在个人房东中，就比例大多了。12、加对方微信，尽量与对方进行视频： 加上对方微信，可以看房东的朋友圈，了解这个人的情况，如果是中介，在很多方面，往往还是有差异的。同时，通过与对方微信视频，可以更清楚地看清房东的样貌、修养，而且还可以手机同步录音，截屏等，这些都是保留的一些制约假房东的证据，如果是黑中介，这些未来可以可以有法律作用，至少把录音、照片放在网上，或是提交给管理黑中介的住建委，或诉讼时交给法院，还是很有震撼作用的。 最关键不是事后，而是租房之前，在去看房前，如果通过微信视频，看到对方的气质、言谈、衣着等，如果修养、品味、气质、常识很不错的人，是中介的可能性就会很低，毕竟，这样的人往往工作不错、事业有前途，不会去做黑中介的。 当然，一切都不是绝对的，保有警惕之心很重要。13、搜索贴子中图片去判断，同时注意图片质量： 租房贴子里面的图片，用百度、搜狗、360的图片搜索功能，去拖进去，看看网上哪里，还有这样的图片，就可以判断一些房源的真伪。 中介往往从别处扒房子的图用，在这些搜索引擎的图片搜索功能中，往往会显其原形，但很多时候，也有房子的图，是中介们自已拍的，或之前多拍备用的。 另外，发在58、赶集上面的租房贴的图片质量，个人房东，有房子的人，相对收入往往较高，都是用苹果等高端手机，拍的图片质量很好，但那些黑中介发的，往往是来自于低劣的手机拍的，或是从别处扒的假房源图片粗糙处理以逃避58等网站的图片比较功能，所以，低劣质量的房源图片，看上去模糊的，是黑中介可能性较大，甚至很大。14、现场看房环节的骗局（尤其注意）： 如果现场看房，遇到了黑中介，也有几种情况列给大家如下。1）、对方穿着中介常穿的深蓝色西装，年轻，而且直接告诉你他就是中介，并且说现在网上根本找不到真实的房东的房子，来打击你让你租他们的房子。其实你自已完全可以在网上找到真实个人房东的。2）、对方冒充房东，然后说这套房子代理给他们了，或是和房东是朋友，这套房子和他签就行了，可以给你看复印的房产证，以及租给他的合同等等，反正就是各种让你要特别相信他们，他们一定不会骗你等等。这种人，是黑中介的可能性很大。3）、对方是北京人，年龄较大，同时有时旁边还有年轻人，这个年龄大的，往往是黑中介找来的托儿，冒充房东看着更可信。而年轻的，是黑中介本人，来看看租客的情况。很多时候，假房东就是一个人出现。 上面情况中，如果他们说自已是房东本人，看其身份证、房产证，尤其再去物业核实其真假，往往就会露馅。但他们想办法会说服你，说和房东关系好，是亲戚或朋友，这套房子他来管，你和他签没有任何问题等，如果你没有能力去判断真伪，建议一定要找真实的个人房东本人出面，可以大大降低被骗概率。相信我，不要过度迷信自已高学历，或是工作经验丰富，在黑中介这里，骗的很多人，都高学历高工作背景的。15、租房合同的猫腻，以及如何选择合适的合同文本： 在现场，黑中介往往用各种身份，骗你签一份“代理合同”，注意，看到这种“代理”合同，要特别小心，这就是黑中介们通过他们的律师，帮助他们精心设计的条款，对租客非常不利，合同名称是某某出租代理合同，最后签的是一个中介公司的名字。但其实，黑中介往往都是蛮不讲理，有时就算签了非常正常的合同，也会坑得你损失很大。 因此，最关键的，是别太相信合同，而是以预防避免上当为主。否则上了当，你很难有大量精力与时间，去与这些像黑社会一样的黑中介去纠缠到底的。目前走法律诉讼的很少，而且在执行中，也难度极大。 所以，最好签自已提前打印的合同带去，尽量用自已的合同，在北京市住建委官方网站上的《北京市房屋租赁合同（自行成交版）》可下载，网站见下图： 作者：宋增建 链接：https://www.zhihu.com/question/54461291/answer/139471473 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 同时，想补充一点，签合同时，最好自已提前带着印泥，彼此都在名字上按上手印，并且双方把手印，像骑缝章一样，同进按在每一页边侧，证明合同的完整性。16、现场看房产证，以及去物业实地核实： 这是现场验证对方真假的重要途径。 对方是不是真实的房东，最安全的，还是直接和房东本人签合同，仔细看房产证，并且去物业验证这个人就是真实的房东，小区的物业是有责任帮助租房者验证房东真伪的。 房产证真件，印刷的很精致，很少有伪造的，但也要小心，而再加上去物业核实真假这一条，基本上是假房东的可能性就很小了。17、签合同现场，同时录下照片或视频： 最好签合同后，现场录下照片与视频，并且是一段连续视频，里面要出现合同，说出来时间、地点、这套房子的小区、楼、牌号等，并且房东要保证对方是房东等信息，这些法律证据非常有用。而且，未来如果是黑中介，这段视频用在网上，或交给政府相关部门的震撼作用非常大。18、可先交定金，租金支付时间上适当后置，但别太晚。 看房时，最好就提前如上面15条所讲，随着带着自已的合同两三份（至少双方一人一份，一份还可以打草稿）。看好房，验证好房东身份，可以现场马上打定金。最好可以网银转帐，或是用支付宝，这样保留下证据。而且尽量少一些，比如500，或是1000元，但也别太少。 同时，尽量让房东给你留出一定搬家的时间，比如一周后起算等，到时交全款。但根据我的经验，有时如果真是很看好房子，并且房子很抢手，还是签合同，尽量把押一付三，或是约定租金尽快交全为好，这样，房东就不能毁约再租给别人了。如果没有定金的约束，房东就算嘴上说得好，给你留着，但如果中介带人来，或别人看好给更多租金，房东也往往会和你毁约。至少定金，是一定的约束，如果合同里写出条款，让房东如果毁约支付一个月的违约金。但现实中，还是双方协商为主，真正打官司的很少。因此，当你确定对方是真实房东，房子也满意，就要尽快交清全款，才是真正的“定下来”，否则，后面的变化真得很多。 支付房租方式，可以在合同上写清楚，向房东的某某银行帐户打入的款项，就视作是支付的定金与租房款，这样，只要向此帐户打款，就视同交了租金。 尽量避免现金交接，这样，银行转帐记录本身也是法律证据。19、了解黑中介会怎么骗你： 黑中介，最后会不退押金，而且合同里各种陷阱，更恶劣的，是让你住在中途，就用各种手段说你违约为由，采用野蛮暴力的手段，把租户提前强行赶出去清房，他们行儿话，叫“做违约”，而且会把你提前多交的一两个月房租，以及押金等都找理由扣着不给。 还有在租房后，提出的各种另收的卫生费、服务费等等，先让你上钩，再收各种不合理费用。 黑中介不是每一个都这样恶劣，给你造成的损失也都不一样大，但如果租了黑中介的房子，有一定比例，会让你中途就被赶走，以北京的租金水平，你可能会被黑掉上万元。 还有的，是黑中介与房东签的合同，快到期了，却收入了你一年的钱，到时候，房东来收房，黑中介拿钱不管了，让你们双方去协商，麻烦很大。 你在交涉中，黑中介往往还会暴力化，而且无赖化，并且一家有事，周边各家黑中介一起帮忙对付你，各种手段，让你非常郁闷难受，所以尽量直接租真实个人房东的房子为好。20、如果着急找房，要找中介，尽量找大的、市场主流的中介公司，在北京市场，主要是链家、我爱我家、中原地产、麦田房产等。 基本上主流的就是这几家，尤其是以链家、我爱我家为主，他们要收一个月的中介费。注意，大中介的一些店有时也会有黑人的现象，但比黑中介还要好很多，各种什么看房费等，是不用交的，在北京看房，不用提前交任何费用。 重点小心中小型中介，有相当比例会存在一定的黑中介化。当然，规模大的一些中介，也有黑中介化的现象。所以，如果非要找中介，最好是找链家、我爱我家这两家。21、特别小心，那种所谓黑中介“代理”的房子，更是他们常用的方式。 很多黑中介，用的手段，就是“代理”，从房东那里把房子代理下来，再转租给租客。这种“代理”的房子，是黑中介的主要手段，他们相对做居间，就是让你和房东双方见面，最后只收入中介费的较少，主要利润，还是来源于这种“代理”。你和他们签这种“代理”的房子，最后就会造成很多的麻烦，上面我讲过了。22、如果合租，可以选择链家的“自如”，或是58同城租房版块下的“品牌公寓”，找一些在网上搜搜，可以看到一些风投融资等相关信息的公寓品牌。 当然，这些公寓，也不是都很令人满意，但是相对于黑中介那种合租，还是相对好一些。黑中介的合租，从房租价格上，表面上看很低，但最后算上坑你的钱，还有其它的一些乱收的钱，其实不比品牌公寓便宜。 如果你有有经验的朋友，他整租下来一套个人房源，你与他合租，是性价比相对更高的。23、租房遇到黑中介时，一定不能单纯只看租金，黑中介往往报的租金很低，这后面的坑就更大了。 你想，他们从房东那里代理来每月要6000元，而租给你5000元，甚至4000，怎么可能呢？租金明显低于市场价的，相当大的可能，会对你“做违约”，就是想办法很快让你违约，把你多交的房租，以及押金，都扣光，并赶你走。再一个个用此“代理”的房子，去陆续坑人。 因此，如果你和黑中介谈租金，他们很低都可以租给你，但最后损失的，一定是你自已。他们有太多手段对付你，你租不久就会知道的。24、找个对在北京个人租房非常有经验的朋友，甚至是认识两个黑中介，在租房过程中咨询他们： 我和黑中介打交道时间很长了，对这个行业的理解也很深。我特别想告诉大家，北京的租房黑中介行业，能够形成，是有很多方面非常复杂的因素综合造成的。这些黑中介，不能说他们每个人都是坏人，只是这个行业的商业模式，不断演化到这个样子，他们只能按照这套模式去坑你。但不能因此就简单地认为，这些黑中介个人都是坏人。在整个行业的大潮中，个人的力量与选择，往往是非常狭小的，明白了这一点，你就会更了解这些黑中介，也就更能避免被他们狠狠地坑你。 建议在你租房时，提前找找在北京个人租房非常有经验，了解如何避免上黑中介当的朋友，在你租房时，可以向他咨询和寻求帮助，最好陪你一起去。甚至你也可以认识一两个干黑中介这行的人，花几十块、上百块钱请他们吃顿饭，当你租房时，咨询一下他们，毕竟同行是最了解同行手段的，如果他们拿你当朋友，就会告诉你如何避免上当。25、最后，告诉大家一个经过实践中得来的一个重要的金律： 当你在租房时，感觉对方可能是黑中介，或是感觉这个房东不太对劲，就尽可能别租！ 因为你要相信自已的直觉，你的直觉已经感受到一些地方不太对劲，这是潜意识在对你发了警告。而你没有听从这种来自感觉的警告，租了房子，往往后患与麻烦无穷。 所以，当你租房时，上面这一条条我写的，你都处理好了，理性也认为还可以，但就是直觉不断告诉你，不太对劲，你特别要相信这种直觉，通过我过去做租房领域创业项目大量的亲身体验，这种直觉，往往会在后期被验证。 记着，北京市场上，总同时有大量的房子在出租，从来不存在房源没有的情况，而且新的房子也会大量的不断空出来，只要还有可能，尽量避免避免麻烦，而不是后期真遇到黑中介，过高估计了自已处理麻烦的能力，经济损失、心情与尊严上的损失，都会让你久久不能忘怀。 reference 2017北京租房全攻略（租房必看） 马上毕业了，租房有哪些要注意的呢？ 租房要点，适用于北上广深杭，欢迎补充","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"租房","slug":"租房","permalink":"https://sean10.github.io/tags/租房/"}]},{"title":"白帽子讲Web安全Note","slug":"白帽子讲Web安全","date":"2018-05-10T11:58:53.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/05/10/白帽子讲Web安全/","link":"","permalink":"https://sean10.github.io/2018/05/10/白帽子讲Web安全/","excerpt":"计划看好久了，一直没看，现在终于简单过了一遍。","text":"计划看好久了，一直没看，现在终于简单过了一遍。 我的安全世界观 威胁分析 STRIDE模型 威胁 定义 对应的安全属性 Spoofing(伪装) 冒充他人身份 认证 Tampering(篡改) 修改数据或代码 完整性 Repudiation(抵赖) 否认做过的事情 不可抵赖性 InformationDisclosure(信息泄露) 机密信息泄露 机密性 Denial of Service(拒绝服务) 拒绝服务 可用性 Elevation of Privilege(提升权限) 未经授权获得许可 授权 风险分析 DREAD模型 windows Vista的UAC功能，询问用户是否允许该行为，这里说如果用户能分辨什么样的行为是安全的，那么还要安全软件做什么。这里说的很对，不过也是存在一种解释，这里的提醒只是一种用户个人对行为承担责任的方式吧，已经予以提醒，之后的操作的安全保障已经不是操作系统层面的安全性能够提供了。 客户端安全 &lt;img&gt;&lt;iframe&gt;&lt;link&gt;等标签都可以跨域加载资源，不同于XMLHttpRequest，通过Src属性加载的资源，JS权限被浏览器限制了，不能读写返回的内容，XMLHttpRequest可以读写同源，访问跨域需要遵循标准，通过目标域返回的HTTP头来授权 EVSSL相比普通的SSL,在浏览器里会有绿色高亮 跨站脚本攻击(XSS) 反射型XSS 存储型XSS Dom Based XSS 除了User Agent以外，还可以通过一些浏览器限定的操作来判断实际浏览器 XSS也是有一些攻击框架，如Attack API、BeEF等等 XSS Worm 蠕虫属于终极XSS 可以通过location.hash来发送XSS payload base标签 window.name Anehta回旋镖 XSS攻击主要发生在MVC的View层，模板引擎支持htmlEncode来对抗XSS Anti-Samy 最好的XSS filter CSRF 这个问题在之前写前后端分离部署的时候倒是遇到过……然后为了能跑起来，似乎对安全性完全没有考虑过 P3P头和Firefox等浏览器是支持发送第三方Cookie的 Anti CSRF Token ClickJacking 唔，很多盗版内容网站通过这个来获取广告点击 XSIO图片覆盖攻击 fram busting 防止跨域iframe攻击 X-Frame-Options HTML5安全 sandbox 注入攻击 使用类似xp_cmdshell等存储过程获取webshell 文件上传漏洞 避免方法: 1. 文件上传的目录设置为不可执行 2. 判断文件类型 3. 使用随机数改写文件名和文件路径 4. 单独设置文件服务器的域名 认证与会话管理 访问控制 垂直权限管理(RBAC) 水平权限管理 OAuth 加密算法与随机数 ECB(Electronic Codebook)模式 伪随机数问题 如果伪随机数的空间太小，可能被预测到，那的确很危险 小结 不要使用ECB模式 不要使用流密码(比如RC4) 使用HMAC-SHA1代替MD5(甚至是代替SHA1) 不要使用相同的key做不同的事情 salts与IV需要随机产生 不要自己实现加密算法，尽量使用安全专家已经实现好的库 不要依赖系统的保密性 当你不知道该如何选择时 1. 使用CBC模式的AES256用于加密 2. 使用HMAC-SHA512用于完整性检查 3. 使用带salt的SHA-256或SHA-512用于Hashing Web框架安全 利用好如django自身提供的安全解决方案，也仔细想想框架自身是否存在漏洞。 应用层拒绝服务攻击 即对消耗较大的应用页面不断发起正常的请求，如select * from xxx这种数据库查询操作阻塞数据库，或者占用服务端的最大连接数，亦或是通过https申明一个较大的content-length,小字节包慢慢发，占用资源。 业务前进行一个判断访问频次异常 验证码 Yahoo设计的算法(Detecting system abuse) 根据IP地址和cookie，计算客户端的请求频率并进行拦截(好眼熟，好像吴军老师的《浪潮之巅》里也提到过这个样例) WebServer配置安全 互联网业务安全 安全开发流程（SDL) Reference [《白帽子讲Web安全》] URL的井号","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"信息安全","slug":"信息安全","permalink":"https://sean10.github.io/tags/信息安全/"}]},{"title":"mac OS memory与常规memory、swap","slug":"Mac-Memory与常规memory、swap","date":"2018-05-08T15:45:18.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/05/08/Mac-Memory与常规memory、swap/","link":"","permalink":"https://sean10.github.io/2018/05/08/Mac-Memory与常规memory、swap/","excerpt":"在跑Tensorflow的时候，在Mac上没有出现的内存耗尽导致的dead问题，出现在了ubuntu上，本以为会和mac一样用硬盘来进行交换内存，而不只是使用默认设置的swap空间，结果并没有如想象的那样。","text":"在跑Tensorflow的时候，在Mac上没有出现的内存耗尽导致的dead问题，出现在了ubuntu上，本以为会和mac一样用硬盘来进行交换内存，而不只是使用默认设置的swap空间，结果并没有如想象的那样。 mac OS的activity monitor中的Memory提供了好多名词 简要 Physical Memory: 实际RAM使用的 Memory Used: App Memory: APP使用的内存量，包含其虚拟内存和物理内存 Wired Memory: 系统核心占用的，此内存中的信息无法移动到硬盘，因此必须保留在 RAM 中。联动内存的大小取决于当前使用的应用程序 Compressed: RAM中被压缩的部分,从而让出一些RAM的空间给其他进程， Cached Files: 最近使用的内存被临时存储，在使用其他应用前再次打开会直接从这里访问，加快访问速度 Swap Used: 硬盘中用来交换RAM中无用内容的大小 内存详细 Real Memory Size: 被进程使用的实际内存 Virtual Memory Size: 进程空间大小，64bit内存地址空间，所以会很大，不重要 Shared Memory Size: 表示已经被加载到物理内存中的进程私有数据所对应的虚拟内存地址空间大小。 Private Memory Size: 表示已经被加载到物理内存中的进程私有数据所对应的虚拟内存地址空间大小。 比较 在操作系统书中讲述的内存管理，其实mac OS并没有与他有太大差别，现在理解来看大致思想还是相近的。 看下mac OS是在哪个部分能够出现30G占用这种情况，是swap空间没有设置上限吗？ 看下面的swap大小与上面的virtual memory size的确对上了，的确是swap空间够大的原因……而检测过程中，占用大量内存的问题所在是tensorboard,暂时只好手动导出数据用matplot画了。 Reference Apple Activity Monitor Instrument Mac 的 memory 和 real size memory 有什么区别 Mac OS 内存管理知识 Memory terminology in Mavericks Activity Monitory How to use Activity Monitor on your Mac","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Memory","slug":"Memory","permalink":"https://sean10.github.io/tags/Memory/"},{"name":"OS","slug":"OS","permalink":"https://sean10.github.io/tags/OS/"}]},{"title":"VMWare远程控制tensorflow踩坑","slug":"VMWare远程控制踩坑","date":"2018-05-07T10:14:08.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/05/07/VMWare远程控制踩坑/","link":"","permalink":"https://sean10.github.io/2018/05/07/VMWare远程控制踩坑/","excerpt":"最近做毕设跑tensorflow占用资源挺大的，就想用旧电脑来跑，本来计划的是用旧电脑双系统里装好的ubuntu来跑，不过最近发现跑完保存模型和tensorboard，甚至在跑的时候就用了很多虚拟内存，至少mac上就达到了30G。这样的话，只给分配了20个G的ubuntu就相当不够用了。只好在windows上开虚拟机再配置一下远程了。","text":"最近做毕设跑tensorflow占用资源挺大的，就想用旧电脑来跑，本来计划的是用旧电脑双系统里装好的ubuntu来跑，不过最近发现跑完保存模型和tensorboard，甚至在跑的时候就用了很多虚拟内存，至少mac上就达到了30G。这样的话，只给分配了20个G的ubuntu就相当不够用了。只好在windows上开虚拟机再配置一下远程了。 安装完ubuntu，为了能让远程直接ssh到虚拟机里，需要对NAT进行设置，在虚拟网络设置中，比如我就把将主机的10086端口映射到虚拟机IP的22端口，这样就可以直接远程ssh了。 首先修改一下apt源到清华，不过为什么感觉反而这次更慢了呢？ 不过在使用VMWare共享文件夹给ubuntu的时候倒是遭遇了一些问题。 1. legacy install 一开始为了减少桌面环境的资源占用，修改了grub的选项，默认启动命令行界面了。理论上这个部分对我之后安装vmware-tools是没有什么影响的，照常挂载cdrom,mount -t auto /dev/cdrom /mnt/cdrom，然后解压到根目录执行就好。 vmware据说是安装了vmware tools以后就可以访问共享文件夹，但是在ubuntu里安装失败多次，成功一次以后依旧没能发现那个文件夹。 sudo ./vmware-install.pl -d之后是完全不够的 需要按照2对tools打一个补丁， 然后使用更新的vmfuse替换mount，``之后就能访问共享文件夹了。 2. open-vm-tools install 1234sudo apt-get install gitgit clone https://github.com/rasa/vmware-tools-patches.gitcd vmware-tools-patchessudo ./patched-open-vm-tools.sh Python环境重建 好久没在ubuntu下重新配置环境了 123456sudo add-apt-repository ppa:deadsnakes/ppasudo apt-get updatesudo apt-get install python3.6curl https://bootstrap.pypa.io/get-pip.py -o get-pip.pypython3.6 get-pip.py 然后把pip源改到清华，OK。 终于可以跑起来了，之后再装好jupyter打开对外访问,win10防火墙开放一下修改的映射端口，就OK啦~ Jupyter远程跑的时候，频频会弹出窗口提示 Notebook has changed since we opened it. Overwrite the changed file? 一开始搜了下，最高票都提示说是bug，是自动modify_checkpoint间隙太短，在5.5版本里添加了修改这个时间的配置文件。但我之前单机使用是没有问题的，新装的版本和单机用的notebook版本是相同的，所以变量是控制了的，之后发现有人多次提到主要出现原因是因为同时多个窗口在访问这个页面，那么，细想一下，在启动notebook时默认会自动打开一个网页，text启动的ubuntu是不是也存在了这个情况(目前猜想是由于毕竟是desktop版本的ubuntu，所以还是存在自动打开网页进程的能力)，那么就去修改一下配置文件，默认不打开网页，解决了一个小问题。 但是依旧会定时弹出这个网页……暂时先集中到内容上，之后在处理吧 jupyter kernel重建 在另一台电脑上重新安装jupyter，发现由于系统内存在多个python3版本，执行的python3内核并不是我所要的。 首先修改ipython 解决方式: 12which ipythonwhich python3 将ipython文件中启动方式里的python路径改为你要用的那个版本的python即可，像我就是修改为python3。 再使用jupyter kernelspec list得到所需要修改kernel.json路径，将其中的python路径改为自己所要用的即可。 不过这里显然存在一个问题，这里我list出来的是我在virtualenvwrapper里配置的环境里装的jupyter的kernel的路径，虽然这里改了以后能够运作了，但这应该是存在问题的。 看[6]中提到的，ipython kernel install可以按自己想要的安装内核，但是我安装后还是没能出现在上面的list中，稍后再看吧。 Reference vmhgfs-fuse替换mount vmware-tools-patches pip install doc tsinghua pypi Anaconda &amp; ipython路径问题 &amp; jupyter notebook 启动核心问题（使用方法&amp;不常见的问题） jupyter与python的内核","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"VMWare","slug":"VMWare","permalink":"https://sean10.github.io/tags/VMWare/"},{"name":"jupyter","slug":"jupyter","permalink":"https://sean10.github.io/tags/jupyter/"}]},{"title":"LaTex学习记录","slug":"LaTex学习记录","date":"2018-05-04T12:30:59.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/05/04/LaTex学习记录/","link":"","permalink":"https://sean10.github.io/2018/05/04/LaTex学习记录/","excerpt":"","text":"编译过程 12345xelatex main.texbibtex main.auxxelatex main.texxelatex main.texopen -a preview main.pdf 将tex转成word 1pandoc -s main.tex -o main.docx 12345# 调用方法 ：# 单个文件texcount your-file-name.tex# 多个文件texcount file-name1.tex file-name2.tex 出现问题 —they aren’t the same literal types for entry shenyaoZhongGuoDianYingZaiXianPiaoWuFaZhanYanJiu2016 while executing—line 2571 of file buptbachelor.bst 0 is an integer literal, not a function, for entry shenyaoZhongGuoDianYingZaiXianPiaoWuFaZhanYanJiu2016 while executing—line 2571 of file buptbachelor.bst You can’t pop an empty literal stack for entry shenyaoZhongGuoDianYingZaiXianPiaoWuFaZhanYanJiu2016 while executing—line 2571 of file buptbachelor.bst 根据检索，按照4次编译过程来[4]，就可以得到文献结果，只不过出现中文编码错误 英文参考文献中出现中文字符 对language域进行判断的话，需要改bst文件，针对一些特殊的域进行判断，比较麻烦。 现成的GBT7714的那个，只要language域不是空的，就按中文输出。[5] Reference Latex中bib参考文献的编译 bib格式 使用 BibTeX 生成参考文献列表 Latex下使用IEEEtran模板编译bib失败报错的解决方法 对于中英文参考文献，如何区别输出？","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"LaTex","slug":"LaTex","permalink":"https://sean10.github.io/tags/LaTex/"}]},{"title":"使用github二级域名部署服务","slug":"使用github二级域名部署服务","date":"2018-04-13T13:42:36.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/04/13/使用github二级域名部署服务/","link":"","permalink":"https://sean10.github.io/2018/04/13/使用github二级域名部署服务/","excerpt":"以前比较偏向买个域名，然后理论上用服务商提供的dns解析根据不同的sub domain指向不同ip就能部署服务了。其中，将github page CNAME到自己的域名上。 如果是使用提供的二级域名作为主域名呢？域名指向权限不在自己手中的情况下，github如何提供的解决方法呢？","text":"以前比较偏向买个域名，然后理论上用服务商提供的dns解析根据不同的sub domain指向不同ip就能部署服务了。其中，将github page CNAME到自己的域名上。 如果是使用提供的二级域名作为主域名呢？域名指向权限不在自己手中的情况下，github如何提供的解决方法呢？ github支持gh-pages分支生成项目页&lt;username&gt;.github.io/&lt;project&gt;，但还是不能利用自己的服务器部署服务。 在参考1中提出了一个利用gh-pages+HTML 302的方法进行跳转的方法。 再仔细找了找，除了自定义域名和这个302的方法，Github官方没有开放这个域名指向其他服务器的权限，仔细想想这样也是有道理的。否则岂不是github的域名也无法保证这个网页的安全性了。 Reference 把 Github 用作 DNS 设置二级域名跳转","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"DNS","slug":"DNS","permalink":"https://sean10.github.io/tags/DNS/"},{"name":"github","slug":"github","permalink":"https://sean10.github.io/tags/github/"}]},{"title":"广告系统初探","slug":"广告系统初探","date":"2018-04-11T13:53:18.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/04/11/广告系统初探/","link":"","permalink":"https://sean10.github.io/2018/04/11/广告系统初探/","excerpt":"有一家公司给出了广告系统方向的offer，虽然最后没有选择，但还是了解了一下广告业务。","text":"有一家公司给出了广告系统方向的offer，虽然最后没有选择，但还是了解了一下广告业务。 引言 传统视角的广告给人的主观感觉是破坏体验，而现在如游戏联运、团购、返利等广告的新后向变现传播方式，给用户带来的体验是不差的。 互联网广告的关键不再是创意、策略等人工服务，而是以数据支撑的流量规模化交易为典型特点。 规模化的重点是让流量更加有效、高质量，构建更清晰的用户画像，精准掌握用户的个性化需求。 《计算广告》 《计算广告》主线： * 商业逻辑驱动的在线广告产品和技术的升级 * 数据的加工、利用与交易 传统媒体时代，供给方与需求方在市场地位上有相当的距离，不论你运营的是电视台、机场或杂志，都与大多数广告主需要的转化行为之间有相当大的差距。因此这一阶段广告的目的是希望借助媒体的力量来快速接触大量用户，以达到宣传品牌形象、提升中长期购买率与利润空间的目的。这种目的的广告被称为品牌广告（brand awareness)。当然，也有许多广告商 希望能利用广告手段马上带来大量的购买或其他 转化行为，这种目的的广告称为直接效果广告 （direct response），有时也简称为效果广告。 计算广告的核心问题，是为一系列用户与环境的组合找到最合适的广告投放策略以优化整体广告活动的利润。 竞价策略主要研究处于纳什均衡状态下的收益和其他特性。 关键技术 Lucene全文检索引擎 信息检索(Information Retrieval, IR) 倒排索引 向量空间模型 最优化(Optimization) \b 这方面这本书写的很详细，不过好细，还是实践的时候再细看吧。 Reference 《计算广告》 大型广告系统架构概述 一分钟读懂互联网广告竞价策略GFP+GSP+VCG 互联网广告中，品牌广告和效果广告如何对比分析？","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://sean10.github.io/tags/算法/"},{"name":"广告","slug":"广告","permalink":"https://sean10.github.io/tags/广告/"}]},{"title":"Pycharm快捷键记录","slug":"Pycharm快捷键记录","date":"2018-03-24T15:11:40.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/24/Pycharm快捷键记录/","link":"","permalink":"https://sean10.github.io/2018/03/24/Pycharm快捷键记录/","excerpt":"Pycharm 键位图","text":"Pycharm 键位图 Command+B 函数跳转 Command+alt+left 返回上一页 Reference 麻瓜编程","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Pycharm","slug":"Pycharm","permalink":"https://sean10.github.io/tags/Pycharm/"},{"name":"快捷键","slug":"快捷键","permalink":"https://sean10.github.io/tags/快捷键/"}]},{"title":"virtualwrapper管理环境","slug":"virtualwrapper管理环境","date":"2018-03-23T14:12:05.000Z","updated":"2021-01-23T14:15:22.962Z","comments":true,"path":"2018/03/23/virtualwrapper管理环境/","link":"","permalink":"https://sean10.github.io/2018/03/23/virtualwrapper管理环境/","excerpt":"","text":"在看工程源码时，要配置python2.7环境，这个时候发现一直用的virtualenvwrapper建立环境后就无法切换到2.7来安装环境了。 一开始找了好久，以为需要比如pyenv+virtualenv之类的多个工具才能管理python版本和环境。 结果找啊找发现，virtualenvwrapper就支持这个要求。 1mkvirtualenv --python python2.7 envname 不过在官方doc里倒是没能搜索到这个功能，只有mkvirtualenv --help才能看到这个功能…… 为什么把这里的help里的文字放到官方搜索里都搜不到………… 常用功能 12345mkvirtualenv test --python=python3lsvirtualenvworkon testdeactivatermvirtualenv test pycharm自带venv使用 Reference 使用virtualenv搭建独立的python环境","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"virtualenv","slug":"virtualenv","permalink":"https://sean10.github.io/tags/virtualenv/"}]},{"title":"kcp协议理解","slug":"kcp协议理解","date":"2018-03-23T06:24:38.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/23/kcp协议理解/","link":"","permalink":"https://sean10.github.io/2018/03/23/kcp协议理解/","excerpt":"TCP Qos 问题 TCP的流量控制仅针对单条TCP连接，而在网络中UDP、ICMP等包并不遵循这个规则，TCP迫于流量控制，检测到端到端阻塞就会减小自己的窗口，然后被UDP等占据闲置出的带宽，导致饿死。 由于这个TCP在阻塞情况下迫于大环境无法保证传输质量，就有大批转而使用UDP协议加速的方式。","text":"TCP Qos 问题 TCP的流量控制仅针对单条TCP连接，而在网络中UDP、ICMP等包并不遵循这个规则，TCP迫于流量控制，检测到端到端阻塞就会减小自己的窗口，然后被UDP等占据闲置出的带宽，导致饿死。 由于这个TCP在阻塞情况下迫于大环境无法保证传输质量，就有大批转而使用UDP协议加速的方式。 UDP 加速 kcp的设计是为了解决在网络拥堵情况下tcp协议的网络速度慢的问题。(包括BBR等，还有很多)一般使用udp作为下层传输协议。 KCP对TCP的一些细节进行了改良[1] RTO翻倍VS不翻倍 全部重传VS选择性重传 快速重传 非延迟ACK VS 延迟ACK ACK+UNA VS UNA 非退让流控 KCP正常模式同TCP一样使用公平退让法则，即发送窗口大小由：发送缓存大小、接收 端剩余接收缓存大小、丢包退让及慢启动这四要素决定。但传送及时性要求很高的小 数据时，可选择通过配置跳过后两步，仅用前两项来控制发送频率。以牺牲部分公平 性及带宽利用率之代价，换取了开着BT都能流畅传输的效果。 RTT(round trip time) &amp;&amp; RTO(Retransmission timeout) RTT: 数据包往返时间 RTO: 超时重传时间 RTO重传间隔是指数增加的。丢包一次后，下一次重传RTO会从1，2，4，8……。叫做指数回避策略。(RTO下限200ms,写在协议里的，无法修改) 数据链路层ARQ与传输层ARQ区别 数据链路层的ARQ只能保证点到点之间传输的可靠性。 如A-B-C，数据链路层只能保证A-B不丢包，但是B会不会由于传输窗口满而丢弃包就无法保证，A-C之间传输的可靠就需要上层传输层协议来确认，这就叫做端到端的可靠性。 Reference kcp 详解 RTO 对TCP超时的影响 TCP RTO 计算方法及Go实现验证","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://sean10.github.io/tags/网络/"},{"name":"kcp","slug":"kcp","permalink":"https://sean10.github.io/tags/kcp/"},{"name":"tcp","slug":"tcp","permalink":"https://sean10.github.io/tags/tcp/"}]},{"title":"travis CI 部署","slug":"travis-CI-部署","date":"2018-03-19T14:39:02.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/19/travis-CI-部署/","link":"","permalink":"https://sean10.github.io/2018/03/19/travis-CI-部署/","excerpt":"","text":"根据参考1部署了一下自动化travis， 然后自动化部署依旧报错，终于意识到了next主题无法正常运作的原因，是配置文件过时了的原因，没跟上next版本迭代的速度，所以其中有些配置信息的导入造成了错误。 重新修改之后，终于可以在travis CI正常运作了。 在更改为pandoc解析引擎时，忘记了hexo-renderer-pandoc是依赖于pandoc来执行的，按照[2]在travis.yml里添加了安装pandoc环境后就可以正常运行了。 参考: 用 Travis CI 自动部署 hexo segmentfault travis CI pandoc","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"automate","slug":"automate","permalink":"https://sean10.github.io/tags/automate/"},{"name":"travis","slug":"travis","permalink":"https://sean10.github.io/tags/travis/"}]},{"title":"dockerfile学习","slug":"dockerfile学习","date":"2018-03-17T12:06:44.000Z","updated":"2021-01-24T12:54:56.465Z","comments":true,"path":"2018/03/17/dockerfile学习/","link":"","permalink":"https://sean10.github.io/2018/03/17/dockerfile学习/","excerpt":"现在装的环境有点多了，一不留神就会改动了其他工具使用的环境，这种环境下学下docker可以保障运行环境的一致性。","text":"现在装的环境有点多了，一不留神就会改动了其他工具使用的环境，这种环境下学下docker可以保障运行环境的一致性。 试着先给毕设用的环境写个dockerfile, 顺便提了个PR，希望能被合并吧。 在找错的过程中，看到好多人用docker run来后台执行命令，感觉好微妙，每次从镜像新建一个容器来执行命令，那旧的容器是继续保留吗？还是说生产环境的确就是这样做的。 可能因为我这算是学习环境，所以对Docker的变动都是在内部修改，并不完全是从dockerfile来的吧。 1docker build -t sean10:tensorflow . 在docker run时，最后的命令行参数是会和dockerfile中的RUN, CMD, ENTRYPOINT相关的。 RUN是在Build时运行的，先于CMD和ENTRYPOINT。Build完成了，RUN也运行完成后，再运行CMD或者ENTRYPOINT。 比如这个，最后的bash会覆盖CMD指定的命令 1docker run -p 7777:8888 -v /Users/sean10/Code/LSTM-Sentiment-Analysis:/LSTM-Sentiment-Analysis -it tensorflow/tensorflow:1.1.0-py3 bash todo docker如何使用相对路径的文件内? .dockerignore 在docker命令行界面中发送上下文到docker的守护进程之前，它会检查上下文目录根路径下名为.dockerignore的文件，如果这个文件存在，命令行界面会修改上下文，排除那些被.dockerignore中的模式匹配到的文件和目录。 docker stage 如何显示之前下载过的stage用的image ? 显示已下载的image的dockerfile systemd的docker内启动 docker run -tid –name test_1 –privileged=true centos:latest /usr/sbin/init docker exec -it test_1 /bin/bash 多重from image 精简Docker镜像的几个方法 - 那少年和狗 - 博客园 参考 Dockerfile里指定执行命令用ENTRYPOING和用CMD有何不同？ 跟我一起学Docker——RUN、ENTRYPOINT与CMD Docker容器怎样更改容器内应用程序的配置文件？","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://sean10.github.io/tags/Docker/"}]},{"title":"iTerm & zsh加载缓慢","slug":"iTerm-zsh加载缓慢","date":"2018-03-16T12:31:12.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/16/iTerm-zsh加载缓慢/","link":"","permalink":"https://sean10.github.io/2018/03/16/iTerm-zsh加载缓慢/","excerpt":"","text":"最近iTerm每开一个tab都要等4、5秒的时间，按照ssd的加载速度来说这是本不应该发生的事情。 顶部栏是从python-&gt;ruby等等的变化，最后才到菜单栏。 猜想应该是导入的配置文件中导入了过多。 找了一下其他人遇到的问题，发现果然主要都是nvm造成的影响，把nvm的导入注释掉，就恢复到了1、2s加载速度。 不过，除此之外，iTerm默认是从系统的/usr/bin/login启动，启动时需要读取apple 系统日志(apple system log)，所以这里有两种解决方案。 清除日志 1sudo rm /private/var/log/asl/*.asl 更换启动shell 在Iterm Perferences&gt;Profile&gt;General&gt;Command 设置为/bin/zsh 参考资料 iTerm 2、Terminal 启动加速","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"},{"name":"iTerm","slug":"iTerm","permalink":"https://sean10.github.io/tags/iTerm/"}]},{"title":"刘慈欣谈科幻","slug":"刘慈欣谈科幻","date":"2018-03-15T12:08:27.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/15/刘慈欣谈科幻/","link":"","permalink":"https://sean10.github.io/2018/03/15/刘慈欣谈科幻/","excerpt":"在这本书中，大刘对于科幻在国内的地位以及趋势的理解认识逐渐展现，让人又一次为他所折服。","text":"在这本书中，大刘对于科幻在国内的地位以及趋势的理解认识逐渐展现，让人又一次为他所折服。 悲观主义 外国科幻对国内科幻创作产生较强影响力的时期，处于中国科幻史的两端，是在清末民初和20世纪90年代至今这两个阶段。 在清末民初，世界科幻文学也还在起步阶段，依旧与文学相关，并未成立一个独立的体裁。导致国内对科学的技术幻想都只是为文学服务的。 自20世纪90年代中期至今，这一时期的科幻是一种文学型科幻，不再是阿西莫夫科普型科幻那样凸显科学和技术的地位，而是通过晦涩的象征展现幻想。 在这个时期，书中提到共有三种科幻。 科普型科幻 文学型科幻 赛博朋克科幻（这个倒是没看到过） 在20世纪90年代以前那段时间内，国内的科幻受西方悲观影响，对科学未来持一种悲观的态度，刘慈欣对于这点是觉得相当需要改变的，国内的科幻对科学的推崇尚且还没达到盛极转衰，就在文中不断对科学的前景唱衰，这对于大众读者的影响来说并不是一件好事。 大刘觉得，最美的科幻还是需要偏乐观主义一些。 再仔细看看共产主义的定义，请注意这定义中以前最不为我们注意的一句话：劳动是人们的第一需要。 天哪，这句话就反转我对共产主义的认识了。 科幻硬伤 哇，大刘居然也上过龙空(lkong.cn) 疏忽硬伤 知识硬伤 背景硬伤 灵魂硬伤","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/科幻/"},{"name":"刘慈欣","slug":"刘慈欣","permalink":"https://sean10.github.io/tags/刘慈欣/"},{"name":"评论","slug":"评论","permalink":"https://sean10.github.io/tags/评论/"}]},{"title":"重读《失控》","slug":"重读《失控》","date":"2018-03-12T13:56:47.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/12/重读《失控》/","link":"","permalink":"https://sean10.github.io/2018/03/12/重读《失控》/","excerpt":"第一章 人造与天生 仿生学产物很有可能存在失控的可能性","text":"第一章 人造与天生 仿生学产物很有可能存在失控的可能性 第二章 蜂群思维 分布式的管理最后还是需要部分人的一致性来引导的吧？虽然会有一个大方向上的默认行为。 去年reddit的place游戏在最后脚本的协作中才实现稳定。 后文中提到，稀疏内存模拟的分布式记忆可以还原的能力，这点倒是有点难以理解了。 第三章 有心智的机器 机械自洽，这个也是蛮有意思的。如果过于不控制，机械之间无冲突就见不到美感了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"凯文","slug":"凯文","permalink":"https://sean10.github.io/tags/凯文/"},{"name":"失控","slug":"失控","permalink":"https://sean10.github.io/tags/失控/"},{"name":"技术","slug":"技术","permalink":"https://sean10.github.io/tags/技术/"}]},{"title":"读《韩松——宇宙墓碑》","slug":"读《韩松——宇宙墓碑》","date":"2018-03-11T07:15:53.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/11/读《韩松——宇宙墓碑》/","link":"","permalink":"https://sean10.github.io/2018/03/11/读《韩松——宇宙墓碑》/","excerpt":"导读中说到，韩松主要风格是参考现实文学，要营造出一种反思的内涵。 总的来说这本上个世纪的作品集锦中，现在姑且只有宇宙墓碑和灿烂文化的背景设定还不错了。","text":"导读中说到，韩松主要风格是参考现实文学，要营造出一种反思的内涵。 总的来说这本上个世纪的作品集锦中，现在姑且只有宇宙墓碑和灿烂文化的背景设定还不错了。 宇宙墓碑 相比大刘的作品，这部作品读起来文字简洁，但却让人有些难以理解。 上篇中，是从现代的角度来叙述，讲述未来人从太空人的墓碑中莫名获得的迷恋感，甚至到了掘墓的程度。 下篇，造墓人的信中提出了太空女性带来的异常，以及宇宙也是个墓的想法。以及第三处曾经造过的墓的莫名消失。 下篇中的一个个线索的出现让人摸不着头绪。 灿烂文化 这篇文章从来自地球的业余考古者降落到大荒星来寻找灿烂文化开始，以大荒星时空场的变动结束，这些考古者成为灿烂文化的开拓者后又引领自己的飞船的降落，形成了一个莫比乌斯环. 没有答案的航程 飞船，一个孤立空间中，失去记忆的2人之间的人心的揣测，最终依旧没有确定的答案。 劫 又是一个时空场交错的故事，不过这次以外星人佛陀和特工诗人为主角。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/科幻/"},{"name":"韩松","slug":"韩松","permalink":"https://sean10.github.io/tags/韩松/"}]},{"title":"豆瓣爬虫细节","slug":"豆瓣爬虫细节","date":"2018-03-09T12:54:27.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/09/豆瓣爬虫细节/","link":"","permalink":"https://sean10.github.io/2018/03/09/豆瓣爬虫细节/","excerpt":"","text":"1https://movie.douban.com/j/new_search_subjects?sort=T&amp;range=0,10&amp;tags=%E5%89%A7%E6%83%85&amp;start=10 像这种json获取的链接，倒是没有cookie的要求，即便多线程爬取几百页也没有被ban. 之前直接使用了rq任务队列，导致不知道该怎么写多线程了。 暂时先重新用自带的queue写写看多线程。 目前20个线程爬取10页约200个评论，耗时8.98秒,不过这里固定一个ip测试立马就被ban了。 只是添加了bid的cookie 和 随机UA似乎并不足够. 稍稍追加了一下header,然后用多进程跑起来了……真的伤心，用的其他的再复杂的框架反而失败了，协程也遭遇各式各样的难题，暂时还是用多进程拿下数据吧。 明明使用了可用的代理，但是被ban的却还有我的真实ip，经过测试，和代码无关，是代理问题。透明代理相比高匿代理是否会导致真实ip被ban还没有测试过。 在aiohttp中试图使用https代理时，才意识到https代理像贡献者说的那样没有必要，在V站讨论中，可以看到HTTPS代理仅仅是起到在客户端到代理端之间进行SSL认证的功能，与访问https还是http网站完全没有关系。 在没有用redis持久化时，想到 布隆过滤器似乎也需要持久化，查了一些，似乎基于redis或者pickle序列化持久化都是可选的，但是在找官方文档的时候看到这么一句。 Since this package natively uses mmap files, no serialization is needed. Therefore, if you have to do a lot of moving between disks etc, this module is an obvious win. mmap是什么文件 在用charles测试抓包的过程中遭遇了SSLError(SSLError(1, ’[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)’),))问题,似乎与python requests对charles ssl认证有关。 从charles保存根证书导入python requests即可。 参考资料 (requests charles SSL)[https://www.charlesproxy.com/documentation/using-charles/ssl-certificates/] Python requests请求https遇到问题 HTTP代理和HTTPS代理的区别 通过一台 HTTPS proxy 上网，这台 proxy 能获得我访问的网址吗?","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sean10.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sean10.github.io/tags/爬虫/"},{"name":"Spider","slug":"Spider","permalink":"https://sean10.github.io/tags/Spider/"}]},{"title":"《最好的告别》note","slug":"《最好的告别》note","date":"2018-03-08T14:00:39.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/08/《最好的告别》note/","link":"","permalink":"https://sean10.github.io/2018/03/08/《最好的告别》note/","excerpt":"这本其实是豆瓣送礼券了，看着比较顺眼找的一本。 这本书整体还是以故事性更多，对于不了解这些思想的人可能有收获，对于已知的人就有些鸡肋了。 自序中，作者说他对一位彻底无救的病患实施了安乐死。这位患者进行了医生所知道的技术上的手术，虽然无法满足他康复的需求，结果在成功的手术后痛苦而去。 作者对病患接受无效手术的这个选择觉得有些不太恰当。这位作者的观点我还是很赞同的，不过不知道书中内容还会有哪些突破。","text":"这本其实是豆瓣送礼券了，看着比较顺眼找的一本。 这本书整体还是以故事性更多，对于不了解这些思想的人可能有收获，对于已知的人就有些鸡肋了。 自序中，作者说他对一位彻底无救的病患实施了安乐死。这位患者进行了医生所知道的技术上的手术，虽然无法满足他康复的需求，结果在成功的手术后痛苦而去。 作者对病患接受无效手术的这个选择觉得有些不太恰当。这位作者的观点我还是很赞同的，不过不知道书中内容还会有哪些突破。 在这篇序言的最后，作者提到下文: 其实，恰恰是因为我们的文化拒绝接受生命周期的限定性，以及衰老与死亡的不可避免性，我们的末期病人和老人才会成为无效治疗和精神照顾缺失的牺牲品。 这里指的是美国的文化吗？中国似乎并不存在生命周期的限定性这点。 01 独立 美国文化中，似乎老人即便不满足一些独立生活的指标，但还是会独立生活，而不是被送去疗养院（虽然疗养院才是更符合实际的做法）。 现代化并没有降低老年人的地位，而只是降低了家庭的地位。 这句话倒是表达的相当直接，老年人在家庭中的话语权随着现代化带来的选择多样化而逐渐变得不那么重要了。 这里提到一个退休社区，似乎国外还是形成了一个比较大的规模的。 对于老年痴呆，这里说到医生没有办法让老人恢复独立生活的能力，只有让家人或疗养院几个选择。据了解，这也的确是现实。 02 崩溃 老了以后，身体就像机器一样持续磨损直到一下子崩溃，如果每个细节都能持续关注维护，还是很有效果的。 03 依赖 在疗养区，因为护理人员的不理解，只是被当做病人而不是一个正常人对待，精神上并不能得到痛快。但家人也往往还没有进入老年生活，往往没有足够的时间来照料，需要花费高额工资可能也不一定能雇到能令人放心的护工。 50多年前，社会学家欧文 戈夫曼在他的著作《收容所》(Asylums)里写到监狱和疗养院之间的相同之处。疗养院和军事训练营、孤儿院及精神病院一样，是“纯粹的机构”——在很大程度上是跟社会隔绝的地方。 而绝大多数人还是需要一个隔离的空间了，老了而在这种集体空间内还是令人非常恐惧的。 04 帮助 这篇中的威尔逊提出了一个辅助生活中心、独立公寓，将机构的权力所属归还了老人们，护理人员们会意识到所有所有权归属在于老人，老人不愿意的事情便不去处理。 这个单看他给出的结果是很棒的，不过还是有很多借用这个名词却依旧只提供集中床铺的疗养院。 05 更好的生活 杰奎依 卡尔森 山伯恩之地，另一种辅助生活机构，为居民考虑更多，只需要为老人收拾他们带来的副结果。 06 放手 保险公司会提供善终服务 临终时，需要从医生那里得到的不是病人想要什么，而是需要通过谈话接受个人的必死性、清楚了解医学的局限性和可能性，这是个过程，而不是顿悟 花钱决定化疗之前，更有必要花钱与医生讨论做与不做哪个选择更明智。 07 艰难的谈话 08 勇气","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"死亡","slug":"死亡","permalink":"https://sean10.github.io/tags/死亡/"},{"name":"衰老","slug":"衰老","permalink":"https://sean10.github.io/tags/衰老/"}]},{"title":"公众号开发笔记","slug":"公众号开发笔记","date":"2018-03-06T07:49:46.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/03/06/公众号开发笔记/","link":"","permalink":"https://sean10.github.io/2018/03/06/公众号开发笔记/","excerpt":"试着用微信公众号来做一些bot的任务，这里稍稍记些笔记吧。","text":"试着用微信公众号来做一些bot的任务，这里稍稍记些笔记吧。 首先，id/secret/token设置需要记录下。测试接口似乎可以使用ngrok这样工具。 未认证的订阅号的被动回复权限理论上是满足我的需求了的。 遇到问题: 在用搬瓦工服务器处理消息时，似乎那边收不到我的消息，但是认证token那个收发包过程还是通过了的，暂时怀疑是服务器端口冲突了。但是iptables并没有查到冲突问题，用nginx映射时倒是才提示端口已占用。 在centos6安装python时，出现了 ModuleNotFoundError: No module named '_sqlite3',在SF，似乎是python3.6移除了3.5中的_sqlite3.so，不过按照最高票的cp python2的module过去再altinstall会引发新的ImportError: dynamic module does not define module export function (PyInit__sqlite3) 最后，只是configure时(添加个动态库选项)[http://blog.csdn.net/jaket5219999/article/details/53512071]就可以了。 12./configure --enable-loadable-sqlite-extensionsmake &amp;&amp; make install 参考资料: https://stackoverflow.com/questions/1210664/no-module-named-sqlite3 https://stackoverflow.com/questions/16018463/difference-in-details-between-make-install-and-make-altinstall http://blog.csdn.net/jaket5219999/article/details/53512071","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"微信","slug":"微信","permalink":"https://sean10.github.io/tags/微信/"}]},{"title":"算法学习目录","slug":"算法学习目录","date":"2018-03-05T14:44:08.000Z","updated":"2020-12-27T11:29:16.361Z","comments":true,"path":"2018/03/05/算法学习目录/","link":"","permalink":"https://sean10.github.io/2018/03/05/算法学习目录/","excerpt":"快排、归并、二分","text":"快排、归并、二分 数组 原地转置 不过这个是对一维数组的操作，暂时没想到对二维非方阵数组，除了不停的resize以外的方法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950int getNext(int i, int m, int n)&#123; return (i%n)*m + i/n;&#125; /* 前驱 */int getPre(int i, int m, int n)&#123; return (i%m)*n + i/m;&#125; /* 处理以下标i为起点的环 */void movedata(int *mtx, int i, int m, int n)&#123; int temp = mtx[i]; // 暂存 int cur = i; // 当前下标 int pre = getPre(cur, m, n); while(pre != i) &#123; mtx[cur] = mtx[pre]; cur = pre; pre = getPre(cur, m, n); &#125; mtx[cur] = temp;&#125; /* 转置，即循环处理所有环 */void transpose(int *mtx, int m, int n)&#123; for(int i=0; i&lt;m*n; ++i) &#123; int next = getNext(i, m, n); while(next &gt; i) // 若存在后继小于i说明重复 next = getNext(next, m, n); if(next == i) // 处理当前环 movedata(mtx, i, m, n); &#125;&#125; /* 输出矩阵 */void print(int *mtx, int m, int n)&#123; for(int i=0; i&lt;m*n; ++i) &#123; if((i+1)%n == 0) cout &lt;&lt; mtx[i] &lt;&lt; &quot;\\n&quot;; else cout &lt;&lt; mtx[i] &lt;&lt; &quot; &quot;; &#125;&#125; 双指针法 http://chocoluffy.com/2016/12/04/%E6%B5%85%E6%9E%90%E7%BB%8F%E5%85%B8%E9%9D%A2%E8%AF%95%E7%AE%97%E6%B3%95%E9%A2%98-two-pointer%E7%9A%84%E8%BF%90%E7%94%A8/ 表: 双重链接表 正交表 树: 二叉树 平衡二叉树 AVL树 自由树 有向树 无穷性引理 树的枚举 通路长度 图 有向图 有向无环图 拓扑排序 我们都知道对于有向图进行拓扑排序可以判断是否存在环。 对于有向图的拓扑排序，大家都知道的kahn算法： 计算图中所有点的入度，把入度为0的点加入栈 如果栈非空： 取出栈顶顶点a，输出该顶点值，删除该顶点 从图中删除所有以a为起始点的边，如果删除的边的另一个顶点入度为0，则把它入栈 如果图中还存在顶点，则表示图中存在环；否则输出的顶点就是一个拓扑排序序列 dfs bfs 邻接矩阵 邻接表 十字链表 舞蹈链算法 BFS BFS（显式用队列） DFS（隐式用栈）（即递归） 当然，对于DFS，用递归可能会造成栈溢出，所以也可以更改为显示栈。 1234567891011将（起始）首节点加入队列：q.push(head); 标记首节点已经被访问：isvisited[head]=true; 以下自动反应：while(!q.empty())&#123; int temp=q.front(); q.pop(); 访问temp，并标记temp已被访问过，将temp的子相关节点加入队列 q.push(temp相关节点);&#125; DFS 123456789101112131415161718void dfs(int 当前状态) &#123; if(当前状态为边界状态) &#123; 记录或输出 return; &#125; for(i=0;i&lt;n;i++) //横向遍历解答树所有子节点 &#123; //扩展出一个子状态。 修改了全局变量 if(子状态满足约束条件) &#123; dfs(子状态) &#125; 恢复全局变量//回溯部分 &#125; &#125; 转换 为 迭代时 尾递归 非尾递归:下一个函数结束以后此函数还有后续，所以必须保存本身的环境以供处理返回值。 尾递归的精髓在于往内进行下一层解析的时候，这一层函数执行完了没卵用了，编译器一想，你都没卵用了我把你参数改改也没事啊，改了之后发现，哟呵这不是你儿子吗，那你爷俩就用这一块地儿好了。所以空间复杂度是O(1)。 尾递归优化主要看语言编译器的支持吧？python，因此鼓励用迭代的方式来实现。「似乎说是为了抛出异常时有完整的Stack trace」 好像C中并没有规定需要尾递归优化，默认并不开启，也不推荐写尾递归，如果代码需要跨平台（那就不要写了） 似乎Erlang更推荐。Erlang的虚拟机会进行优化。 是不是应该写个例子出来？ 尾递归优化主要解决内存占用问题，从O(n)转为O(1) dijkstra单源最短路径算法 Prim最小生成树算法 每个阶段只有一个状态-&gt;递推； 每个阶段的最优状态都是由上一个阶段的最优状态得到的-&gt;贪心； 每个阶段的最优状态是由之前所有阶段的状态的组合得到的-&gt;搜索； 每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到而不管之前这个状态是如何得到的-&gt;动态规划。 每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到这个性质叫做最优子结构； 而不管之前这个状态是如何得到的这个性质叫做无后效性。 动态规划 数字三角形问题， 由底向上，才算是每个阶段的最优状态 最长上升子序列(LIS) 究竟怎么由状态转移方程写成代码？ 水库抽样算法 12345678910111213/* S has items to sample, R will contain the result*/ReservoirSample(S[1..n], R[1..k]) // fill the reservoir array for i = 1 to k R[i] := S[i] // replace elements with gradually decreasing probability for i = k+1 to n j := random(1, i) // important: inclusive range if j &lt;= k R[j] := S[i] 滑动窗口问题，substring 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;int&gt; findAnagrams(string s, string p) &#123; vector&lt;int&gt; pv(26, 0), sv(26, 0), ans; if (s.size() &lt; p.size()) return ans; for (int i = 0;i &lt; p.size(); i++) &#123; ++pv[p[i] - 'a']; ++sv[s[i] - 'a']; &#125; if (pv == sv) ans.push_back(0); for (int i = p.size(); i &lt; s.size(); i++) &#123; ++ sv[s[i] - 'a']; -- sv[s[i - p.size()] - 'a']; if (sv == pv) ans.push_back(i - p.size() + 1); &#125; return ans; &#125;&#125;; leetcode 样题: 1562 动态规划 最长公共子序列 12345678910111213141516171819202122class Solution &#123;public: int LongCommonSubsequence(string word1, string word2) &#123; vector&lt;vector&lt;int&gt;&gt; dp(word1.size()+1, vector&lt;int&gt;(word2.size()+1, 0)); for (int i = 0;i &lt;= word1.size(); i++) dp[i][0] = 0; for (int j = 0;j &lt;= word2.size(); j++) dp[0][j] = 0; for (int i = 1;i &lt;= word1.size(); i++) for (int j = 1;j &lt;= word2.size(); j++) &#123; if (word1[i-1] == word2[j-1]) dp[i][j] = 1 + dp[i-1][j-1]; else dp[i][j] = max(dp[i-1][j], dp[i][j-1]); &#125; return dp[word1.size()][word2.size()]; &#125;&#125;;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://sean10.github.io/tags/算法/"}]},{"title":"锯齿数独_推理数独 解法","slug":"锯齿数独-推理数独-理解","date":"2018-02-26T13:25:45.000Z","updated":"2018-02-26T17:25:45.000Z","comments":true,"path":"2018/02/26/锯齿数独-推理数独-理解/","link":"","permalink":"https://sean10.github.io/2018/02/26/锯齿数独-推理数独-理解/","excerpt":"推理数独： 将1～9填入空格内，使格内数字满足右侧对应关系：每个圆圈连接的其它数字的和等于右侧对应关系中圆圈内的数字对应的数字。 如右侧为1：30则表示数字1对应线连接的格子中数字的和为30. Neighbourhood:Enter numbers from 1 to 9 once each, into the nine circles. For each number, the sum of all numbers connected to it is given.","text":"推理数独： 将1～9填入空格内，使格内数字满足右侧对应关系：每个圆圈连接的其它数字的和等于右侧对应关系中圆圈内的数字对应的数字。 如右侧为1：30则表示数字1对应线连接的格子中数字的和为30. Neighbourhood:Enter numbers from 1 to 9 once each, into the nine circles. For each number, the sum of all numbers connected to it is given. Example: 这个问题乍一眼看上去很眼熟，第一感觉可以用拓扑排序来解决。实际上目前也的确用拓扑排序成功解决了几道题。 首先观察这个图的特征，假定所有都是出路，可以观察到 2出路: 4个 3出路: 4个 4出路: 1个 将4出路标记为1，按逆时针递增标记 算法大致是下面这样，只是脑海里按照下面这个思路迭代了几次就能实验出结果了。 12340. 将图中数字降序排列1. for 取最大数置于4出路处（即1号位）2. \b for 取最小数，置于与4出路直连的2个2出路处（即2与7号位）3. 迭代求解 答案: 独 数之道的这类题是直接生成了图片再发到浏览器的，看来不能直接读包然后发回结果了。需要进行一下识图了。 参考资料 独 数之道 锯齿数独-&gt;推理数独(需注册登录才能访问)","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"数独","slug":"数独","permalink":"https://sean10.github.io/tags/数独/"},{"name":"sudoku","slug":"sudoku","permalink":"https://sean10.github.io/tags/sudoku/"}]},{"title":"数独note","slug":"数独note","date":"2018-02-24T11:40:46.000Z","updated":"2018-02-27T09:00:00.000Z","comments":true,"path":"2018/02/24/数独note/","link":"","permalink":"https://sean10.github.io/2018/02/24/数独note/","excerpt":"unique rectangle type 1~4没什么疑问，不过hidden unique rectangle 的删除有些疑惑，如何确定哪个是候选数a，哪个是候选数b的呢","text":"unique rectangle type 1~4没什么疑问，不过hidden unique rectangle 的删除有些疑惑，如何确定哪个是候选数a，哪个是候选数b的呢 有些技巧似乎国内的那个论坛上也并没有提到，国外那位大神总结的真是全。 Generalising X-Wing X-Wing is not restricted to rows and columns. We can also extend the idea to boxes as well. If we generalise the rule above we get: When there are * only 2 candidates for a value, in each of 2 different units of the same kind, * and these candidates lie also on 2 other units of the same kind, then all other candidates for that value can be eliminated from the latter two units. Now we have 6 combinations: Starting from 2 rows and eliminating in 2 columns -&gt; Classic X-Wing Starting from 2 columns and eliminating in 2 rows -&gt; Classic X-Wing Starting from 2 boxes and eliminating in 2 rows -&gt; Same effect as line/box reduction Starting from 2 boxes and eliminating in 2 columns -&gt; Same effect as line/box reduction Starting from 2 rows and eliminating in 2 boxes -&gt; Same effect as pointing pairs Starting from 2 columns and eliminating in 2 boxes -&gt; Same effect as pointing pairs 参考资料： SudokuWiki","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"数独","slug":"数独","permalink":"https://sean10.github.io/tags/数独/"}]},{"title":"Docker TensorFlow运行笔记","slug":"TensorFlow运行笔记","date":"2018-02-24T05:24:58.000Z","updated":"2018-03-01T17:00:00.000Z","comments":true,"path":"2018/02/24/TensorFlow运行笔记/","link":"","permalink":"https://sean10.github.io/2018/02/24/TensorFlow运行笔记/","excerpt":"为了防止环境问题，所以使用了docker配置的TensorFlow环境，","text":"为了防止环境问题，所以使用了docker配置的TensorFlow环境， 为了防止万一被收录，论文查重问题，这篇之前一直没发布。 部署 12345docker pull tensorflow/tensorflowdocker run -it tensorflow/tensorflow bash发现这个仓库只能在1.1版本下跑，重新下载了个docker pull tensorflow/tensorflow:1.1.0-py3 Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA 一开始在使用tf.Session()时就报了这个错误。暂时没理会。 但是对docker 不那么熟悉，不知道代码和数据应该存在哪个位置，在那还是决定代码通过volume挂载到docker内。 12345678910111213141516docker run -p 7777:8888 --name=tensorflow_sean10 -v /Users/sean10/Code/LSTM-Sentiment-Analysis:/LSTM-Sentiment-Analysis -it tensorflow/tensorflow bash这个版本tensorflow支持python3docker run -p 7777:8888 --name=tensorflow_sean10_py3 -v /Users/sean10/Code/LSTM-Sentiment-Analysis:/LSTM-Sentiment-Analysis -it tensorflow/tensorflow:latest-py3 bashdocker ps -a -ldocker rm $container_iddocker rmi $image_iddocker stop tensorflow_sean10_1.1.0_py3docker start -i tensorflow_sean10_1.1.0_py3docker attach tensorflow_sean10_1.1.0_py3docker exec -t -i tensorflow_sean10_1.1.0_py3 bashdocker run -p 7777:8888 -v /Users/sean10/Code/LSTM-Sentiment-Analysis:/LSTM-Sentiment-Analysis -it tensorflow/tensorflow:1.1.0-py3 bash 对运行中的docker进行网络映射 1234docker port tensorflow_sean10_1.1.0_py3docker inspect tensorflow_sean10_1.1.0_py3 | grep IPAddresspfctl 然后又接触到了jupyter,才逐渐明白这个做的不是ide的任务，有更多其他有意思的功能。 12345jupyter notebook --no-browser --ip=0.0.0.0 --allow-root想要再次获取docker exec -it &lt;docker_container_name&gt;jupyter notebook list 然后在主机浏览器内访问http://localhost:7777?token=xxxxxf 然后运行代码时，显示已经使用了python3的内核，但实际运行弹出的错误来源始终是python2.7，查到的说是默认的tensorflow image只有python2.7安装了tensorflow包，需要pull python3-latest版本才行。的确更换后就可以了…… jupyter默认没有配置自动wrap, 创建~/.jupyter/nbconfig/notebook.json配置文件，追加这一段 123456789101112&#123; &quot;MarkdownCell&quot;: &#123; &quot;cm_config&quot;: &#123; &quot;lineWrapping&quot;: true &#125; &#125;, &quot;CodeCell&quot;: &#123; &quot;cm_config&quot;: &#123; &quot;lineWrapping&quot;: true &#125; &#125;&#125; No module named ipykernel jupyter install 后 无法找到ipykernel_launcher 解决方法： 12pip3 install pykernelpython -m ipykernel install --user Tensorflow错误记录 输入维度错误 ValueError: Input 0 of layer basic_lstm_cell_1 is incompatible with the layer: expected ndim=2, found ndim=1. Full shape received: [400] 输入数据占位符的维度错误了 basicRNNCell ValueError: Shape must be rank 2 but is rank 1 for ‘MatMul’ (op: ‘MatMul’) with input shapes: [64], [64,32]. 将BasicLSTMCell更换成BasicRNNCell时，始终出现错误。唉，在占位符embiding时没注意到传错数了，导致很久都没debug出来…… dynamic_rnn Dynamic_Rnn与Static_rnn主要区别在于输入数据的结构上。 static_rnn 输入的list的大小[序列长度,batch_size,embed大小]，所以一一般在经过embed层后，使用x = tf.unstack(embed, seq_len, 1)变换为[序列长度,batch_size,embed大小]，然后输入到static_rnn，输出也是list，大小形状为[seq_len,batch_size,hidden_size],所以我们取最后一个的输出就直接为static_rnn_out[-1],但是我们的dynamic_rnn不是这样，它的输入是[batch,seq_len,input],所以一般经过embeding层后不需要变化直接输入dynamic_rnn里面，然后输出结果为dynamic_rnn_out，他的shape为[batch,seq_len,hidden_size] ,这样我们要取到最后一个的输出，需要多维度进行一个转化：tf.transpose(dynamic_rnn_out, [1, 0, 2])，然后才可以去计算loss和accuracy等。[5] tensorflow 的dynamic_rnn方法，我们用一个小例子来说明其用法，假设你的RNN的输入input是[2,20,128]，其中2是batch_size,20是文本最大长度，128是embedding_size，可以看出，有两个example，我们假设第二个文本长度只有13，剩下的7个是使用0-padding方法填充的。dynamic返回的是两个参数：outputs,last_states，其中outputs是[2,20,128]，也就是每一个迭代隐状态的输出,last_states是由(c,h)组成的tuple，均为[batch,128]。 到这里并没有什么不同，但是dynamic有个参数：sequence_length，这个参数用来指定每个example的长度，比如上面的例子中，我们令 sequence_length为[20,13]，表示第一个example有效长度为20，第二个example有效长度为13，当我们传入这个参数的时候，对于第二个example，TensorFlow对于13以后的padding就不计算了，其last_states将重复第13步的last_states直至第20步，而outputs中超过13步的结果将会被置零。[6] 如果由于batch一次读入过大，可以使用API中的eval_in_batches(https://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/models/image/mnist/convolutional.py#L255) graph的权值偏置值复用[7] 如果不复用，训练的和测试的图就一点关系都没有了，就很有可能导致下面的那样输出结果完全无关 1tf.get_variable_scope().reuse_variables() lstm 准确率过低 输出的训练集上的loss还算正常，但是acc连50%都没有 根据知乎大神所说，二分类问题50%的准确率就等同于没有学习到，没有进行优化。 12345678910111213141516171819202122lSTMloss:5.716831 batch_Acc: 0.5 acc:0.525loss:0.16445649 batch_Acc: 0.9583333 acc:0.2225loss:0.21239458 batch_Acc: 0.9583333 acc:0.2075loss:0.07486567 batch_Acc: 1.0 acc:0.23loss:0.015121219 batch_Acc: 1.0 acc:0.275loss:0.10024478 batch_Acc: 0.9583333 acc:0.2475loss:0.056348186 batch_Acc: 0.9583333 acc:0.25loss:0.018785348 batch_Acc: 1.0 acc:0.255loss:0.017489845 batch_Acc: 1.0 acc:0.255loss:0.0008791888 batch_Acc: 1.0 acc:0.275loss:0.0012423135 batch_Acc: 1.0 acc:0.27loss:0.010488756 batch_Acc: 1.0 acc:0.2525loss:0.008405162 batch_Acc: 1.0 acc:0.245loss:0.0038538638 batch_Acc: 1.0 acc:0.2125loss:0.00075430545 batch_Acc: 1.0 acc:0.2375loss:0.0011128571 batch_Acc: 1.0 acc:0.2275loss:0.014299699 batch_Acc: 1.0 acc:0.325loss:0.00064932863 batch_Acc: 1.0 acc:0.3775loss:0.0039427895 batch_Acc: 1.0 acc:0.425loss:0.0043920926 batch_Acc: 1.0 acc:0.4025loss:0.0037787214 batch_Acc: 1.0 acc:0.41 1234567891011121314151617181920212223传统RNNloss:4.7681885 acc:0.51loss:1.3538479 acc:0.48loss:1.7510027 acc:0.4825loss:1.2965189 acc:0.5175loss:0.8639291 acc:0.4725loss:0.7651406 acc:0.48loss:0.5035551 acc:0.4725loss:0.7856639 acc:0.5125loss:0.41615644 acc:0.535loss:0.63352686 acc:0.515loss:0.8058832 acc:0.5125loss:0.715534 acc:0.5225loss:0.58976775 acc:0.49loss:0.6922045 acc:0.4875loss:0.6963689 acc:0.5225loss:0.6474119 acc:0.48loss:0.6436865 acc:0.4725loss:0.79238504 acc:0.4925loss:0.63156253 acc:0.535loss:0.6858673 acc:0.51loss:0.65090233 acc:0.52answer 模型暂时和原本的初版差别不大，训练集也还是原本的随机出的，测试集顺序理论上应该没有影响才对 就是上面那个weight和bias复用的问题……我定义在def model里了，导致reuse根本没有可以存下来 tf.truncated_normal() 这个函数产生正太分布，均值和标准差自己设定。这是一个截断的产生正太分布的函数，就是说产生正太分布的值如果与均值的差值大于两倍的标准差，那就重新生成。 bi-lstm实现 参考了[8][9][重点10] weight初始化导致无法梯度下降 使用Xavier initialization[11] basicRNNCell使用上需要在LSTMCell基础上修改一些地方 参考[13]的代码修改的，原来在rnncell的时候就直接取当前state计算就可以ile 使用MultiRNNCell的时候 InvalidArgumentError: Dimensions must be equal, but are 128 and 464 for ‘rnn/while/rnn/multi_rnn_cell/cell_0/basic_rnn_cell/MatMul_1’ (op: ‘MatMul’) with input shapes: [24,128], [464,64]. 要用python迭代器生成list，而不能直接用乘法，并且需要从函数来获取多个cell,不能直接对一个cell进行迭代 tf.metric.recall使用前需要initilizer 1sess.run(tf.local_variables_initializer()) 使用完 发现 这个值依旧是不能用的，因为这个统计的是整个session周期内的 梯度消失和梯度爆炸，如何从指标上判断出来 梯度消失似乎主要指的是多层效果反而没有浅层的好 关于recall,f1等指标计算 按照[16]条执行，成功跑出来了。 使用IndRNN 报错，似乎和while_loop有关 ValueError: Cannot use ‘rnn/while/rnn/multi_rnn_cell/cell_0/ind_rnn_cell/Mul_1’ as input to ‘rnn/while/rnn/multi_rnn_cell/cell_0/ind_rnn_cell/clip_by_value’ because they are in different while loops. See info log for more details. 看了下源码，出现了clip_by_value位置的只有设置了recurrent_abs_max的时候，所以把这个参数先取消看看，成功跑起来了~hhh 性能和普通的lstm差不多，之后再和官方的lstmcell比较一下源码，看看怎么改能够跑起来 发现问题，由于最初对tensorflow认识不足，导致训练集和测试集虽然复用了weight和bias，但是实际是运行在不同的网络中的，而IndRNN可能由于没能针对Tensorflow处理好这些问题，因此无法应用。在修改后的代码中，复用同一个网络后，这个参数添加后就没有报错了。 参考资料 本地访问远程服务器的Docker容器的Jupyter Notebook 关于Docker目录挂载的总结 wrap jupyter config No module named ipykernel tensorflow中dynamic_rnn与static_rnn区别 tensorflow高阶教程:tf.dynamic_rnn # Reference Tensorflow 变量的共享 tensorflow bilstm官方示例 TensorFlow实战12：Bidirectional LSTM Classifier tensorflow学习笔记(三十九) : 双向rnn (BiRNN) 谷歌工程师：聊一聊深度学习的weight initialization ensorFlow教程：利用TensorFlow处理自己的数据 RNN入门：利用TF的API（二） A bug in tensorflow r1.4 when applying MultiRNNCell Add precision and recall summaries tensorflow中precision,recall和F1","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://sean10.github.io/tags/TensorFlow/"},{"name":"docker","slug":"docker","permalink":"https://sean10.github.io/tags/docker/"}]},{"title":"update hexo node9 and theme next","slug":"update-hexo-node-and-next","date":"2018-02-16T18:14:16.000Z","updated":"2018-02-24T08:00:00.000Z","comments":true,"path":"2018/02/17/update-hexo-node-and-next/","link":"","permalink":"https://sean10.github.io/2018/02/17/update-hexo-node-and-next/","excerpt":"之前没有用nvm管理node版本，导致node升级到9.5以后，hexo里的依赖都不能正常运作了，单独一个个升级依赖没能成功解决bug.","text":"之前没有用nvm管理node版本，导致node升级到9.5以后，hexo里的依赖都不能正常运作了，单独一个个升级依赖没能成功解决bug. 在hexo里已经支持了update时间，在模板里添加updated即可，在next 主题配置里，修改post_meta为true即可 参考 front-matter 1234Error: write EPIPEat _errnoException (util.js)at WriteWrap.afterWrite [as oncomplete] (net.js) 遇到这个错误，重装好久，也没解决，在#2913里找到，更新了hexo-renderer-pandoc就no error了。 中途，在一个个卸载plugin判断错误来源，发现卸载了hexo-renderer-stylus之后，就无法生成css样式了。 遭遇白屏问题，似乎字号颜色渲染问题？只有下方的copyright可见，内容虽然可以点击，但是不可见，全选也看不到文字颜色反转（所以其实也不算字体颜色问题？） 似乎这是一个next久远的bug. 在network看到是fancybox.js的加载404，在console里看到的是config is not defined, next is not defined，导致后续无法识别. 根据这条issue关闭了motion就可以正常显示了。 No layout问题。 为了升级next，发现_config.yml是一个非常影响的文件，官方说hexo3支持了data file功能，可以将站点和主题config都放到到_data/next.yml中，在翻译的文档中都没有提到一点，原始的站点配置不能删除 Then, in main site’s hexo/_config.yml need to define theme: next option (and if needed, source_dir: source). 来源 弄了好久……，恢复站点配置文件之后，data-file就生效了 关于pandoc解析mathjax，目前还是存在错误，view状态也存在错误 需要在每篇需要的md Frontter开启mathjax: true 首页不显示最新的，以及分类页面缓存了之前的错误","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"},{"name":"node","slug":"node","permalink":"https://sean10.github.io/tags/node/"}]},{"title":"《深度探索C++对象模型》Note","slug":"《深度探索C++对象模型》","date":"2018-02-08T06:00:07.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/02/08/《深度探索C++对象模型》/","link":"","permalink":"https://sean10.github.io/2018/02/08/《深度探索C++对象模型》/","excerpt":"static initialization保证了在main函数执行以前已经实例化类。 不过实际依赖于开发环境。","text":"static initialization保证了在main函数执行以前已经实例化类。 不过实际依赖于开发环境。 译者推荐阅读一、三、四章 似乎&lt;&lt;不推荐作为类的成员函数，会由于左操作数是该实例而导致ostream只能是第二个参数，不过这本书中屡屡都是作为成员函数使用的，而且依旧是正常使用，这个疑问保留。（或许inline具有使其为非成员函数的功能？） 1234Sales_item item;item &lt;&lt; cout;似乎会变成这样，但是书里还是正常的。 泛型 就是 参数化吗？ 不定长参数如何参数化？书上那个看不太懂 简单对象模型 members 不放在object中的意思是什么？不是member本就是实例化后存储在其他位置，内部成员函数才在编译后就被分配了一个空间吗 噢噢，一开始被分配的空间只是一个指向成员的指针空间，实际成员空间在外面分配 表格驱动对象模型 数据成员表，成员函数表 对象内存储指向这两个表的指针 c++对象模型 非静态数据成员存储在对象中，静态存储在堆区。 主要优点是空间和时间存取的速度，不过实际上性能优点如何知晓？只是通过指针来访问，效率的影响有多少呢？ 似乎上面那个表格驱动模型，因只存储了指针地址，所以修改了成员函数代码时，无需重新编译其他的应用程序代码，不过付出了时间和效率上的代价 虚继承有些忘记了 编译器会在派生类B的实例中保存一个A的实例，然后在B中加入一个变量，这个变量是A的实例在实际B实例中的偏移量，实际上B中并不直接保存offset的值，而是保存的一个指针，这个指针指向一个表vbtable，vbtable表中保存着所有虚继承的基类在实例中的offset值，多个B的实例共享这个表，每个实例有个单独的指针指向这个表，这样就很好理解为什么多了4个字节了。用代码表示就像下面这样。 这个offset的作用是什么不太理解，有个指针地址不就已经能访问这个对象了吗？ 向前预览(lookahead)？ 编译器应该是能够做到经过unparser工具处理后，可以还原原本使用的关键词的。（来自cfront 中遭遇过的bug) 123struct mumble &#123; char pc[1];&#125; 这种通过malloc来分配的可变数组为什么违背了c++的规范呢，成为c++的陷阱？ \b指定多个access section，内含数据 这是什么意思? 就是访问权限区域。 private和public 在内存布局中的位置并不一定始终维持一个前后关系。 通过malloc来维持可变长数组的struct在转化为class时不可知属于哪个access section，容易出现问题 要组合C和C++，比较适合使用组合的方法，继承在当前的编译器中才存在被添加一些额外的Data members的可能性。 C++分为3个程序模型 * procedural model(过程型) * abstract data type model(抽象数据类型) * object-oriented model(面向对象模型) 只有通过pointer或reference的间接处理，才支持OO程序设计所需的多态性质。 cast 其实是一种编译器指令，大部分情况下它并不改变一个指针所含的真正地址，它只影响“被指出之内存的大小和其内容”的解释方式 一个pointer或一个reference之所以支持多态，是因为它们并不引发内存中任何”与类型有关的内存委托操作(type-dependent commitment)， 会受到改变的只是它们所指向的内存的“大小和内容解释方式”而已 构造函数语意学 Conversion运算符的引入 如果没有implicit conversion的支持, String函数库必须将每一个拥有字符串参数的C runtime library函数都复制一份。 有趣的是，标准的C++ library string class并不提供一个implicit conversion运算子, 它提供的是一个具体实名(named instance),使用者必须明确调用。 上面这个具体实名是什么情况呢？好像没见过的样子。 Schwarz Error memberwise initialization named return value optimization(NRV)身上 带有default constructor 的member class object inline是什么设计 未完待续","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"}]},{"title":"LeetCode_Algorithm_Note","slug":"LeetCode-Algorithm-Note","date":"2018-01-23T14:50:32.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/01/23/LeetCode-Algorithm-Note/","link":"","permalink":"https://sean10.github.io/2018/01/23/LeetCode-Algorithm-Note/","excerpt":"刷题注意事项 每道题需要总结的 思路 算法 核心代码 这个题得到的启示!!!重点是bug free的能力","text":"刷题注意事项 每道题需要总结的 思路 算法 核心代码 这个题得到的启示!!!重点是bug free的能力 linked list理解 enter image description here 结果两个都是 1 2 3 node是存在main函数里的局部变量, 还是全局变量? 局部 node1 是一个指针, 在32位即中占有4个字节. 也可以理解为引用, 存的是一个内存的地址. 所以一个ListNode占8个字节, val占4个, next占四个. 可以理解为, 内存是个大数组, ref和pointer都是数组的下标, 是index enter image description here Reverse Nodes in k-Groups Given a linked list, reverse the nodes of a linked list k at a time and return its modified list. If the number of nodes is not a multiple of k then left-out nodes in the end should remain as it is. You may not alter the values in the nodes, only nodes itself may be changed. Only constant memory is allowed. 复杂问题的解决方案 复杂的, 不能一眼看到结果的, 要拆分. 拆分就是要步骤化, 先框架, 再细节. 复杂的问题通过一个for循环, 一个while循环, 或者一个123步怎么做, 变成一个更小的问题. 每个function需要明确 dummy node java要new， c++不要new，c++如果new了要删除 HEAD = DUMMY 这句话总是需要么？ 几乎 什么时候使用 DUMMY NODE? 链表结构发生变化的时候 DUMMY NODE 是否需要删除？ 不需要 使用 DUMMY NODE 算面试官会说我耗费了额外空间么？ 他没那么神精病， O(1)的额外空间不算额外空间，O(n)才算 DUMMY NODE 非用不可么？ 不是, 但是用了代码比较简洁 DUMMY NODE 初始化的值重要么？ 不重要, 只需要它的next的值 LeetCode 小结 数组: leetcode 1 add two numbers to be the target，返回这2个数的位置 用hash map能实现O(n)甚至O(1)，但是不太清楚原理 leetcode 561 直接用std::stable_sort排序，从小到大每2个取第一个，然后累加就是最大的最小数对和了 这个的时间复杂度应该是O(nlogn)，有没有 leetcode 566 看了下Solution才知道有3种方法 1. 要求把能够重组的矩阵重组，按照从行到列的顺序重排，所以我一开始考虑把原本的矩阵数组输入到一个队列里，然后一个个pop，不过想了下，没有必要浪费空间，直接用迭代器，每到这行矩阵的末尾，就直接推进到下一行的begin()就好了。 2. 把原始的矩阵加到队列里去 3. 使用整除和取余符号,直接进行换行赋值 时空复杂度都是O(m*n). python可以有numpy等等模块直接使用 不过在用python进行这个逻辑时， 始终提示列表越界…… 12345678910111213141516171819202122232425262728class Solution: def matrixReshape(self, nums, r, c): \"\"\" :type nums: List[List[int]] :type r: int :type c: int :rtype: List[List[int]] \"\"\" if (len(nums[0])*len(nums)) != r*c: return nums #tmp = [[None] * c for i in range(r)] tmp = [[None for row in range(r)] for col in range(c)] i = 0 j = 0 leng_x = len(nums[0]) x = 0 y = 0 for i in range(r): for j in range(c): tmp[i][j] = nums[x][y] y += 1 if y == leng_x: x += 1 y = 0 return tmp 12345678910111213141516import numpy as npclass Solution: def matrixReshape(self, nums, r, c): \"\"\" :type nums: List[List[int]] :type r: int :type c: int :rtype: List[List[int]] \"\"\" if len(nums)*len(nums[0]) != r*c: return nums ans = [[None for row in range(r)] for col in range(c)] for i in range(r*c): # if i//c &lt; r and i%c &lt; c and ((i//len(nums[0]) &lt; len(nums)) and ((i%len(nums[0])) &lt; len(nums[0])): ans[i//c][i%c] = nums[i//len(nums[0])][i%len(nums[0])] return ans 这2份代码tmp[i][j] = nums[x][y] 究竟是哪里越界了呢？ leetCode 485 最大连续1长度 O(n)时间复杂度，应该已经是最好了的吧，遍历一遍 leetCode 717 自动机 比较简单， 状态0:刚得到的是0的string 状态1:收到1个1，接下来读取0\\1 状态2:刚刚结束10/11的string 最后判断是状态0还是状态2就可以了 时间复杂度是O(n) leetCode 695 找最大的岛屿，第一反应就是DFS或者BFS 边界条件 越界or已被标记or为0 迭代和递归两种方法 时间复杂度O(r*c) C++做迭代的时候，对allocator不怎么理解，stack&lt;vector&gt;的时候一直报错…… 最后用了pair leetCode 448 题目要求不使用额外空间。 想了想，第一个思路是不符合要求的，想到的是建个flag标记数组，然后输出没标记的。 没想到第二个方法，看了下答案，才意识到，可以把每个位置的值作为坐标来对该坐标位置进行*-1标记，既不影响值，又可以进行标记 leetCode 283 遍历一遍，j作为非0位的位置，i作为遍历位置，向前移位，最后再从j的位置置0到end。 不过看到std::remove,可以找到value，直接向前补足，起到了上面第一个部分的功能，然后调用std::fill，结束 leetCode 697 不理解题目……看了别人的代码以后才理解的题目是要的最长下标……不是说要最长子序列吗？ leetCode 122 股票问题 完全没思路，看了下解题报告 一个叫Peak Valley Approach，寻找极值点来靠近最优解 直接后一个减去前一个，只要大于0，就加到ans就好了 O(n)时间复杂度，O(1)空间复杂度 leetCode 167 只有输出上在leetCode 1基础上+1,并排序 不过说起来，理论上，输出的时候应该本就是从低到高的吧，为什么偶尔会输出逆序的呢？ 似乎是输出找到的最后一个，那么应该需要返回换下序就好了 leetCode 169 打算写个标记的，结果写完跑出来RE，才意识到输入是有负数的， leetCode 661 比较简单，就是遍历二维数组，O(n^2)的时间复杂度，O(1)的空间复杂度 leetCode 628 打算直接用max_element找，结果漏考虑了负数也可以得到最大值了。 还是需要用到nth_element，来获取前K大和K小, 应该是O(nlog)复杂度，还不如直接排序了 leetCode 268 要求是O(n)，用set.find()吧 忘记了可以用异或运算了 leetCode 674 除了第一个，只要比前一个大，就可以+1 leetCode 121 参考答案是不停的找最低点，然后之后的每个数都减一下他，获取最大利润。 完全没想到，我的思路是一开始先找到最低点/最高点，然后再找另一个，但是没想到方法。 leetCode 442 第一反应就是插入set，使用find函数 时间复杂度应该是O(nlogn),空间复杂度O(n) 看了下discuss，有O(n)的方法，把nums[i]放到nums[nums[i]]的位置，最后不在自己位置的就是，还有一种更好的，每一个反转一下，有2个就会为正 leetCode 238 要求常数空间复杂度和不用除法的O(n)的时间复杂度。 参考答案给出的方案是，因为每个数组中的结果都需要乘N-1次，而循环的次数也差不多是N-1次，每个循环都同时对2个结果进行累乘，而使用的参数from_begin和from_end则在不停累乘，得到除了self以外的乘积。 天哪，genius! leetCode 53 要去给出一个连续的能求出最大和的数组序列 依旧是动态规划，不过这个时间复杂度只有O(n)了 leetCode 338 想到了应该是在临近的几位之间的位运算有状态变化，但没想到是位与 leetCode 141 判断是否有环 我一开始想简单了，忘了只要中间有一个相交点就算环，而不是一定回到head leetCode 160 目前来看，看到了2种方法，一种就是先进行链表长度的计算，然后保证同步前进 第二种，就是两个进行交互遍历，A跑完了就指向B的表头，再开始跑，B跑完了就指向A的表头，总会有最大公约数的时候。 leetCode 445 用了栈把输入的链表逆序输出了，然后再进行计算，头插 leetCode 328 把奇数序号的节点移到最前面，要求O(1)空间复杂度和O(n)时间复杂度。 用了tail_odd,curr_odd,head_even,curr_even，搞定 leetCode 24 要求每两个都交换节点。 记得有pre来连接每2个之间就可以了 leetCode 19 这道题n直接说明定义域是从1开始就好了，还得自己测试 leetCode 75 折半查找 255ms， 直接插入，冒泡，希尔都是3ms 可能因为只有0，1，2排序？ leetCode 101 一开始想到的是层次遍历二叉树，然后用迭代器正反迭代匹配一下，有一个不匹配就返回false。 忘了写中间为空时填充一个nullptr，导致有些案例也返回了true。 又发现如果找不到就填充nullptr，会导致队列永远不会为空，内存溢出MLE的情况，试图在匹配过程中发现空指针，就erase掉，但是迭代过程中erase会导致后续的所有迭代器前移 并且，erase反向迭代器需要进行一下显示类型转换，并在erase时转换成正向迭代器(++it_r).base()。 因为我是new了一个ptr来替代nullptr来实现普遍性，考虑到智能指针可能可以省力，但是实际情况下，似乎容器中不能添加智能指针。虽然我用shared_ptr.get()传递进了容器，但是这样猜测应该是违背容器管理的。 一个容器全部被erase后，迭代器得到的并不是end()，所以需要添加一个empty的判断条件 但是，我又发现，在erase最后一个，之后得到的是地址的顺推，但是end()因为在队列中被释放了2次，所以得到的是原本的倒数第二个，与实际不相符合了。所以需要添加一个计数器来管理结束 看了下参考答案，原来是在遍历的时候就直接正反遍历，最后直接匹配树就好了，我想复杂了。 不过也是成功实现了。 leetCode 88 题目讲的也太不清楚了，m和n的边界功能完全没交代，难怪差评那么多。 leetCode 105 DFS版本，似乎没法做出 BFS版本来 引用传递指针，忘了这条，导致定义的指针始终没能指向函数中分配的堆地址 leetCode 287 这道题，一开始没注意可以多次重复这件事，所以应该不是用异或运算了，而是利用值在1-n之间的这个条件。 看了一下，大致的解法有2种，1种就是用slow和fast两个迭代器，进行前进 另一种是用二分查找，但是这个挺不能理解的，因为没有规定重复的一定是连续的呀？ leetCode 11 从n的中间点开始向两边遍历，找分别最长的2条线， 后来发现，还是直接从两端还是朝里走更简单，可以少去一些边界条件 leetCode 134 leetCode 142 我们注意到第一次相遇时 慢指针走过的路程S1 = 非环部分长度 + 弧A长 快指针走过的路程S2 = 非环部分长度 + n * 环长 + 弧A长 S1 * 2 = S2，可得 非环部分长度 = n * 环长 - 弧A长 让指针A回到起始点后，走过一个非环部分长度，指针B走过了相等的长度，也就是n * 环长 - 弧A长，正好回到环的开头。 要注意，让fast和slow同时从起点出发，否则遇到长度为2的环，就会TLE了 leetCode 632 leetcode 324 这道题，应该从后向前赋值，因为最后一位需要与他身后那一位比较，就可以免去与正向最大那一位的比较 leetCode 524 sort中的比较函数compare要声明为静态成员函数或全局函数，不能作为普通成员函数，否则会报错。Line 26: invalid use of non-static member function 因为：非静态成员函数是依赖于具体对象的，而std::sort这类函数是全局的，因此无法再sort中调用非静态成员函数。静态成员函数或者全局函数是不依赖于具体对象的, 可以独立访问，无须创建任何对象实例就可以访问。同时静态成员函数不可以调用类的非静态成员。 leetCode 713 窗口每次向右增加一个数字，然后左边去掉需要去掉的数字后，窗口的大小就是新的子数组的个数，每次加到结果res中即可 leetCode 662 这里max({a,b,c})和max(a,max(b,c))得到的是两个结果，后一个完全错误了 没能想到是为什么，难道是对栈处理的问题？ 换成引用值，在过程中使用max,久一点没有问题了 啊啊啊， leetCode 372 遵循公式 f(a,1234567) = f(a, 1234560) * f(a, 7) % k = f(f(a, 123456),10) * f(a,7)%k; leetCode 387 直觉，遍历过程中在之后的子串中进行find,找到就不是第一个，但是这个因为没有进行标记，完全可能把第二个出现的给标记成结果，导致错误。 leetCode 696 始终没看懂题意，总算看懂以后也没看懂题解的方法，最后用了一个O(n^2)的解法，先找出所有的临界点，然后从临界点向外延伸 leetcode 441 这道题感觉可能是可以理解成一个数学题的，但是完全想不到是什么keyword 等差数列求和公式、阶梯、一元二次方程 leetcode 241 stoi和atoi还是有点不一样，处理string上，我把stoi换成atoi c_str就可以跑出结果，虽然还是错的 其实没有问题，只是我把substr传入范围出错了……天哪，我卡了一个晚上 leetcode 90 subsets 为什么这里必须要先排序呢？我都用set来接收数据了， leetcode 60 第k个全排列数 这道题不能用回溯法了，需要寻找排列组合的规律 leetcode 204 求素数数量 简单的话还是用素数筛选算法， 如果是应用需要的话，还是得用基于费马小定理的Miller Rabin算法，可以用快速幂取模优化一下 似乎这算是一个蒙特卡洛算法 因为是随机检测的原因吧","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://sean10.github.io/tags/算法/"},{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"pdf解密脚本","slug":"pdf解密脚本","date":"2018-01-11T02:36:16.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/01/11/pdf解密脚本/","link":"","permalink":"https://sean10.github.io/2018/01/11/pdf解密脚本/","excerpt":"这两天要打印pdf,结果发现老师的pdf被加密了，需要解密一下，就心血来潮想解决一下。","text":"这两天要打印pdf,结果发现老师的pdf被加密了，需要解密一下，就心血来潮想解决一下。 一开始想到的方法是，pdf可以通过浏览器打开，那么其实也就完全可以通过浏览器截图，自动下拉继续截图生成新的pdf，这算是一种解决方法嘛。似乎是可以通过浏览器打印保存pdf也能实现解密，不过莫名的pdf expert直接就能编辑被加密过的pdf。所以没想到怎么判断是否被加密。 总之，回来之后发现用linux下的ghostscript工具，可以先通过pdf2ps2pdf转换一下，转换回来之后就是无加密状态的pdf了。 但是看了看，需要转换十来个，每个需要转换的时间还挺长的，索性就看看能不能从python调用程序吧。 就有了这样一个版本的代码(github repo)[https://github.com/Sean10/Algorithm_code/tree/master/script/pdf_decrypt]。 python有2个模块可以做到调用外部程序需求，os.popen与基于前者之后升级后的subprocess.popen。 单线程执行虽然基本可以完成需求，但是多线程应该能快一些吧，如果这个模块是fork出一个子进程调用其他进行操作的话，而不是在python内部执行的话（GIL锁）。 现在每个语言基本都有了concurrent模块，对multithread和multiprocess进行了新的封装实现。 基本使用还是比较简单的，pool = subprocess.threadPoolExecutor 之后将函数添加进入就可以执行了,pool.submit(func,para)，就能实现出基本的调用操作。 不过，还遇到了一些问题，如，使用call而不是popen时，ghostscript打开文件总会报一些错误,换回popen就一切正常。 还有，subprocess和线程池进程池同时使用，效率并没有多大的提升，猜想哪个部分可能出现了阻塞？ 之后，考虑到暂时不太能区分出差别的情况，决定用shell试试。 其中主要遇到的问题就是文件名如果存在空格，就会因满足IFS（the Internal Field Separator），导致文件名被分割，最终的解决方法是在获取文件名前修改IFS,运行结束时再恢复。 多线程部分因时间问题暂时没再写，不过可以参考该博客，（linux_shell如何实现多线程)[https://www.cnblogs.com/signjing/p/7074778.html].","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"script","slug":"script","permalink":"https://sean10.github.io/tags/script/"},{"name":"shell","slug":"shell","permalink":"https://sean10.github.io/tags/shell/"}]},{"title":"银翼杀手2049","slug":"银翼杀手2049","date":"2018-01-02T03:53:13.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2018/01/02/银翼杀手2049/","link":"","permalink":"https://sean10.github.io/2018/01/02/银翼杀手2049/","excerpt":"这部作品，一开始并没有注意到是银翼杀手的续集，剧情前半段将背景等等交代的非常清楚，让作品对没有看过银翼杀手的新观众也能有一个比较良好的体验。","text":"这部作品，一开始并没有注意到是银翼杀手的续集，剧情前半段将背景等等交代的非常清楚，让作品对没有看过银翼杀手的新观众也能有一个比较良好的体验。 电影中，究竟谁是复制人是一个非常好的引人思考的主线。 前半段中，每一个登场的人都会被猜测身后的背景，我曾以为是华莱士公司的那个助理，但没想到直到最后，她的设定也只是作为华莱士的助理，只为他服务，在电影中丝毫没有展现其除了美甲以外的个人欲望，可能这才是华莱士所说的最美的天使的存在应有的。 到了后期，男主究竟是婴儿的本尊还是复制人让人感到扑朔迷离，上一部的男主说出他教伪装复制人修改数据时，我也依旧没有意识到男主会是这样的作品。因为电子数据中的女婴已死既诱导了男主偏离方向，同样也诱导了我们。 Joi和男主的感情线作为一个剧情的辅佐，也是相当具有卖点的，虽然机器人与人的恋爱、复制人与人的恋爱的概念已经许久了，但是真实呈现出的人工智能投影与人的恋爱还是第一次。还有！安娜 阿玛斯好漂亮。 最后男主失去了一切人生希望，Joi的消失、自身溯源的失败，他最后的拯救行为可能是为他这个溯源的过程找到的一个合适的结束，作为他个人价值的体现吧。之后，可能不是离去就是颓废了吧。 真正的婴儿的谜底揭晓时，真的是没想到，这么简单的谜底居然没能想到。病体，对于这个婴儿来说是非常现实的，同样，又是作品中少有的剧情牵扯较少的女性，完全存在其是主线剧情中心的可能性。 总的来说，以我的眼光，这部的剧情将原著还是修改的非常棒的。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/影评/"},{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/科幻/"}]},{"title":"《尼采在世纪的转折点上》尼采初识","slug":"《尼采在世纪的转折点上》尼采初识","date":"2017-12-07T16:12:57.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/12/08/《尼采在世纪的转折点上》尼采初识/","link":"","permalink":"https://sean10.github.io/2017/12/08/《尼采在世纪的转折点上》尼采初识/","excerpt":"之前虽然向往周国平老师的作品，但是一直没来翻阅过其关于尼采的作品，对尼采占据哲学重要地位的上帝之死抱有相当的疑惑，直到这部作品，终于化解了心中的一部分好奇。","text":"之前虽然向往周国平老师的作品，但是一直没来翻阅过其关于尼采的作品，对尼采占据哲学重要地位的上帝之死抱有相当的疑惑，直到这部作品，终于化解了心中的一部分好奇。 上帝之死，单只从这部书中来看，指的是当时科学发展起来，引发的基督教等大众信仰的崩塌，之后在社会上发生的一系列思想等等的变革。之后的哲学家们之中诸如海德格尔、萨特似乎都带有了这一部分色彩。不过，上帝之死也并不单单是这么简单的，需要更深入的看些方能知道了。 尼采对道德的一些判断单从书中这些内容，有些不好理解，需要看看他的原作。 尼采的自我、无意识等等，在弗洛伊德那里得到了发展，当然，现在弗洛伊德的理论也已经算不上最完善的了。个人来看，荣格的理论相对弗洛伊德更贴合现在这个时代。 尼采的超人理论，似乎并不只是指自我超越，所以周国平老师才说超人理论存在缺陷。在这个基础上的，尼采的等级制度，弱者接受强者的领导，完全可以理解，平等的概念本就只有在机会上平等才是公正的，强者利用自己的能力抓住机会，弱者无力抓住机会，这本就是人的主动选择的结果，并不算得上是达尔文主义。不过，我的这个解读应该也是一种对原作的误解吧，毕竟理论是具有时代性的。 另外，尼采对学者、教育的认知已经与当下对不上了，当时的教育工厂现在都已经经过了变革，主打促进创新了。这是时代变化后的价值重估，尼采的那些论点在当时还是非常有价值的。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"尼采","slug":"尼采","permalink":"https://sean10.github.io/tags/尼采/"},{"name":"周国平","slug":"周国平","permalink":"https://sean10.github.io/tags/周国平/"},{"name":"读后感","slug":"读后感","permalink":"https://sean10.github.io/tags/读后感/"},{"name":"哲学","slug":"哲学","permalink":"https://sean10.github.io/tags/哲学/"}]},{"title":"《尼采在世纪的转折点上》笔记","slug":"《尼采在世纪的转折点上》笔记","date":"2017-12-07T16:10:55.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/12/08/《尼采在世纪的转折点上》笔记/","link":"","permalink":"https://sean10.github.io/2017/12/08/《尼采在世纪的转折点上》笔记/","excerpt":"开创了由生命哲学到存在主义的道路","text":"开创了由生命哲学到存在主义的道路 人生的三个阶段 * 效仿 * 否定 * 肯定 二次世界大战后，科学发展，基督教信仰瓦解，流行价值真空和信仰危机，所以存在主义发展起来了 尼采将哲学家与学者相区分，认为学者不具有创造性 悲观主义是直面现实，叔本华的悲观、虚无 而基督教是逃到所谓的现实背后的真实的世界之中，属于逃离现实 酒神精神 强力意志消极的一面，拥有强力意志的人是少数，从中衍生出强者理应支配弱者和统治弱者的结论，站到了反民主的角度上去了。 永恒轮回 起源于赫拉克利特 尼采是为了抵制无意义的人生即人生来是偶然事件的这个恐惧而提出的永恒轮回，但这样的无限轮回其实也是一个二律背反。 现代西方哲学的许多流派，包括现代西方马克思主义哲学，对于人性的看法有一个重要特点， 就是强调人性的未完成性、开放性和无限可能性， 在哲学史上，断然主张绝对决定论的哲学家有之，断然主张绝对自由论的哲学家为数微乎其 微，而两者都有着明显的偏颇性。我们发现，许多哲学家动摇于两者之间（如斯宾诺莎、伏 尔泰由意志自由论转向决定论），或者试图在两者之间寻求某种折衷和结合（如康德、费希 特把人分为两部分，现象界的人受因果律支配，本体界的人有意志自由）。有趣的是，号称 唯意志论哲学家的叔本华和尼采也都并不主张意志的绝对自由，相反是反对意志自由论的。 重要的不是“从 何而自由”，而是“为何而自由”。《尼采全集》第 6 卷，第 92 页。许多人并无创造的意愿， 把自由理解为摆脱一切责任，结果所谓的“自由”一旦到手，精神倍感空虚。现代西方社会中 不是已经响起“逃避自由”的呼喊了吗? 力量是自由的前提，评价和创造是自由的真义。要把握尼采的人性观和自由观，关键是弄清 他对评价和创造的看法。 。尼采是不承认客观真理的。他认为，人与周围世界的关系只是一种价值关系，真理 只是一种价值判断，认识只是评价。 尼采认为，真实的“自我”往往是隐藏在无意识之中的， 而通常的认识方式，借助于语言，求之于思维，不但不能达到“自我”，反而歪曲了“自我”。 我们用来概括我们心理状态的语词，多半是为某些极端状态所取的名称，并不能指示出我们 大部分时间内所具有的不可名状的非极端状态，然而正是这些状态织成了我们的性格和命运 之网。 在尼采那里，真实的“自我”有两层含义。在较低的层次上，它是指隐藏在潜意识之中的个人 的生命本能，种种无意识的欲望、情绪、情感和体验。在较高的层次上，便是精神性的“自 我”，它是个人自我创造的产物。不过，对于尼采来说，这两层含义并不矛盾，因为他一向 把生命本能看作创造的动力和基础。 真正的个人主义追 求的既非财产，亦非浮名，而是真实的“自我”。 不过，王尔德因此而赞成公有 制意义上的社会主义，尼采却始终反对作为一种政治运动的社会主义，这又是他们的不同之 处。 自私就是恶，无私就是善，这种道德观念早已体现在基督教的邻人爱的原则中了。功利主义 的思想家们用合理的利己主义来反对基督教的抹杀个人的道德观念，为经济上的自由竞争制 造理论根据。可是，在资产者的实践中，事实上却是两种道德并存，一方面是最无耻最露骨 地追逐物质私利，另一方面是嫉恨和反对个人精神上的优异。 健康的“自私”是健康的 生命本能，是高尚的自我保护的力量。反对这样的“自私”，赞扬“无我”和牺牲，实际上是奖 劣惩优，压抑生命力旺盛、热爱生活的人，却鼓励那样的人。这种人“不把他的全部力量和 才智用在他的保存、发展、超越、前进、强力之扩展上，而是对自己卑谦、无头脑或许竟淡漠或冷嘲地生活着”。 可谓激进，但是在如何振兴人类的具体途径问题上，他所设计的方案却又极为保守，总是脱 不开贵族政体的陈旧观念。他不满于资产者社会的现状，但在社会学说上他提不出更进步的 社会理想，反而一再缅怀和主张早已过时的带有浓厚奴隶制色彩的等级社会。这是尼采思想 中最触目的矛盾。 尼采并非要抹煞科学本身的价值，相反，对于卢梭否定科 学文化而提出“回到自然”的倒退主张，他是坚决反对的。问题在于，要恰如其分地看待科学 的价值，它只具有工具价值。如果把科学当作目的本身，漫无止境地追求对物的支配，结果 只能丧失人生本真的意义，使人成为物的奴隶。 哲学始终与本体论 结下不解之缘，这种本体论以构造“真正的世界”为唯一使命。 。他反对的是按照人类自身的理性本性 去构造一个合乎理性的世界模式，然后又用这样的世界模式来规束人的现实生活。这样，理 性在世界上所看到的不过是它自身，逻辑把自己的界限当作世界的界限，人类认识活动的工 具被抬高到至高无上的地位，冒充为形而上学的真理，进而冒充为最高的价值标准。于是， 生命被贬值，本能受压制，法则统治一切，人生失去了生命的活力和乐趣。 对于尼采来说，审美状态是一种不可分割的肉体精神状态的整体，是“活着 的情绪存在，是留在情绪中的肉体存在，是交织在肉体存在中的情绪 一种受压抑的冲动为了在 假想中得到满足，往往会歪曲记忆，故意遗忘。“我的记忆说：”我做过这事。“我的骄傲说， 并且顽强地坚持：”我不可能做这事。“最后，记忆让步了。” 遗忘成了满足愿望的手段。我们不禁想起了弗洛伊德对于日常生活中种 种过失的心理分析。 重估一切价 值“就是要把被颠倒的评价重新颠倒过来，否定一切被肯定者，肯定一切被否定者。这也就 是”价值的翻转“。 。他却 不但否定了基督教伦理的根本原则，对善恶作了全新的评价，并且在一定意义上还否定了伦 理本身，把数千年来视为明白无疑的东西带入问题的领域，把道德从至高无上的地位拉下来， 确定了它对别的更高价值的从属关系。所以，他自称：“我是第一个非伦理主义者。” 尼采对于道德的否认，据他自己说，有两层意思：第一，否认某人的行为是出于所谓道德的 动机，也就是说，动机本身就不真实，真实的动机却是不道德的，经过自我欺骗作用而化妆 成了道德的；第二，动机是真实的，然而这动机却是一种根本错误的道德观念。 那么，尼采要否认的是道德的什么大前提呢?如果我们没有理解错尼采的意思的话，这个大 前提我们不妨称之为“道德本体论”，也就是把道德实体化的倾向。 。道德判断与宗教 判断有一共同点： 相信不存在的实在。道德仅是对一定现象的解释，确切地说是一种误释。 透彻地说，这是把道德现象归结为生物现象。或者说，只有生物现象，没有道德现象，人们 把生物现象曲解为道德现象了。尼采似乎就是这么说的。他用讽刺的口吻谈到，上流社会中 的所谓道德行为，如小心谨慎地避免着可笑的事、露头角的事和争端，隐匿着自己的才能和 欲求，与环境同化，从俗，自卑，这一切与动物中的保护色作用、肖形作用、装死等现象是 一回事，无非是避开仇敌和保存自己的手段，所以，仍是一种动物性现象。 基督教假定，人不知道也不可能知道，对他来说，何为善，何为恶：他信仰唯一 知道这一切的上帝。基督教道德是一个命令，它的起源是超验的；它是超越一切批评的。&quot; 。可是， 作为一种社会意识形态，道德自有它的现实的社会根源和必不可少的社会功能。尼采自己比 任何人都重视评价的意义，现在他又全盘否定作为最重要的价值形态之一的道德，岂非自相 矛盾? 尼采懂得，习俗和舆论的力量是巨大的。“天天听着关于我们的批评，甚至忖度人家心中对我们的想法，–这会毁灭掉最坚强的人。 。以同情为道德的心理基础和基本原则，在 伦理学史上是一重要传统，尤为英国经验主义者和功利主义者所主张。叔本华也持这一见解。 其次，同情与尊重是两种相反的感情，在同情中蕴含着对他人 的不尊重。譬如说，我们对某人非常尊敬，羡慕，甚至崇拜，后来突然发现他有痛苦，并且 需要我们的同情，这时我们就会欣然同情他，同时也削弱了我们对他的尊敬。同情一个人， 意味着把他看成一个弱者，谁会去尊敬一个弱者呢? 那些爱表 同情的人，内心深处是在寻求一种作为施恩者的满足。最明显的证据是，倘若他们的同情遭 到拒绝，他们就会感到失望，甚至觉得受了侮辱，由同情一变而为愤怒。 更有些人所谓 的同情，不过是拿别人的痛苦当消遣。尼采讽刺地写道：“他居于不幸中了，”同情者“于是 走来，将他的不幸描画一遍，–于是他们满足而且飘然走开了：他们哀不幸者的痛苦，犹如 哀自己的痛苦，很好地消磨了一下午。 尼采并非反对向痛苦者伸出帮助之手。问题是，第一，最大的帮助是唤起痛苦者的自尊自强 之心；第二，帮助必须真诚，而真诚的标准仍是不伤害痛苦者的自尊自强之心。你不要让人 感到你是一个施恩者，而你也确实不以施恩者自居。 怎样才算真诚?仅举二例。其一：“假如我们不把别人的名誉在私下一如在人前保持，我们便 不是好人。 尼采从希腊出发，走向超人，他寄希望于一种新的人的类型的产生。在这一 点上，以存在主义为代表的现代流派不那么理想主义，也不那么贵族气，他们更多地把超越 的使命赋予每个人自己，让每个人自己通过对真实存在的体验来摆脱文明的祸害。 尼采也是反对社会达尔文主义的。在他看来，进化不利于杰出个体，反而有利于“末人”的生 存和繁衍。如要用生物学术语来表达，毋宁说超人的产生要靠人工选择而非自然选择，也就是要靠人类有意识地创造条件。 诚然，尼采所主张的等级制度主要地不是依据血统，而是依据精神，但这仍然是一种地道的 等级制度。他感到遗憾的是：“自然为何对人这么吝啬，不让人按照内心的光源发光，使一 个人辉耀，另一个人黯淡?为何伟大人物的升降不像太阳那样明丽?” (极度赞同) 。促使尼采主张等级制度 的原因有二。一是他蔑视群众，对大多数人失去信心，认为他们一旦占据支配地位，就会对 少数优秀人物施行暴政。二是他认为在事关创造文化的时候，幸福如何分配的问题无关紧要， 多数人应当为少数能够创造高级文化价值的人做出牺牲。 我们的二十世纪，已经很少有人相信超人说了，可是谈论人的自我超越 性的却越来越多。也许，这就是“超人”寓言的收获。（超人说难道不是指自我超越吗？） 世上有哪部哲学著作如今真的被谱成了交响乐呢?只有《查拉图斯特拉如是说》。 德国的浪漫化哲学，从席勒、费 希特、谢林、诺瓦里斯、施莱尔马赫、叔本华发展到尼采，算是达到了炉火纯青的地步，又 启示了狄尔泰、海德格尔、马尔库塞在这条路上进一步探索。求人生的诗化，进而求本体的 诗化，进而求哲学思考方式本身的诗化，是这种浪漫化哲学的主旨。 本体的艺术化与艺术的本体化是同一件事情的两个方面。既然世界本体原是一种艺术活动， 那就只有艺术活动才能体现世界本体。尼采始终强调艺术的本体论意义：“艺术是生命的最 高使命和生命本来的形而上活动。 如果我们追循尼采的思想逻辑，我们就会发现，他之所以要把本体艺术化，又把艺术本体化， 仍然是为了给人生提供一种意义。艺术的形而上学意义实来自人生需要形而上学意义。“我 们的最高尊严在艺术活动的价值之中，因为只有作为审美现象，人生和世界才永远有充足理 由。 世界本身并无意义，它不断产生和毁灭个体生命的活动本身也并无意义，如果你要 用真理或道德的眼光去探究它的意义，你只会失望，会对生命本身失去信心。可是，一旦用 艺术的眼光去看世界，无意义的生成变化过程突然有了一种意义，那就是审美的意义。在尼 采看来，舍此别无肯定存在的途径。“艺术的本质方面始终在于它使存在完成，它产生完美 和充实，艺术本质上是肯定，是祝福，是存在的神化。 尼采提出的主要问题是：在传统价值全面崩溃的时代，人如何重新确立生活的意义?我们可 以把他的答案归结为：一、解除理性和道德对于生命本能的压抑，使生命本能健康发展；二、 发扬人的超越性，做精神文化价值的创造者；三、以审美的人生态度取代科学和伦理的人生 态度。 当我们分别从这三个方面向前探寻时，我们在第一条路上发现了生命哲学家和弗洛伊德主义 者，在第二条路上看见了存在哲学家的活跃的身影，在第三条路上遇到了高举艺术革命旗帜 的浪漫主义骑士马尔库塞。 总的来说，在人的自由和超越性问题上，存在主义的主要进展在于，通过对人的存 在结构的分析，从本体论上建立了人的自由和超越性命题，它也就是存在主义的基本命题： “存在先于本质”。 。到了存在主义，情绪更加明确地获得了本体论意义。 海德格尔就直截了当地认为情绪是基本的存在状态。当他分析人的存在结构时，“畏”、“烦” 的情绪在此结构中起了关键的作用。萨特的“恶心”，雅斯贝尔斯的“临界状态”、“沟通”，也 无不起了这样的作用。在存在主义者那里，人生的意义实际上被归结为内心的某种情绪体验， 情绪成了实现自由和超越的唯一阵地。对比之下，尼采至少还重视创造高级文化这一可见形 式的超越，似不如此偏颇。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"尼采","slug":"尼采","permalink":"https://sean10.github.io/tags/尼采/"},{"name":"周国平","slug":"周国平","permalink":"https://sean10.github.io/tags/周国平/"},{"name":"哲学","slug":"哲学","permalink":"https://sean10.github.io/tags/哲学/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/读书笔记/"}]},{"title":"leetcode-101","slug":"leetcode-101","date":"2017-12-02T09:05:37.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/12/02/leetcode-101/","link":"","permalink":"https://sean10.github.io/2017/12/02/leetcode-101/","excerpt":"重新复习，这道题想复杂了……","text":"重新复习，这道题想复杂了…… 一开始想到的是层次遍历二叉树，然后用迭代器正反迭代匹配一下，有一个不匹配就返回false。 忘了写中间为空时填充一个nullptr，导致有些案例也返回了true。 又发现如果找不到就填充nullptr，会导致队列永远不会为空，内存溢出MLE的情况，试图在匹配过程中发现空指针，就erase掉，但是迭代过程中erase会导致后续的所有迭代器前移 并且，erase反向迭代器需要进行一下显示类型转换，并在erase时转换成正向迭代器(++it_r).base()。 因为我是new了一个ptr来替代nullptr来实现普遍性，考虑到智能指针可能可以省力，但是实际情况下，似乎容器中不能添加智能指针。虽然我用shared_ptr.get()传递进了容器，但是这样猜测应该是违背容器管理的。 一个容器全部被erase后，迭代器得到的并不是end()，所以需要添加一个empty的判断条件 但是，我又发现，在erase最后一个，之后得到的是地址的顺推，但是end()因为在队列中被释放了2次，所以得到的是原本的倒数第二个，与实际不相符合了。所以需要添加一个计数器来管理结束 看了下参考答案，原来是在遍历的时候就直接正反遍历，最后直接匹配树就好了，我想复杂了。 不过也是成功实现了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: bool isSymmetric(TreeNode* root) &#123; deque&lt;TreeNode*&gt; stack_; TreeNode* curr = root; if(curr) stack_.push_back(curr); int level = 2; int curr_level = 0; shared_ptr&lt;TreeNode&gt; ptr_null(new TreeNode(0)); while(!stack_.empty()) &#123; //cout &lt;&lt; curr-&gt;val &lt;&lt; endl; curr = stack_.front(); stack_.pop_front(); if(curr-&gt;left) &#123; stack_.push_back(curr-&gt;left); &#125;else &#123; stack_.push_back(ptr_null.get()); &#125; if(curr-&gt;right) &#123; stack_.push_back(curr-&gt;right); &#125;else &#123; stack_.push_back(ptr_null.get()); &#125; curr_level += 2; cout &lt;&lt; curr_level &lt;&lt; ' '&lt;&lt;level &lt;&lt; endl; for(deque&lt;TreeNode*&gt;::iterator it_t = stack_.begin(); it_t != stack_.end(); it_t++) cout &lt;&lt; (*it_t)-&gt;val &lt;&lt; ' '; cout &lt;&lt; endl; if(level == curr_level) &#123; curr_level = 0; deque&lt;TreeNode*&gt;::iterator it; // for(it = stack_.begin(); it != stack_.end(); it++) // cout &lt;&lt; (*it)-&gt;val &lt;&lt; \"\"; // cout &lt;&lt; endl; int cnt = 0; deque&lt;TreeNode*&gt;::reverse_iterator it_r; int temp_lv = level/2; for(it = stack_.begin(), it_r = stack_.rbegin();\\ cnt &lt; temp_lv; cnt++) &#123; // cout &lt;&lt; cnt &lt;&lt; ' '&lt;&lt; level/4 &lt;&lt;endl; // for(deque&lt;TreeNode*&gt;::iterator it_t = stack_.begin(); it_t != stack_.end(); it_t++) // cout &lt;&lt; (*it_t)-&gt;val &lt;&lt; \"\"; // cout &lt;&lt; endl; if((*it) == ptr_null.get() &amp;&amp; ptr_null.get() == (*it_r)) &#123; it = stack_.erase(it); it_r = deque&lt;TreeNode*&gt;::reverse_iterator(stack_.erase(next(it_r).base())); level -= 2; continue; &#125; if((*it)-&gt;val == (*it_r)-&gt;val) &#123; cout &lt;&lt; cnt &lt;&lt; ' '&lt;&lt;temp_lv &lt;&lt; endl; cout &lt;&lt; (*it)-&gt;val &lt;&lt; \" \" &lt;&lt; *it &lt;&lt; \" \"&lt;&lt; (*it_r)-&gt;val &lt;&lt; \" \" &lt;&lt; *it_r &lt;&lt; endl; it++; it_r++; continue; &#125; else &#123; cout &lt;&lt; cnt &lt;&lt; ' '&lt;&lt; temp_lv &lt;&lt; endl; cout &lt;&lt; (*it)-&gt;val &lt;&lt; \" \" &lt;&lt; *it &lt;&lt; \" \"&lt;&lt; (*it_r)-&gt;val &lt;&lt; \" \" &lt;&lt; *it_r &lt;&lt; endl; return false; &#125; &#125; level *= 2; &#125; &#125; return true; &#125;&#125;;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"《Effective_C++》note","slug":"《Effective-C-》note","date":"2017-11-28T14:47:56.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/11/28/《Effective-C-》note/","link":"","permalink":"https://sean10.github.io/2017/11/28/《Effective-C-》note/","excerpt":"in-class 初值设定 只支持整型常量","text":"in-class 初值设定 只支持整型常量 class static专属变量可以不定义，直接声明并使用 如果要取地址，就在定义文件里再定义const ，不要初始化，因为值在声明时已经默认了。 这不知道是哪个C++的版本加入的功能，旧编译器不支持初值 不支持in class时，可以用enum{NumTurns = 5}替代 这叫做enum hack补偿做法 这是template metaprogramming的基本技术 bitwise constness(physical constness) and logical constness 二进制常量性 和 逻辑常量性 利用Mutable解决掉non-static的const摆动场，释放bitwise constness 新式转型 static_const转型操作 const_cast去除const操作 core dump错误 基类使用派生类函数 1. 使用virtual从继承向上移动 2. 使用安全容器 绝对拒绝cascading dynamip_cast，理由不理解 尽可能使用C++ style新式转型 无参数构造函数，为什么也需要用到初始化操作？ （噢，可能是为了不忘记哪个参数不需要初值） 不同编译单元内定义之non-local static对象，编译器对初始化顺序并没有设定 **多个编译单元内的non-local static对象经由“模板隐式具现化 implicit template instantiations””形成 将non-local 移到专属函数中，调用一个函数返回一个reference指向所含的对象， 这是Singleton模式的一个常见实现手法 但是在多线程环境下存在不确定性 做法：在程序的单线程启动阶段手工调用所有reference-returning函数，可消除与初始化有关的”竞速形式(race conditions) 编译器拒绝生成拷贝构造函数和操作符的几种情况 将成员函数声明为private并不去实现，就可以阻止编译器生成public拷贝构造函数等等 声明一个uncopyable基类，继承他就可以直接阻止编译器 c++的异常绝对不要放在析构函数里 连锁赋值 返回*this，这个是返回引用 自我赋值，释放，陷阱 传统做法，添加identity test 异常安全性是什么？ 工厂函数factory function RAII，资源取得时机便是初始化时机(Resource Acquisition is Initialization) 智能指针 或者 referenced counting smart pointer resource handler shared_ptr存在删除器，可以指定调用函数作为释放这种行为 std::tr1::shard_ptr&lt;Investor&gt; ptr ptr(m1, Unlock) 有时APIs直接接触原始资源，无法通过资源管理类来接触 对原始资源的访问最好是通过显式转换，但是对客户来说，隐式转换 可能更加方便 隐式转换也是可以在自定义类中重载的吗？ 以独立语句将newed对象存储于智能指针内。如果不这样做，一旦异常被抛出，有可能导致难以察觉的资源泄露 优良接口 许多客户端错误可以因为导入新类型而获得预防 以函数替换对象，表现某个特定月份 和non-local static对象的初始化次序有什么关系？ 嗯，想起来了，构造函数的赋值和初始化次序可能不定，还是直接调用函数效果更确定 tr1::shared_ptr支持定制型删除器，可防范DLL问题，可被用来自动解除互斥锁。 这条不太理解，不知道DLL可能发生什么错误 设计class犹如设计type 函数内的static local对象何时释放？ global slinton 在一个命名空间内添加多个头文件也是一种做法 特化版本是什么，好像没见过 条款25，特化swap，感觉不理解，特别复杂 避免返回handles（包括references、迭代器）指向对象内部 异常安全性 不泄露任何资源 不允许数据败坏 异常安全码 copy and swap一般化策略 pimpl idiom function template和头文件是啥关系，似乎没啥关系 条款31 将文件件的编译依存关系降至最低 我们可以这样做，将person分割为两个classes，一个只提供接口，另一个负责实现该接口。 这样可以实现接口与实现相分离 std头文件依旧引用，除此之外。接口使用前置声明。 关键:用“声明的依存性”替换“定义的依存性” Pass By Value就需要用到定义，而如果传递指针或引用，就不需要定义，只要声明 为声明式和定义式上提供不同的头文件 就像 这个被称为Handle classes. 2种: * 接口与实现相分离 * 抽象基类，叫interface class 类似Java的Interface 继承这个抽象基类的叫做具象类(concrete classes)，调用基类的创建函数，在创建函数中调用具象类对象动态分配，并返回static，然后通过基类中提供的接口对返回的对象进行操作。哇，这也是一种接口与实现相分离 handle classes 和Interface classes解除了接口和实现之间的耦合关系，从而降低了文件间的编译依存性(compilation dependencies) virtual意味着接口必须被继承，non-virtual意味着接口和实现必须被继承 转角函数 forwarding function 函数接口继承和函数实现继承 virtual和inline究竟有什么关系？ 接口和缺省实现应该分开 可以在纯虚函数的定义中进行缺省实现 简朴的(非纯)impure vritual函数具体制定接口继承及缺省实现继承。 缺省实现继承不还是pure virtual函数实现的吗？ 难道这个简朴的，指的不是virtual函数？ non-virtual interface(NVI手法)，外覆器(wrapper) Template Method设计模式 虚函数private，还能被继承吗？ 不能的话，那有什么意义？ strategy设计模式 传递函数指针 tr1::function可以实现stategy设计模式 任何兼容的可调用物(callable entity) 与给定之目标签名式(target signature)兼容 上面2条什么意思？ 非虚函数，Base类指针指向派生类，执行的函数式Base类中的，而不是派生类中的。 如果是虚函数，那么就都执行派生类中的。 静态绑定，动态绑定 dynamically bound,stataically bound 不能调用继承Private的virtual函数，那么允许重新定义这个虚函数的价值是什么呢？ 如果继承的private是非虚函数，也是可以重新定义的吧？ 难道这个不行 Java和C#自带 组织derived class 重新定义virtual 函数 空白基类最优化 多重继承 virtual inheritance 泛型编程 衍生出模板元编程 显式接口，运行期多态 template中指涉一个嵌套丛书类型名称，就必须在紧邻它的前一个位置放上关键字typename 模板 特化 全特化模板的调用很有可能编译器不会去查询，也就无法调用，存在一些问题 共性与变性分析 模板化基类 被覆盖 working set 因非类型模板参数造成的代码膨胀，可以用class来替换template，但是完全理解不了 Traits是一门技术，获取类型信息的，无论是内置还是自动类型 TMP元编程技术越来越牛了 可以定制new和delete，set_new_handler","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"}]},{"title":"东野圭吾作品的别致","slug":"东野圭吾作品的别致","date":"2017-10-31T12:57:52.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/10/31/东野圭吾作品的别致/","link":"","permalink":"https://sean10.github.io/2017/10/31/东野圭吾作品的别致/","excerpt":"这应该是我看的东野圭吾的第二部作品，第一部看的是《白夜行》。","text":"这应该是我看的东野圭吾的第二部作品，第一部看的是《白夜行》。 感觉上，在印象里，东野圭吾的风格和我曾经看过的其他悬疑推理作品完全不同，其他作品诸如柯南道尔的《福尔摩斯》会给出细微的描写的线索，然后将凶手隐藏起来，需要切切实实的仔细推理，存在多个凶手的可能性。 而东野圭吾的作品却是一开始便只提供了唯一的凶手选项，然后带领读者逐渐获取线索，寻找真相。在这个过程中，让读者对凶手的性格有所成形，并逐渐理解凶手的杀人动机。如果简单地说句和其他人的作品的不同，恐怕就是东野圭吾的作品都是挂着推理外壳的情感小说吧，而其他人的则是挂着情感线索外壳的推理悬疑小说，不过这部《拉普拉斯的魔女》藏在推理外壳内的应该算是一个科幻小说吧，主要试图讲述的人类大脑建模计划的成果?。 另外，在这部小说中，每个角色的戏份似乎是相近的，都构造出了一个真实的人的模样。说来，其他推理作品，我看的都是探案集，只有主角是长久的，其他的配角都只需要为主角提供助力，营造一个模糊性格就足够了，而东野圭吾的作品中没有冗余的角色，可能在他眼中，真实的社会中每个人都是主角，具有好奇心的人都会发展出各自的故事？ 这样的故事读完，倒是别有一番风味，没有推理完的烧脑感，但能有一股引人思考的回味感。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"推理","slug":"推理","permalink":"https://sean10.github.io/tags/推理/"},{"name":"读后感","slug":"读后感","permalink":"https://sean10.github.io/tags/读后感/"},{"name":"东野圭吾","slug":"东野圭吾","permalink":"https://sean10.github.io/tags/东野圭吾/"},{"name":"小说","slug":"小说","permalink":"https://sean10.github.io/tags/小说/"}]},{"title":"仿佛天元突破","slug":"仿佛天元突破","date":"2017-10-07T14:25:18.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/10/07/仿佛天元突破/","link":"","permalink":"https://sean10.github.io/2017/10/07/仿佛天元突破/","excerpt":"这部作品是这两天我补番过程中，唯一能被称之为杰作的作品了把。","text":"这部作品是这两天我补番过程中，唯一能被称之为杰作的作品了把。 而这部来自深渊，一开始我认为是相对比较简单的，可是在接触了解这个世界观越来越深以后，愈发有种可能与《天元突破》那部老番拥有神似的感觉了。虽然故事并不相同，但是将主角身世等等的秘密逐渐揭露，逐渐发现隐藏的更深的秘密，这种引动好奇心的叙事能力，令人欲罢不能。同样是奇幻类型，同样围绕着一个限定的职业展开之后的故事。 这部作品也是近年来少有的用吉卜力风格的作品，并不使用当下流行的九头身的GAL画风，而是用了3头身，将着重点放在整个冒险故事本身。这种做法，不盲随大流，展现给观众的表现力着实不错。 仔细想来，这种设定下，如果用偶像风格，那可能这个故事就会因为主次区分度不足，而导致观众无法理解故事本身了吧。说来，前段时间的那部《ReWrite》，我就完全没能看懂。听说只有玩了原著游戏才能稍稍有所了解。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/动漫/"},{"name":"来自深渊","slug":"来自深渊","permalink":"https://sean10.github.io/tags/来自深渊/"},{"name":"吉卜力","slug":"吉卜力","permalink":"https://sean10.github.io/tags/吉卜力/"},{"name":"奇幻","slug":"奇幻","permalink":"https://sean10.github.io/tags/奇幻/"}]},{"title":"系列首作，所以只是引观众进行哲思","slug":"系列首作，所以只是引观众进行哲思","date":"2017-10-07T14:23:15.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/10/07/系列首作，所以只是引观众进行哲思/","link":"","permalink":"https://sean10.github.io/2017/10/07/系列首作，所以只是引观众进行哲思/","excerpt":"《全部成为F》，这可以说是比较棒的一部作品，不过也是有局限性的。","text":"《全部成为F》，这可以说是比较棒的一部作品，不过也是有局限性的。 《全部成为F》应该说是推理、悬疑类的标准作品，在动漫中的排名不低，但是在整个悬疑类动漫里，可能就并不能显得非常出色了，唯有他的系列设定中所占不小的试图表现的哲学+数学内涵可以拉动一些他的分数。相比其他的纯推理作，这部作品在当下这个年代，二进制普及的年代，F的谜题不算难想到了（在当年推出的那个背景是算是非常了不起的了，不愧是工科博士/教授)。所以，作为S&amp;M系列的正式首作，终究只是给系列作品起了个开幕式。动画并不能算完整。 这部里，我感觉到的内涵，就是天才认为活着有种病态感了。 天才的真贺田博士，在认知上已经超出了常人的范畴，对一切的理解似乎是已经超出了读者的想象。而犀川教授，虽然在常人的范畴，也可以称之为天才，但是他与真贺田博士终究还是不同的，他与女主西之园萌绘互相支撑，互相度过了最艰难的时间，终究没有选择走向自由、死亡的那一步，而真贺田博士最终是落实了自由的那一步，放弃了作为普通人类所拥有的道德观与人生观，杀死了父母，女儿自杀而摆脱了阻碍，进入了社会。 这个动画，我剪了所有的哲思对话(B站15155955)，发现动画里回答的还是比较简单的，没有用理论主义的演绎法，也没有用经验主义的归纳法，只是在阐述与寻找共鸣，就感觉有点让观众不那么好理解了。(个人感觉只能算是给观众提了问题，动画里的回答只是设定里的回答，并不能让观众信服) 恐怕，也是存了毕竟只是一个系列的开幕，所以不需要在这一部里讲的太多，反而讲不清案件了吧。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/动漫/"},{"name":"全部成为F","slug":"全部成为F","permalink":"https://sean10.github.io/tags/全部成为F/"},{"name":"真贺田四季","slug":"真贺田四季","permalink":"https://sean10.github.io/tags/真贺田四季/"}]},{"title":"「序列之争」最后30分钟太可惜","slug":"「序列之争」最后30分钟太可惜","date":"2017-10-02T08:46:28.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/10/02/「序列之争」最后30分钟太可惜/","link":"","permalink":"https://sean10.github.io/2017/10/02/「序列之争」最后30分钟太可惜/","excerpt":"前80分钟我觉得剧情完全可以，将VR与AR之间的差异与美妙讲述的相当清楚。","text":"前80分钟我觉得剧情完全可以，将VR与AR之间的差异与美妙讲述的相当清楚。 只看这部分的话，桐人在这里的展现就像是一个偏好宅VR的人被AR的现充给打倒了，然后逐渐接受，开始成长。到这里为止，剧情的设定还算是显得比较普通，虽然不算杰作，但在这个杰出的背景设定下也绝对不差。 然而，从进入演唱会阶段开始，可能是为了突出一个打倒BOSS，主角们都很棒，反派必须死的主线?就设定了一个必须要桐人出面才能拯救所有人的条件吧。 首先，桐人居然直接就打开了会场的门，从楼上直接就能跳到主会场里，就说这一点，难道后面支援的部门里的大人们就不行？他们非要把这个责任完全交给孩子？无论如何，多手准备总归是要有的吧，桐人走主流通关路线，分配几个人去会场引导大家摘下设备完全可以，留几个人直接去关闭游戏主服务器，再分配几个人去找博士呗。前面的剧情相当有脑，怎么到了这里就这么的让人想吐槽呢。 其次，就算你一时忘了吧，用枪打开门那部分，我也想说说了，既然是同样的电子锁，你这里直接打爆断电能够开门还是比较正常的，那为什么在会场那里你不直接开枪打开门呢……给桐人堆戏份的目的也太明显了…… 再三，博士明明可以慢工出细活，慢慢收集数据就是了。明知道这么直接，暴露被抓的话，显然对未来复活的尤娜来说也不是一件好事。明明可以通过长时间发布活动来收集他们的回忆，这种曾经的冒险时的记忆显然已经是处于长期记忆状态了，并不会在短时间内遗忘了，不存在迫使博士必须要短时间爆发强制扫描记忆的动机。 像茅场晶彦那样准备已久，一次爆发，之后完全安全地存活在信息世界中，才是真正符合现实的吧。博士已经有眼前的经验了，居然仍旧这么选择，就显得有些角色崩坏了吧。 当然，整部作品不考虑后面的剧情失常表现，打斗的画面还是一如既往的精致。结衣开外挂那里开的倒也挺正常，毕竟现在SAO服务器启动了，结衣权限再次生效还是可能的。 这部作品，在这个大数据热门的时代，倒是很符合潮流，很有热点。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/动漫/"},{"name":"刀剑神域","slug":"刀剑神域","permalink":"https://sean10.github.io/tags/刀剑神域/"}]},{"title":"考研预报名脚本","slug":"考研预报名","date":"2017-09-26T14:43:40.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/09/26/考研预报名/","link":"","permalink":"https://sean10.github.io/2017/09/26/考研预报名/","excerpt":"","text":"本来打算自己写JS填表的，不过在github上直接搜到了一个同学的杰作，就直接使用了，链接放在这里。 之前每次手填怪慢和累的，而且还经常最后提示繁忙什么的……用脚本就没问题了。 祝各位报名顺利吧~","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"考研","slug":"考研","permalink":"https://sean10.github.io/tags/考研/"}]},{"title":"未来镜像","slug":"未来镜像","date":"2017-08-24T07:03:07.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/08/24/未来镜像/","link":"","permalink":"https://sean10.github.io/2017/08/24/未来镜像/","excerpt":"这本作品原来中外合作的意思是双语啊，看完才知道……很赞","text":"这本作品原来中外合作的意思是双语啊，看完才知道……很赞 《以太》: 一个神似《1984》的故事，不过并非通过监控而后暴力压制，而是通过监控后彻底的欺骗，这个故事完全可以存在且有效。 《开光》: 一个违反熵的算法的出现，引发了宇宙的干扰行为，最终始作俑者终将受到处置。 《格里芬太太决定于今夜去死》: 一个存在了人工智能的世界里，一个人与一个家用机器人的故事，一个男人为了妻子另外兼职试图购买一个家用机器人，刚刚攒够之际遭遇意外，妻子明白了丈夫对她的爱，却没有机会再见。妻子还是讲本该购买的机器人LW31买回了家，在自己离开之后，LW31来照顾自己的女儿格里芬。格里芬为了在废除机器人的时代保护LW31，遇到了自己的丈夫，在逃亡直到政府破灭通缉失效方才回归，而她的丈夫则因为逃亡中的伤害而早早离开。后来，她的女儿也遇到了自己心爱的人准备移民，却在星际移民过程中遭遇不测。最终，只有LW31与格里芬太太相依为命，所幸LW31依旧存在，作为最后一个爱着格里芬的人而保护着她。 《饿塔》: 人性的归原，最终舍弃了智慧的人也舍弃了得救的希望。 《安检》: 在安检的过程中通过纳米器械彻底替换物质乃至人，为了国家的安全。感觉脑洞不够大。这和人时时刻刻在新陈代谢，下一秒不再是刚才的自己一般。 《留下她的记忆》: 记忆是真实的，但部分的记忆又是虚假的，毕竟记忆是带有主观色彩与方向的，就像事实一般具有诱导性。 《祖母家的夏天》: 之前读过一遍的郝景芳大大的作品，依旧感觉是那么的赞，你永远不知道一样东西的真正用处是什么。这里用《物语》里班长的话来说就是:“我不是什么都知道，只是刚好知道而已。”我们知道的只是刚好知道的，而永远不会是全部。 《寒冬夜行人》: 只是一个隐藏喜欢的诗人隐私的故事，为什么算是科幻作品呢？只能算是一个文艺的短篇小说吧。 《圆圆的肥皂泡》: 童年的幻想化作未来的坚持，幻想的真正用处终究能找到。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/读书笔记/"},{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/科幻/"}]},{"title":"克苏鲁神话初学","slug":"克苏鲁神话","date":"2017-08-04T07:24:18.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/08/04/克苏鲁神话/","link":"","permalink":"https://sean10.github.io/2017/08/04/克苏鲁神话/","excerpt":"初闻，有所疏漏，请见谅。","text":"初闻，有所疏漏，请见谅。 克苏鲁神话短篇译名对照表(详见附录一): 作者 分类 原名 译名 创作时间 译者 制表：玖羽 HPL 小说 The Alchemist 炼金术士 1908 白苹果 早期 Ashes 灰烬 1923 zimmer 共作 At the Mountains of Madness 疯狂山脉 1931.02-03.23 竹子 重要 较长 Azathoth 阿撒托斯 1922.06 玖羽 残篇 较短 The Battle that Ended the Century 新世纪前夜的决战 1934.06 玖羽 恶搞 共作 较短 The Beast in the Cave 洞中兽 1905.04.21 Milk 早期 较短 Beyond the Wall of Sleep 翻越睡梦之墙 1919 竹子 早期 The Book 书 1933 玖羽 残篇 较短 The Call of Cthulhu 克苏鲁的呼唤 1926.夏 竹子 重要 The Case of Charles Dexter Ward 查尔斯·迪克斯特·瓦德事件 1927.01-05.01 竹子 重要 较长 The Cats of Ulthar 乌撒的猫 1920.06.15 玖羽 早期 幻梦境 较短 Celephaïs 塞勒菲斯 1920.11 玖羽 早期 幻梦境 较短 The Challenge from Beyond 来自彼方的挑战 1935.08 竹子 共作 Collapsing Cosmoses 崩坏的宇宙 1935.06 玖羽 恶搞 共作 残篇 较短 The Colour Out of Space 星之彩 1927.05 修白川 重要 Cool Air 寒气 1926.05 竹子 The Crawling Chaos 伏行的混沌 1920/21 竹子 早期 The Curse of Yig 伊格的诅咒 1928 竹子 共作 Dagon 达贡 1917.07 玖羽 早期 较短 Deaf, Dumb, and Blind 聋，哑，瞎 1924 竹子 共作 The Descendant 后裔 1926 yolu 残篇 较短 The Diary of Alonzo Typer 阿隆佐·泰普尔的日记 1935.10 玖羽 共作 The Disinterment 掘墓 1935.09 竹子 共作 The Doom That Came to Sarnath 降临在萨尔纳斯的灾殃 1919.12.03 玖羽 早期 幻梦境 较短 The Dream-Quest of Unknown Kadath 秘境卡达斯梦寻记 1926.秋-1927.01.22 竹子 重要 幻梦境 较长 The Dreams in the Witch House 魔女屋中之梦 1932.01-02.28 竹子 重要 较长 The Dunwich Horror 敦威治恐怖事件 1928.夏 竹子 重要 较长 The Electric Executioner 电刑器 1929 竹子 共作 The Evil Clergyman 邪恶的教士 1933.10 竹子 较短 Ex Oblivione 来自遗忘 1920/21 玖羽 早期 幻梦境 较短 Facts Concerning the Late Arthur Jermyn and His Family 关于已故亚瑟·杰尔敏及其家系的事实 1920 玖羽 早期 The Festival 魔宴 1923.10 玖羽 重要 From Beyond 自外而来 1920.11.16 竹子 早期 The Ghost-Eater 噬鬼者 1923 zimmer The Green Meadow 绿色草原 1918/19 玖羽 早期 幻梦境 The Haunter of the Dark 夜魔 1935.11 竹子 重要 He 他 1925.08.11 竹子 Herbert West – Reanimator 尸体复活者赫伯特·威斯特 1921-1922 竹子 枪稿 重要 History of the Necronomicon 《死灵之书》的历史 1927 竹子 随笔 较短 The Hoard of the Wizard-Beast 巫兽的宝藏 1933 竹子 共作 The Horror at Martin’s Beach 马丁海滩的怪物 1922.06 竹子 共作 较短 The Horror at Red Hook 雷德胡克的恐怖 1925.08.01-02 竹子 The Horror in the Burying-Ground 墓园里的恐怖 1933/35 竹子 共作 较短 The Horror in the Museum 蜡像馆惊魂 1932.10 竹子 共作 The Hound 猎犬 1922.09 cimar Hypnos 休普诺斯 1922.03 玖羽 Ibid 伊比德 1928 玖羽 恶搞 In the Vault 地窖中 1925.09.18 竹子 In the Walls of Eryx 厄瑞克斯之墙 1936.01 竹子 The Last Test 最终测试 1927 竹子 The Little Glass Bottle 小玻璃瓶 1897 玖羽 幼年 较短 The Loved Dead 可爱的死者 1923 zimmer The Lurking Fear 潜伏的恐惧 1922.11 玖羽 枪稿 The Man of Stone 石像 1932 Setarium 较短 Medusa’s Coil 美杜莎的卷发 1930 竹子 较长 Memory 记忆 1919 玖羽 早期 较短 The Moon-Bog 月之沼 1921.05 Setarium 早期 较短 The Mound 丘 1929-1930 竹子 重要 较长 The Music of Erich Zann 埃里奇·赞之曲 1921.12 竹子 The Mysterious Ship 神秘船 1902 竹子 幼年 较短 The Mystery of the Grave-Yard 墓园之谜 1898 竹子 幼年 较短 The Nameless City 无名都市 1921.01 竹子 The Night Ocean 夜之洋 1936.秋 annshark01 共作 Nyarlathotep 奈亚拉托提普 1920.12 玖羽 早期 较短 Old Bugs 老臭虫 1919 竹子 早期 较短 The Other Gods 蕃神 1921.08.14 玖羽 幻梦境 较短 Out of the Aeons 超越万古 1933 竹子 重要 较长 The Outsider 异乡人 1921 竹子 重要 较短 Pickman’s Model 皮克曼的模特 1926 玖羽 重要 The Picture in the House 屋中画 1920.12.12 竹子 早期 Poetry and the Gods 诗与诸神 1920 玖羽 早期 随笔 共作 较短 Polaris 北极星 1918.05 玖羽 早期 幻梦境 较短 The Quest of Iranon 伊拉农的探求 1921.02.28 玖羽 幻梦境 较短 The Rats in the Walls 墙中之鼠 1923.08-09 竹子 重要 A Reminiscence of Dr. Samuel Johnson 回忆塞缪尔·约翰逊博士 1917 竹子 早期 较短 The Secret Cave or John Lees Adventure 隐秘的洞穴，或约翰·李的冒险 1898 竹子 幼年 较短 The Shadow Out of Time 超越时间之影 1934.11-1935.05 竹子 重要 较长 The Shadow Over Innsmouth 印斯茅斯之影 1931.11-12.03 竹子 重要 较长 The Shunned House 畏避之屋 1924.10.16-19 竹子 The Silver Key 银钥匙 1926 竹子 重要 The Slaying of the Monster 诛杀怪物 1933 玖羽 共作 较短 The Statement of Randolph Carter 兰道夫·卡特的供述 1919.12 竹子 早期 较短 The Strange High House in the Mist 雾中怪屋 1926.11.09 玖羽 The Street 道路 1920 玖羽 早期 随笔 较短 Sweet Ermengarde 甜美的艾门嘉德 1917 Setarium 早期 恶搞 较短 The Temple 神殿 1920 玖羽 早期 The Terrible Old Man 可怕的老人 1920.01.28 玖羽 早期 较短 The Thing in the Moonlight 月下之物 1927.11.25(托名) Setarium 共作 较短 The Thing on the Doorstep 门口的东西 1933.08.21-24 竹子 Through the Gates of the Silver Key 穿越银匙之门 1932.10-1933.04 竹子 重要 共作 较长 Till A’ the Seas 直至诸海…… 1935.01.01 竹子 共作 The Tomb 坟墓 1917.06 竹子 早期 The Transition of Juan Romero 胡安·罗梅洛的变貌 1919.09.16 玖羽 早期 较短 The Trap 圈套 1931 玖羽 共作 The Tree 树 1920 玖羽 早期 较短 The Tree on the Hill 山上的树 1934.05 竹子 Two Black Bottles 两只黑瓶 1926.07-10 竹子 Under the Pyramids 金字塔下 1924.02-05 竹子 枪稿 The Unnamable 不可名状 1923.09 竹子 The Very Old Folk 远古的民族 1927.11.02 玖羽 较短 What the Moon Brings 月光下 1922.06.05 竹子 较短 The Whisperer in Darkness 暗夜呢喃 1930.02.24-09.26 竹子 重要 The White Ship 白船 1919.11 玖羽 早期 幻梦境 较短 Winged Death 有翼死神 1933 竹子 共作 文章 Notes on Writing Weird Fiction 怪奇小说创作笔记 1934.06 玖羽 Supernatural Horror in Literature 文学中的超自然恐怖 1927 Setarium 重要 较长 资料收集 海中岛屿， 死城拉莱耶，伟大的克苏鲁及其部署长眠于此。 《皮克曼的模特》： 作品中主要讲述的便是从一个欣赏者的角度发现一名画家的作品之惊悚，而在其家中参观时发现了，本以为是幻想作品的作品实际上是写实了一幅令人惊悚的照片，作品与之没有任何区别。 《印斯茅斯之影》： 印斯茅斯这个城镇中的居民在恶魔礁上与异形做出了交易，选择了与之通婚，令后代拥有永生的能力，只是会随着年龄增长，逐渐趋于异形，最终回到海中。而主角的曾祖母便是出自这个通婚后的家族的后代，主角在挖掘家族根源时发现了这个真相，在最终自己也进行变化时，选择回到起源的海中永恒生存。 《墙中之鼠》： 主角将家族的一栋悬崖边的别墅整修后，准备在这里颐养晚年。第一个夜晚，相伴的老猫发现了这栋建筑下隐藏的恐怖，惊醒了主角，主角叫上了同伴，逐渐挖掘真相。在原本的祭坛（祭祀的应该是奈亚拉托提普）下，发现了一个洞穴，在其中是祖先曾经圈养过某种怪物（老鼠？或是邪神之下的某种怪物）的痕迹，食物短缺时，这些老鼠将一切都啃尽。主角在最后受到了奈亚拉托提普的召唤，永远被困在了墙中之鼠的梦之中。 《星之彩》： 来自宇宙的陨石带来的异常，这个陨石会逐渐消失（似乎无法隔绝，暂定空间上具有扩散性质，沉浸到了附近的土地中），这个陨石令着陆周围的一切动植物受到了克苏鲁的影响，令周围的一切都变得异乎寻常，最终导致周围的那家人全部带着恐惧或精神失常而死去。 《克苏鲁的呼唤》： 在调查叔伯遗留下的记录时，发现了带有克苏鲁印象的雕塑、浮雕等等，与警长、学者找到了一个现存的依旧崇拜旧日支配者的邪教，证实了克苏鲁的真实存在，直到当下。 《夜魔》： 布莱克在好奇中进入了星之智慧教徒召唤夜魔的教堂，偶然间完成了召唤的步骤，将夜魔唤醒，逐渐与夜魔合二为一，最终似乎融合之后而离开了。 这部中布莱克在融合时还记录了其他邪神，似乎是进入了那个世界。 《敦威治恐怖事件》： 这部小说中，老沃特雷教导威尔伯通过犹格·索托斯召唤旧日支配者，然而在老沃特雷去世之后，威尔伯没能在图书馆取得所需的完整的《死者之书》，反而死在了那里，导致召唤仪式并不完整，之后，他的孪生兄弟从被关着的家中逃了出来，在山顶祭坛与村落中往返可能试图召唤其父亲旧日支配者，但最终被来自图书馆的三个阿卡姆人以破译出的咒语送回了世界之外。 《丘》： 登上土丘进行挖掘的人便会消失，可能能够带着邪神的见闻而带着不同的概念神智不健全地回来，也可能永远回不来。 洪水将老一代洗净，没有进来的，没有出去的。 伟大的图鲁——阿撒托斯——奈亚拉托提普——等待着，等待着 在传说中，那是一个可怖的存在，早在地球尚且年轻还未完全成形之时，它就已经从群星之间降临到了大地上 地下之人居住在撒托的巨大城市之中，其生物结构与人类存在两百万年之间的差距，所以他们能够永生，而外来的人类学习了也很难完全做到，另外，他们已经可以做到物质与非物质之间的转化（衍生出一种投射能力，类似于占卜？可以与目标建立联系，获得到一些信息（神秘度倾注））。 这里有一点可以看到比较好奇，记录者，对于未知动物（这里是还设定了一个显然的非自然造物），因为无知而恐惧。那现代的人会恐惧吗？还是只是会萌发好奇心呢？猜想我自己如果遇到应该是会恐惧的。 撒托古亚：蟾蜍样 图鲁: 章鱼样 伊格: 蛇样 莎布 尼古拉斯: 万物之母 这篇在开头设立了一个现象，文中从多个角度发现一个真相，而文末将开头的现象给彻底解密，悬疑类小说的通常表达方式，这种比较吸引读者，之前看的几篇综觉得有些坑并没有解释清楚，写的似懂非懂。 《屋中画》: 又是一个与阿卡姆相关的地点的故事。 仅仅只是在一个孤僻的地带遭遇了食人者的故事。 根据译者所说，这个故事中才是第一次提到阿卡姆这个背景，即洛夫克拉夫特在小说最常用的背景——那个想象中的新英格兰世界，阿卡姆以及密斯卡托尼克河。 这个背景后来也经常被人们称为“Lovecraft Country”。在此之后，直到他去世前，洛夫克拉夫特用这个背景写了一连串著名的故事。例如《敦威治恐怖事件》、《印斯茅斯的阴霾》、《魔宴》、《魔女屋中之梦》等等。然后，随着德雷斯的进一步扩充，这片充满了孤僻村落、阴森人群以及黑暗秘密的新英格兰世界终于成为了克苏鲁神话中的标志之一。 《埃里奇·赞之曲》： 这里面有一个隐晦的暗示：关于奥斯尔路的名字，在英文小说中是the Rue d’Auseil. 这是个法语词，其中Rue d’的意思是路，而Auseil其实是个短语 au seil意思是“门槛”。 这个故事中隐含的就是在一堵墙外可能就是另一个世界的意思吧。 《异乡人》: 一个尚且以为自己是人类的已然化身为其他人眼中的怪物的寻找光明却意识到自身的历程。 《门外之物》: 同样是阿卡姆与印斯茅斯的背景下的故事，来自印斯茅斯家族的亚西纳控制了爱德华的身体，通过献祭给莎布 尼古拉斯，最终将以爱德华的身体重生，而爱德华将不得不在亚西纳的身体里。 传统鬼怪故事，按照译者的意思，似乎这部作品并不受欢迎，由于缺乏了那种洛夫克拉夫特独有的宇宙观（我还不太能理解这个宇宙观）。 《达贡》：（这个还是玖羽翻译的好，克苏鲁那本书里的翻译用的词不太恰当感觉） 设定了一个海中的恐怖，之后就被所谓的海中半人半鱼之神达贡给缠身了。 《关于已故亚瑟·杰尔敏及其家系的事实》： 感觉是类似印斯茅斯的一个背景下的，设定是亚瑟的曾祖父与一个类人猿女神(体毛稀少，几近人类)结合，亚瑟返祖，与那位类人猿女神极度相似。 《奈亚拉托提普》： 噩梦的记述作。 《可怕的老人》: 强盗遭遇超常怪物就此Over的故事。 2017.08.26 买了《克苏鲁神话》那本电子书，看了下，感觉翻译没有 《黑暗中的低语》: 这个是在新出的《克苏鲁神话》这本书里收录的，引领读者逐渐去探寻克苏鲁的世界，埃克利最终还是没能逃脱，而教授在被米戈蒙骗之后成功逃脱将经历记述了下来。 《自彼界而来》: 乍一看前几段时，有一种接下来的故事可能就是在对自己摧残式地实验中偶然接触到了伟大的存在(在那个时代可能辐射就是最大的幻想诱因)，而后就将其召唤或是被附身之类了。 结果倒也相近，进入了一个可以类似称为高维的状态，见到了奇妙的物种，主角过于自信，拒绝了克劳福德，结束了这段神奇的故事，最终却发现自己还是错了。 《神殿》: 潜艇上可能因为异常导致船员心理异常(受到了伟大存在的召唤)，最终只有上尉在下沉中见到了传说中的“亚特兰蒂斯”，但潜艇里失去了光源，上尉逐渐也开始进入异常状态，似乎见到了之前死去的船员的尸体。 《猎犬》: 盗墓的故事，猜想是盗墓者在某个古墓唤醒了一个恐怖的存在？ 盗墓者拿走了一个与《死灵之书》有关的护身符，后面的结果可以想象了。最终选择逃往死之世界。 《乌撒之猫》: 乌撒的杀猫者终受到了超能者的报复的结局。 《无名之城》： 参考资料: (克苏鲁神话新手入门书单/豆瓣)[https://www.douban.com/note/581689161/]","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"克苏鲁","slug":"克苏鲁","permalink":"https://sean10.github.io/tags/克苏鲁/"},{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/科幻/"}]},{"title":"原计划更换markdown渲染引擎","slug":"更换markdown渲染引擎","date":"2017-07-01T09:01:14.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/07/01/更换markdown渲染引擎/","link":"","permalink":"https://sean10.github.io/2017/07/01/更换markdown渲染引擎/","excerpt":"","text":"前两天在写复习笔记的时候，发现渲染出的mathjax公式不像本地预览时显示的那样正常，含有_符号的都被渲染成了&lt;em&gt;标记，导致公式显示异常。网上推荐更换渲染引擎hexo-renderer-krame，虽然这个是fork出来特地解决了hexo-renderer-marked的这个问题的，但是同样，也修改了markdown的一些基本语法，在写行内公式时，就需要在$$外套上一层`符号，而我本地的预览使用的渲染引擎同样也会需要修改，这就比较麻烦了。 再进行了搜索，发现了一个据说非常强大的引擎pandoc，不过我在安装后，始终遇到以下错误。 INFO Start processing FATAL Something’s wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html Error: [pandoc warning] YAML header is not an object “source” (line 67, column 1) at ChildProcess. (/Users/sean10/Code/sean10.github.io/node_modules/hexo-renderer-pandoc/index.js:73:20) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:191:7) at maybeClose (internal/child_process.js:877:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:226:5) 经过搜查，这似乎属于pandoc解析时的错误，找到了以下类似内容。 See http://johnmacfarlane.net/pandoc/README.html#yaml-metadata-block There must be something in your document that looks like a YAML metadata block, but isn’t. Such a block would start with—on a line by itself and end with—or…on a line by itself. The line numbers in the error message refer to lines inside the metadata block, not to lines of the document. By the way, you can turn off YAML metadata block parsing entirely by putting 1--from markdown-yaml_metadata_block in your pandoc command line. 不过这个解决方法并没能解决问题，我换了一个思路。 后来想了想，是否可能是在渲染文章头部YAML格式时出现错误，导致后续的markdown就无法渲染了，所以可能是在文章内容上出现了问题，但是这个error信息没能显示具体文件，又没有日志，我决定二分排查是哪篇的错误。 很快就发现了，是最近写的Unix复习那篇的错误，在第67行，没有意识到错误所在，经过测试，发现问题是在于markdown的语法上，pandoc语法要求标题#前必须插入一空行，修改后终于成功渲染了。真是不容易。 Extension: blank_before_header 始 markdown 語法在標題之前並不需要預留空白行。Pandoc 則需要（除非標題位於文件最開始的地方）。這是因為以 # 符號開頭的情況在一般文字段落中相當常見，這會導致非預期的標題。例如下面的例子： I like several of their flavors of ice cream: 1#22, for example, and #5. 参考文献 parse yaml","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"},{"name":"markdown","slug":"markdown","permalink":"https://sean10.github.io/tags/markdown/"}]},{"title":"计算机系统结构复习note","slug":"计算机系统结构复习note","date":"2017-06-28T07:58:32.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/06/28/计算机系统结构复习note/","link":"","permalink":"https://sean10.github.io/2017/06/28/计算机系统结构复习note/","excerpt":"仅供参考~ 看到了，没记住是最悲剧的……","text":"仅供参考~ 看到了，没记住是最悲剧的…… 第一章 基础知识 系统结构的相关概念 计算机系统的层次结构概念 由硬件、软件和固件（被固化在ROM中的微程序）组成的复杂系统。 按语言功能（非组成）划分成多级层次结构: 硬件层(物理机):如果问几层的话还是去除L0硬件层 第0层：硬件 第1层：微程序（固件） 由微程序控制实现，逻辑程序员用微指令集编写，微程序由固件／硬件来解释。 第2层：机器语言机器(软硬件界面) 机器语言是指令系统，程序通过中央处理机由L1级微程序或L0级硬联逻辑进行解释 虚拟机: 第3层：操作系统机器 运行在L2级的操作系统级解释程序。 包括传统的机器指令(如算术、逻辑运算)及操作系统级指令(打开、关闭文件、读/写文件等) 与L2级指令相同由微程序解释 第4层：汇编语言机器 汇编语言程序，负责将上级语言翻译成L2和L3级语言，再由机器执行。完成汇编语言翻译的程序称为汇编程序 第5层：高级语言机器 语言：如C、C++、FORTRAN等。高级语言程序一般由称为编译程序的翻译到L4或L3级上。个别高级语言程序如Python等,采用解释方法实现，即用解释程序翻译到L4或L3级。 第6层：应用语言机器 语言：为满足某种用途而专门设计的面向问题的应用语言（使用超级计算机时优化用的语言吧)，由应用程序包翻译到L5级上 广义机器、虚拟机器、透明性、编译、解释 广义机器: 执行和存储程序的算法和数据结构的集合体 虚拟机器: 由软件实现的机器 透明性: 在计算机技术中，一种本来存在的事物或属性，但从某种角度看又好像不存在的概念称为透明性。通常底层机器的属性对于高层机器程序员来说是透明的。 编译: 转换程序将高一级机器上程序转换为低一级机器上的等效程序，然后在低一级机器上运行，实现程序的功能。 解释: 把高一级机器上的每一条语句，转换为低级机器上的一段等效程序并执行。执行完后，去高一级机器再取下一条语句或指令执行，如此反复，直到解释执行完整个程序。 计算机系统结构、组织和实现 计算机系统结构: 计算机系统的软、硬件的界面 计算机组成: 计算机系统结构的逻辑实现 计算机实现: 计算机组成的物理实现 具有相同系统结构的计算机可以采用不同的物理组成。 同一种物理组成又可以采用不同的计算机实现。 计算机系统分类方法 Flynn 分类法 按指令流和数据流的组织方式分类 * 单指令流单数据流（SISD）计算机系统：传统顺序处理计算机 * 单指令流多数据流（SIMD）计算机系统：阵列处理机 * 多指令流单数据流（MISD）计算机系统：未定 * 多指令流多数据流（MIMD）计算机系统：多处理机 系统分析技术 大概率事件优先原理 优先加速使用频率高的部件 此原理适用于资源分配、减灾防灾等 Amdahl定律、加速比定义 Amdahl定律可计算因改进某些部件而获得的系统性能的加速比, 也可用来确定系统中对性能限制最大的部件 程序访存的局部性原理 程序执行时所访问的存储器地址分布不是随机的 常用经验规则: 程序执行时间的90%都是在执行程序中10%的代码 可以根据程序最近的访问情况来比较准确地预测将要访问的指令和数据。凡是涉及数据重用的地方都可能会用到它。 CPU性能公式 CPU时间 \\[ CPU_{时间} = 执行程序所需的时钟周期数 \\times 时钟周期时间 \\] 时钟周期时间t(ns)是系统时钟频率的倒数 每条指令执行的平均时钟周期数CPI \\[CPI = \\frac{执行程序所需的时钟周期数}{IC}\\] IC：所执行的指令条数 则CPU时间可以写成下式 \\[CPU时间 = IC ×CPI ×时钟周期时间 \\] 性能评价标准 性能指标（CPU时间， CPI， MIPS,MFLOPS) MIPS 每秒百万条指令数 性能比较 执行时间 吞吐率 实例 1.11 假设浮点数指令FP指令的比例为30%，其中浮点数平方根FPSQR占全部指令的比例为4%, FP操作的CPI为5，FPSQR操作的CPI为20, 其他指令的平均CPI为1.25.现有两种改进方案，第一种是把FPSQR操作的CPI减至3, 第二种是把所有的FP操作的CPI减至3, 试比较两种方案对系统性能的提高程度。 答: 改进之前，系统指令平均时钟周期CPI为 \\[CPI=\\sum{(CPI_i \\times \\frac{I_i}{I_c})}=(5 \\times 30 % )+(1.25\\times70 %) = 2.375\\] 如果采用A方案：FPSQR操作的CPI减至3，则整个系统的平均时钟周期数为: \\[CPI_A=CPI-(CPI_{FPSQR}-CPI_{FPSQR}^{&#39;}) \\times 4 %=2.375-(20-3) \\times 4 %=1.695\\] 如果采用B方案：把所有的FP操作的CPI减至3，则整个系统的平均时钟周期数为： \\[CPI_B=CPI-(CPI_{FP}-CPI_{FP}^{&#39;})\\times4 %=2.375-(5-3)\\times30 %=1.775\\] 从降低整个系统的指令平均时钟周期数的程度来看，方案A要优于B。 另外，分别计算两种方案的加速比: \\[S_A=\\frac{改进前CPU的执行时间}{A的CPU执行时间}=(I_C\\times时钟周期\\times CPI)/(I_c \\times 时钟周期\\times CPI_A)=\\frac{CPI}{CPI_A}\\] \\[S_A=\\frac{2.375}{1.695}=1.4\\] \\[S_B=\\frac{2.375}{1.775}=1.34\\] 由此也可知，方案A优于方案B。 第三章 流水线技术 流水线的概念： 静（动）态流水线 单（多）功能流水线 线性流水线 流水线的各段串行连接，没有反馈回路。数据通过流水线中的各段时，每一个段最多只流过一次 非线性流水线 流水线中除了有串行的连接外，还有反馈回路 单功能与多功能流水线 （按照流水线所完成的功能来分类） 单功能流水线：只能完成一种固定功能的流水线。 多功能流水线：流水线的各段可以进行不同的连接，以实现不同的功能。 例： 多功能流水线：加、乘流水线 流水线表示方法–时空图 、连接图 {% image http://ww3.sinaimg.cn/large/006tNc79ly1fh1thpz1e8j312e0e440n.jpg '' '' %} 流水线特点：五段流水线（访存部件ME, 转移EX) ALU LOAD/STORE BRANCH(转移) IF 取指 ID 译码，读寄存器堆 EX 执行 计算访存有效地址 计算转移目标地址，设置条件码 MEM (空操作) 访问存储器(读或写) 若条件成立，将转移目标地址送PC WB 结果写回寄存器堆 将读写的数据写入寄存器堆 (空操作) 性能指标 ： 吞吐率、加速比、效率、 最佳段数 流水线相关与冲突及解决办法 数据相关（真数据相关）/名相关/控制相关 结构冲突、数据冲突、控制冲突： 数据冲突解决办法 控制冲突解决办法 多功能流水线时空图 吞吐率：在单位时间内流水线所完成的任务数量或输出结果的数量 {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh01ecrtzsj314k0ukdkz.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh01cbvdvbj314i0raadi.jpg '' '' %} {% image http://ww2.sinaimg.cn/large/006tKfTcly1fh01epwny8j315m0v2dor.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh01f334x0j314y0qigrb.jpg '' '' %} {% image http://ww2.sinaimg.cn/large/006tKfTcly1fh01bz7dutj316c0vk7e8.jpg '瓶颈问题' '' %} 加速比：完成同样一批任务，不使用流水线所用的时间与使用流水线所用的时间之比。 {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh01geo9ytj314g0ueq84.jpg '' '' %} {% image http://ww3.sinaimg.cn/large/006tKfTcly1fh01gotuqcj314s0tkgw9.jpg '' '' %} 流水线的效率：流水线中的设备实际使用时间与整个运行时间的比值，即流水线设备的利用率( 效率) {% image http://ww2.sinaimg.cn/large/006tKfTcly1fh01htdjp8j311e0fkac8.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh01i1kdgaj310k0n6acd.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh01iew0exj31580vmtim.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh01in2tv4j315u0p8teb.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh01ix845tj315e0sctg1.jpg '' '' %} 静态处理分支指令的基本方法： * 预测成功 * 延迟分支 降低流水线分支损失的方法有哪些？ （1）在流水线中尽早判断出分支转移是否成功； （2）尽早计算出分支转移成功时的PC值（即分支的目标地址） * “冻结”或“排空”流水线的方法 * 预测分支失败 * 预测分支成功 * 延迟分支 请对延迟分支办法中的三种调度策略进行评价。 1. 从前调动：分支必须不依赖于被调度的指令，总是可以有效提高流水线性能。 2. 从目标处调度：若分支转移失败，必须保证被调度的指令对程序的执行没有影响，可能需要复制被调度指令。分支转移成功时，可提高流水线性能。但由于复制指令，可能加大程序空间。 3. 从失败处调度：若分支转移成功，必须保证被调度的指令对程序的执行无影响。分支转移失败时，可提高流水线性能。 {% image http://ww2.sinaimg.cn/large/006tKfTcly1fh01a6ta51j316s0qgjvp.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh01ajhkxrj315m0psgoi.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh02vicb2cj31c00hoq4r.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh01b5j07zj30yk0hmq4o.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh02pfx12qj31840xq7bh.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh02rm0h07j30xg0g2wfw.jpg '' '' %} {% image http://ww2.sinaimg.cn/large/006tKfTcly1fh02rud2wzj315a0vagoe.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh02t7isdpj31940gejuk.jpg '' '' %} {% image http://ww3.sinaimg.cn/large/006tKfTcly1fh02tofxv1j316c0lejwd.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh02tuh1e8j317c0i0779.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh02wlha1qj31900u4gvd.jpg '' '' %} {% image http://ww3.sinaimg.cn/large/006tKfTcly1fh02wwrlr9j30zm02yjrx.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh032aoegij31640eg0yz.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh032jai5yj318u0p842u.jpg '预测分支' '' %} {% image http://ww3.sinaimg.cn/large/006tKfTcly1fh032pug9zj314k0mon4h.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh0qdynhf8j30x60dg0v7.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh0336nedfj313m0igjwb.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh033dgx53j31880w2k15.jpg '' '' %} {% image http://ww2.sinaimg.cn/large/006tKfTcly1fh033m66xdj317k0skdl4.jpg '' '' %} {% image http://ww3.sinaimg.cn/large/006tKfTcly1fh02y72c0tj311807ut9r.jpg '' '' %} {% image http://ww2.sinaimg.cn/large/006tKfTcly1fh02ye2nbbj317m0vak1b.jpg '' '' %} 命中Cache似乎不考 第四章 向量处理机 向量处理方法 横向处理: N次数据相关、2N次功能相关 纵向处理: 1次数据相关、1次功能相关 当向量长度超过寄存器长度N时，可分组处理 纵横处理: 组内纵向处理, 组间横向处理 适合“寄存器-寄存器结构”工作的向量处理机 向量流水处理机结构 存储器-存储器结构：纵向处理 占据一般存储器的3倍带宽，一个时钟周期内读入2个操作数并写回1个结果 延迟缓冲器 寄存器-寄存器结构：纵横处理 支持流水线链接技术 不遭遇向量Vi冲突和功能部件冲突，就都能并行工作 提高向量处理机性能的方法 多个功能部件的并行操作 链接技术 WD相关 链接技术：具有先写后读相关的两条指令，在不出现功能部件冲突和Vi冲突的情况下，可以把功能部件链接起来进行流水处理，以达到加快执行的目的。 空间方面约束条件 向量寄存器使用冲突 源寄存器冲突: 同时只能提供一个 结果寄存器冲突: 同时只能写一个 功能部件冲突 时间方面约束条件 前一条指令的第一个结果分量送入寄存器的那一个时钟周期方可链接 执行时间和寄存器长度必须相同 顺序执行时，一个向量的所有操作数执行完方才进行下一个向量的处理。而链接执行，就可以在一个向量的一个操作数得到结果后立即获得，对下一个向量立即进行处理。这样就可以免去等待第一个向量所有操作数完成运算的过程。 分段开采(循环开采) 流水线启动时间 多处理机系统结构 向量处理机性能的主要参数 一条向量指令的处理时间 执行一条向量长度为n的向量指令所需的时间: \\[T_{vp} = T_{s} + T_{e} + (n-1)T_{c}\\] {% image http://ww4.sinaimg.cn/large/006tNc79ly1fh125jxoi7j30xg06sdgh.jpg '' '' %} \\(T_s\\) : 流水线的建立时间为了使处理部件流水线能开始工作所需要的准备时间。 \\(T_e\\) : 向量流水线的通过时间第一对向量元素通过流水线并产生第一个结果所花的时间。 \\(T_c\\) : 流水线的时钟周期时间 {% image http://ww2.sinaimg.cn/large/006tNc79ly1fh13biyv2zj313o0tite3.jpg '一条指令' '' %} 上式转换为时钟周期个数 \\[T_{vp} = [s + e + (n-1)]T_c\\] 令 \\(T_{start} = s + e -1\\) , 则 \\[T_{vp} = (T_{start} + n)T_c\\] \\(T_{start}\\) : 向量指令的启动时间。产生第一个结果的前一个时钟周期数。 每秒多少个浮点运算结果（MFLOP或一个浮点运算的时间） \\[MFLOPS = \\frac{I_{FN}}{T_p \\times 1000000}\\] \\(I_{FN}\\) : 程序中浮点运算总次数 \\(T_p\\) : 执行程序时间 一组向量指令的处理时间 影响因素: 向量的长度 向量操作之间是否存在流水功能部件的使用冲突以及数据的相关性 数据的相关性 编队: 能在一个时钟周期内一起开始执行的几条向量指令 流水功能部件冲突 \\(V_i\\) 冲突 数据的相关性 编队后时间计算公式 \\[T_{all} = \\sum_{i = 1}^{m}{T_{vp}^{(i)}}\\] 当一个编队是由若干条指令组成时，其执行时间就是该编队中各指令的执行时间的最大值 一组向量指令、m个编队的处理时间 \\[T_{all} = \\sum_{i = 1}^{m}{T_{vp}^{(i)}} = \\sum_{i = 1}^{m}{(T_{start}^{(i)} + n)T_c} = (\\sum_{i = 1}^{m}{T_{start}^{(i)} + mn)}T_c = (T_{start} +mn)T_c\\] \\(T_{start}^{(i)}\\): 第i编队中各指令的启动时间的最大值 表示成时钟周期个数 \\[T_{all} = T_{start} + mn\\] 分段开采时一组向量指令的总执行时间(复习课件中未作为重点) 向量流水线的最大性能 \\(R_{\\infty}\\) {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh04cjh4x5j31360hu786.jpg '' '' %} 例题 {% image http://ww4.sinaimg.cn/large/006tNc79ly1fh138y1719j31380sogtx.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh0462gbr9j312u0iwad9.jpg '最大性能例题' '' %} 半性能向量长度 \\(n_{\\frac{1}{2}}\\) 半性能向量长度 \\(n_{\\frac12}\\) 是指向量处理机的性能为其最大性能的一半时所需的向量长度。 \\(n_{\\frac12}\\) 小表示流水线建立的时间少。 \\(n_{\\frac12}\\) 越小， 对给定的向量处理，流水线性能越好。反映为建立流水线而导致的性能损失。 {% image http://ww1.sinaimg.cn/large/006tNc79ly1fh1385ja86j314c0rqdnz.jpg '半性能长度计算' '' %} 长度向量临界值 \\(n_v\\)(同样不是重点) 实例 {% image http://ww3.sinaimg.cn/large/006tKfTcly1fh03iki4jij30ys0sqgry.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh03j2nkwdj310009adjg.jpg '' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh03ja3basj30ya0540tq.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh03jh18g4j30wu0pewhf.jpg '' '' %} {% image http://ww2.sinaimg.cn/large/006tKfTcly1fh03xko119j315q0s0jzk.jpg '' '' %} 题目补充：各功能部件的启动时间为：取数和存数部件为12个时钟周期、乘法部件为7个时钟周期，执行标量代码的开销 \\(T_{loop} = 15\\) 个时钟周期，对一个向量元素执行一次操作的时间Tg=一个时钟周期。 第五章 指令集并行 指令级并行度ILP 指令间存在的一种固有的并行性，计算机可以并行执行两条或两条以上的指令。 开发指令级并行度可以降低指令执行的平均周期数CPI 开发ILP的方法可以分为两大类 主要基于硬件的动态开发方法（动态调度） 记分牌动态调度算法 Tomasulo算法 基于软件的静态开发方法（静态调度） 记分牌(Scoreboard)算法 基本思想:记分牌硬件实现了对指令的动态调度。支持乱序执行，在没有结构冲突时尽早地执行没有数据冲突的指令，使多条指令同时处于执行阶段。 记分牌维护3张表： * 指令状态表 记录正在执行的各条指令已经到了哪一段 * 功能部件状态表 记录各个功能部件的状态。每个功能部件有一项，每一项由以下9个字段组成： * Busy：忙标志，指出功能部件是否忙。初值为“no”； * Op：该功能部件正在执行或将要执行的操作； * \\(F_i\\)：目的寄存器编号； * \\(F_j\\)，\\(F_k\\)：源寄存器编号； * \\(Q_j\\)，\\(Q_k\\)：指出向源寄存器 \\(F_j\\)、 \\(F_k\\)写数据的功能部件 ； * \\(R_j\\)，\\(R_k\\)：标志位，“yes”表示 \\(F_j\\)，\\(F_k\\) 中的操作数就绪且还未被取走。否则就被置为“no”。 结果寄存器状态表 指出哪个功能部件将把结果写入该寄存器 为了乱序执行，译码段ID分解成流出和读操作数 流出：指令译码，检查是否存在结构冲突。 读操作数：等待数据冲突消失，然后读操作数。 第3章的5段流水线局限性:只能按序流出(In-order Issue)和按序执行(In-order Execution) 每条指令的执行过程分为4段（主要考虑浮点操作） * 流出：如果当前流出指令所需的功能部件空闲，并且所有其他正在执行的指令的目的寄存器与该指令的不同，就向功能部件流出该指令，并修改记分牌内部记录表。 解决了WAW冲突 * 读操作数： 监测源操作数的可用性，如果数据可用，就从寄存器中读出源操作数并开始执行。 解决了RAW冲突，导致乱序执行。 * 执行： 取到操作数后，功能部件开始执行。当产生出结果后，就通知记分牌它已经完成执行。 在浮点流水线中，这一段要占用多个时钟周期。 * 写结果 执行前会检测是否存在WAR冲突 WAR冲突可能发生在以下情况: 1. 前面的某条指令（按顺序流出）还没有读取操作数；而且,其中某个源操作数寄存器与本指令的目的寄存器相同。 2. 在这种情况下，记分牌必须等待，直到该冲突消失。 {% image http://ww4.sinaimg.cn/large/006tNc79ly1fh158ngjffj30va0mmtck.jpg '记分牌MIPS处理器基本结构' '' %} 性能受限(不考) * 程序代码中可开发的并行性，即是否存在可以并行执行的不相关的指令。 * 记分牌的容量（寄存器大小？） 记分牌的容量决定了流水线能在多大范围内寻找不相关指令。流水线中可以同时容纳的指令数量称为指令窗口 * 功能部件的数目和种类 功能部件的总数决定了结构冲突的严重程度 * 反相关和输出相关 它们引起记分牌中WAR和WAW冲突。 Tomasulo算法 基本思想: * 通过分散控制处理数据相关和乱序执行。记录和检测指令相关，将发生RAW的可能性减少到最小 * 通过寄存器换名(通过保留站和流出逻辑实现)来消除WAR冲突和WAW冲突 {% image http://ww4.sinaimg.cn/large/006tNc79ly1fh16e0gi0cj315q0vm496.jpg '结构图' '' %} {% image http://ww2.sinaimg.cn/large/006tNc79ly1fh16fzm21aj30xy06gn0i.jpg '' '' %} 保留站：保存已经流出并等待到本功能部件执行的指令，在保留站通过流出逻辑来完成的寄存器换名（顺序流出，乱序执行） 公共数据总线CDB :所有功能部件计算结果都送到CDB，由它把这些结果直接送到各个需要该结果的地方（乱序完成） 具体算法（可选，暂时不看） 相关与流水线冲突 相关: 程序中指令之间的一种相互依赖关系。是程序固有的属性。 流水线冲突: 由于相关的存在，使得流水线指令流中的下一条指令不能在指定的时钟周期执行。 三种相关: * 数据相关 * 名相关 * 控制相关 三种流水线冲突: * 结构冲突 * 数据冲突 * 控制冲突 ##### 数据相关及其处理技术(其余相关都不是重点) 理想流水线的CPI加上各类停顿的时钟周期数： \\[CPI_{流水线} = CPI_{理想} + 停顿_{结构冲突} + 停顿_{数据冲突} + 停顿_{控制冲突}\\] IPC：Instructions Per Cycle(每个时钟周期完成的指令条数) \\[CPI = \\frac{1}{IPC}\\] 动态分支预测技术 分支历史表BHT 用二进制数10、11、01、00来表示转移预测状态的转换图 {% image http://ww3.sinaimg.cn/large/006tNc79ly1fh16otya5jj31160cqad1.jpg 'BHT状态转换' '' %} 从图中可以看出，只有连续两次预测错误，才会改变对分支去向的预测 优点: 转移预测提前到取指阶段。预测正确，则没有延迟损失。 缺点:仅提供转移目标指令信息,未提供转移目标指令地址信息。 所以它只有在以下情况下才有用: 判定分支是否成功所需的时间大于确定分支目标地址所需的时间。在前述5段流水线中，由于判定分支是否成功和计算分支目标地址都是在ID段完成的，所以BHT方法不会给该流水线带来好处。（用BHT时，上一条指令的EX在执行，分支预测的判定和取指是同时在进行的，判定时间(上一条指令的执行时间)更长时才可以保证存在开销减少的价值，否则预测成功，也是需要多花一个周期来进行译码） 预测不正确，则清除指令预取(队列)缓冲器。会产生延迟时间损失。 BHT方法可以同 I-cache（指令cache）结合起来 对于前述5段流水线来说，BHT方法是在ID段对BHT进行访问，所以在ID段的末尾，能够获得分支目标地址(在ID段计算出)、顺序下一条指令地址以及预测的结果。如果能再提前一拍，即在IF段就知道这些信息，那么分支开销就可以减少为0.BTB能够实现这一点。 （BHT方法不像静态分支预测技术会直接加载预测的分支指令地址，所以导致即便预测成功也需要一个时钟周期来取得地址） 分支目标缓冲器BTB（有时也称为分支目标Cache） 将分支成功的分支指令的地址和它的分支目标地址都放到一个缓冲区中保存 缓冲区以分支指令的地址作为标识 得到转移目标指令地址信息 {% image http://ww1.sinaimg.cn/large/006tNc79ly1fh17birrf6j30re0n2q7u.jpg '结构图' '' %} 流水线各阶段进行的操作 {% image http://ww2.sinaimg.cn/large/006tNc79ly1fh17k44ua3j31560pcq93.jpg '' '' %} 超标量处理机 在每个时钟周期内流出多条指令， CPI＜1 在每个时钟周期流出的指令条数不固定,但有上限，依代码的具体情况而定。 设这个上限为n，就称该处理机为n-流出(发射)。 可以通过编译器进行静态调度，也可以基于Tomasulo算法进行动态调度。 超流水线处理机 将每个流水段进一步细分，这样在一个时钟周期内能够分时流出多条指令。这种处理机称为超流水线处理机。 对于一台每个时钟周期能流出n条指令的超流水线计算机来说，这n条指令不是同时流出，而是每隔1/n个时钟周期流出一条指令。 实际上该超流水线计算机的流水线周期为1/n个时钟周期。 超长指令字（VLIW)处理机 在每个时钟周期流出的指令条数是固定的，这些指令构成一条长指令或者一个指令包。 指令包中，指令之间的并行性是通过指令显式地表示出来的。 指令调度是由编译器静态完成的。 流水线时空图必考。 超标量流水线调度策略及时空图 1.按序流出按序完成；2.按序流出无序完成；3.无序流出 第1条是无调度 第2条是动态调度，考上述的记分牌算法吧 第3条可能是考多流出技术 实例 记分牌算法中，记分牌中记录的信息由哪三部分构成 答: 指令状态表、功能部件状态表、结果寄存器状态表 动态分支预测技术 5.6 给出采用分支目标缓冲器(BTB)后，在流水线三个阶段(IF段、ID段、EX段）所进行的相关操作有哪些？ {% image http://ww3.sinaimg.cn/large/006tKfTcly1fh0pdjh6x9j31520pajxj.jpg '' '' %} {% image http://ww1.sinaimg.cn/large/006tKfTcly1fh0q8osu6vj317e0x0gw0.jpg '5.8 分支延迟' '' %} {% image http://ww4.sinaimg.cn/large/006tKfTcly1fh0q9lysb7j316a0weai9.jpg '5.9 ' '' %} {% image http://ww3.sinaimg.cn/large/006tKfTcly1fh0qgt6xhnj30zq0osadj.jpg '画超标量处理机时空图' '' %} {% image http://ww2.sinaimg.cn/large/006tKfTcly1fh0qh9ohspj30ya0zead2.jpg '' '' %} 第九章 互联网络 互连网络相关概念 分类 静态互联网络 动态互联网络 总线网络 多级互连网络 交叉开关网络 三大要素：互连结构、开关元件、控制方式 特征 拓扑结构 静态 动态 控制策略 集中式 分布式 定时方式 同步 异步 交换方法 线路交换 分组交换 互联函数 基本互联函数 恒等函数 交换函数 实现二进制地址编码中第k位互反的输入端与输出端之间的连接。 主要用于构造立方体和各种超立方体互连网络。 它共有 \\(n = log_{2}{N}\\) 种互联函数。（N为结点个数） 例子： 当N＝8时，n＝3，可得到常用的立方体互连函数: \\[Cube_{0}(x_{2}x_1x_0) = x_2x_1\\overline{x_0}\\] \\[Cube_{1}(x_{2}x_1x_0) = x_2\\overline{x_1}x_0\\] \\[Cube_{2}(x_{2}x_1x_0) = \\overline{x_2}x_1x_0\\] 均匀洗牌函数 将输入端分成数目相等的两半，前一半和后一半按序一个隔一个，从头依次与输出端相连，类似洗牌方式 \\[\\sigma(x_{n-1}x_{n-2}\\cdots x_1x_0) = x_{n-2}x_{n-3}\\cdots x_1x_0x_{n-1}\\] 逆均匀洗牌函数 将输入端的二进制编号循环右移一位而得到所连接的输出端编号。 蝶式函数 蝶式互连函数：把输入端的二进制编号的最高位与最低位互换位置，便得到了输出端的编号 \\[\\beta(x_{n-1}x_{n-2}\\cdots x_2x_1x_0) = x_0x_{n-2}\\cdots x_1x_{n-1}\\] 均匀洗牌，蝶式函数不能单独实现任意结点间互连。它们与交换函数多级组合是构成复杂多级网络的基础 反位序函数 将输入端二进制编号的位序颠倒过来求得相应输出端的编号。 \\[\\rho(x_{n-1}x_{n-2}\\cdots x_1x_0) = x_0x_1\\cdots x_{n-2}x_{n-1}\\] 移数函数 将各输入端都错开一定的位置（模N）后连到输出端。 \\[\\alpha(x) = (x\\pm k)mod N\\] \\[1\\leqslant x\\leqslant N-1, 1\\leqslant k\\leqslant N-1\\] PM2I移数函数(重点) 该函数又称为“加减 \\(2^i\\)”函数 \\[ PM2\\_{+i}(x) = (x +2^i)mod N\\] \\[ PM2\\_{-i}(x) = (x -2^i)mod N\\] \\[ 1\\leqslant x\\leqslant N-1, 1\\leqslant i\\leqslant n-1, n=log\\_2N\\] PM2I共有2n个互联函数(怎么算出来的?) 实质为1,2,4个环型网（环形网是什么） 移数函数可构成环型网(单向环网、双向环网)、方格网、移数网 互联网络的结构参数 网络参数 : 网络规模、 结点度、 距离、直径，等分宽度（重点) 网络规模N：网络中结点的个数。 结点度d：与结点相连接的边数（通道数），包括入度和出度。 进入结点的边数叫入度。 从结点出来的边数叫出度。 结点距离：对于网络中的任意两个结点，从一个结点出发到另一个结点终止所需要跨越的边数的最小值。 网络直径D：网络中任意两个结点之间距离的最大值。 网络直径应当尽可能地小。 等分宽度b：把由N个结点构成的网络切成结点数相同（N/2）的两半，在各种切法中，沿切口边数的最小值。 线等分宽度：B＝b×w 其中：w为通道宽度（用位表示） 该参数主要反映了网络最大流量。 互联网络的性能指标 评估互连网络性能的两个基本指标：时延和带宽 * 通信时延 指从源结点到目的结点传送一条消息所需的总时间 * 软件开销：在源结点和目的结点用于收发消息的软件所需的执行时间 * 通道时延：通过通道传送消息所花的时间。 * 选路时延：消息在传送路径上所需的一系列选路决策所需的时间开销 * 竞争时延：多个消息同时在网络中传送时，会发生争用网络资源的冲突。为避免或解决争用冲突所需的时间就是竞争时延。 * 网络时延 通道时延与选路时延的和 * 端口带宽 对于互连网络中的任意一个端口来说，其端口带宽是指单位时间内从该端口传送到其他端口的最大信息量。 * 聚集带宽 网络从一半结点到另一半结点，单位时间内能够传送的最大信息量。 * 等分带宽 与等分宽度对应的切平面中，所有边合起来单位时间所能传送的最大信息量。 互联网络 典型互联网络:立方体型 和Illiac网，Omega网络（混洗函数）（重点） ##### 典型静态互联网络 * 线性阵列 * 环和带弦环 * 循环移数网络 * 树形和星形 * 胖树形 * 网格形和环网形 * Illiac网络 * 超立方体 * 带环n-立方体 * k元n立方体 {% image http://ww1.sinaimg.cn/large/006tNc79ly1fh1doxascvj313q0t8aic.jpg '' '' %} 动态互联网络 由交换开关构成的互联网络，可按运行程序的要求改变网络的连接状态 特点： * 网络中开关元件可以控制（有源）。 * 链路可通过设置开关的状态来重构。 * 网络边界上的开关元件可与处理机相连。 总线网络 交叉开关网络 多级互联网络的构成 MIMD和SIMD计算机都采用多级互连网络MIN（Multistage Interconnection Network） 一种通用的多级互连网络 * 由a×b开关模块和级间连接构成的通用多级互连网络结构 * 每一级都用了多个a×b开关 * 相邻各级开关之间都有固定的级间连接 各种多级互连网络的区别在于所用开关模块、控制方式和级间互连模式的不同。 * 控制方式：对各个开关模块进行控制的方式。 * 级控制：每一级的所有开关只用一个控制信号控制，只能同时处于同一种状态。 * 单元控制：每一个开关都有一个独立的控制信号，可各自处于不同的状态。 * 部分级控制：第i级的所有开关分别用i＋1个信号控制，0≤i≤n－1，n为级数。 * 常用的级间互连模式 * 均匀洗牌、蝶式、多路洗牌、纵横交叉、立方体连接等 多级立方体网络 多级立方体网络包括STARAN网络和间接二进制n方体网络等。 * 两者仅在控制方式上不同，在其他方面都是一样的。 * 都采用二功能（直送和交换）的2×2开关。 * 当第i级（ \\(0\\leqslant i\\leqslant n-1\\) ）交换开关处于交换状态时，实现的是 \\(Cube_i\\) 互连函数。 一个N输入的多级立方体网络有 \\(log_2N\\) 级，每级用 \\(\\frac N2\\) 个2×2开关模块，共需要 \\(log_2N\\times\\frac {N}{2}\\) 个开关。 一个8个入端的多级立方体网络 {% image http://ww2.sinaimg.cn/large/006tNc79ly1fh1e0cszsgj30zk0liadb.jpg '' '' %} STARAN网络采用级控制和部分级控制。 * 采用级控制时，所实现的是交换功能； * 采用部分级控制时，则能实现移数功能。 间接二进制n方体网络则采用单元控制。 * 具有更大的灵活性。 Omega网络 一个8×8的Omega网络 * 每级由4个4功能的2×2开关构成 * 级间互连采用均匀洗牌连接方式 {% image http://ww2.sinaimg.cn/large/006tNc79ly1fh1em87ixaj30so0hcwgp.jpg '' '' %} 一个N输入的Omega网络（重点） * 有 \\(log_2N\\) 级，每级用 \\(\\frac N2\\)个2×2开关模块，共需要 \\(\\frac N2log_2{N}\\) 个开关。 * 每个开关模块均采用单元控制方式。 * 不同的开关状态组合可实现各种置换、广播或从输入到输出的其它连接。 动态互联网络的比较 {% image http://ww4.sinaimg.cn/large/006tNc79ly1fh1e295ct6j31300kwdmq.jpg '' '' %} 消息传递机制（重点） 当源结点和目的结点之间没有直接的连接时，消息需要经过中间的结点进行传递。寻径就是用来实现这种传递的通信方法和算法。有的称之为路由 路由选择和消息传递方法式: 线路交换和包交换（存储转发，虚拟直通、虫孔方式） * 线路交换：在传递信息之前，先建立一条从源结点到目的结点的物理通路( 所需时间 Lt ×（D+1）/B)，然后再传递信息( 所需时间 L/B) 。包经中间结点时,包无需存储 {% image http://ww1.sinaimg.cn/large/006tNc79ly1fh1e9ptgbwj30o80c476a.jpg '' '' %} * 优点：包经中间结点时,包无需存储，实际通信时间较短，使用缓冲区少. 适合于具有动态和突发性的大规模并行处理数据的传送。 * 缺点： 1. 物理通道非共享。传输过程中通道一直占用。 2. 若频繁建立源到目的结点的通路，时间开销大 * 存储转发：最简单的分组交换方式。 * 存储转发中，包是信息传递的基本单位。包从源结点经过一系列中间结点到达目的结点。 * 要求：包经过的每个中间结点都要设置一个包缓冲器。当一个包到达某个中间结点时，该结点先把这个包全部存储起来，然后在出口链路可用、而且下一个结点的包缓冲器也可用的情况下，传递给下一个结点。 * L为消息包的长度 * 存储转发中网络时延与源和目的地距离成正比. * 第一代多计算机系统常采用存储转发方式 * 缺点： 1. 包缓冲区大，不利于VLSI实现； 2. 网络时延大，与结点距离成正比。 * 虚拟直通: 为减少存储转发中 包存储的时延较大，包不必全部存入缓冲后再做路由判断，只要接收到用作寻径信息（头部），即进行路由选择。 1. 如果结点的输出链路空闲，包立即转送到下一个结点。如果整个通路都空闲，包直达目的结点，如同线路交换 2. 如果没有空闲链路时或出现寻径阻塞时，须将整个信息全部存储在寻径结点中。等同存储转发。 * 缺点： 1. 每个结点中需要有缓冲。以便没有空闲链路时，要用缓冲器存储。 2. 包缓冲区大，不利于VLSI实现； * 虫孔(wormhole)方式 为减少存储转发中包的存储时延，包可分为更小的“片” 。当一个结点把头片送到下一结点后，后面的各个片也依次送出。 * 特点：包不必全部存入缓冲后再做路由判断，只要接收到用作寻径信息（头片），即进行路由选择。 * 结点中缓冲器的容量小，各片的传送可按流水方式进行。传输延迟略大于线路交换，网络冲突较小。 * 一个结点一旦开始传送一个包中的头片后，必须等待这个包所有片都送出后，才能传送其他包。不同包的片不能混合在一起传送。 * 在新型的多计算机系统中得到了广泛的应用。 * 与虚拟直通的不同之处 当输出通路忙时，结点是把一个片存储到缓冲器中。 片的大小比包小很多，所以能有效地减少缓冲器的容量，使得它易于用VLSI实现。 存储转发与虫孔方式的时间比较 死锁与虚拟通道 流量控制策略 包冲突的解决 通过通道在两个相邻结点之间传送一个片，要同时具备3个条件： 源缓冲区已存有该片； 通道已分配好； 接收缓冲区准备接收该片。 当两个包到达同一个结点时，可能都在请求同一个接收缓冲器或者同一个输出通道，这时必须对两个问题进行仲裁。 4种解决方案 后一个包暂存(在缓冲区) 优点:不会浪费已经分配了的资源，但要求结点中有一个足够大的缓冲器来存放整个信息包。 阻塞后一个包 第一个包送入片缓冲区，用门控拒绝第二个包（阻塞）。不丢弃。 丢弃后一个包 第一个包送入片缓冲区。 有可能会造成严重的资源浪费，而且要求重新进行被丢弃包的传输与确认。 后一个包绕道 在包寻径方面有更多的灵活性，但为了到达目的结点，可能要花费 较多的通道资源，造成浪费。 确定性寻径和自适应寻径 确定性寻径：通信路径完全由源结点地址和目的地址来决定，也就是说，寻径路径是预先唯一地确定好了的，而与网络的状况无关。 自适应寻径：通信的通路每一次都要根据资源或者网络的情况来选择。 对于二维的网格网络来说，这种寻径方法被称为X-Y寻径。 先沿X维方向进行寻径，然后再沿Y维方向寻找路径。 对于超立方体来说，这种寻径方法被称为E-cube寻径。 通信模式 单播：对应于一对一的通信情况，即一个源结点发送消息到一个目的结点。 选播：对应于一到多的通信情况，即一个源结点发送同一消息到多个目的结点。 广播：对应于一到全体的通信情况，即一个源结点发送同一消息到全部结点。 会议：对应于多到多的通信情况。 通道流量和通信时延是常用的两个参数 * 通道流量用传输消息所使用的通道数来表示。 * 通信时延用包的最长传输时间来表示。 优化寻径网络以最小通道流量或通信时延为目标。 实例 混洗交换题计算方法: 在混洗交换网络中，最远的两个入、出端号 是全 “0” 和 全“1”, 它们的连接需要 n 次交换 和n-1 次混洗。 所以其 最大距离为2n - 1. 在有8个处理器的混洗交换网络中，若要使第0号处理器与第7号处理器相连，需要经过2次混洗和 \\(\\underline{3}\\) 次交换 在有16个处理器的混洗交换网络中，若要使第0号处理器与第15号处理器相连，需要经过多少次混洗和交换 答：3次混洗和4次交换 设Cube为立方体互联函数， \\(\\sigma\\) 为均匀洗牌函数， \\(\\beta\\) 为蝶式函数， \\(\\rho\\) 为反位序函数，分别求 \\(Cube_{3}(0110)\\) 、 \\(\\sigma_{(3)}(0110)\\) 、 \\(\\beta(0110)\\) 、 \\(\\rho^{(2)}(0110)\\) . 答: * \\(Cube_3(0110) = 0010\\) * \\(\\sigma_{(3)}(0110) = 0101\\) * \\(\\beta(0110) = 0110\\) * \\(\\rho^{(2)}(0110) = 1010\\) 9.11 N=16的STARAN网络在级控制方式下实现分组交换置换，如果实现的分组交换置换是：首先是4组4元交换，然后是2组8元交换，最后是1组16元交换，写出网络实现的互联函数。 9.12 具有 \\(N=2^n\\) 个输入端的Omega网络，采用单元控制。 (1) N个输入总共应有多少种不同的排列？ (2) 该Omega网络通过一次可以实现的置换总共可有多少种？ (3) 若N=8, 计算一次通过能实现的置换数占全部排列的百分比。 答: (1) N个输入可有N!种不同排列。 (2) 该Omega网络通过一关可以实现的置换有 \\(2^{\\frac{N}{2}log_2N}=N^{\\frac{N}{2}}\\) 种不同。 (3) 若N=8, 通过Omega网络一次可以实现的不重复置换有 \\(8^4 = 4096\\) 种。 8个输入可实现的不重复排列有 \\(8! = 40320\\) 种。 故，一次可实现的置换数占全部排列数的10.16%. Omega网络 第十章 多处理机 多处理机概念: 由若干台独立的计算机或处理机(CU或PU)组成，每台计算机能独立执行自己程序。不同于并行处理机。 多个指令部件控制，统一操作系统，实现指令级以上(任务级、作业级）并行。MIMD结构。 多处理机通过互连网络连接，以共享某种设备（主存、输入输出或网络）方式，实现程序间数据交换和同步。 算法上，开发、挖掘和实现更多通用算法中隐含的并行性；不限于向量数组处理. 依靠软件手段解决资源分配和管理问题，特别是处理机管理和进程调度等。 MIMD计算机的特点、分类 Flynn分类法 SISD、SIMD、MISD、MIMD MIMD已成为通用多处理机系统结构的选择，原因： MIMD具有灵活性； MIMD可以充分利用商品化微处理器在性能价格比方面的优势。 计算机机群系统（cluster）是一类广泛被采用的MIMD机器。 根据存储器的组织结构 ，把现有的MIMD机器分为两类 （每一类代表了一种存储器的结构和互连策略） * 集中式共享存储器结构 * 最多由几十个处理器构成。 * 共享一个集中式的物理存储器。 * 分布式存储器多处理机（DSM) * 存储器在物理上是分布的。 * 非均匀访存模型，NUMA。 多处理机一致性问题 Cache的一致性问题和原因 允许共享数据进入Cache，就可能出现多个处理器的Cache中都有同一存储块的副本， 当某个处理器对其Cache中的数据进行修改后，会使得其Cache中的数据与其他Cache中的数据不一致。 例 由两个处理器（A和B）读写引起的Cache一致性问题 存储器的一致性 如果对某个数据项的任何读操作均可得到其最新写入的值，则认为这个存储系统是一致的。 单处理机系统中，Cache一致性问题存在于Cache与主存之间，可通过全写法（write－through，写直达，写通过）解决。 全写法：同时修改Cache和主存中值(或策略)。回写法：仅修改Cache值，不立即修改主存。 全写法只能维持一个Cache和主存之间的一致性，不能更新其他处理机中的Cache的相同副本。 解决Cache一致性问题是多处理机的重要问题。 实现一致性的基本方案 在一致的多处理机中，Cache提供迁移、复制两种功能： 共享数据的迁移：把共享数据拷贝后迁入本地Cache 减少了对远程共享数据的访问延迟，也减少了对共享存储器带宽的要求。 共享数据的复制：把共享数据多个副本拷放在多个处理器Cache 不仅减少了访问共享数据的延迟，也减少了访问共享数据所产生的冲突。 一般情况下，小规模多处理机是采用硬件的方法来实现Cache的一致性。 Cache一致性协议 在多个处理器中用来维护一致性的协议。 * 关键：跟踪记录共享数据块的状态 * 两类协议（采用不同的技术跟踪共享数据的状态） * 目录式协议（directory）： 存储器数据块的共享状态被保存在一个称为目录的地方 * 监听式协议（snooping） 处理机向局部Cache 写数据通过总线广播，其他处理机对广播的写事务进行监视，如果某Cache中有数据副本，用写作废或写更新处理. 采用两种方法来解决Cache一致性问题。 写作废协议 在处理器对某个数据项进行写入之前，作废其它的副本(保证它拥有对该数据项的唯一的访问权) 写更新协议 当一个处理器对某数据项进行写入时，通过广播使其它Cache中所有对应于该数据项的副本进行更新。 监听协议的实现 监听协议的基本实现技术 实现监听协议的关键有3个方面 处理器之间通过一个可以实现广播的互连机制相连。 通常采用的是总线。 当一个Cache响应本地CPU的访问时，如果涉及到全局操作，就在总线上发出相应的消息。 所有处理器都一直在监听总线，它们检测总线上的地址在它们的Cache中是否有副本。若有则响应，并进行相应的操作 。 Cache发送到总线上的消息主要有以下两种： RdMiss——读不命中 WtMiss——写不命中 需要通过总线找到相应数据块的最新副本，然后调入本地Cache中。 写直达Cache：因为所有写入的数据都同时被写回主存，所以从主存中总可以取到其最新值。 对于写回Cache，得到数据的最新值会困难一些，因为最新值可能在某个Cache中，也可能在主存中。 （后面的讨论中，只考虑写回法Cache） 目录协议的基本思想 监听一致性协议的可扩放性很差 主存中设置一个中央目录，存放每个数据块状态位和指针位（位向量） ，指针位对应处理机Cache 。 目录：一种集中的数据结构。对于存储器中的每一个可以调入Cache的数据块，在目录中设置一条目录项，用于记录该块的状态以及哪些Cache中有副本等相关信息。 任何一个数据块，都可以在目录表唯一的一个位置中找到相关的信息。使一致性协议避免了广播操作 状态位指示数据块状态，指针位（位向量）指向处理机Cache ，指出Cache中是否有数据块副本。 当一个处理机写入本身Cache时，根据目录表有选择地通知存有数据块的处理机的Cache。避免Cache不一致性 目录协议的三种结构 不同目录协议的主要区别主要有两个 所设置的存储器块的状态及其个数不同 目录的结构 目录协议分为3类 全映象目录、有限映象目录、链式目录 多处理机分类 按多处理机之间物理连接的紧密程度与交互作用能力强弱 紧耦合系统 松耦合系统 按处理机结构 同构型多处理机系统 异构型多处理机系统 按系统组成结构 并行向量处理机(PVP) 对称多处理机(SMP) 分布共享存储器多处理机(DSM) 大规模并行处理机(MPP) 工作站机群(COW) 五类机器特征比较 按存储器组织结构 集中式共享存储器结构(SMP) 分布式存储器结构（DSM) 第十三章 阵列处理机 阵列处理机 多处理单元(PE)按照一定互连方式，在同一控制部件(CU) 控制下，对各自数据完成同一条指令规定的操作。 * 从CU看，指令串行执行。 * 从PE 看，数据并行处理。 * 属于单指令流多数据流结构(SIMD)。细粒度并行处理机 * 应用领域：主要用于高速向量或矩阵运算。 操作模型 阵列处理机的操作模型可用五元组表示 阵列处理机＝（N，C，I，M，R） * N：机器的处理单元（PE）数。 例如：Illiac Ⅳ计算机有64个PE MP-1计算机有16384个PE * C：控制部件CU直接执行的指令集，包括标量指令和程序流控制指令。 * I：由CU广播至所有PE进行并行执行的指令集。 包括算术运算、逻辑运算、数据寻径、屏蔽以及其他由每个PE对它的数据所执行的局部操作。 * M：屏蔽方案集 每种屏蔽将所有PE划分成允许操作和禁止操作两种工作模式。 * R：数据寻径功能集 说明互连网络中PE间通信所需要的各种设置模式。 阵列处理机的结构 分布式存储器的阵列机: 含有多个相同的处理单元PE，每个PE有各自的本地存储器LM。 PE之间通过数据寻径网络以一定方式互相连接。它们在阵列控制部件的统一指挥下，实现并行操作。 指令的执行顺序基本上是串行进行的。 程序和数据是通过主机装入控制存储器。 共享存储器的阵列机: 集中设置存储器 共享的多体并行存储器SM通过对准网络与各处理单元PE相连。 存储模块的数目等于或略大于处理单元的数目。 必须减少存储器访问冲突 （将数据合理地分配到各存储器模块中 ） 在处理单元数目不太多的情况下是很理想的 所有阵列指令都必须使用长度为n的向量操作数 （n为PE的个数) 阵列处理机的特点(与流水线向量对比) * 阵列机是以单指令流多数据流方式工作的 * 阵列机是通过设置多个相同的处理单元来开发并行性的，它利用并行性中的同时性，而不是并发性。所有处理单元必须同时进行相同的操作。这与利用时间重叠的向量流水处理机是不一样的。 * 阵列机是以某一类算法为背景的专用计算机。这是因为阵列机通过都采用简单，规整的互联网络来实现处理单元间的连接操作，从而限定了它所使用的求解算法类别。 * 阵列机的研究必须与并行算法的研究密切结合，以便能充分发挥它的处理能力。 * 阵列机的控制器实质上是一台标量处理机，而为了完成I/O操作以及操作系统的管理，尚需一个前端机。因此实际的阵列机系统是由上述三部分构成的一个异构型多处理机系统。 SIMD机与并行算法的关系 以Illiac Ⅳ为例，讨论阵列处理机的算法。 解有限差分方程（需要知道大致含义） 把一个有规则的网格覆盖在整个场域上，用网格点上的变量值写出差分方程组以代替场方程来进行计算。 描述平面场的拉普拉斯方程 差分法求解的精度与网格间距有直接的关系，网格越小，精度越高，但求解所花费的时空开销越大。 Illiac Ⅳ在计算时，是把内部网格点分配给各个处理单元的。因此，上述计算过程可以并行地完成，从而大幅度地提高处理速度。 矩阵加 矩阵乘 设A、B和C为3个8×8的二维矩阵。若给定A和B，则 C＝A*B的64个分量可利用下列公式计算。 \\[c_{ij} = \\sum_{k=0}^{7}{a_{ik}b_{kj}}\\] \\[0 \\leqslant i,j \\leqslant 7\\] FORTRAN 程序 12345DO 10 I＝0，7 DO 10 J＝0，7 C（I，J）＝0 DO 10 K＝0，7 10 C(I，J) ＝C(I，J)＋A(I，K)*B(K，J) 在SISD计算机上求解，三重循环，每重循环执行8次，共需512次乘加的时间 在SIMD阵列处理机上求解这个问题 执行下列FORTRAN程序： 1234DO 10 I＝0，7 C（I，J）＝0 DO 10 K＝0，7 10 C(I，J) ＝C(I，J)＋A(I，K)*B(K，J) 速度提高到原来的8倍，即每个处理单元的计算时间缩短为64次乘加时间。 递归折叠求和算法 一个将N个数的顺序相加转变为并行相加的问题。 取N＝8。即有8个数A（I）要顺序累加（0≤I≤7） 这是一个串行程序，共要进行8次加法。 在阵列处理机上采用成对递归相加的算法，则只需 \\(log_28＝3\\) 次加法 。 实例 阵列处理机操作模型可以用5元组表示:阵列处理机=(N, C, I, M, R), 简述其中N、C、I、M、R的含义。 答:N为极其的处理单元(PE)数； C为控制部件CU I为由CU广播至所有PE进行并行执行的指令集 M为屏蔽方案集，其中每种屏蔽将所有PE划分成允许操作和禁止操作两种模式 R为数据寻径功能机，说明互联网络中PE间通信所需要的各种设置模式 13.3 简述阵列处理机的特点 答： 1. 阵列机是以单指令流多数据流方式工作的。 2. 阵列机是通过设置多个相同的处理单元来开发并行性的，它利用并行性的同时性，而不是并发性 3. 阵列机是以某一类算法为背景的专用计算机 4. 阵列机的研究必须与并行算法的研究密切结合 5. 阵列机的控制器实质上是一台标量处理机 试分析与比较SIMD计算机与向量计算机的相同与不同 答: 相同点: 都能对大量数据进行向量处理 不同点: * SIMD获得高处理速度主要是采用资源重复的并行措施 * 各个处理单元并行工作 * 向量处理机依靠的是多功能流水线部件时间重叠，指高速度 * 另一区别是SIMD计算机有它的互联网络 简述SIMD计算机的分布式存储器与共享存储器的异同 答: 相同点: 都存在互联网络 不同点: * 在共享方案中，共享的多体并行存储器通过对准网络与各处理单元相连 * 在分布内存方案中，每个处理单元有自己的本地存储器，处理单元之间的数据通过数据寻径网络完成。 存储器 这道题，推算体号地址公式的知识点不在我们书上，理论上，我们应该只能一个个尝试填表。 **例1．试分别在下面两种计算机系统上用最短的时间来计算表达式s=A1B1+A2B2+…A32*B32。假设加法和乘法分别需要两个和四个单位时间，从存储器取指令、取数据、译码的时间忽略不计，所有的指令和数据已装入有关的PE。试确定下列每种情况的最小计算时间：（重点，必考） 1. 一台SISD串行计算机。 2. 一台有8个PE的SIMD计算机，8个PE用移数函数PM2I连接。每个PE用一个单位时间可以把数据直接送给它的相邻PE。操作数Ai和Bi最初存放在PEi mod 8中，其中i=1，2，…，32。每个PE可在不同时刻执行加法或乘法** 答: 1. 在SISD计算机中,需要32次乘法和31次加法。 共需要时间：T=432+231=190单位时间 在SIMD计算机上计算的算法： 假定向量中的32对元素平均地分配到8个处理器中，每个处理器分配4对，则每个处理器计算时间为 44+32 总时间 =每个处理器计算时间+递归折叠求和算法 T=44+32+1+2+1+2+1+2=31","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"系统结构","slug":"系统结构","permalink":"https://sean10.github.io/tags/系统结构/"}]},{"title":"Unix编程环境复习笔记","slug":"Unix编程环境复习笔记","date":"2017-06-27T06:36:03.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/06/27/Unix编程环境复习笔记/","link":"","permalink":"https://sean10.github.io/2017/06/27/Unix编程环境复习笔记/","excerpt":"关于shell内的圆括号的问题，圆括号不是本来就在shell中作与操作吗，为什么还要用转义符转义才能在find中用？ 难道说如果不用转义符，其优先级会更高？导致会报错误？姑且先这么记吧。 check: 括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用","text":"关于shell内的圆括号的问题，圆括号不是本来就在shell中作与操作吗，为什么还要用转义符转义才能在find中用？ 难道说如果不用转义符，其优先级会更高？导致会报错误？姑且先这么记吧。 check: 括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用 检索目录src以及其子孙目录中的所有文件名后缀为.c和.h文件，查找哪些文件中含有字符串TPDU，并列出在这文件中的行号。 答：使用find命令和grep命令。find命令可以在指定的目录树 中查找满足某个条件的文件或目录，并对查找到的满足条件的对象执行一个动作。指定查找条件为“文件名后缀为.c和.h”，动作为“查找哪些文件中含有字符串TPDU，并列出在这文件中的行号”，分别是find的-name和-exec选项。完整的命令为： 1find src –name &quot;*.[ch]&quot; –exec grep –n TPDU &#123;&#125; /dev/null \\; 这里是将grep的数据输出到/dev/null作为垃圾处理吧，但不用&gt;重定向符了？ 统计出由用户liu创建并且正在运行的进程数目。 答：使用ps命令列表出系统中所有进程，过滤后仅保留用户liu创建的进程（用grep），每个进程占一行，用wc命令统计一共有多少行即可。 ps –ef | grep liu | wc –l 这里我感觉也可以用ps -ef -u liu | wc -l来替换吧，但是跑出来结果却不同，看来是进程创建者和使用者不同概念，-u只能检索出使用者。 去掉文件list.txt中的所有空行(所谓空行指：行内不含有任何除空格之外的字符)，存为新文件list-new.txt。 答：使用grep命令可以用正则表达式对文本文件过滤，-v选项用于筛选掉能匹配指定正则表达式的行，描述一个空行的正则表达式为^ *$，即：从行首开始(^)，有零个到多个空格( *)，然后是行尾($)，命令为： grep –v ’^ *$’ list.txt &gt; list-new.txt 为什么我man grep得到的是–invert-match，显示不匹配的部分呢？，grep实际使用中不需要-v就能识别正则吧。 增量备份 cp -ur test test.bak 不过我实际操作找不到-u，google用的人也不多，都用rsync LINUX文件权限设计为简单的三级控制，用户liu对用户sun的文件data.txt要么具有全部的读权限，要么不可以读。因此，没有办法限制liu只对文件的指定部分读。 答：错误。可以利用SUID权限，用户sun将文件data.txt的读写权限设置为rw——-，由文件所有者sun自己编写程序以实现对文件的访问，程序中的访问当然可以限制只对文件的指定部分读，但是该程序文件的属性应当为rws–x–x，用户liu只有执行这个可程序程序文件才能实现对文件data.txt的访问。 查看僵尸进程 ps -ef | grep defunct | wc -l 查看进程表表项上限 MacOS下据说写在proc_internal.h中的PID上限是99999，下限是100. 而Linux下32位似乎是32768. 参考资料：http://blog.csdn.net/gatieme/article/details/51058797 Linux操作系统被设计得非常健壮，所以程序在运行过程中不会产生死锁。 答：错误。像信号量等，Linux仅给出了一组信号量操作的机制，如果应用程序设计的多个进程之间对信号量的操作处置不当，仍然可能导致死锁。操作系统没有办法检测出应用进程之间的逻辑操作不正确产生的死锁。使用管道等其他的进程之间通信的系统调用，也可能产生死锁。 Windows用户使用命令行命令ftp从Linux下载文件ftas.c，即使没有病毒破坏，成功下载结束后，下载的文件与原文件也有可能在文件大小（字节数）上不符。 答：正确。这种情况是可能存在的， FTP支持ASCII方式和BINARY方式的文件传输。前者会把数据文件理解为文本文件，会在通信的两个机器之间进行文本文件格式的转换。LINUX和Windows对文本文件的定义方式不同，Windows行间保留“换行”和“回车”两个字符，但是LINUX行间仅包括“换行”一个字符。所以在使用ASCII方式在Windows和Linux间交换文件可能会导致下载的文件与原文件在文件大小（字节数）上不符的情况。 关于文本文件处理的实用程序都有哪些？这些程序都有哪些共同的特点？为什么要这样设计这些命令？ 答：关于文本文件处理的实用程序有很多，如：head，tail，sort，grep，wc，cat，od，sed，awk，等等。 这些程序的共同特点是：每个小程序的功能设置简洁；当不指定处理对象时从标准输入获取处理数据；当指定文件名时，从指定的文件中获取处理数据，而且允许指定多于一个的文件名；处理结果在标准输出文件中输出。 这样设计这些命令的原因是：可以利用系统提供的输入、输出重定向和管道，连接和组合多个命令，提供灵活又丰富的使用功能；允许指定多于一个的文件作为处理对象可以和shell 的文件名通配符替换功能配合使用。体现了“策略和机制相分离”的设计理念。系统设计不复杂却可以提供强大的功能。 正则表达式中，一些配对的元字符使用转义时，只需要对开始的一个转义即可。 比如与开方括号 [ 对应的闭方括号 ]，与开花括号 { 对应的闭花括号 } ，这两个字符是否元字符，需要依据具体正则表达式的情况确定，我们以闭方括号]的情况为例（}的情况与此类似）：如果之前能找到与之对应的元字符开方括号[，则]作为元字符出现，否则，作为普通字符出现。 正则表达式里，使用圆括号时，为什么前面必须要加\\转义，变成\\(s+\\)这样呢？ (4) 将格式为“日-月-年”的日期数据，如：18-06-2010，替换为“年.月.日”格式，如：2010.06.18 s/\\([0-9][0-9]*\\)-\\([0-9][0-9]*\\)-\\([0-9][0-9]*\\)/\\3.\\2.\\1/ 正则表达式里，[0-9][0-9]*和[0-9]+有什么区别？ 记得有一个命令执行以后，整个终端的字符显示会全部错乱，似乎是ASCII序列被打乱了？ 好像是执行了一个重定向操作？ 并不是，是执行了一个cat命令，打印出一个二进制文件到终端，而这个二进制文件中某个字段可能刚好和某个命令相同，执行出来导致系统字符乱码。 select系统调用的主要作用是什么？ 答：使得用户进程可同时等待多个事件发生 用户进程告知内核多个事件，某一个或多个事件发生时select返回，否则，进程睡眠等待。例如：告知内核在rfds集合中的任何文件描述符“读准备好”，或在wfds集合中的任何文件描述符“写准备好”，或在efds集合中的任何文件描述符有“异常情况”发生，或者超时时间tm指定的时间间隔到。 **下列的脚本程序从键盘输入三个整数A,B,C，并且求出A*(B+C)的值。 在划线出填入适当的内容，完成整个程序。显式地标出你所添加的命令中必须有的空格和转义字符，并解释为什么必须这些空格和转义。** 123456#!/bin/shecho –n ”Input A:”; read Aecho –n ”Input B:”; read Becho –n ”Input C:”; read CV= echo ”A*(B+C)=$V” 答：expr $A \\* \\( $B + $C \\) 由于星号和圆括号属于shell的元字符，所以前面增加反斜线，阻止shell对元字符的处理，而是将这些符号直接传递给expr命令。上述命令一共需要6个空格，空格起单词分界线的作用。如果丢失了相应的空格，expr命令将无法得到正确的参数输入，导致expr无法按预期的功能工作。 写出一段完整的C语言程序，使用fork()系统调用，创建两个子进程，第一个子进程打印HELLO后立刻终止，第二个子进程打印WELCOME后立刻终止，父进程等待两个子进程都终止后，打印BYE然后终止。 答：程序如下： 12345678910111213141516main()&#123; int sv; if (fork() == 0) &#123; printf(”HELLO\\n”); return 0; &#125; if (fork() == 0) &#123; printf(”WELCOME\\n”); return 0; &#125; wait(&amp;sv); wait(&amp;sv); printf(”BYE\\n”); return 0;&#125; 这里的sv是接收fork的子进程返回的结果，作为子进程的结束。 int execlp(const char * file,const char * arg,……); execlp的第一个参数是用来在PATH或者路径中查找可执行文件，第二个参数是作为显示的进程名，我设置为aaa，则在ps -ef | grep test中可以查看到这个名字。 123456789101112131415#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main(int argc, char *argv[])&#123; execlp(&quot;ls&quot;, &quot;test&quot;, &quot;-al&quot;,(char*)0); //最后一个0是形同NULL,表示数组的结束 // for(int i = 0;i &lt; 1;i++) // &#123; printf(&quot;argv[0]:%s\\n&quot;, argv[0]); printf(&quot;argv[1]:%s\\n&quot;, argv[1]); printf(&quot;argv[2]:%s\\n&quot;, argv[2]); // &#125; return 0;&#125; 我这样写执行结果和将第二个参数设置为ls是一样的，只是在查看进程时，名字显示为第二个 管道完整程序： 12345678910111213141516171819202122232425262728293031#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;int main(int argc, char *argv[])&#123; int fd[2], sv; pipe(fd); //fd[0] = open(&quot;out.txt&quot;,O_RDONLY); //fd[1] = open(&quot;out.txt&quot;, O_WRONLY); if(fork() == 0) &#123; dup2(fd[1],1); close(fd[1]); close(fd[0]); execlp(&quot;ls&quot;, &quot;test&quot;, &quot;-al&quot;,(char*)0); &#125;else if(fork() == 0) &#123; dup2(fd[0], 0); close(fd[1]); close(fd[0]); //execlp(&quot;ls&quot;, &quot;test2&quot;, &quot;-l&quot;, (char*)0); execlp(&quot;grep&quot;, &quot;MtGrep&quot;, &quot;javaw&quot;, (char*)0); &#125; close(fd[1]); close(fd[0]); wait(&amp;sv); wait(&amp;sv); return 0;&#125; linux 执行命令 先搜索Path，而windows先搜索当前目录 区别原因？ 考虑到安全问题，如果本地路径下自己写的程序的操作是类似rm -rf /，那就没救了 linux ./操作和. 操作区别 ./操作是fork一个子进程执行 . 操作就是用当前的进程直接执行 — linux 如何显示出 所有的命令行参数与选项 据说是man argv，不过我执行的是man xargv","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://sean10.github.io/tags/Linux/"},{"name":"Unix","slug":"Unix","permalink":"https://sean10.github.io/tags/Unix/"}]},{"title":"图形学复习笔记","slug":"图形学复习笔记","date":"2017-06-26T08:35:28.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/06/26/图形学复习笔记/","link":"","permalink":"https://sean10.github.io/2017/06/26/图形学复习笔记/","excerpt":"","text":"第一章 计算机图形学概论 1． 比较计算机图形学与图象处理技术相同点和不同点。 Computer Graphics将抽象的语义信息转化成图像(数据转换为图形)，Computer Vision从图像中提取抽象的语义信息。Image Processing（图像处理）探索的是从一个图像或者一组图像之间的互相转化和关系，与语义信息无关。 图形学输入的是对虚拟场景的描述，通常为多边形数组，而输出的则是图像，多维像素数组。 而图像处理技术输入的是图像，输出的也是图像。 2． 列举三个计算机图形的应用实例。 CAx领域 计算机辅助设计CAD; 计算机辅助制造CAM; 计算机辅助教学CAI; 等 系统模拟、虚拟现实 航空、航天、建筑、体育等模拟与训练 OA与电子出版系统 过程控制 飞船、卫星、导弹、工业生产过程等 绘制勘探、测量图 地形、地貌、矿藏、气象、GIS • 艺术、娱乐和商业 平面设计、动画、影视制作 • 医学诊断技术 CT、核磁共振等数据分析诊断病因,手术模拟 • 科学计算可视化 复杂数据的直观表示,方便观察结果 3． 简述计算机图形学发展动向。 造型技术 规则形体: 可用欧氏几何描述的形体 几何造型技术（几何描述） 特征造型技术（特征作为形状描述的单元） 基于物理的造型技术（动画） 不规则形体: 过程式模拟, 如分形、粒子系统、基于文法生成 真实图形生成技术 简单局部光照模型、全局光照模型, 基于图象绘制技术 人-机交互技术 三维人-机交互技术, 虚拟环境, 多通道技术, 非精确交互 基于网络的图形技术 网络和多媒体技术, 分布式图形, 虚拟现实建模语言VRML 第二章 计算机图形系统概述 1． 叙述计算机图形系统的基本功能。 输入、输出、计算、存储、对话 2． 输入设备可有哪几种逻辑功能？请举出各自对应的物理设备。 共有6类逻辑输入设备： * 定位(locator): 指定一个坐标点。对应的物理设备有鼠标器、键盘、数字化仪、触摸屏等。 * 笔划(stroke): 指示一个坐标点系列, 如指定一条曲线的控制点等。主要物理设备有数字化仪 * 送值(valuator): 输入一个数值。最常用的物理设备是键盘的数字键。 * 字符串(string)：输入一个字符串。最基本的物理设备是键盘的数字字母键 * 拾取(pick)：选择一个显示对象, 为应用程序处理确定目标。常用的物理设备是各种定位设备 * 选择(choice)：在一个可选动作或选项中进行选择, 如选择菜单项。典型的物理设备是鼠标器、数字化仪、键盘的功能键等。 3． 画出图形软件的层次结构及主要组成。 4． 颜色查找表的概念及实现原理。 彩色表又称为调色板, 用来定义图像的 不同颜色。 彩色表的工作原理 代号-颜色RGB值对照表 5. 光栅扫描显示器结构与工作原理。 (1)图形信息的产生有两种主要途径: 其一, 由计算机执行相应的图形应用程序, 图像生成系统接受指令将图形的矢量表示转换成像素表示, 再将像素值存入显示存储器; 其二, 图像生成系统直接把图形输入设备(摄像 机、扫描仪等)输入的图形图像直接或经过主存 储器间接地存放到显示存储器中。 (2)显示控制器生成水平和垂直同步扫描信号送到 监视器, 使CRT电子束进行水平扫描和垂直扫描形成光栅; 另一方面又根据电子束在屏幕上的 行、列位置, 不断地读出显示存储器中对应位 置的像素值。 (3)利用彩色表将读出的像素值转换成R、G、B 三原色的亮度值, 来控制CRT的R、G、B电子束, 在屏幕对应点生成需要的像素颜色。 6． 什么要制订图形软件标准？举例说明它的分类。 制定图形软件标准的目的在于使图形软件能 够在不同的计算机和图形设备之间进行移植, 以便提高图形软件的利用率, 降低开发成本, 缩短研制周期, 使图形软件向着通用、高级与 设备无关的方向发展。 目前已经制定或正在制定的一些图形标准都是接 口标准。这些标准的功能旨在使图形系统中两 部分之间的接口标准化, 可以分为两类: * 数据接口标准 * 子程序接口标准 第三章 基本图形生成算法 1． Bresenham 直线生成算法原理。它与 DDA 算法相比，有何改进？ 根据直线的斜率确定选择X或者Y方向作为计 长方向, 在此方向上每次递增一个单位步长(或 者一个像素单位), 另一个方向上是否同时产生 一个单位增量由一个计算量很小的判别式来判 断。 Bresenham算法相比DDA算法去除了费时的取整运算，效率更高了。 2． 比较几种常用画圆弧算法的原理和效率。 Bresenham算法 与Bresenham直线生成算法一样, 其基本方法 是从一个起点出发, 利用判别式选择下一个显 示点。判别式的值通过简单计算获得, 其符号 用作判断。 算法特点 Bresenham圆弧算法是最有效的算法之一, 生 成圆时利用第一象限的上八分之一圆弧对称 扩展。选择点时所用判别式是递推表达式， 仅用加、减和移位即可计算, 算法效率高。 正负法（逐点比较法） • 首先,区分不同象限的圆弧； • 然后,选定圆弧起点后,在输出圆弧的过程中, 根 据当前点的位置与理想圆弧的关系和所在象限， 决定下一步的走向, 每次只在一个方向(X 或 Y) 走步取点; • 这样一步步地逼近产生应显示的圆弧。 算法特点 计算机用正负法生成圆弧时运算只有加、减和 移位(乘2)运算, 无乘除, 因此运算效率高, 这很 适用于用硬件实现。 较之Bresenham算法, 正负法的运算更为简单, 但对于同一段圆弧而言, 由于正负法每次只是 单向走步, 因而生成的点数比Bresenham算法生 成的点数要多。 多边形逼近法 当圆的内接多边形边数足够多时, 该多边形可 以和圆接近到任意程度, 因此在允许的误差范 围内(例如圆周和多边形之间的最大距离小于半 个像素的宽度), 可用显示多边形代替显示圆。 显示多边形的边可以用Bresenham直线生成算 法来实现。 个人猜想：毕竟采用的不是描点法，因而效率会更高 3． 简述两种字符生成方法。 矢量字符 写字模：采集每一笔两个端点的值。 点阵字符 采用mask来定义字符 所谓(mask)字符掩膜,就 是包含该字符的像素信息的一小块光栅。 4． 何谓四连通和八连通？写出一种边界表示的八连通区域填充算法。 4连通区域：取区域中的任何两个像素,从一象 素出发,通过上、下、左、右4种运动,只经过 该区域的点可以达到另一像素 8连通区域：取区域中任何两个像素,从一象素 出发通过上、下、左、右、两条对角线方向共 8种运动,只经过该区域的点可达到另一像素 4连通区域和8连通区域的关系： 4连通区域是8连通区域的一种特殊情况。4连通区域的边界必定是8连通式的；（8连通区域的边界必定是4连通式的？）。 这里指的是连通（而不是边界） 5． 解释活化边表的思想，以多边形区域填充为例介绍它的应用。 6．已知多边形各个顶点的坐标为(2,2), (2,4), (8,6), (12,2), (8,1), (6,2)及 (2,2), 在用扫描线填充算法实现扫描转换时, 写出其边表(ET)和全部的活化边表(AET)的内容。 7. 设计和实现一个图形函数库，具有绘制直线段、任意圆弧、椭圆弧、 多边形区域的阴影填充和颜色填充等功能。（仅调用画点函数） 大作业第一个 见附录 第四章 图形变换与裁剪 1．什么是灭点? 任何一束不平行于投影平面的平行线的透视投 影将汇聚成一点,称为灭点。灭点可以看作是 无限远处的一点在投影面上的投影。灭点有无 限多个。 在坐标轴方向上的灭点, 称为主灭点。 透视投影根据主灭点的个数分为一点透视、二 点透视和三点透视。主灭点数是和投影平面切割坐标轴的数量相对应的。 2．试用几种不同顺序的简单几何变换,求出将平面上的任一线段P1(x1, y1), P2(x2, y2)变换成与 X 轴重合的变换阵,并说明其等效性。 3．已知 OXYZ 坐标系下平面方程是 x+y+z+d=0，试求变换距阵 T，使该平面在 O’X’Y’Z’坐标系下变成 z’=0。 4．试简述二维图形裁剪的基本原理及可选用的裁剪策略. 在显示图形之前, 组成图形的每一个基本元素都 要经过裁剪, 因此裁剪算法直接影响整个图形系 统的效率。 裁剪的基本目的是判断图形元素是否在所考虑 的区域内。如在区域内, 则进一步求出在区域内 的那一部分。因此裁剪处理包含两部分内容: 1)点在区域内外的判断; 2)计算图形元素与区域边界的交点。 可选用的裁剪策略： * 编码裁剪法(Sutherland-Cohen算法) * 中点分割裁剪法 * 多边形的裁剪 * 逐边裁剪法 * 双边裁剪法 第五章 人机交互技术 1. 基本的交互任务有哪些？它们可用什么设备执行？ 定位 定位设备 选择 选择设备 数量输入 取值设备 文本输入 键盘 三维交互 鼠标 设备有:定位设备，键盘设备，取数设备，选择设备，其他输入设备 2. 举例说明 WINDOWS 系统常用的交互方式，编程实现其中一例。 windows系统常用选择交互方式，鼠标点选选项进行操作。 3. 叙述设计人机交互的一般风格和原则。 现在计算机系统的人机界面一般具有下列风格, 即: “所见即所得”(what you see is what you get) , 直接操作(direct manipulate)及菜单和图形符号 (icon)驱动。 * “所见即所得”在交互式图形系统中一般都 能做到, 即在屏幕上所见到的设计结果和用硬 拷贝所得的输出结果是一致的。 * 直接操作是对对象、特性及关系等操作时用 户可得到一种直观及形象的表示, 以说明这个 操作是正确地被执行了。 * 图形符号驱动的目的是要用户不需要专门学 习及记忆便可借助于菜单选择来运行系统。 要做到这一点最主要的是要设计好图形符号, 使它一看便知道它代表什么操作。 第六章 曲线曲面的表示 1. Bezier 曲线具有哪些特性？试用 n 的归纳法证明其凸包性。 证明就算了，一点都看不懂…… 2. B 样条曲线的定义及其特点。 3. 比较 Bezier 曲面和Ｂ样条曲面的功能特点。 Bezier曲面和B样条曲面的特点是曲面逼近控制网 格。 Ｂ样条曲面不仅在保留了Bézier曲面的优点的同时克服了由于整体表示带来的不具有局部修正性质的特点，而且成功地解决了样条函数的局部控制问题，轻而易举地在参数连续性上解决了贝奇尔方法的连接问题。 4. Coons 曲面片构造方法及其特点。 Coons曲面特点是插值, 它构造满足给定边界条 件的曲面。 第七章 三维实体的造型 1. 体素构造表示法中两物体正则运算的公式，并举例说明它们的计算方 法。 2. 形体的拓扑信息和几何信息各包含哪些内容？举例说明它们起何作用。 几何信息－物体大小、尺寸、位置、形状等 拓扑信息－物体上所有顶点、棱边、表面间连接关系 几何信息和拓扑信息分开表示的优点: 便于具体查询物体中各元素、获取它们的信息; 容易支持对物体的各种局部操作; 对于具有相同拓扑结构而只是大小、尺寸不同 的物体,可以用统一的数据结构加以表示; 便于在数据结构上附加各种非几何信息。 3. 欧拉公式及其应用意义。 给用户提供了直接使用顶点、棱边、表面等基 本元素构造三维立体的手段。用户可以通过输入 点,再建立边, 构成面, 形成体。 任何数目顶点、棱边、表面并不能构成一个体。 它们之间须满足拓扑一致性和几何一致性。 – 几何一致性由用户输入几何信息时保证, 系统应 提供检查输入信息几何一致性功能。 4. 试写出判定空间任意位置的两个长方体是否相交的算法。 5. 试比较实体的边界表示、扫移表示、CSG 表示及八叉树表示的优缺点。 说明它们适应的应用。 边界表示法：用顶点、棱边、表面等物体的边界信息来表示物体。边界就是物体内部点与外部点的分界面。 扫描表示 CSG表示：一个复杂物体可由一些比较简单、规则的物体经过布尔运算而得到。其中叶结点为基本体素(立方体, 圆柱, 圆锥等); 中间结点为正则集合运算结点。 优点: 将复杂物体表示转换为简单物体之间运算,也可递归求出物体性质; 缺点: 方法有局限性,物体复杂时,这种表示不太适应。 空间位置枚举：使用该方法时, 先将空间分割成均匀的立方体网格, 然后根据物体所占据的网格位置来定义物体的形状和大小。 优点–适合所有形状三维物体表示, 容易实现物体的并交差及整体性质计算(对应着数组运算) 缺点–没有明确给定物体边界信息, 占据存储量大 八叉树（改进的空间位置枚举) • 物体之间集合运算在八叉树中十分简单 物体并－两物体一共占有的空间； 物体交－两物体共同占有的空间。 运算时只需同时遍历参加集合运算两物体相应的 八叉树。 • 简化了隐藏线和隐藏面的消除 核心是排序(按离观察点远近排序); 八叉树中物体元素已按空间位置排成一定顺序, 同一层的八叉树结点通过优先级表示。 • 计算物体的性质(体积、质量)更简单 对物体的各项操作＝》体元的操作。 第八章 消隐技术 1. 为何要进行隐藏面的消除？ 消除图形的二义性 2. 简述区域子分消隐算法思想和描述。 区域子分算法是针对光栅扫描式图象显示器上 填色产生图形的。它是一种所谓分而治之的算 法。 整个屏幕称为窗口, 每一次把矩形的窗口等分成 4个相等的小矩形,分成的矩形也称为窗口, 见图 8.2。 每一次子分, 均要把要显示的多边形和窗口的 关系做一次判断。这种关系有以下4种: –多边形包围了窗口(图8.3中情况1); –多边形和窗口相交(图8.3中情况2); –窗口包围了多边形(图8.3中情况3); –窗口和多边形分离(图8.3中情况4)。 窗口和每个多边形的关系确定之后, 有些窗口 内的图形便可显示了, 它们属于下列情况: (1)所有多边形都和窗口分离。这时只要把窗口 内所有的象素填上背景颜色。 (2)只有一个多边形和窗口相交,或这个多边形 包含在窗口内。这时先对窗口内每一象素填 上背景颜色, 再对窗口内多边形部分用扫描 线算法填色。 (3)只有一个多边形和窗口相交,这个多边形把 窗口整个包围在内;或虽有几个多边形和窗 口相交,但离观察者最近的一个多边形包围 了整个窗口。这时把整个窗口填上离观察者 最近的那个多边形的颜色。 对上述3种情况不成立的窗口再一分为四,见图 8.2。分得的窗口重复上述的处理。 • 重复处理后,窗口的边长越分越短, 分了若干次 后, 窗口的边长就和一个象素的宽度一样了。 这时, 这个窗口对应的象素的颜色可取成最靠 近观察者的多边形的颜色, 或和这个窗口相交 的多边形颜色的平均值。 3. 简述 Z 缓存消隐算法思想和描述。 深度缓存算法(Z-Buffer)是一种最简单的图象空间 面消隐算法, 既适应于多边形面也适用其它曲面。 • 它需要一个深度缓存数组ZB, 其大小与屏幕上象素 点的个数相同, 也与显示器的帧缓存FB的单元个数 相同, 彼此一一对应。 • 如图8.6, 在屏幕坐标系中, 过屏幕上任一象素点(i, j) 作平行于Z轴的射线R, 与物体表面上的多边形相交 于p 1 和p 2 点。 • 比较p 1 和p 2 的Z值, 将最大Z值存入深度缓存数组ZB, 最大Z值所对应点的颜色存入显示器的帧缓存FB。 算法描述 4. 比较几种主要的隐藏面的消除算法的特点。 区域子分算法是针对光栅扫描式图象显示器上 填色产生图形的。它是一种所谓分而治之的算 法 用边界盒的办法就可判定一些多边形和指定窗 口是无交的。因此, 这些多边形可从窗口多边 形序列中排除, 从而提高排序效率 深度缓存算法的优点是简单、可靠, 不需要对显示对象的 面预先进行排序; • 缺点是要很大的Z缓冲器, 显示对象的表面和象素对应的 每一个点处都要计算它的Z值, 因而工作量较大。 第九章 真实感图形技术 1. 用框图描述三维真实感图形的产生流程。 –用数学方法建立所需三维场景的几何描述, 并将它们输入计算机； –将三维几何描述转换为二维透视图； –确定场景中的所有可见图(消隐)； –计算场景中可见面的颜色。（本章重点） 2. Phong 局部光照模型及其实现算法描述。 3. 叙述 Phong 多边形明暗处理算法原理, 与 Gouraud 算法比较它的优缺 点。 Phong明暗处理技术(Phong Shading) • 思想: 对离散的法向量采样作双线性插值, 构造一个连续的法向量函数, 将这个连续的 法向量插值函数代入光亮度计算公式, 即得 到一个非线性的光亮度插值公式。 如图9.7所示, 任一点P处法向按插值方法由 各顶点处法向推出。 • 优点: 大大减少了马赫带效应;产生真实的高光效果。 缺点: 由于对每一像素光亮度计算还需使用 光照模型, 故计算量大。 Gouraud明暗处理技术(Gouraud Shading) • 思想：对离散的光亮度采样作双线性插值 以获取连续的光亮度函数。 • 过程： a.计算出多边形顶点处的光亮度值, 作为 插值采样点； b.对多边形顶点的光亮度插值计算出多边 形内任一点的光亮度。 优缺点 效果尚好, 计算量小; 不能正确模拟高光, 会产生Mach带效应(光亮度 变化率不连续的边界处呈现亮带或黑带)。 4. 何为全局光照模型，典型的模型举例。 Phong模型仅考虑光源直接照射在景物表面产生 的反射光能, 因而是一种局部光照模型。 • 局部光照模型忽略了光能在环境景物之间的传 递, 很难生成高质量真实感图形。 原因: 未能考虑环境的漫射、镜面反射和规则透 射对景物表面产生的整体照明效果。 Whitted在Phong模型中增加了环境镜面反射光 亮度Is 和环境规则透射光亮度It , 从而模拟周围环境的光透射在景物表面上产生的理想镜面反 射和规则透射现象。 5. 实现真实感绘制的光线跟踪技术的主要思想和算法描述。 光线跟踪技术是为了求解Whitted模型而提出 一种高度真实感图形绘制技术. 6. 加速光线跟踪算法的主要方法。 包围盒技术 景物空间分割技术 7. 何谓纹理映射，简述其实现原理。 纹理：物体表面所呈现的表面细节。 生成颜色纹理的方法。其过程是: 在一平面区域(纹理空间)上预先定义纹理图案; 然后建立物体表面的点与纹理空间的点之间的 对应关系(即映射)。 主要有法向扰动法、分形生成技术等。 8. 试写出将一幅图片贴到三维圆柱体表面的算法。 第十章 OPEN GL 简介 1. 试设计一个室内三维环境, 并利用 OPEN GL 展示它的三维效果。要求：(1)包含基本的实体元素：球、多面体、锥体、柱体、曲面等； (2)有全局光照效果和纹理功能； (3)程序具有交互功能。 第二次大作业。 附录","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://sean10.github.io/tags/图形学/"},{"name":"openGL","slug":"openGL","permalink":"https://sean10.github.io/tags/openGL/"}]},{"title":"Qt学习汇总遇到的问题","slug":"Qt学习汇总遇到的问题","date":"2017-06-15T08:42:46.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/06/15/Qt学习汇总遇到的问题/","link":"","permalink":"https://sean10.github.io/2017/06/15/Qt学习汇总遇到的问题/","excerpt":"","text":"使用qt信号槽时，始终no such slots，原因是我没有在槽函数的类中使用Q_OBJECT MACRO 这个的原因是什么呢？ 在类声明的开始位置必须加上Q_OBJECT语句，这条语句是不可缺少的，它将告诉编译器在编译之前必须先应用 moc工具进行扩展 这个时候先执行qmake，再build 开了一个refresh信号的线程，但是一使用emit signalRefresh就爆出系统错误 &gt;:-1: error: symbol(s) not found for architecture x86_64 &gt;:-1: error: linker command failed with exit code 1 (use -v to see invocation) 这个错误经常会出现 c++跨文件或跨类传输变量参数是通过在对应文件声明类，然后调用该类获得参数的函数 但是qt里我一旦这样做，就会出现上面那个系统错误。 普通形参加不加const限定符对实参没有影响，引用形参和指针形参前面没有const限定符时，实参必须是非const的，而前面有const限定符时对实参也没有什么影响。 为什么会出现这种情况？ 原因在于实参的传递方式不同，函数中的形参是普通形参的时，函数只是操纵的实参的副本，而无法去修改实参，实参会想，你形参反正改变不了我的值，那么你有没有const还有什么意义吗？引用形参和指针形参就下不同了，函数是对实参直接操纵，没有const的形参时实参的值是可以改变的，这种情况下怎能用函数来操纵const实参呢。 ui文件似乎必须要建一个类通过setupUI才能使用 主要需要新建一个dialog来show就可以了 Qt的模态对话，setModal和dialog.exec() == box::accepted有什么区别？ QT的close没有反应，似乎要使用事件循环 setAttribute (Qt::WA_DeleteOnClose); 这个明明是解决内存泄露问题，为什么可以关闭窗口呢，而close却做不到 qVector输入之后，造成implicitly deleted because base class “QObject” has a deleted copy constructor Qt 资源文件，可以通过添加qrc来实现路径的操作 但是 //路径这里存在问题，为什么添加了qrc之后依旧不需要前缀就可以使用了呢？ 明明理论上说要“:/db/user.db” 但只是“user.db”就可以使用了 始终不能调用数据库，原因是我没有使用query.finish，以及建表语法出现了错误。 事件似乎和信号有点相似，又有点不同。 事件是一个新的概念，与信号不一样。 又遇到了当初的link错误，没有详细信息的那种 SF的答案是这个，感觉比较靠谱，我也确实有在Compile Output里看到问题，是client.o的问题，不过这个文件我都没有引用，为什么会错呢 Posting comment by N1ghtLight as an answer. Duplicate symbols found error is a linker error, which says that linker has found more than one symbols with the same name. Following are some common causes for this. You have written a function definition in a header file (outside a class), which is included in two or more cpp files. You have defined a static variable twice. You have written a function definition twice in a cpp file. You can find out what are the duplicate symbols by checking Compile Output tab in Qt Creator 把databaseControl设置继承QObject就出现编译不过的问题 就是上面的link错误，不过更复杂 遇到这个错误error: member function not viable this argument has type const 但是我一时忘了怎么解决的了 call to implicitly-deleted copy constructor /Users/sean10/Qt/5.8/clang_64/lib/QtCore.framework/Headers/qlist.h:461: error: call to implicitly-deleted copy constructor of ‘centralAirConditioner’ current-&gt;v = new T(reinterpret_cast&lt;T&gt;(src-&gt;v)); ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 遇到这个错误，发现又是因为继承了基类QObject的原因 暂时设计了从multithread发送信号到databaseControl,暂时没能测试出数据是否发送成功 好像知道为什么发送了信号，但槽函数没有执行的原因了，似乎是因为信号和槽不在一个线程里 但是默认是会执行异步的啊 上面的猜想是错误的，实际的问题是在于我把UserRegister写在mainwindow的构造函数里的，导致还没有执行connect就把信号已经发送出去了，所以这个信号浪费了 稍后添加对于开关机的容错措施 数据锁尚未添加 优先设置spinBox的lowtem会导致workTemperature变成这个lowTem,明明是满足他的约束的 噢，可能是因为spinBox一开始是0，没有设置，当有了约束之后，自动变成了18，满足了值变动，所以导致初始化被覆盖了。 tcp粘包问题： 怎么分也需要双方组织一个比较好的包结构，所以一般可能会在头加一个数据长度之类的包，以确保接收。 从控机修改工作模式，但没有发送给主控机的过程，这个问题有待修正 这里应该根据文档来写：从控机没有调整工作模式的机会，只能由主控机设定 connectToHost似乎是mac的问题，大大的windows执行就没有问题。 找到每次修改完工作温度，室温就顺便同步的原因了，是因为信号问题，每发送一个SignalSendRequest就执行了9次SendRequest. 但是没有找到有多次connect的函数啊。 即便是用了uniqueConnection还是执行了多次。 找到问题了，有另外一个函数不停发送了signal，定时发送 第二次从控机开机，主控机上没有再显示出那台从控机状态？ why? 还有解决粘包问题 把室温用电子时钟模式展示出来 可以使用doxygen来进行根据注释生成文档 /** * 要输出成文档的注释 */ 或者 //! qmake project 变量使用 一个pro生成多个app似乎现在不行了，只能通过subdirs来实现了？ 通过$$PWD来导入公用包 用CLion的Cmake和 命令直接clang++都没办法把sqlite3成功编译通过，但是用Qt就能过，真的是奇特。 sqlite3 使用怪怪的 select * from sqlite_master; 始终得到结果为空 然后报错 libc++abi.dylib: terminating with uncaught exception of type std::__1::system_error: SQL logic error CREATE TABLE main.table_name( column1 datatype PRIMARY KEY(one or more columns), column2 datatype, column3 datatype, ….. columnN datatype, ); 现在尝试用回俊宁大佬的库，但是连创建table都使用不了…… 找到了俊宁大佬自己的作业，从那里的实例来进行操作 Qt dialog传递参数 https://blog.csdn.net/xzh_blue/article/details/51490747 现在很奇怪，有时候能够充值上去，有时候就报这个错误，导致失败 123456[INFO] send message: &#123;&quot;define&quot;:2&#125;[INFO] receive message: &#123;&quot;define&quot;:3,&quot;username&quot;:&quot;ls1&quot;&#125;[INFO] Get user balance request comes[INFO] send message: &#123;&quot;balance&quot;:0,&quot;define&quot;:1&#125;SQL error: &apos;UNIQUE constraint failed: OrderInfo.type&apos; at &apos;insert into OrderInfo(type,amount,out_account,in_account,record_time) values (4,25,&apos;cash&apos;,&apos;ls1&apos;,1536938826);&apos;[INFO] Someone offline, now 0 conne C/S架构下， 登录过程中 密码 是否需要加密？ 出现了一个权限值为25，似乎是哪里传输的时候顺序出错了？把转账的值写入到了权限的位置？ QT 点击自定义QDialog类“确定”按钮 , 模态框立刻关闭 , 之后又做空值检查问题解决 - CSDN博客 mac 自带openssl 0.98，而官方最新版 1.1 (6 条消息)UUID是如何保证唯一性的？ - 知乎 现在有一个问题，我的tableView没有释放过standardItem，因此一定会出现内存泄露问题 (6 条消息)互联网中TCP Socket服务器的实现过程需要考虑哪些安全问题？ - 知乎 引用openssl库的方式 clang client.c -o client -I/usr/local/opt/openssl/include -L/usr/local/opt/openssl/lib -lcrypto -lssl 像上面这样加上最后那4条就可以正常运行了 openssl生成过程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273mkdir misccd miscsudo cp /usr/local/etc/openssl/openssl.cnf ./cp /usr/local/etc/openssl/misc/* .///这里生成的是rsa的ca.key和 .rnd 输入密钥是fightonopenssl genrsa -out ./private/ca.key -rand ./private/.rnd -des 2048// 这里确认了密钥，然后要求输入下面那些内容openssl req -new -x509 -days 3650 -key ./private/ca.key -out ./private/ca.crt -config openssl.cnf&lt;!-- Enter pass phrase for ./private/ca.key:You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &apos;.&apos;, the field will be left blank.-----Country Name (2 letter code) [AU]:ZHState or Province Name (full name) [Some-State]:BeijingLocality Name (eg, city) []:BeijingOrganization Name (eg, company) [Internet Widgits Pty Ltd]:HikvisionOrganizational Unit Name (eg, section) []:bjyfCommon Name (e.g. server FQDN or YOUR name) []:sean10Email Address []:sean10reborn@gmail.com --&gt;// 这个应该是显示一下证书openssl x509 -in ./private/ca.crt -noout -text## // 产生server证书openssl genrsa -out ./private/server.key 1024openssl req -new -key ./private/server.key -out ./newcerts/server.csr -config openssl.cnf&lt;!-- You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &apos;.&apos;, the field will be left blank.-----Country Name (2 letter code) [AU]:ZHState or Province Name (full name) [Some-State]:BeijingLocality Name (eg, city) []:BeijingOrganization Name (eg, company) [Internet Widgits Pty Ltd]:bjyfOrganizational Unit Name (eg, section) []:hikCommon Name (e.g. server FQDN or YOUR name) []:sean10Email Address []:sean10reborn@gmail.comPlease enter the following &apos;extra&apos; attributesto be sent with your certificate requestA challenge password []:helloworldAn optional company name []:hik --&gt;touch index.txttouch serialecho 00 &gt; serialopenssl ca -in ./newcerts/server.csr -cert ./private/ca.crt -keyfile ./private/ca.key -config openssl.cnf -policy policy_anything -out ./certs/server.crtopenssl genrsa -out ./private/proxy.key 1024//这步要是产生错误，请看后面的解决方法openssl req -new -key ./private/proxy.key -out ./newcerts/proxy.csr -config openssl.cnfopenssl ca -in ./newcerts/proxy.csr -cert ./private/ca.crt -keyfile./private/ca.key -config openssl.cnf -policy policy_anything -out ./certs/proxy.crtopenssl x509 -in ./certs/proxy.crt -noout -text 基于OpenSSL自建CA和颁发SSL证书 | Sean’s Notes Qt 如何 引入 openssl库 QT总结第3篇：如何在QT中添加.lib，.dll还有.h文件 - CSDN博客 现在在编译时，ui_widget.h丢失？ 奇怪了。将lssl等加到LIBS这里之后，server可以编译了，但是client又出现了上面的问题，明明这次client一行代码都没改…… 终于发现了，我在socket.h里多导入了一个curve.h这个包，这个包里的一个函数qblog和 Qt 的一个包 重名了 case中无法定义同一个变量 用if else 代替 switch 语句; 2：在case中用{}将代码括起来,这样在{}中就能定义变量了; 3：如果变量在各个case中都要用的话,就把变量定义在switch外面吧; 目前在switch case中定义的变量无法被后续的代码发现，从而使用 可能是作用域的原因？ 想要手动定义，但是无法通过typeid .name 打印出来 还需要找到办法手动定义 openSSL OpenSSL主配置文件openssl.cnf - 骏马金龙 - 博客园 基于OpenSSL自建CA和颁发SSL证书 | Sean’s Notes 使用c语言实现在linux下的openssl客户端和服务器端编程 - 欢跳的心 - 博客园 openssl编程轻松入门（含完整示例）-飞月-51CTO博客 (6 条消息)用 C++ 写 HTTPS 客户端和服务器大体步骤有哪些？ - 知乎 OPENSSL编程入门学习 - 骑着蜗牛逛世界 - 博客园 用Cross Functional Vertical就可以画图了 https://www.processon.com/view/5938c757e4b036140a0ef5ef?fromnew=1 https://www.processon.com/diagrams/new#temp-system","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"Qt","slug":"Qt","permalink":"https://sean10.github.io/tags/Qt/"}]},{"title":"git笔记","slug":"git笔记","date":"2017-02-20T16:12:09.000Z","updated":"2021-01-16T15:04:05.092Z","comments":true,"path":"2017/02/21/git笔记/","link":"","permalink":"https://sean10.github.io/2017/02/21/git笔记/","excerpt":"常用命令 切换分支 git reset --hard ## 查看操作历史，寻找之前记录的分支 git reflog ## 查找指定行的commit log git log -S &quot;void ss()&quot; /path/file 查看未提交的文件修改 1git show show not staged 1git diff tag功能 子模块 git subtree(第三方, 独立仓库子树合并) git submodule(独立的子仓库) 记录 git的快照流是指什么？ (参见 Git 内部原理 来了解更多关于到底 .git 文件夹中包含了哪些文件的信息。) 事实上，如果你的服务器的磁盘坏掉了，你通常可以使用任何一个克隆下来的用户端来重建服务器上的仓库（虽然可能会丢失某些服务器端的挂钩设置，但是所有版本的数据仍在，详见 在服务器上搭建 Git ）。","text":"常用命令 切换分支 git reset --hard ## 查看操作历史，寻找之前记录的分支 git reflog ## 查找指定行的commit log git log -S &quot;void ss()&quot; /path/file 查看未提交的文件修改 1git show show not staged 1git diff tag功能 子模块 git subtree(第三方, 独立仓库子树合并) git submodule(独立的子仓库) 记录 git的快照流是指什么？ (参见 Git 内部原理 来了解更多关于到底 .git 文件夹中包含了哪些文件的信息。) 事实上，如果你的服务器的磁盘坏掉了，你通常可以使用任何一个克隆下来的用户端来重建服务器上的仓库（虽然可能会丢失某些服务器端的挂钩设置，但是所有版本的数据仍在，详见 在服务器上搭建 Git ）。 $ git clone https://github.com/libgit2/libgit2 mylibgit 这将执行与上一个命令相同的操作，不过在本地创建的仓库名字变为 mylibgit。 Git 支持多种数据传输协议。 上面的例子使用的是 https:// 协议，不过你也可以使用 git:// 协议或者使用 SSH 传输协议，比如 user@server:path/to/repo.git 。 在服务器上搭建 Git将会介绍所有这些协议在服务器端如何配置使用，以及各种方式之间的利弊。 最后，该命令还显示了当前所在分支，并告诉你这个分支同远程服务器上对应的分支没有偏离。 现在，分支名是 “master”,这是默认的分支名。 我们在 Git 分支 会详细讨论分支和引用。 忽略文件 一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。 来看一个实际的例子： $ cat .gitignore .[oa] ~ 第一行告诉 Git 忽略所有以 .o 或 .a 结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的。 第二行告诉 Git 忽略所有以波浪符（~）结尾的文件，许多文本编辑软件（比如 Emacs）都用这样的文件名保存副本。 此外，你可能还需要忽略 log，tmp 或者 pid 目录，以及自动生成的文档等等。 要养成一开始就设置好 .gitignore 文件的习惯，以免将来误提交这类无用的文件。 文件 .gitignore 的格式规范如下： 所有空行或者以 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。 星号（）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）；问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号（) 表示匹配任意中间目录，比如a/**/z 可以匹配 a/z, a/b/z 或 a/b/c/z等。 我们再看一个 .gitignore 文件的例子： no .a files *.a but do track lib.a, even though you’re ignoring .a files above !lib.a only ignore the TODO file in the current directory, not subdir/TODO /TODO ignore all files in the build/ directory build/ ignore doc/notes.txt, but not doc/server/arch.txt doc/*.txt ignore all .pdf files in the doc/ directory doc/**/*.pdf TIP GitHub 有一个十分详细的针对数十种项目及语言的 .gitignore 文件列表，你可以在 https://github.com/github/gitignore 找到它. 查看已暂存和未暂存的修改 git .gitignore 我的powershell不能调用，待会看看 GitHub 有一个十分详细的针对数十种项目及语言的 .gitignore 文件列表，你可以在 https://github.com/github/gitignore 找到它 Git Diff 的插件版本 在本书中，我们使用 git diff 来分析文件差异。 但是，如果你喜欢通过图形化的方式或其它格式输出方式的话，可以使用 git difftool 命令来用 Araxis ，emerge 或 vimdiff 等软件输出 diff 分析结果。 使用 git difftool –tool-help 命令来看你的系统支持哪些 Git Diff 插件。 另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 换句话说，你想让文件保留在磁盘，但是并不想让 Git 继续跟踪。 当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。 为达到这一目的，使用 –cached 选项： $ git rm –cached README git rm 命令后面可以列出文件或者目录的名字，也可以使用 glob 模式。 比方说： $ git rm log/*.log 注意到星号 * 之前的反斜杠 ， 因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开。 此命令删除 log/ 目录下扩展名为 .log 的所有文件。 类似的比如： $ git rm *~ 该命令为删除以 ~ 结尾的所有文件。. Git 保存的不是文件的变化或者差异，而是一系列不同时刻的文件快照。 http://git-scm.com/book/zh/v2/Git-%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF 远程分支不太能够理解，比如远程仓库和本地仓库分支之间fetch什么的 还有origin/master怎么操作 现在，可以运行 git fetch teamone 来抓取远程仓库 teamone 有而本地没有的数据。 因为那台服务器上现有的数据是 origin 服务器上的一个子集，所以 Git 并不会抓取数据而是会设置远程跟踪分支 teamone/master 指向 teamone 的 master 分支。 这里有些工作被简化了。 Git 自动将 serverfix 分支名字展开为 refs/heads/serverfix:refs/heads/serverfix，那意味着，“推送本地的 serverfix 分支来更新远程仓库上的 serverfix 分支。” 我们将会详细学习 Git 内部原理 的 refs/heads/ 部分，但是现在可以先把它放在儿。 你也可以运行 git push origin serverfix:serverfix，它会做同样的事 - 相当于它说，“推送本地的 serverfix 分支，将其作为远程仓库的 serverfix 分支” 可以通过这种格式来推送本地分支到一个命名不相同的远程分支。 如果并不想让远程仓库上的分支叫做 serverfix，可以运行 git push origin serverfix:awesomebranch 来将本地的 serverfix 分支推送到远程仓库上的 awesomebranch 分支。 如何避免每次输入密码 如果你正在使用 HTTPS URL 来推送，Git 服务器会询问用户名与密码。 默认情况下它会在终端中提示服务器是否允许你进行推送。 如果不想在每一次推送时都输入用户名与密码，你可以设置一个 “credential cache”。 最简单的方式就是将其保存在内存中几分钟，可以简单地运行 git config –global credential.helper cache 来设置它。 想要了解更多关于不同验证缓存的可用选项，查看 凭证存储。 git branch 如何切换一个本地分支跟踪远程仓库的分支 git checkout 哑（Dumb） HTTP 协议 如果服务器没有提供智能 HTTP 协议的服务，Git 客户端会尝试使用更简单的“哑” HTTP 协议。 哑 HTTP 协议里 web 服务器仅把裸版本库当作普通文件来对待，提供文件服务。 哑 HTTP 协议的优美之处在于设置起来简单。 基本上，只需要把一个裸版本库放在 HTTP 跟目录，设置一个叫做 post-update 的挂钩就可以了（见 Git 钩子）。 此时，只要能访问 web 服务器上你的版本库，就可以克隆你的版本库。 下面是设置从 HTTP 访问版本库的方法： $ cd /var/www/htdocs/ $ git clone –bare /path/to/git_project gitproject.git $ cd gitproject.git $ mv hooks/post-update.sample hooks/post-update $ chmod a+x hooks/post-update 这样就可以了。 Git 自带的 post-update 挂钩会默认执行合适的命令（git update-server-info），来确保通过 HTTP 的获取和克隆操作正常工作。 这条命令会在你通过 SSH 向版本库推送之后被执行；然后别人就可以通过类似下面的命令来克隆： $ git clone https://example.com/gitproject.git 这里我们用了 Apache 里设置了常用的路径 /var/www/htdocs，不过你可以使用任何静态 web 服务器 —— 只需要把裸版本库放到正确的目录下就可以。 Git 的数据是以基本的静态文件形式提供的（详情见 Git 内部原理）。 通常的，会在可以提供读／写的智能 HTTP 服务和简单的只读的哑 HTTP 服务之间选一个。 极少会将二者混合提供服务。 1、git pull返回错误“You asked to pull from the remote ‘origin’, but did not specify a branch. Because this is not the default configured remote for your current branch, you must specify a branch on the command line.” http://stackoverflow.com/questions/3133387/confusing-error-message-from-git refusing to merge unrelated histories 强制git merge --allow-unrelated-histories yourbranch w强制回滚，用来撤销失败的调试 git reset --hard HEAD Auto packing the repository in background for optimum performance. See “git help gc” for manual housekeeping. error: The last gc run reported the following. Please correct the root cause and remove .git/gc.log. Automatic cleanup will not be performed until the file is removed. warning: There are too many unreachable loose objects; run ‘git prune’ to remove them. Git的底层并没有采用 CVS、SVN 底层所采用的那套增量式文件系统，而是采用一套自行维护的存储文件系统。当文件变动发生提交时，该文件系统存储的不是文件的差异信息，而是文件快照，即整个文件内容，并保存指向快照的索引。这种做法，提高 Git 分支的使用效率；但也容易导致代码仓库中内容重复程度过高，从而仓库体积过大。当遇到这种情况时，或者需要将仓库推送到远程主机时，就需要Git中的gc（garbage collect）功能，也就是垃圾回收功能。 大体来说，当运行 “git gc” 命令时，Git会收集所有松散对象并将它们存入 packfile，合并这些 packfile 进一个大的 packfile，然后将不被任何 commit 引用并且已存在一段时间 (数月) 的对象删除。 此外，Git还会将所有引用 (references) 并入一个单独文件 git prune功能，似乎是在遇到大文件的问题,有意思，这个git的垃圾回收问题以前倒是没遇到过呢 参考 git gc功能 Git子仓库深入浅出 - 知乎****","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"git","slug":"git","permalink":"https://sean10.github.io/tags/git/"}]},{"title":"C++_Note","slug":"C-Note","date":"2017-02-10T14:49:18.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2017/02/10/C-Note/","link":"","permalink":"https://sean10.github.io/2017/02/10/C-Note/","excerpt":"使用qt信号槽时，始终no such slots，原因是我没有在槽函数的类中使用Q_OBJECT MACRO 这个的原因是什么呢？ 在类声明的开始位置必须加上Q_OBJECT语句，这条语句是不可缺少的，它将告诉编译器在编译之前必须先应用 moc工具进行扩展 这个时候先执行qmake，再build","text":"使用qt信号槽时，始终no such slots，原因是我没有在槽函数的类中使用Q_OBJECT MACRO 这个的原因是什么呢？ 在类声明的开始位置必须加上Q_OBJECT语句，这条语句是不可缺少的，它将告诉编译器在编译之前必须先应用 moc工具进行扩展 这个时候先执行qmake，再build 开了一个refresh信号的线程，但是一使用emit signalRefresh就爆出系统错误 &gt;:-1: error: symbol(s) not found for architecture x86_64 &gt;:-1: error: linker command failed with exit code 1 (use -v to see invocation) 这个错误经常会出现 c++跨文件或跨类传输变量参数是通过在对应文件声明类，然后调用该类获得参数的函数 但是qt里我一旦这样做，就会出现上面那个系统错误。 普通形参加不加const限定符对实参没有影响，引用形参和指针形参前面没有const限定符时，实参必须是非const的，而前面有const限定符时对实参也没有什么影响。 为什么会出现这种情况？ 原因在于实参的传递方式不同，函数中的形参是普通形参的时，函数只是操纵的实参的副本，而无法去修改实参，实参会想，你形参反正改变不了我的值，那么你有没有const还有什么意义吗？引用形参和指针形参就下不同了，函数是对实参直接操纵，没有const的形参时实参的值是可以改变的，这种情况下怎能用函数来操纵const实参呢。 ui文件似乎必须要建一个类通过setupUI才能使用 主要需要新建一个dialog来show就可以了 Qt的模态对话，setModal和dialog.exec() == box::accepted有什么区别？ QT的close没有反应，似乎要使用事件循环 setAttribute (Qt::WA_DeleteOnClose); 这个明明是解决内存泄露问题，为什么可以关闭窗口呢，而close却做不到 qVector输入之后，造成implicitly deleted because base class “QObject” has a deleted copy constructor Qt 资源文件，可以通过添加qrc来实现路径的操作 但是 //路径这里存在问题，为什么添加了qrc之后依旧不需要前缀就可以使用了呢？ 明明理论上说要“:/db/user.db” 但只是“user.db”就可以使用了 始终不能调用数据库，原因是我没有使用query.finish，以及建表语法出现了错误。 事件似乎和信号有点相似，又有点不同。 事件是一个新的概念，与信号不一样。 又遇到了当初的link错误，没有详细信息的那种 SF的答案是这个，感觉比较靠谱，我也确实有在Compile Output里看到问题，是client.o的问题，不过这个文件我都没有引用，为什么会错呢 Posting comment by N1ghtLight as an answer. Duplicate symbols found error is a linker error, which says that linker has found more than one symbols with the same name. Following are some common causes for this. You have written a function definition in a header file (outside a class), which is included in two or more cpp files. You have defined a static variable twice. You have written a function definition twice in a cpp file. You can find out what are the duplicate symbols by checking Compile Output tab in Qt Creator 把databaseControl设置继承QObject就出现编译不过的问题 就是上面的link错误，不过更复杂 遇到这个错误error: member function not viable this argument has type const 但是我一时忘了怎么解决的了 call to implicitly-deleted copy constructor /Users/sean10/Qt/5.8/clang_64/lib/QtCore.framework/Headers/qlist.h:461: error: call to implicitly-deleted copy constructor of ‘centralAirConditioner’ current-&gt;v = new T(reinterpret_cast&lt;T&gt;(src-&gt;v)); ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 遇到这个错误，发现又是因为继承了基类QObject的原因 暂时设计了从multithread发送信号到databaseControl,暂时没能测试出数据是否发送成功 好像知道为什么发送了信号，但槽函数没有执行的原因了，似乎是因为信号和槽不在一个线程里 但是默认是会执行异步的啊 上面的猜想是错误的，实际的问题是在于我把UserRegister写在mainwindow的构造函数里的，导致还没有执行connect就把信号已经发送出去了，所以这个信号浪费了 稍后添加对于开关机的容错措施 数据锁尚未添加 优先设置spinBox的lowtem会导致workTemperature变成这个lowTem,明明是满足他的约束的 噢，可能是因为spinBox一开始是0，没有设置，当有了约束之后，自动变成了18，满足了值变动，所以导致初始化被覆盖了。 tcp粘包问题： 怎么分也需要双方组织一个比较好的包结构，所以一般可能会在头加一个数据长度之类的包，以确保接收。 从控机修改工作模式，但没有发送给主控机的过程，这个问题有待修正 这里应该根据文档来写：从控机没有调整工作模式的机会，只能由主控机设定 connectToHost似乎是mac的问题，大大的windows执行就没有问题。 找到每次修改完工作温度，室温就顺便同步的原因了，是因为信号问题，每发送一个SignalSendRequest就执行了9次SendRequest. 但是没有找到有多次connect的函数啊。 即便是用了uniqueConnection还是执行了多次。 找到问题了，有另外一个函数不停发送了signal，定时发送 第二次从控机开机，主控机上没有再显示出那台从控机状态？ why? 还有解决粘包问题 把室温用电子时钟模式展示出来 可以使用doxygen来进行根据注释生成文档 /** * 要输出成文档的注释 */ 或者 //! C++在类头文件中试图定义QVector的成员变量，提示错误，不能理解。 std::vector numList[9]; 头文件这样定义成员变量，但是在构造函数中不能对他初始化。 不管是QVector还是vector都不行。 问题的回答是这么说的： 这是定义，不是声明。良好的C++规范要求，除了类定义、inline函数定义、const常量定以外，头文件内不应该放置其他定义。 其次：猜测一下，你这是在试图定义(或声明)类的成员变量么？ 建议：补充一下C++基础。 找到原因了，成员函数内不能定义，毕竟只是一个声明. 在主函数内就可以了 用QVector需要先进行resize,就像分配内存一样？因为QVector我不能直接定义一个81个单元的Vector。 为什么重定向输入，结果读取不了呢？明明从控制台输入就可以。 使用macro宏定义时，始终没能正确替换表达式 现在虽然会了用clang编译选项，但是还是非常不对。 结果居然是因为我宏用了小写……导致了错误，我居然一直没发现。 tmp[] = {9,9}; //vector_2 = tmp; vector vector_2(tmp, tmp+1); 这样就报出了 1234567code.cpp:158:9: error: expected expression tmp[] = &#123;9,9&#125;; ^code.cpp:158:13: error: expected expression tmp[] = &#123;9,9&#125;; ^2 errors generated. 奇怪，用vector&lt;int&gt; vector_2(begin(tmp), end(tmp)); 同样也有这个问题，但是上面那个赋{1}的单项的就没有问题。 发现问题了，只能初始化的时候直接赋列表值，之后就只能一个个赋，或者再定义一个了。 发现segmentfault的原因了，传入指针时，得先定义或者new一下，不然传入赋完值，定义的指针位置什么都没变，就得不到你要的结果了。 C++11添加的raw字符串 C++允许省略C中的结构体的struct语句 C++11支持数组、字符串、结构体列表初始化 c++仅当使用可变参数时函数参数使用……，而C在函数原型中使用可以使用空格()，C++就必须至少是(……),但是更推荐句首说的规则。 有一层const关系时，可以通过非const数据的指针来修改const类型的指针指向的非const类型的数据。 函数指针中(*pf)居然与pf在使用时等价，天哪~ 这种函数引用操作的意义是什么？怎么感觉和在函数中使用没什么区别呀？ 噢，可以省去写重载几个方法的过程，直接传入参数和使用的方法就可以返回结果。 c++11的auto(auto似乎只是自动类型推断，出了错还是程序员的问题)类型转换和显式、隐式类型转换区别在哪里？ 如何传递参数给引用调用时，这个参数是个表达式时，会报错，因为这样会把引用的参数被赋值成那个为了计算表达式而自动建立的临时变量 但是用const引用即可，可以保证这个引用不会被临时变量修改，又可以创建临时变量来计算表达式。 c++11有了 右值引用，可以接受常量了，据说是用来实现移动语义，(move semantics) 返回引用的作用，传统返回，会先把返回的结构复制到一个临时位置，再复制给要赋值的变量，而引用的返回就省去临时位置了。(但是如果这个返回的是该函数中的一个临时变量，这样就会越界，程序出错了，因为该临时变量已经被释放了，却还要从这个位置调用变量) PS:返回引用的函数实际上是被引用的变量的别名。 在使用引用返回时时，如果不使用const，会导致该函数成为左值，可以被赋值，导致错误 重载运算符时省略const是个好方法，但是一般还是使用const更好。 继承有另一个特征，基类引用可以指向派生类对象，而不用进行强制类型转换。 一个基类作为形参的函数，可以输入这个基类的派生类作为实参！！！ 棒！ 默认参数 函数多态和函数重载，似乎不太一样 一个函数的多个形式，是长什么样呢？据说是同一回事，但是通常使用函数重载 在检查特征标时，编译器将引用和类型本身视为同一个特征标。 将非const变量作为实参赋给const变量是合法的。 返回类型可以不同，但是特征标也必须不同。 编译器会跟踪重载函数，进行名称修饰或者名称矫正 模板里的typename是C++98添加的，在这以前都是用class的，所以能用typename还是用typename吧 template需要声明也需要定义 模板重载 模板局限性，有些类型的操作不支持 ### 显示具体化 具体化优先于常规模板，而非模板函数优先于具体化和常规模板。 template&lt;&gt; void Swap&lt;job&gt;(job &amp;, job &amp;); 实例化和具体化 隐式实例化，就是使用模板生成函数定义 现在支持了显式实例化， template void Swap&lt;int&gt;(int, int); 显式实例化可以将原本不匹配的模板函数调用，进行了强制类型转换以后进行调用。 。 以上统称为具体化。 相同之处在于，它们表示的都是使用具体类型的函数定义，而不是通用描述。 选择最佳重载函数时 1. 完全匹配 2. 提升转换(char/short到in, float到double) 3. 标准转换(int to char,long to double) 4. 用户定义的转换，如类声明中定义的转换 术语“most specialized”并不一定意味着显示具体化，指编译器推断使用哪种类型时执行的转换最少。 这个属于C++98增加的函数模板的部分排序规则 不知道模板函数中，应该在声明中使用哪种类型，现在可以用关键字decltype 还有一种函数声明语法（C++11后置返回类型) 1234567891011double h(int x, float y);变成auto h(int x, float y) -&gt; double;使用template &lt;class T1, class T2&gt;auto gt(T1 x, T2 y) -&gt; deltype(x+y)&#123; ... return x + y;&#125; c++内存模型 存储持续性 自动存储持续性 静态存储持续性 线程存储持续性(C++11) 动态存储持续性 内部链接性和外部链接性 const默认内部链接性 可以通过extern扩展 内联函数 似乎不需要满足单定义规则 multable可以让优化 实现可以使用其他语言链接性 new失败返回，std::bad_alloc new是在堆中建立 p1 = new(buffer) int;在buffer中建立，buffer指定的是静态内存中，不能用delete 名称空间 using编译指令和using声明 C++保证函数不会修改变量， void Stock::show() const 声明为const成员变量 用枚举来创建符号常量 可以用static在类声明中定义常量 static const int Mouth = 12; ^ | 像这样 c++11提供了新枚举 12enum class egg &#123;Small, Medium, Large, Junbo&#125;;enum class t_shirt &#123;Small, Medium, Large, junbo&#125;; 不过这种不支持隐式类型转换，不能自动变成int，需要显式转换 当构造函数只接受一个参数是，下面这3个是等价的 123Swtonewt incognito = 275;Swtonewt incognito(275);Swtonewt incognito = Swtonewt(275); 不过，如果把构造函数声明成explicit，就不能用上面的第一行了，就关闭了隐式自动转换 转换函数： 把类赋给基本类型变量： 12operator int();operator double(); 转换函数必须是类方法； 转换函数不能指定返回类型 转换函数不能有参数 过程中自动应用了类型转换 出现多个转换函数，用隐式存在二义性时，编译器会error 类中的静态存储类 static声明的变量 即便有多个类副本，也只有一个这个变量，是共享的。 C++11提供了2个特殊成员函数： 移动构造函数和移动赋值运算符 c++11空指针nullptr 静态类成员函数，只能用这种方法调用 1int count = String::HowMany(); 继承 继承is-a关系：公有继承 is a kind of关系 而不是has a 关系 多态公有继承 虚方法 在派生类中重新定义基类的方法 虚函数能够根据指针/引用的对象实际是什么类型而确定选择基类的方法还是派生类的方法 可以使用一个对象的指针数组来保存他和他的派生类，实现一种多态性 虚析构函数也是有作用的，比如保证派生类的析构作用能够生效 静态联编(static binding) 使用了虚函数时，静态联编不足以做到，就需要使用到动态联编 由于效率和概念模型才使用2种联编方式 如果要在派生类中重新定义方法，才定义虚函数，否则就定义非虚函数 虚函数的工作原理 析构函数应当是虚函数， 因为基类的析构函数如果不是虚函数，就无法释放在派生类中新添加的对象的内存 友元不能是虚函数 重新定义虚函数，将隐藏基类的方法 不过如果返回类型是基类引用或指针，则可以修改为派生类的引用或指针，叫做covariance of return type 抽象基类 ABC概念 使用纯虚函数 包含纯虚函数的对象只能用作基类，无法被定义，声明结尾为0 1virtual double Area() const = 0; 继承和动态内存分配 友元类 lambda表达式 123[](int x) &#123;return x % 3 == 0;&#125;//匿名函数[](double x)-&gt;double&#123;int y = x; return x-y;&#125;//不止一句时要用后置语法，因为只有一句返回语句组成lambda时，自动类型推断才管用。 基类动态内存分配，派生类不用，则不用显示定义析构函数、复制构造函数和复制运算符 派生类有，则需要，并且派生类的复制构造函数需要调用基类的复制构造函数（因为没有权限访问基类成员） c++11添加了可以继承的构造函数，不过默认不开 valarray类 使用公有继承，可以获得接口和实现（基类有纯虚函数只能获得接口） 使用组合，可以获得实现，但没有接口 explicit将禁止隐式类型转换 私有继承：可以直接在成员方法中使用基类的私有变量和方法了 也是has-a关系 也可以同时私有继承多个类 C++11的初始化列表是通过initializer_list il来实现的，之后可以看下 在头文件中 智能指针，auto _ptr,unique _ptr和shared _ptr，auto在C++11已经被摒弃 throw()也被摒弃，但是这个是什么东西？ unique _ptr强调对象所有权，而shared _ptr则添加引用计数，在最后的计数为0时才释放 unique可用于数组的变体，new []，而其他2个没有 在用的迭代器的时候，可以用C++11的自动推断，auto pd = score.begin()挺有意思的 for_each(),random_shuffle(),sort()都挺特别的 c++11的循环类似python中的 for(auto x: books) ShowReview(w) 正向迭代器:双向通行算法 迭代器类型只是概念性描述 \badapter，一个类或函数，可以将一些其他接口转换为STL使用的接口 看不太懂 就像这样 123#include &lt;iterator&gt;ostream_iterator&lt;int,char&gt; out_iter(cout, \" \"); vector反向打印 可以使用rbegin()的指向超尾的反向迭代器，rend()返回一个只想第一个元素的反向迭代器 插入迭代器 c++11添加的概念，可复制插入，可移动插入 移动构造函数 异常规范方面的修改，noexcept 作用域内枚举 右值引用（完全不记得了） 包装器，std::function&lt;double(char, int)&gt; ef c++11，atomic原子操作，并行编程 多个专业库 regex支持正则表达式 — 不会写widget，所以先写console版本测试时，发现conio.h不是ANSI C标准的，在mac平台C++中 并不支持。 c++ hash函数 hash在C++11有了元编程 123hash&lt;string&gt; h;size_t n = h(url);cout &lt;&lt; n; c++ stringstream getline作为分隔符相当好用 1234while(getline(ss, temp, ','))&#123;&#125;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"}]},{"title":"《星之梦》传播星空之人","slug":"《星之梦》传播星空之人","date":"2017-01-04T07:03:45.000Z","updated":"2020-10-18T07:54:16.000Z","comments":true,"path":"2017/01/04/《星之梦》传播星空之人/","link":"","permalink":"https://sean10.github.io/2017/01/04/《星之梦》传播星空之人/","excerpt":"","text":"《星之梦》开篇引出的AI机器人第一时间给我的反应是，这极可能又是基于阿西莫夫机器人三定律之上的人与机器人的故事。 梦美在这里的设定显然不止是常规的Robot，虽然她自称是廉价型，不过也显然不同于故事开始时攻击人类的武装机器人一般只是贯彻攻击指令，她是具有自主性的AI。姑且忽视老化、无修理能力、供电持续30年等一系列相对不现实的因素，当作满足了千万分之一的偶然性吧。这样的设定给梦美提供了一个令人不由得深思的背景，29年多的等待只为服务人类、坚守机器人的守则，这样的梦美为我们揭示的想必就是机器人之中善良的特质吧。 在这个男主时刻为机器人追杀、攻击的年代里，从未遇到善良机器人的男主为其感动，信任了梦美，也得到了梦美的回报，梦美以自己的理念贯彻保护人类。以星空作为回忆媒介，令男主回忆起作为人，不仅仅应该只为生存而生存，而是应当为梦想而追逐。 不过显然啦，假想现实如果发生这样的故事，也就只有人物设定成梦美这样萌，才有后续发展的一丝可能性了。无论如何，亲和感终究只会发生在有羁绊亦或是感官上可接受的对象之间。 在《星之人》剧场版里好像就是之后发生的故事，男主与梦美作为传播星空之人而四处游走之后的故事了，不过现在国内还没上映，估计要等段时间了吧。 超级萌的梦美","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/日本/"},{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/动漫/"},{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/影评/"}]},{"title":"爬虫学习笔记","slug":"爬虫学习笔记","date":"2016-10-27T12:49:28.000Z","updated":"2018-03-09T12:49:28.000Z","comments":true,"path":"2016/10/27/爬虫学习笔记/","link":"","permalink":"https://sean10.github.io/2016/10/27/爬虫学习笔记/","excerpt":"爬虫学习笔记 2016.10.27 在一开始按照例子写最简单的爬虫的时候居然都写错了，写成了如下的","text":"爬虫学习笔记 2016.10.27 在一开始按照例子写最简单的爬虫的时候居然都写错了，写成了如下的 1234567import urllib2req = urllib2.Request('http://example.com')#response = urllib2.urlopen('http://python.org')response = urllib2.urlopen(req)html = response.readf = open(\"out.txt\",\"w\")print &gt;&gt; f,html 在html = response.read()这里少加了个括号，导致赋值的内容不是爬到的内容，而是read的属性？ 1&lt;bound method _fileobject.read of &lt;socket._fileobject object at 0x7fea52107bd0&gt;&gt; 得到了这种奇怪的东西 URLError 通常，URLError在没有网络连接(没有路由到特定服务器)，或者服务器不存在的情况下产生。 这种情况下，异常同样会带有“reason”属性，它是一个tuple（可以理解为不可变的数组）， 包含了一个错误号和一个错误信息。 我们建一个urllib2_test06.py来感受一下异常的处理： 12345678910111213import urllib2req = urllib2.Request('http://www.example.com')f = open(\"out.txt\",\"w\")try: urllib2.urlopen(req)有些东西用js解密的方法，python实在是不会啊except urllib2.URLError, e: print &gt;&gt;f ,e.reason 按下F5，可以看到打印出来的内容是： [Errno 11001] getaddrinfo failed 也就是说，错误号是11001，内容是getaddrinfo failed i have no answer. 123456789101112import urllib2req = urllib2.Request('http://bbs.csdn.net/callmewhy')f = open(\"out.txt\",\"w\")try: urllib2.urlopen(req)except urllib2.URLError, e: print &gt;&gt;f ,e.reason #print &gt;&gt; f, e.code 2.HTTPError 服务器上每一个HTTP 应答对象response包含一个数字“状态码”。 有时状态码指出服务器无法完成请求。默认的处理器会为你处理一部分这种应答。 例如:假如response是一个“重定向”，需要客户端从别的地址获取文档，urllib2将为你处理。 其他不能处理的，urlopen会产生一个HTTPError。 典型的错误包含“404”(页面无法找到)，“403”(请求禁止)，和“401”(带验证请求)。 HTTP状态码表示HTTP协议所返回的响应的状态。 比如客户端向服务器发送请求，如果成功地获得请求的资源，则返回的状态码为200，表示响应成功。 如果请求的资源不存在， 则通常返回404错误。 HTTP状态码通常分为5种类型，分别以1～5五个数字开头，由3位整数组成： ———————————————————————————————— 200：请求成功 处理方式：获得响应的内容，进行处理 201：请求完成，结果是创建了新资源。新创建资源的URI可在响应的实体中得到 处理方式：爬虫中不会遇到 202：请求被接受，但处理尚未完成 处理方式：阻塞等待 204：服务器端已经实现了请求，但是没有返回新的信 息。如果客户是用户代理，则无须为此更新自身的文档视图。 处理方式：丢弃 300：该状态码不被HTTP/1.0的应用程序直接使用， 只是作为3XX类型回应的默认解释。存在多个可用的被请求资源。 处理方式：若程序中能够处理，则进行进一步处理，如果程序中不能处理，则丢弃 301：请求到的资源都会分配一个永久的URL，这样就可以在将来通过该URL来访问此资源 处理方式：重定向到分配的URL 302：请求到的资源在一个不同的URL处临时保存 处理方式：重定向到临时的URL 304 请求的资源未更新 处理方式：丢弃 400 非法请求 处理方式：丢弃 401 未授权 处理方式：丢弃 403 禁止 处理方式：丢弃 404 没有找到 处理方式：丢弃 5XX 回应代码以“5”开头的状态码表示服务器端发现自己出现错误，不能继续执行请求 处理方式：丢弃 ———————————————————————————————— HTTPError实例产生后会有一个整型’code’属性，是服务器发送的相关错误号。 Error Codes错误码 因为默认的处理器处理了重定向(300以外号码)，并且100-299范围的号码指示成功，所以你只能看到400-599的错误号码。 BaseHTTPServer.BaseHTTPRequestHandler.response是一个很有用的应答号码字典，显示了HTTP协议使用的所有的应答号。 当一个错误号产生后，服务器返回一个HTTP错误号，和一个错误页面。 你可以使用HTTPError实例作为页面返回的应答对象response。 这表示和错误属性一样，它同样包含了read,geturl,和info方法。 我们建一个urllib2_test07.py来感受一下： i have no answer 1234567891011121314151617import urllibimport urllib2url = 'http://www.someserver.com/cgi-bin/register.cgi'user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'values = &#123;'name': 'Michael Foord', 'location': 'Northampton', 'language': 'Python' &#125;headers = &#123;'User-Agent': user_agent&#125;data = urllib.urlencode(values)req = urllib2.Request(url, data, headers)response = urllib2.urlopen(req)the_page = response.read()f = open(\"out.txt\",\"w\")print &gt;&gt; f, the_page this has been unacceptable. 2017.11.18 使用selenium+PhantomJS 编写爬虫时，如果单纯是静态网站，Nodejs的cheerio,requests以及Python的urlib、urlib2与request(BeautifulSoup)就能解决需求。如果碰上网站通过AJAX获取数据或者JS延迟获取数据时。 使用lxml解析器的原因是比较性能之后，还是lxml比较优异，基本都能解析 HTTP请求主要分为Get和Post两类： GET是从服务器上获取指定页面信息，POST是向服务器提交数据并获取页面信息。 GET请求参数都显示在URL上，服务器根据该请求所包含URL中的参数来产生响应内容。 “Get” 请求的参数 是URL的一部分。 POST请求参数在请求体当中，消息长度没有限制而且以隐式的方式进行发送，通常用来向HTTP服务器提交量比较大的数据（比如请求中包含许多参数或者文件上传操作等）。 “POST”请求的参数 不在URL中，而在请求体中。 页面的form表单一般都有method属性，默认值是“get”。 举个栗子，登录时提交用户名和密码： 如果用“get”方式，提交表单后，则用户输入的用户名和密码将在地址栏中暴露无遗； 如果设置为“post，则提交表单后，地址栏不会有用户名和密码的显示。 所以处理登录页面的form表单时，发送的请求都是”POST“方式。 wsgi协议 字节协议 没找到为什么，python socket建立服务器的时候，浏览器始终接收不到数据，接收到也显示不出来，不明白为什么 chrome和safari不显示，但是firefox显示了，先用firefox,以后再想这几个之间的区别 去掉了HTTP/1.1的表头，居然还能显示出来 换行符协议 特殊字符分割协议 二进制字符长度定义协议 为什么使用301永久重定向呢？ 一个解答是为了SEO 启动和停止ssdb服务 启动：ssdb-server /usr/local/etc/ssdb.conf 守护进程启动方式 ssdb-server -d /usr/local/etc/ssdb.conf 停止： ssdb-server /usr/local/etc/ssdb.conf -s stop 重启：停止： ssdb-server /usr/local/etc/ssdb.conf -s restart 启动客户端:ssdb-cli 支持数据类型 SSDB ⽀持三种数据类型, 别分是 KV(key-value), Hashmap(map), Zset(sorted set). requests爬取中文乱码 使用str(html.content,“utf-8”)搞定 http://www.cnblogs.com/bitpeng/p/4748872.html StringIO这个模块在python3里有点不一样了，存在了Io模块里，没办法直接用别人的资料了 保存图片在本地 123456789101112from PIL import Imageimport ioimport requestshtml = requests.get(\"http://jwxt.bupt.edu.cn/validateCodeAction.do?random=\")f = open('code.jpg','wb')f.write(html.content)f.close()img = Image.open('code.jpg')#'/Users/sean10/Desktop/code.jpg' 而在python3.x中，GIL不使用ticks计数，改为使用计时器（执行时间达到阈值后，当前线程释放GIL），这样对CPU密集型程序更加友好，但依然没有解决GIL导致的同一时间只能执行一个线程的问题，所以效率依然不尽如人意。 这些队列都实现了锁原语，能够在多线程中直接使用 python并发 从threading到multiprocess，再到concurrent.future支持 jsessionid似乎是j2ee的东西 beautifulSoup的对象，如何打印出来，他的子对象tag对象没有text方法 常见的反爬策略主要有： IP限制 UA限制 Cookie限制 资源随机化存储 动态加载技术 …… 对应的反爬处理手段主要有： IP代理池技术 用户代理池技术 Cookie保存与处理 自动触发技术 抓包分析技术+自动触发技术 有效地存储（数据库应该怎样安排） 有效地判重（这里指网页判重，咱可不想把人民日报和抄袭它的大民日报都爬一遍） 有效地信息抽取（比如怎么样抽取出网页上所有的地址抽取出来，“朝阳区奋进路中华道”），搜索引擎通常不需要存储所有的信息，比如图片我存来干嘛… 及时更新（预测这个网页多久会更新一次） BeautifulSoup找不到解析的元素的原因，似乎是因为网页编码问题，比如学校教务系统用的是GBK,不是utf-8，就不好搞了 在使用Beautifulsoup过程中，对于大多数html源码，通过指定正确的编码，或者本身是默认UTF-8编码而无需指定编码类型，其都可以正确解析html源码，得到对应的soup变量。 然后就接着去利用soup实现你所想要的功能了。 但是有时候会发现，有些html解析后，有些标签等内容丢失了，即所得到的soup不是所期望的完整的html的内容。 这时候，很可能遇到了非法的html，即其中可能包含了一些不合法的html标签等内容，导致Beautifulsoup虽然可以解析，没有报错，但是实际上得到的soup变量，内容缺失了一部分了。 比如我就遇到过不少这样的例子： 部分Blogbus的帖子的html中非html5和html5的代码混合导致Beautifulsoup解析错误 之前在为BlogsToWordPress添加Blogbus支持过程中去解析Blogbus的帖子的时候，遇到一个特殊的帖子：http://ronghuihou.blogbus.com/logs/89099700.html，其中一堆的非html5的代码中，包含了这样一段html5的代码的写法，即标签属性值不加括号的： document.oncontextmenu=new Function(\"event.returnValue=false;\"); //禁止右键功能,单击右键将无任何反应 document.onselectstart=new Function( \"event.returnValue=false;\"); //禁止先择,也就是无法复制 结果导致Beautifulsoup解析错误，得到的soup中，找不到所需要的各种class等属性值。 对应的解决办法就是，把这部分的代码删除掉，然后再解析就可以了： 其中一堆的非html5的代码中，包含了这样一段html5的代码的写法，即标签属性值不加括号的： foundInvliadScript = re.search(“ .+ “, html, re.I | re.S ); logging.debug(”foundInvliadScript=%s“, foundInvliadScript); if(foundInvliadScript): invalidScriptStr = foundInvliadScript.group(0); logging.debug(”invalidScriptStr=%s“, invalidScriptStr); html = html.replace(invalidScriptStr,”“); logging.debug(”filter out invalid script OK“); soup = htmlToSoup(html); 判断浏览器版本的相关代码，导致Beautifulsoup解析不正常 之前在给BlogsToWordpress添加新浪博客的支持的过程中 遇到很多新浪博客的帖子的html中，包含很多判断浏览器版本的相关代码： &lt;!–[if lte IE 6]&gt; xxx xxx &lt;[endif]–&gt; 由此导致Beautifulsoup解析html不正常。 font标签嵌套层次太多，导致Beautifulsoup无法解析html 接上面那个解析新浪博客帖子的例子，期间又遇到另外一个问题，对于一些特殊帖子：http://blog.sina.com.cn/s/blog_5058502a01017j3j.html 其包含特殊的好几十个font标签且是一个个嵌套的代码，导致无法Beautifulsoup无法解析html，后来把对应嵌套的font标签删除掉，才可以正常解析。 相关python代码为： handle special case for http://blog.sina.com.cn/s/blog_5058502a01017j3j.html processedHtml = processedHtml.replace(‘’, “”); processedHtml = processedHtml.replace(“”, “”); 遇到其他类似的问题，也可以去删除或替换出错代码，即可解决问题。 不过需要说明的是，很多时候，你未必很容易就找到出错的代码。 想要找到出错的代码，更多的时候，需要你一点点调试，一点点的删除看似可疑的一些html源码，然后最终才能定位到出错的代码，然后删除掉后，才可以正常工作的。 uri资源文件如何获取，似乎有格式 似乎是jquery自带的延迟加载技术 像淘宝或者京东这样的APP页面上有很多图片,当我们滑到下一屏时下一屏的图片才会加载,这就采用了图片懒加载的方式. 图片懒加载,简单来说就是在页面渲染过程中,图片不会一次性全部加载,会在需要的时候加载,比如当滚动条滚动到某一个位置时触发事件加载图片,如下代码: 通过js将img标签的data-src属性赋值给src属性 但是如果是用base64的，在dom里属性就消失不见了 针对decode base64编码的图片比较慢的问题,我们可以选择使用canvas来加速.当向canvas发出绘画命令时,浏览器直接将指令发到图形加速器而不需要开发者更多的干预,硬件图形加速器则以难以执行的运算速度实时绘画和渲染图形.因此,我们可以使用canvas来渲染base64编码后的图片 Inlined Placeholder Image To reduce the amount of request you can use data uri images as the placeholder. 最后解析出来的base64居然不是图片，也是怪奇怪的 http://api.nicodic.jp/ 豆瓣获取url还是非常简单的，就是被403了，明天再看了吧，还有个数据库连接池多线程的问题需要试试。 python的json.dumps方法默认会输出成这种格式“","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sean10.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sean10.github.io/tags/爬虫/"},{"name":"Spider","slug":"Spider","permalink":"https://sean10.github.io/tags/Spider/"}]},{"title":"吸血鬼起源","slug":"吸血鬼起源","date":"2016-08-26T09:25:43.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/08/26/吸血鬼起源/","link":"","permalink":"https://sean10.github.io/2016/08/26/吸血鬼起源/","excerpt":"之所以写起这个，是因为最近开始写起宅文了，背景设定需要就来搜集一些资料。 所以本文会提到的起源只会是从神话角度和各式作品里提取的。","text":"之所以写起这个，是因为最近开始写起宅文了，背景设定需要就来搜集一些资料。 所以本文会提到的起源只会是从神话角度和各式作品里提取的。 当下流行的魅力无边的吸血鬼来自于1819年约翰·波里道利，这是19世纪早期最有影响力的吸血鬼作品。 不过，作为吸血鬼小说的精粹而被铭记，并且为现代吸血鬼传说铺路的，是布莱姆·斯托克1893年所著的《德古拉》。 在民间传说之中，虽然认为吸血鬼在夜间比较活跃，但通常它们并没有被认为对阳光敏感。 在一些文化里，吸血鬼不能在镜中倒映，也没有影子，也许这是吸血鬼没有灵魂的表现。（这点可以借鉴） 吸血鬼起源除了小说作品和民间传说之外，在《圣经》等传说、史诗中也保有可追溯的典故。 1.犹大 犹大背叛耶稣的典故众所周知，他背叛耶稣，加上他自缢身亡不符合礼数，因而死后灵魂没有办法安息，天堂与地狱都没有他的位置。因此犹大的灵魂回到原本的身体，变成了吸血鬼。 据说背叛上帝或是基督教信仰的人，一定会变成吸血鬼，因为灵魂无处可去，只好游荡人间，永世不得安息，直到获得赦免的那一天。 2.该隐(Cain) 该隐弑弟亚伯，受到上帝的诅咒，永远不能行于白天之下，只能在黑暗中与夜晚的生物共存，并靠吸食动物的血为生。与小说中的吸血鬼形象十分贴切，因而便传出了其为吸血鬼先祖的传说。 该隐之后与同被诅咒的莉莉丝相结合，诞生了13个孩子，之后传说中的吸血鬼十三氏族是他们的后代第三代吸血鬼所创立的，据说他们叛变了他们的父母。 在面临天主教捕杀危险即将灭族之际，七大幸存氏族确立了六条戒律。 第一戒律：避世(The First Tradition: The Masquerade) 不可對非氏族的人顯露自己的面目，否則其他吸血鬼會和你斷絕一切關係。 第二戒律：領權(The Second Tradition: The Domain) 在自己的領土上，你有著至高無上的權利，任何外來的吸血鬼都要尊重你。 第三戒律：後裔(The Third Tradition: The Progeny) 如果你要創造新的吸血鬼，你必須得到尊長的同意。如果你違反此戒條，你和你的後裔都會被處死。 第四戒律：責任(The Fourth Tradition: The Accounting) 你所創造的吸血鬼是你的後裔，在他們被讓渡之前，你應該在各個方面指導他們。他們的罪要當成自己的來忍耐。 第五戒律：客尊(The Fifth Tradition: Hospitality) 吸血鬼應該互相尊重領權，當你到達陌生的土地的時候，應該向當地的長老引薦自己，不得他的批准，你不能做任何事情。 第六戒律：殺親(The Sixth Tradition: Destruction) 嚴禁殺害你的同類，只有長老有獵殺的權利。 以下是动漫世界中的背景设定，可忽视 《噬血狂袭》： 魔族中的一种，不老不死，恢复力和身体能力超越一般人类，同时拥有眷兽。 吸血鬼吸血可以补充魔力，不过吸血行为多半是由于性欲引起的冲动，因为吸血冲动而把爱人吸血过度致死的事件也不少。 吸血鬼之所以被称为最强的魔族，那都是因为有压倒性战力的眷兽，其肉体能力在魔族中并不算强。 即便被夸大成不咯不死，吸血鬼也并非彻底的不死之躯。特别是控制魔力的脑以及司掌血液循环的心脏，都算致命性弱点。 这里的真祖的来源是人类被现在已逝去的神施加了诅咒，或是经由神的密咒自身变成吸血鬼，通过吞噬吸血鬼也可以把人类变成真祖，也可能被反噬，如主角晓古城。 这里的吸血鬼无法进行同族相噬，年轻世代的吸血鬼如果吞噬了高等级的吸血鬼，可能被对方从身体内侧吞噬。 《十字架与吸血鬼》： 有“力量之大妖”的称号的稀少种族。自尊心很强，能够把自身的妖气化成力量以使出各种物理攻击，而且有异常强的复原能力及妖气探知。不过，这里的吸血鬼参考了民间传说，弱点为水和十字架。他们只能使用放入特殊草药的水。另外，吸血鬼的血拥有使人复原的能力，只要肉体能够承受血液，即使在濒死边缘也可以复原。不过，接受者也有副作用，拥有吸血鬼力量就有机会像主角一样尸鬼化。 《终结的炽天使》中提取到的背景资料是这样的。 这里的吸血鬼设定是有尖耳锐牙与赤瞳，以及常年不易老化的身体，身体能力是人类的七倍以上，这部分是基本设定。 这里的吸血鬼依旧遵循了常规的怕光的设定，不过这里吸血鬼外出的服装上会装备一种叫做紫外线中和的装置，是左上臂黑色那块。 据称这个世界观下的吸血鬼发展下去最终是变成鬼。 1 2 然后，这里并没有提到始祖的的由来。 参考资料： [1] 《终结的炽天使》漫画8.5卷，http://home.gamer.com.tw/creationDetail.php?sn=2860481 [2] 维基百科——吸血鬼，https://zh.wikipedia.org/wiki/%E5%90%B8%E8%A1%80%E9%AC%BC [3] 维基百科——噬血狂袭，https://zh.wikipedia.org/wiki/%E5%99%AC%E8%A1%80%E7%8B%82%E8%A5%B2 [4] 维基百科——十字架与吸血鬼，https://zh.wikipedia.org/wiki/%E5%8D%81%E5%AD%97%E6%9E%B6%E8%88%87%E5%90%B8%E8%A1%80%E9%AC%BC [5] 吸血鬼起源的三大典故，http://darthmoon.pixnet.net/blog/post/19794082 [6] 揭秘吸血鬼种族的由来，http://www.nownews.com/n/2013/06/15/231804","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"小说","slug":"小说","permalink":"https://sean10.github.io/tags/小说/"},{"name":"吸血鬼","slug":"吸血鬼","permalink":"https://sean10.github.io/tags/吸血鬼/"}]},{"title":"小议各式主角之死","slug":"小议各式主角之死","date":"2016-08-04T23:25:34.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/08/05/小议各式主角之死/","link":"","permalink":"https://sean10.github.io/2016/08/05/小议各式主角之死/","excerpt":"","text":"在作家手中，为了推进故事发展，往往总是会有角色离开我们，主角也无例外。 在我最喜欢的《叛逆的鲁鲁修》中，lelouch在故事的最后以自己的死亡来解放全世界。Lelouch决心背负世界的罪恶，作为全世界的敌人而死，让人们珍惜来之不易的和平。而型月世界里的Gilgamish说过“王来承认，王来允许。王来背负整个世界。”各个故事中，作为王的主角，若是离去，必背负着一切。在《罪恶王冠》中，集如同Lelouch的挚友朱雀一般，背负了祈和涯托付给他的未来以及他自身的罪孽继续活着。 不过，存在王的故事往往都是基于一个宏大的世界观，具有伟大的背景，这样的故事写好了的终究还是少数。更多的还是基于现实的日常，但又脱离了现实的故事。《命运石之门》，我想就可以说是一部代表作。以世界线变动作为这个世界的基准，凤凰院凶真扰动了世界线，拯救了克里斯蒂娜的死，但有得必有失，等价交换的原则，以真由理之死为代价。故事最终找到了一个完美的世界线，作者给了一个幸福的结局。这类故事基于日常，所以主线都会围绕着人与人之间的感情而展开，最多的是爱情，友情其次。 说到爱情之死，不得不提到Key社名作《Clannad》了。在After Story中，渚身体虚弱离去了，朋也崩溃了，颓废了，直到在早苗的安排下带着汐旅行时意识到自己的父亲在同样的处境下所背负的，意识到了自己所该做的，决心照顾好汐。同样的，汐也走上了和渚小时候面临的同样的处境，坚强的汐最后还是没能挺过发烧。这个时候，这个小镇的奇迹发生了，朋也回到了渚生下汐的那一刻，这个世界里，渚活下来了。故事终于在一遍又一遍的催泪中达成了一个满意的结局。 爱情之死，都是作为剧情的推动，引发其他角色的心理的一个巨大变化。 除此之外，就是推理故事中的推理所需的案件之死了。《弹丸论破》是以角色的死亡来为主角提供线索破解故事，《名侦探柯南》则是柯南所到之地，必有人死亡。 前两种死亡，都会带来无比的催泪效果，虐心倒不觉得，毕竟作者提供的铺垫已足够强烈。 PS:《斩！赤红之瞳》里的死根据剧情明明可以避免，却偏要以悲剧来推动，并不能接受。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"死亡","slug":"死亡","permalink":"https://sean10.github.io/tags/死亡/"}]},{"title":"论Pokemon Go","slug":"论Pokemon-Go","date":"2016-07-14T13:30:20.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/07/14/论Pokemon-Go/","link":"","permalink":"https://sean10.github.io/2016/07/14/论Pokemon-Go/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"重读《爱的艺术》","slug":"重读《爱的艺术》","date":"2016-07-02T02:09:22.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/07/02/重读《爱的艺术》/","link":"","permalink":"https://sean10.github.io/2016/07/02/重读《爱的艺术》/","excerpt":"","text":"弗洛姆在书中首先讲述了爱情其本质也是一门艺术，而非对象问题。 其次讲述了爱情的本质目的是为了补全人类的天性的缺失，弥补个人的孤独，这是人类的生存的必要条件。 第三讲述的是孩子对父母的依存，从父母身上找到仍在胎中时的温暖的感觉。而父母在这个过程中对孩子的影响则是巨大的，导向了孩子长大后对爱的艺术的掌握。， 第四正式讲述了关于爱的对象的问题，对不同对象所见所具有的不同的爱，博爱、母爱、性爱、自爱、神爱。 关于博爱，无法做到对所有需要帮助的人均爱，则无法称之为博爱。 母爱，则是对上一章的补充，补充了唯有无私并能奉献出一切，除了被爱者的幸福一无所求的母亲才真的就具有母爱。 关于性爱，则是讲到性要求的数种误解，其一是认为性要求能够解除一切的隔阂，然而这样建立的亲密关系随着时间的推进会很快消失;其二，认为有了性要求必然是已经具备了爱的结果，然而性要求是爱情之后的衍生，但性要求并非唯有具备了爱之后才会产生。另外，一种认为性爱完全是两个人之间的吸引力，是两个特殊的人之间绝无仅有的联系;另一种认为性爱只是意志的行为。以上两种观点都是正确的其实。是两者综合之后方具有的爱情。 关于自爱，这种爱是判断你是否具有爱的能力的标志。无法以爱自己般爱他人与无法以爱他人般爱自己均是不具有爱的能力的体现，仅仅是一种利己的表现。 关于神爱，神爱是另一种形式的爱。 依据悖论逻辑，人只有在现实的矛盾中才能感觉现实，人永远无法在思想上把握最终实体，把握宇宙。人们不应该把从思想上找到答案看作最终目的。思想只能使我们认识到思想不能使我们作出最终回答，思想的世界囿于悖理之中。即对神的爱既不是从思想上了解神，也不是指自己爱神的思想，而是在爱的体验中体验自己同神的一致。这里印度、中国和神秘主义的宗教中，是以此作为神爱。 而在西方主流思想中，人们相信在正确的思想中会找到最终真理，因而也会引起科学的发展。 第五，爱情在当下西方资本主义社会中的衰亡。于当下，迫于社会的高度集中的特性，现代人受到了异化，失去自我，成为一种自动机器。这样的情况下为解除孤独而但诞生的爱情和婚姻概念实际上是强调保护自己免遭不可忍受的孤独感的侵袭。两个人结成以反对全世界的同盟，却把这种两个人的自私看作是爱情和信赖。后续还稍稍提及了神经技能病态爱情的部分。 第六，爱的实践。在这一部分中，作者着重强调了任何艺术掌握的必备条件，在生活中的每一个阶段将训练纪律、集中和耐心作为实践爱的艺术的开端。之后讲述了关于作者认为的爱的艺术的必备条件——克服自恋与积极的活动。整个这一段的内容放至当下仍无不可。 大致就是以上的内容了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/读书笔记/"},{"name":"爱的艺术","slug":"爱的艺术","permalink":"https://sean10.github.io/tags/爱的艺术/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/爱情/"}]},{"title":"综述日本动漫艺术","slug":"综述日本动漫艺术","date":"2016-06-12T10:32:12.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/06/12/综述日本动漫艺术/","link":"","permalink":"https://sean10.github.io/2016/06/12/综述日本动漫艺术/","excerpt":"综述现代日本动漫艺术表现","text":"综述现代日本动漫艺术表现 摘要： 动画从本质上来说是属于电影艺术的一个分支，与根据现实情况拍摄、构造的电影是基本一样的。甚至而言，现实拍摄无法制作的电影，藉由一切由想象力掌控的动画，完全可以得到实现。随着时代的发展，无论是从技术上来说、还是从艺术表现的思想和手段，动画都已经成为了一个极其深刻的思想产物。而仅从现在来看，动画范围内，日本动画无论是从艺术水平来说，还是从动画产业发展的成熟性来说，无愧为世界第一。因而，对于日本动画的艺术表现进行调查十分有必要。日本动画采用分镜、分格系统来描写整个故事，掌控故事节奏。在描写角度上，主要受史诗影响，客观描写整体与细节；而从描写题材上，则以具有传奇性为特点。 关键词：日本动漫；史诗；艺术表现；绘画；特征 一、引言 动画从本质上来说是属于电影艺术的一个分支，与根据现实情况拍摄、构造的电影是基本一样的。甚至而言，现实拍摄无法制作的电影，藉由一切由想象力掌控的动画，完全可以得到实现。 虽然在过去，动画一直都是被定位为面向未成年人，并且这样的情况可能还会存在很长一段时间，不过有点必须为我们所意识到，那便是动画已不再只是简单而附肤浅的了。随着时代的发展，无论是从技术上来说、还是从艺术表现的思想和手段，动画都已经成为了一个极其深刻的思想产物。 动画终将会在艺术范畴内占据一定地位，而仅从现在来看，动画范围内，日本动画无论是从艺术水平来说，还是从动画产业发展的成熟性来说，无愧为世界第一。虽说美国是动画最早诞生之地，技术水平上在世界上处于领先地位，但单从两国的动画作品的艺术境界上来看，迪斯尼作品与日本作品尚还存在天堑之别。以宫崎骏的《千与千寻》为例，以绝对艺术实力在各大电影节中拿下了不少奖项。 因而，对于日本动画的艺术表现进行调查学习，还是存在相当的借鉴意义的。 二、日本动漫的历史[1] 十二世纪到十七世纪江户时代初期，日本漫画界一直把十二世纪的鸟羽僧正觉犹当做祖师爷。在十二世纪，绘卷戏画流行，形成日本独特的绘画形式。十七世纪江户时代初期，京都、大阪的绘师画了一些身材修长的鸟羽绘，成功的造成了时代的风格，引领下一波浮世绘的画风。 十八世纪中到十九世纪，1760年日本伟大的浮世绘师葛饰北斋诞生，一般印象中，他是[漫画]一词用在画作上的第一人。不同于早期的绘卷戏画，北斋的《北斋漫画》创作了很多笔意活泼的滑稽画谱，带动流行，甚至对欧洲绘画界造成一股震撼。 十九世纪中后期，西风东渐，西洋漫画对于日本漫画的革新有很大的贡献。1862年英国漫画家Charles Wirgrman创办《日本笨拙》漫画杂志。这本以时事漫画、风俗漫画为主要内容的创作，用木板美浓纸印刷。《日本笨拙》对日本漫画界产生很大的冲击。西洋漫画的批判式口吻、幽默感以及造型成了时尚。新生代漫画家莫不受其影响，如北泽乐天。 明治时期（1870年-1911年），漫画一直热闹非凡，杂志也多的不胜枚举。1906年，北泽乐天创办了日本第一份漫画刊物《东京小精灵》，是日本现代漫画的鼻祖。日本现代漫画的历史可追溯到明治时期。确立日本现代漫画的是在讽刺画界极为活跃的北泽乐天。 大正时期（1912年-1925年），以冈本一平为重心的十人漫画家成立了东京漫画会，举办漫画展，大正时代就在他们的主导下更为活泼了。漫画大师冈本一平赋予漫画文学的内容，是故事漫画的先驱者。 与此同时，漫画偶像也出现了，促进了儿童漫画的发展。1923年，日本的第一个漫画偶像出现，这就是桦岛胜一的《阿正的冒险》。儿童漫画也在《阿正的冒险》受欢迎后，由于画家纷纷投入创作，阵容日益增强。 同时期，另外，在讽刺漫画的基础上，反映现实题材的幽默漫画兴盛起来。1924年漫画大师麻生丰的幽默长篇漫画《满不在乎的爸爸》在《报知新闻》刊出大为轰动。这部作品鼓舞了东京大地震劫后余生的人们，获得极大的成功，从此幽默漫画大量在报端出现。 昭和十年（1926年-1936年），昭和初年少年漫画大放异彩，一些作品具有很高的水准，如田河水泡的《黑流浪汉》、岛田启三的《阿吉历险记》、横山隆一的《健少爷》、《小阿福》等。这些作品不仅吸引了全国的少年，而且受到了包括成年人在内的普遍喜爱。 这个时代也是漫画改组的时代，漫画家也纷纷成立了团体。1932年，以《漫画人》的执笔画家横山隆一等二十人为主建立了[新漫画派集团]，另外还有[日本漫画奉公会]、[三光漫画工作室]等组织。结合志同道合的人团结出击，有的还出版年鉴，办很多促销活动，漫画界呈现出百花齐放的局面。 不过不久之后，日本军国主义化，漫画界也被强制集中了。1931年田河水泡的《野狗二等兵》在《少年俱乐部》开始连载，作品采取拟人化的手法，反应了强烈地军国主义思想，迎合了当时日本发动侵略战争的需要。日本漫画创作停滞不前，直到战争结束。 战后初新漫画崛起（1945年-1955年），战后十年，新的价值观打乱了战前的传统与秩序，出现了充满生机的混乱，在这种混沌状态中登场的漫画界巨头就是手冢治虫，他在画技上、内容上和风格上都带来革新，形成日本动漫独特的风格，并且使动漫深入人心。1946年手冢治虫的《新宝岛》问世，迈出了成为现代主流映像漫画的第一步。1952年《铁臂阿童木》开始连载，1963年搬上银幕，它确立了以剧情为重点，不追求图象效果，看重角色的塑造这一独特的日式动画风格。从此，日本漫画界形成了将成功作品改编为TV动画长片的不成文惯例。手冢的漫画大大超越二战前的故事漫画，运用电影运镜手法，使漫画映像有了革命性的变革。由手冢发起的新类型漫画，以剧情发展和人物塑造为主的娱乐故事，逐渐向题材的多元化延伸。 1956年-1965年，漫画题材、类型逐渐丰富，电视动画也兴盛起来了。仿佛是为了摆脱喧闹的市井生活，漫画界涌现出很多朦胧作品。少女漫画得到发展，名列榜首的女作家有上田俊子、牧美也子、花村英子等。石森章太郎的处女作《二级天使》是一部童话喜剧，获得第一届文艺春秋漫画奖的谷内六郎的《离家的孩子》是一部反映郁郁寡欢的乡愁和童心的幻想曲。横山隆一的《阿福》和冈部冬彦的《小男孩》等以家庭生活为题材的漫画开始走红。日本从战后的混乱中开始康复，经济开始复苏，人们的生活比较安定。这一时期的漫画题材广泛，贴近人们的生活，容易被更多的人接受并喜欢。 在大阪，连环画开始萌牙，月刊《影》和1957年创刊的《街》成为连环画的基地。这时，日本漫画界又出现了一股新的潮流，即所谓的「貸本漫画」，即“租借连环画”。最早使用“连环画”这个名称的，是在《街》杂志社工作的辰已嘉裕。1959 年在大阪辰已嘉裕、斋藤隆夫、佐藤雅旦等人组织了连环画工作室。杂志方面，1959 年讲谈社的《少年杂志》等周刊杂志纷纷创刊。租借连环画的主要读者层不再是少男少女，而是那些在日本高速经济增长中，从日本各地大量涌入东京、大阪等大城市中的青年人。可以说，租借连环画唤起了成年人对漫画的需求。 动画在手冢治虫的影响下，整个60年代都处在摸索阶段，题材向多元化延伸。1959年东京电视塔建成，家庭电视机拥有台数已超过700万台。电视的普及加快了动漫的发展，扩大了动漫市场。日本第一部彩色动画电影是 1958 年东映动画制作的《白蛇传》，这部电影可以看作是日本现代动画的开端。科幻题材的动画片如《铁臂阿童木》，横山光辉的《铁人28》、平井正和的《8号人》深入人心。藤子不二雄的《怪物Q 太郎》被改编成动画片，这是科幻动画片以外类型的动画片首次获得巨大成功。随着电视突飞猛进的发展，颇受欢迎的漫画开始被搬上银幕，这些动画片的巨大成功加快了漫画电视化的步伐。从题材上看，科幻动画占了主流，向往自由和平、正义光荣的“机器朋友”是刻画的主要角色。 1965年-1975年，这十年里漫画迅速发展。新的漫画杂志应运而生，培育出一批新漫画的读者层，如《少年杂志》的主要读者是中、小学生，他们的社会人际关系很简单，一般就是家长和孩子、学生和老师、男孩和女孩。集英社1968年创办的《少年跳跃》，发掘出一批新漫画家。此时，《少年杂志》的佳作有《巨人之星》（川崎登）、《明日的乔》（千叶铁矢）等就是围绕中、小学生人际关系创作的连环漫画。这些作品描写了少男少女的成长奋斗过程。由于故事内容都来自少年读者身边，所以极受他们的欢迎。漫画开始受到了社会的瞩目。此后，日本漫画的读者也从中、小学生扩展为高中生、大学生，以及各阶层的青年。 这一时期，日本漫画家协会诞生了，它是全国性的漫画家职能团体。它的宗旨 是维护漫画家协会会员的权益，对文化作出贡献。1972 年设立了 “日本漫画家协会奖”。还有“文艺春秋漫画奖”、“小学馆漫画奖”、“讲谈社漫画奖”及“读卖国际漫画奖”等报社设立的漫画奖。还有个人设立的奖，如“手冢奖”、“藤子不二雄奖”等等。日本漫画家协会诞生以及各种奖项的设立表明在日本动漫的文化地位，认知度大大提高，对动漫进一步发展铺平了道路。 60 年代中叶到 70年代中叶，漫画为了适应迅速发展的需要，故事中的相当大的成份是由其它领域的作家来完成的。连环画的老将小岛刚夕，与小池一夫组合后发挥实力创作的《带孩子的狼》就是典型的例子。另一位专业脚本作家泷泽解的《高中流浪派》，也使人感到新鲜的时代气息。科幻作家加纳一郎、动画片作家藤种桂介等等，也分别拿出成功的作品，以漫画脚本为职业的小池一夫等人进一步扩大了市场占有率。漫画质量的提高，与他们的实力有很大关系。 这一时期，少女漫画有了更高的发展，出现了许多知名的女作家，开拓了少女漫画新的题材。较突出的有高中学生里中满智子的处女作《娜娜和丽丽》、情节剧名家细川知荣子的《帕莉子别哭》，还有擅长写爱情剧的西谷样子的《玛丽露》，还有弓月光的《第一次体验》等作品。在少年漫画肥沃的土壤上，少女漫画迅速赶超上来。这一时期连东京大学的书架上都摆着少女漫画，池田理代子的《凡代赛的玫瑰》以其严谨的历史考证和曲折的故事情节，把少女漫画推上了高峰。 1970年代中-90年代初，日本动漫逐步走向成熟。1975 年至 1985 年这一时期，女漫画家的佳作频频，少年漫画的创作仍然十分丰富，欣赏性、艺术性和娱乐性兼好的作品接二连三出现。这些作品在日本不仅家喻户晓，而且又的作 品被翻译成其它语言，为世界各地的人所熟知。细川知荣子的《尼罗河女儿》、青池保子的《伊凡的儿子们》，1977 年美内铃惠的超长篇《玻璃假面》连载十几年，盛况不衰。藤子 F 不二雄的《机器猫》、鸟山明的《阿拉蕾》、安达充的代表作《接触》、女作家高桥留美子的《福星小子》、原哲夫《北斗神拳》也大受欢迎。这些作品在日本不仅家喻户晓，而且又的作品被翻译成其它语言，为世界各地的人所熟知。如以真正的描写和故事吸引读者的作品大友克洋的《阿基拉》，显示出极高的水平，得到西方国家的认可。 进入 90 年代，日本漫画流派在画风、题材、故事情节等方面八仙过海，各显其能，漫画界出现了百花齐放的局面。如鸟山明的《七龙珠》等作品。漫画作为一种宣传媒介，越来越受到人们的重视。石森章太郎的《漫画日本经济入门》、《漫画日本历史》也在连载，这些都是以成年读者为对象的漫画。这一时期，漫画家的个性更加鲜明了，漫画已从战前的儿童伙伴历经半个世纪的成长，变成了社会的大众传播媒体。 自 1974 年松本零士的《宇宙战舰》上演至 1982 年为止，日本第一次动画热爆发，动画的题材渐渐得到了明确。在这期间日本动画在明确了题材的同时也向着商业化发展。七、八十年代，设定复杂的“商业动漫”迅速覆盖了每个频道。宇宙战舰》是日本动画史上第一部超级剧情片，在该片后，松本零士另有《银河铁道 999》，《一千年女王》等受欢迎的作品。继松本零士后，由富野由悠季原作小说改编成《机动战士高达》在 1979 年开始上演，由于剧情结构复杂而严密，受到动画迷热烈的支持。《宇宙战舰》上演，风靡了无数青少年，连续创下票房奇迹。它的空前成功首次向所有人证明了动画片完全可以不止是娱乐小孩子的消遣玩意，动画在日本的文化地位也因这部电影而被彻底改变。其中《机动战士高达》的成功不仅开创了写实机器人动画的新时代，而且也成为日本科幻动画特别是软科幻动画发展的助燃剂。 自 1982 年《超时空 要 塞 》上演至1987年为止，日本第二次动画热爆发，画技得到了突破。1983年日本动画市场上出现了世界上第一部OVA动画。OVA 为动画在电影、电视 市场外，开辟了一个新市场–录影带市场。该时期由于人们追求视觉享受成为风潮，因此动画画技力求突破。《超时空要塞》创新的视点快速移动效果，造成极佳的动感；宫崎俊的《风之谷》和《天空之城》精细写实的背景；《机动战士 Z》的强调反光，明暗对比等，皆对后来的动画贡献很大。日本动画发展至本时期结束时，剧情、内容、画技皆已达到极高的水准。动画进入了成熟期。70 年代的经济复苏使得日本的工业发展异常迅猛。经济飞跃的同时少年的精神生活需求大增，动漫画的热潮带来的庞大的消费市场。 自 1987 年到90 年代初，日本动画进入路线分化期，走向成熟。受年龄路线思路的影响，1987 年后半年以来，电视上的低龄动画逐渐增多，面向较高年龄层的动画开始转向动画电影。日本电视史上第一部以高中生以上为主要对象的文艺动画连续剧《相聚一刻》曾获得 1988 年日本动画优秀作品排行榜第二名 (该年排行第一是《圣斗士星矢》)；另外还有《天空战记》曾获得 1989 年动画排行第一名。动画进入成熟期后，也像漫画一样出现数部佳片。年龄路线思路下的转向，造成目前日本电视上佳作颇少，而动画电影几乎部部精彩的情况。 最后，20世纪90年代到现在，日本动画进入了风格创新期。在画技、制作手法、构思设计方面都日趋成熟的日本动画，开始追求风格上的创新，试图突破原有的模式，以完善的技巧，加上超越时空的构思，带给观众全新的感官冲击。押守井的电影版《攻壳机动队》以阴郁压抑冷酷的风格，冷静地思考身处高科技社会的人类对未来的不安。 95 年庵野秀明监督的《新世纪福音战士》上映，它则是现代人矛盾而孤寂的心理折射。二十世纪末，人类对自身的思考也逐渐深刻，而同时日本的动画也开始越来越关注贴近现实与心理方面的剖析，由原本普遍爱与友情的主题转为更加人性的刻画。各方面都日臻完美的日本动画并没有停止发展的脚步，仍然在不断自我完善和突破。 三、日本动漫描写特点[2] 动画与漫画虽然分属两种不同的艺术形式，但在日本文化中这两者却有着紧密的关联。日本漫画从动画中汲取了电影的许多视觉效果控制技巧，这使得日本漫画突破了原来以四格漫画为主题的漫画形式，形成了长篇的以叙事为主体的漫画。这种漫画与原来的连环画也相当不一样。它们篇幅要宏大得多，在艺术表现手法上更多运用变形、抽象等经典漫画的手法，而连环发比较倾向于写实风格。更重要的是，日本漫画常常自觉运用某些电影的镜头语言，比如特写、快慢镜头等技巧，来表现画格中的内容。由许多漫画家的图画，略加处理，基本就可用做动画电影的分镜头剧本，比如高桥留美子的作品之一《人鱼之伤》。传统连环画在这方面无疑还处于自发的状态。日本动画在漫画上汲取的营养则更多些。它的剧本大多改编自漫画，纵使是原创作品，其故事的构建方式，也差不多是属于漫画类型的。日本动画一般说比美国动画内容深，题材面广，比欧洲动画要建明动人，这和其漫画的叙事风格是分不开的。因此，在某种意义上来说，日本动画与漫画是二位一体的。[2] （一）日本漫画与动画框架特点 日本漫画（manga）根据文献查阅来看，其特点在于基本框架： 1.具有与影视分镜表类似的分镜系统. 2.具有平面构成因素和阅读顺序作用的分格(frame)系统. 3.其他画面符号系统，如拟声词、文本框等。 4.其他非画面因素的阅读系统，如翻页、连载周期等。 这四个系统在相互影响之下共同决定着日本漫画的语言。[2] 漫画为了达成对故事的长篇叙述，是参照着影视语言而发展的，不过他们之间在一些地方存在显著的区别。这也将是动画与现实影视的一些区别，也是其特点。 二者在表现手法上的时间性存在重要的差别。漫画中的一格是不具有时间性的，它单格叙事的时间性依赖于读者想象去补充。而电影中单个镜头的时间性是显然的。当前，漫画基本是采用蒙太奇的方式来模仿影视。多格可以表现事件发展的时空转换，一格就是一个单位的时间，同一事件所用的格子越多，则表明这一事件经过的时间越久。分格构图的动态节奏随着故事的推进而变化，这不仅出于时空变化演进的需要，也是出于故事叙述的节奏和视觉韵律的需要。 二者的第二个区别是漫画分格系统的独立性以及它和分镜系统的互动作用。Manga引入影视语言中的分镜思路而形成的分格系统，达成了对故事节奏的控制。 漫画绘画的间隔性，导致其世界是由读者所想象而创造出的。漫画引入分镜头语言来表现，通过对分块大小、色彩的控制，可以达成对气氛的控制。如日本漫画家多田由美善于使用大块的黑白灰的颜色，充实实体空间以对观众构筑心理空间和想象空间，引发读者的情绪。 而分镜头的远近则是表现人物情绪、营造心理氛围的有效方法。拉进的镜头，由于画面的充实，对人的视觉神经造成强烈地压迫感；而远景相对显得客观真实，有利于交代人物所处的环境和位置关系。 由于漫画的阅读顺序的自由，带来了一个电影不存在的限制，分格对此起到作用。因为电影的观赏是一个不可逆的过程，读者会被中心点快速吸引注意。而漫画是整体同时展现于读者面前，虽然可能没有意识到，但是所有的分镜都在眼中。从整个页面构成上来说，没有特殊意义的重复性只会带来厌倦。为了防止这样的重复性，不得不添加一些空镜头、全景镜头、以及进行一些视角的变化等等，但这些镜头假如是在电影中则是属于多余的部分，因而对于这些部分的分格大小控制就显得十分重要，既不冗余亦填充了页面。[3] 漫画语言与影视语言的第三点区别在于，文学在漫画中的直接介入。文字的魅力毋庸置疑，漫画因而既具备了影视的具象描述性又拥有了文学所具有的抽象描述性。不过如何控制其平衡，也是一种深刻的技术了。 第四点区别则是漫画具有翻页和连载周期的机制。电影是一次性放送的，而连载漫画是一个时间相当长的过程，对故事叙述的时间长度不同决定了它们叙述手法的不同。漫画的翻页和连载机制的本质上是一种悬念和出人意料的机制，作者需要不断地控制节奏保留高潮。上面说过，读者在翻开前就会对整页的构成有了大概印象，看到分格大小即可知道镜头的重要性，所以要达到悬念效果就必然需要在翻页后。 （二）日本动画艺术描写特点 当前日本动画从描写角度来看深受史诗文体的影响，从题材上来说均属“传离奇之事”。 史诗类作品一个至关重要的文体特征是：创作者不但重视世界情况整体概貌的介绍，且将相关的细节描写视作问题表现的一大乐趣。在这描写过程中，作者力求以客观的、陈述式的笔法赋写，不掺入个人的意见。无论写到何等古怪离奇之事物，他们亦作出客观冷静之态，令观者意味他们仅在“直言其事耳”。 不过随着时代环境的变化，现代作家终究有所不同。对于经典作家来说，无论他们描写的对象有多么离奇怪异，他们不会觉得这些东西与他们现实生存的世界有多么截然对立或扞格不入。他们以综合性的思维描写着他们认为是客观的对象。而现在人对于现实、虚构、理想、狂想、信仰不同向度所指对象本质的不同，有着明晰的洞察。因此，根据描写对象的世界观是否属于现实或想象的范畴的不同，动画家门发展出了一些更细致的关于世界情况叙述的亚类型。 而题材，无论是多么朴实的内容，经过创作家改写之后，终将会凸显其别致之处“离奇”，也唯有此方可让读者感到新鲜与好奇。 1.史诗文体影响 （1）关于未来世界的想象 “未来”者就是有可能到来而尚未到来之事，即被列入科幻分类之内容。而科幻又有“硬科幻”和“软科幻”之分。“硬科幻”，一般地说，是在对现代科技发展深入了解的基础上而展开未来想象的虚构故事。故事对未来技术的描写，从科学的逻辑上说是完全有可能实现的。而软科幻类作品对于未来科技的描写，与现代科技的现实和逻辑存在极大的知识上的断层。日本动画基本都是以“软科幻”为主。如押井守的《攻壳机动队》、手冢治虫的《铁臂阿童木》、富野由悠季的《高达》系列。高达系列中包罗万象，有宏大的战争场面，有惊心动魄的机器人格斗；有诡谲的政客政治，有非理性的暴民政治；有世俗气浓重的社会生活，有平静温馨的家庭生活；有勾心斗角的阴暗人性，有阳光少年的青春活力等等。作品很细腻，刻画了各种各样的人和各种复杂的任性，但作者并没有展现出对某种价值观的倾向，展现了坚定的史诗的客观态度。 对未来世界的描写当然不仅仅只是对恒久不变任性的客观谛视、对人类社会中权利争斗的洞察、对未来世界某一标志性的对象物进行复杂的甚至是谱系化的描写等等，不过不得不承认，日本这一类型的动画创作者均受到了深厚的影响，没能脱离这个范围。 (2)追忆过往 过往的历史留有的空白给人们同样留下了巨大的想象空间。追忆已经过去了的好时光，试图弥补已经成为既定历史现实的憾恨，将过去、现在、未来联系起来系统考察并谛视人类宿命的思想冲动等等，都构成了强大的心理情结，使得作家们不禁频频回望人类的既定历史，并以此为基础抒发个人的情怀。和月伸宏的《浪客剑心》以大剑客绯村剑心的爱恨情仇为主线，但这主线并不仅是个人浪漫经历的折射，是与19世纪末叶日本国内可歌可泣的倒幕维新运动和现代化的立国进程紧密地联系在了一起。剑心不断地与大久保利通、新撰组这些不同性质的政治力量周旋、斗争，并从中寻找个人最终价值的皈依。战争中的人性、战争中的正义与非正义、日本为什么会走上军国主义之路等沉重问题，在特定背景中一一给予了反省。 (3)凝望现实 一般地说，史诗性创作的问题特征与现代生活带给人们的感受是有所抵触的。黑格尔说过，“整个现代世界情况是受散文似的秩序支配的，和我们对史诗所要求的必不可少的条件完全背道而驰。”不过，在现实中也是可以诞生史诗品格作品的。创作者对于故事的世界设定需要是单纯的，并充满作者的理想情怀，虽展现现实，但却并非真实现实那般的复杂、残酷。如《足球小将》中的足球世界，充斥着理想与美好，并不存在真实世界的复杂交易，正是因为其不真实的美好，而令读者充分感受其中对足球的热忱向往、及其奋斗的坚毅。 (4)多元时空的混合交融 在这种作品中，世界的先验设定、展开逻辑是与现实世界存在极大不同的。日本动漫家常常假定这样的生存空间，在这个世界里，人类过去、现在、未来的各种经验、想象，甚至是一些纯粹来自于可能世界的想象，被糅合在了一起，被当做了一种客观实存的东西来加以表现，即龙与地下城之类背景风格的故事创作。这种世界观的作品，在日本动漫中一直以来占据重要地位，永井豪、石森章太郎、赤冢不二夫和横山光辉早期的创作、宫崎骏、Clamp、高桥留美子、富坚义博等均是深有影响的描绘平行时空的动漫艺术家。 2.传奇题材 （1）战争主题 虽然动漫作家中很少有人真正去考量整个民族的心灵在历史进程中必须要直面什么，承担什么的问题，但他们还是能够自觉地认识到，有关战争的问题，总是能够引起大部分人的关注。而战争吸引人的，无非是宏大场面，扭转乾坤的英雄人物以及智谋斗争这些基本元素。如《风之谷》、《银河英雄传说》、《高达》系列、《超时空要塞》系列、《EVA》等。 关于战争的描写，在自发展现之余，如手冢治虫、宫崎骏、押井守、大友克洋等人都就此话题展开过沉重的思考。 大友克洋是日本动漫家中关于战争对人性的异化、战争与人的本性关系等问题做过深入考察的一位动漫大家。最具有代表性的，便是《AKIRA》。“AKIRA”是他虚构的一种神秘能力，人如果得到了这种能力，就意味着他拥有了一种超人的支配力；同时也意味着他在人性中就不可避免地走向了暴虐，因为控制别人必然是暴虐的。这样人便往往处于一种两难之境：不如意的生活、混乱的政治体制常常促使人们去追求这股力量，但得到之后，往往快速为这股力量推向迅速灭亡的道路。整部动漫便是以此为背景展开的，在这部动漫的结束中，大友克洋以暴力美学的形式，将战争的绝对的毁灭性之以及战争与人的活动之间无奈的羁绊关系直率地表现了出来。 （2）争战性主题 有些故事，尽管未见金戈铁马的征伐，但其中包含的战斗情绪的激烈程度并不弱于两军对垒的白刃相格。如但丁的《神曲》，“这里基本冲突仍然导源于战争，即恶魔背叛上帝那场原始的斗争，由此在人世现实领域便派生出反抗上帝和崇敬上帝两种势力之间的不断内外战争”。因此，这里讲主要表现多股实力激烈对抗而突出显现其一的求胜意志的作品，统称为争战类。主要集中在角力、竞技游戏、武术技击等几个方面。 角力的代表有《七龙珠》、《圣斗士星矢》等。竞技类则以《灌篮高手》、《棒球英豪》、《游戏王》为代表，以新番而言则为《网球王子》、《黑子的篮球》、《飙速宅男》、《排球少年》为代表了。武术的想必则以《史上第一弟子》为励志典范了。 四、参考文献 [1] 冯 硕，日本动漫的特性及其对中国动漫发展的启示[D]，北京：对外经济贸易大学，2005. [2] 陈奇佳，日本动漫艺术概论[M]，上海：上海交通大学出版社，2006,223. [3] 马静雯，日本动漫特征分析[J]，剑南文学（经典教苑），2012,(3):157-158. [4] 唐立耘，日本动画分镜与漫画分镜比较研究[D]，武汉：武汉理工大学，2013","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/动漫/"},{"name":"综述","slug":"综述","permalink":"https://sean10.github.io/tags/综述/"}]},{"title":"一省幕间","slug":"一省幕间","date":"2016-05-16T14:48:28.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/05/16/一省幕间/","link":"","permalink":"https://sean10.github.io/2016/05/16/一省幕间/","excerpt":"","text":"算来已经快整3周没听课了，整日在刷小说中，试着以放纵来令自己对小说失望，不过成效些微，反倒进度缺失的确实很多。 近来，从动漫同人到电影同人，再到架空历史、竞技，再回到科幻、奇幻、玄幻，爱好的小说类型愈发的变化，曾经最喜欢看的西红柿、三少的小白文倒是无法再入口，其剧情框架已被用烂了，再无出彩的创意，始终从零打怪升级，无非依靠主角光环，不见出彩伏笔，亦不见大气世界观，不过满足了大家的YY想法。 今天看到这样一句，《将夜》中说道： &gt;你究竟喜欢的是读书这件事情，还是读完所有书这件事情呢？ 我不得不说，自己所爱好的是读完书这件事情，在小说上只是希望自己能尽快看到作者出彩的后续剧情，而在专业书上，只是想为自己在豆瓣上的成果上多一笔，自己看完了那本专业巨著呢！ 哎，真的不得不对自己说，真的是太俗了。 也因为这个，虽然收了不少CS的经典了，但看的却没几本，我的兴趣去哪了呢？ 每个人都会碰到很多难题，想要解开这些难题，就必须专心的做下去，就需要疯狂的那股痴劲儿，但这股痴却不是山一般压在你肩上的重量，而是你内心深入向往的那些喜悦。 宁缺望着美丽的书院后山，说道：以前我曾经痴过，这些天却忘了痴的本质是喜欢。不存在虚妄的希望，自然也就没有虚妄的失望，更没有什么绝望。人生如题各种痴，就是各种喜欢，喜欢做什么那便做下去。这道题目总会有答案的。 可能在看的多了之后终究会懂，但却无法持之以恒。向往，却又不够向往。 给我无尽的知识，我便以自身为支点，撬起无尽世界。 虽然没有如此宏伟，但这也可谓是一种追求吧。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"暮省","slug":"暮省","permalink":"https://sean10.github.io/tags/暮省/"}]},{"title":"一省吾身","slug":"反思","date":"2016-04-19T15:31:21.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/04/19/反思/","link":"","permalink":"https://sean10.github.io/2016/04/19/反思/","excerpt":"近来，明明是在时间最紧迫的时刻，作业堆积如山、学姐布置的任务ddl也在迫近，可我却始终感觉缺了点什么似的，用最近看的村上春树的书中常提到的话来说恐怕就是“留在此处的只是我的一半，另一半怕是已然随着某事离开”。","text":"近来，明明是在时间最紧迫的时刻，作业堆积如山、学姐布置的任务ddl也在迫近，可我却始终感觉缺了点什么似的，用最近看的村上春树的书中常提到的话来说恐怕就是“留在此处的只是我的一半，另一半怕是已然随着某事离开”。 话虽如此，我面临的终究是现实，将时间寄托于小说，什么都不能改变。 也许是压力带来的消极，也许只是天性懒惰，严格一点来说，不过都是对自身不满，而将一切的一切倾泄于自暴自弃。以直觉来看，恐怕现在苦恼的这些随着时间的流逝，会什么都算不上。现在明明有那么多的知识摆在面前，只差我的汲取，我却将时间牺牲在摸索自己的消极、苦恼的心理之上。不用一年，一个月后我就又会深深的后悔了吧。毕竟，我已经如此折腾去了近一年了。 我想，于生活，并没有必要去研读那些深厚的心理学专著，只要记住“Just do it”就已经足够了罢。哲学也好，心理学也好，于业余人士来说，若非沉下心去从地基打起，没有丰富的阅历是不足以驾驭住心理学的专著的。无力驾驭，仅仅只言片语的心理分析，理解了，然而你真的懂了吗？真的进入你的心底了吗？于我来说，心理学是一门无比实用的科学，但以我的阅历与智商，实在无法仅凭一己之力将其应用。 话是那么说，不过这也只是我恨自己不能实用心理学而言，各人各有理解。 —————————————————————————————————— 回到我的专业，计算机科学与技术。 实际上来说，我真的明白这门专业是做什么的是在进了大学之后了。虽然我高考时所有的志愿专业都是计算机相关，4个志愿学校也是从计算机排名的高校里依次选的，可惜现在想来，当时似乎只是因为父母对自己使用计算机的限制，以为计算机于自己的意义就只有游戏，而对计算机的理解太过浅薄，将计算机科学神话了之后的选择。当然，现在专业选择了计算，我一点都不后悔。 但是，我很后悔自己不能更早接触到编程。现在既想玩玩前端，也想折腾下服务器搭搭后台，但是又有更主要的DM，只恨现在自己扛不住高压的学习节奏，好几次仅仅几天身体就各种撑不住，给了自己松懈的理由。每每看到同学的快节奏的学习，就不由得对自己的集中力叹气了。再说到，睡眠之浅，对声音的敏感，这样的环境又无可改变，休息不好，时刻增加着精神上的疲惫。 虽说能做的只有适应，适应不行就只能为大流所淘汰，但自己又不具备放下正常学习课表的魄力，弄成这般学习下滑、技术始终初学者的半吊子，所以不得不恨自己呀。 恨归恨，就看我能不能把这股恨刻入心底，真的记住失去的机会的疼痛，去承受高压的学习节奏了。 虽说身体是硬件，但有足够的觉悟，也一定可以无视！","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"暮省","slug":"暮省","permalink":"https://sean10.github.io/tags/暮省/"}]},{"title":"《情书》：平淡-回忆","slug":"情书","date":"2016-04-16T03:47:43.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/04/16/情书/","link":"","permalink":"https://sean10.github.io/2016/04/16/情书/","excerpt":"为图方便，这部电影是从B站上拉标签看评论找到的。 看过了村上春树的几部小说以后，加之桥本爱的《small forest》，对日本的作品的初印象就是非常的平静，在长达1个多小时的作品中逐渐静下来，在看这部片时感觉尤为深刻。","text":"为图方便，这部电影是从B站上拉标签看评论找到的。 看过了村上春树的几部小说以后，加之桥本爱的《small forest》，对日本的作品的初印象就是非常的平静，在长达1个多小时的作品中逐渐静下来，在看这部片时感觉尤为深刻。 电影一开始，便是在令人不由得肃穆的告别辞世之人的场景下，女主博子淡淡的出场，时刻沉浸于对前未婚夫的哀思之中，因为难以抑制其思念，也许是想作为结束思念的标记，想向着已经不存在的地址发出一封寄往天国的思念。然而，在本片的诞生的关键，她所记录的地址是恋人昔日同班的同名的另一位藤井树的家。随后，便是在书信往来中，藤井树逐渐回忆起初中时分。渐渐地，藤井树对于这位藤井树的淡淡的柔情得以揭露，错过的恋爱渐渐在我们面前呈现。 论剧情，可能并不像烧脑惊悚片那样跌宕起伏、让人出乎意料，但这部电影在细节的刻画、细节的共鸣上让我触动不已。 你好吗？ 我很好。 什么样的心理下，能写下如此简单的思念？ 我不知道，不能想象。但其心情传达到了心里，感觉暖暖的。 导演岩井俊二同时也是一个作家，这部电影便是由他的小说改编而成，从刻画上来看，想必原作品的小说同样精彩。 虽然我是奔着《情书》的制作的平淡而去，但最后还是不由得对回忆有所思。 作者岩井俊二在《情书》日文版电影特刊中，接受佐藤佳访问时，认为回忆是推动自己现在的一大原动力。一般人以为过去是过去，现在是现在，两者互无关系。某个时机，回忆起过去的事情，自然会发现一些过去与现在的连带关系，反过来影响了现在的自己。 毕竟回忆存储的是我们过去的时时刻刻，过去曾是现在，正是无数个现在的想法决定了未来的无数分叉点。既然过去既定，塑造而来的现在才得以存在，又何来无关之说呢？回忆可以是对往昔的省悟，也可以是情感的重拾，什么能作为推进的源动力，我想各人各有其道吧。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/日本/"},{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/影评/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/爱情/"},{"name":"青春","slug":"青春","permalink":"https://sean10.github.io/tags/青春/"}]},{"title":"DNA排序","slug":"DNA排序","date":"2016-01-08T10:58:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/01/08/DNA排序/","link":"","permalink":"https://sean10.github.io/2016/01/08/DNA排序/","excerpt":"","text":"总时间限制: 1000ms 内存限制: 65536kB 描述 12现在有一些长度相等的DNA串（只由ACGT四个字母组成），请将它们按照逆序对的数量多少排序。逆序对指的是字符串A中的两个字符A[i]、A[j]，具有i &lt; j 且 A[i] &gt; A[j] 的性质。如字符串”ATCG“中，T和C是一个逆序对，T和G是另一个逆序对，这个字符串的逆序对数为2。 输入 123第1行：两个整数n和m，n(0&lt;n&lt;=50)表示字符串长度，m(0&lt;m&lt;=100)表示字符串数量第2至m+1行：每行是一个长度为n的字符串 输出 1按逆序对数从少到多输出字符串，逆序对数一样多的字符串按照输入的顺序输出。 样例输入 123456710 6AACATGAAGGTTTTGGCCAATTTGGCCAAAGATCAGATTTCCCGGGGGGAATCGATGCAT 样例输出 123456CCCGGGGGGAAACATGAAGGGATCAGATTTATCGATGCATTTTTGGCCAATTTGGCCAAA 本以为可能在排序之外需要剪枝之类的，事实上用不到，直接用快排就可以过 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#include &lt;iostream&gt;using namespace std;typedef struct node&#123; char str[50]; int num;&#125;Node;int cmp(const Node &amp;a,const Node &amp;b)&#123; return a.num &lt; b.num;&#125;int main()&#123; //freopen(\"in.txt\",\"r\",stdin); int n,m; scanf(\"%d%d\",&amp;n,&amp;m); Node s[100]; for(int i = 0;i &lt; m;i++)&#123; scanf(\"%s\",s[i].str); int num = 0; for(int j = 0;j &lt; n;j++)&#123; if(s[i].str[j] == 'A') continue; else&#123; for(int k = j+1;k &lt; n;k++)&#123; if(s[i].str[k] &lt; s[i].str[j]) num++; &#125; &#125; &#125; s[i].num = num; &#125; sort(s,s+m,cmp); for(int i = 0;i &lt; m;i++) printf(\"%s\\n\",s[i].str); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"排序","slug":"排序","permalink":"https://sean10.github.io/tags/排序/"}]},{"title":"The Peanuts","slug":"The-Peanuts","date":"2016-01-08T09:39:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/01/08/The-Peanuts/","link":"","permalink":"https://sean10.github.io/2016/01/08/The-Peanuts/","excerpt":"","text":"总时间限制: 1000ms 内存限制: 65536kB 描述 1234567Mr. Robinson and his pet monkey Dodo love peanuts very much. One day while they were having a walk on a country road, Dodo found a sign by the road, pasted with a small piece of paper, saying &quot;Free Peanuts Here! &quot; You can imagine how happy Mr. Robinson and Dodo were.There was a peanut field on one side of the road. The peanuts were planted on the intersecting points of a grid as shown in Figure-1\\. At each point, there are either zero or more peanuts. For example, in Figure-2, only four points have more than zero peanuts, and the numbers are 15, 13, 9 and 7 respectively. One could only walk from an intersection point to one of the four adjacent points, taking one unit of time. It also takes one unit of time to do one of the following: to walk from the road to the field, to walk from the field to the road, or pick peanuts on a point.According to Mr. Robinson&apos;s requirement, Dodo should go to the plant with the most peanuts first. After picking them, he should then go to the next plant with the most peanuts, and so on. Mr. Robinson was not so patient as to wait for Dodo to pick all the peanuts and he asked Dodo to return to the road in a certain period of time. For example, Dodo could pick 37 peanuts within 21 units of time in the situation given in Figure-2.Your task is, given the distribution of the peanuts and a certain period of time, tell how many peanuts Dodo could pick. You can assume that each point contains a different amount of peanuts, except 0, which may appear more than once. 输入 1The first line of input contains the test case number T (1 &lt;= T &lt;= 20). For each test case, the first line contains three integers, M, N and K (1 &lt;= M, N &lt;= 50, 0 &lt;= K &lt;= 20000). Each of the following M lines contain N integers. None of the integers will exceed 3000\\. (M * N) describes the peanut field. The j-th integer X in the i-th line means there are X peanuts on the point (i, j). K means Dodo must return to the road in K units of time. 输出 1For each test case, print one line containing the amount of peanuts Dodo can pick. 样例输入 12345678910111213141526 7 210 0 0 0 0 0 00 0 0 0 13 0 00 0 0 0 0 0 70 15 0 0 0 0 00 0 0 9 0 0 00 0 0 0 0 0 06 7 200 0 0 0 0 0 00 0 0 0 13 0 00 0 0 0 0 0 70 15 0 0 0 0 00 0 0 9 0 0 00 0 0 0 0 0 0 样例输出 123728 其实没用到什么技巧，只是排序。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;algorithm&gt;#define MAX 50typedef struct node&#123; int weight; int x,y;&#125;Node;int v[MAX][MAX];int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int T,M,N,K; Node order[2500]; scanf(&quot;%d&quot;,&amp;T); while(T--)&#123; int len = 0; int currT = 0,ans = 0;; scanf(&quot;%d%d%d&quot;,&amp;M,&amp;N,&amp;K); for(int i = 1;i &lt;= M;i++)&#123; for(int j = 1;j &lt;= N;j++)&#123; scanf(&quot;%d&quot;,&amp;v[i][j]); if(v[i][j] != 0)&#123; int k; for(k = 0;k &lt; len &amp;&amp; v[i][j] &lt; order[k].weight;k++); for(int l = len;l &gt; k;l--)&#123; order[l] = order[l-1]; &#125; order[k].weight = v[i][j]; order[k].x = i; order[k].y = j; len++; &#125; &#125; &#125; int next_i,next_j,start = 0; currT = 0; int out_i = 0; int curr_i = 0; int curr_j = order[start].y; next_i = order[start].x; next_j = order[start].y; int nextT = currT; while(start &lt; len)&#123; out_i = order[start].x; nextT += abs(curr_i-next_i)+abs(curr_j-next_j); nextT++; if(nextT+out_i &lt;= K)&#123; currT = nextT; ans += order[start].weight; curr_i = next_i; curr_j = next_j; if(nextT+out_i == K) break; &#125;else&#123; nextT = currT; break; &#125; start++; next_i = order[start].x; next_j = order[start].y; &#125; printf(&quot;%d\\n&quot;,ans); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"排序","slug":"排序","permalink":"https://sean10.github.io/tags/排序/"}]},{"title":"牛的选举——取最大k个数","slug":"牛的选举——取最大k个数","date":"2016-01-08T06:20:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/01/08/牛的选举——取最大k个数/","link":"","permalink":"https://sean10.github.io/2016/01/08/牛的选举——取最大k个数/","excerpt":"","text":"总时间限制: 1000ms 内存限制: 65536kB 描述 现在有N（1&lt;=N&lt;=50000）头牛在选举它们的总统，选举包括两轮：第一轮投票选举出票数最多的K（1&lt;=K&lt;=N）头牛进入第二轮；第二轮对K头牛重新投票，票数最多的牛当选为总统。 现在给出每头牛i在第一轮期望获得的票数Ai（1&lt;=Ai&lt;=1,000,000,000），以及在第二轮中（假设它进入第二轮）期望获得的票数Bi（1&lt;=Bi&lt;=1,000,000,000），请你预测一下哪头牛将当选总统。幸运的是，每轮投票都不会出现票数相同的情况。 输入 第1行：N和K 第2至N+1行：第i+1行包括两个数字：Ai和Bi 输出 当选总统的牛的编号（牛的编号从1开始） 样例输入 1234565 33 109 25 68 46 5 样例输出 15 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;#include &lt;algorithm&gt;using namespace std;#define N 50005typedef struct node&#123; int a,b,num;&#125;Node;int ans[N];int bigger[N];int smaller[N];int d[N];int cmp(const Node &amp;a, const Node &amp;b)&#123; return b.a&lt;a.a;&#125;int cmp2(const Node &amp;a, const Node &amp;b)&#123; return b.b&lt;a.b;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int n,k; scanf(&quot;%d%d&quot;,&amp;n,&amp;k); Node x[N]; for(int i = 0;i &lt; n;i++)&#123; scanf(&quot;%d%d&quot;,&amp;x[i].a,&amp;x[i].b); x[i].num = i+1; &#125; sort(x,x+n,cmp); sort(x,x+k,cmp2); printf(&quot;%d\\n&quot;,x[0].num); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"链表","slug":"链表","permalink":"https://sean10.github.io/tags/链表/"}]},{"title":"数组取数——限时排序","slug":"数组取数——限时排序","date":"2016-01-07T11:47:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/01/07/数组取数——限时排序/","link":"","permalink":"https://sean10.github.io/2016/01/07/数组取数——限时排序/","excerpt":"","text":"总时间限制: 1000ms 内存限制: 65536kB 描述 有一个整数数组A和一个目标整数T，希望从A中没有放回地取出两个数，使得两个数之差等于T。请问有多少种不同的取法？（取出的两个数分别相等时视为同一种取法） 输入 输入由两行组成。第一行为两个整型范围内的整数N和T，N为数组长度（N的范围是[2,100000]），T为目标整数。第二行为N个整数，表示数组A，每个整数的范围是[-1000000,1000000]。 输出 A中取出两个数之差为T的不同的取法的数目。 样例输入 126 11 3 2 1 2 2 样例输出 12 这道题式始终WA和TLE中徘徊，不知道怎么修改了暂时。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;#define N 100005typedef struct node&#123; int x,y;&#125;Node;Node num[N];int start = 0;int cmp(const void* a,const void *b)&#123; return *(int*)a-*(int*)b;&#125;void func(int data[],int n,int T)&#123; int flag ; for(int i = n-1;i &gt; 0;i--)&#123; int left = 0,right = i; for(int j = (left+right)/2;j &gt;= left &amp;&amp; j &lt;= right &amp;&amp; left &lt;= right;j = (left+right)/2)&#123; if(data[i]-data[j] == T)&#123; flag = 0; for(int k = 0;k &lt; start;k++)&#123; if((data[i] == num[k].x &amp;&amp; data[j] == num[k].y) || (data[i] == num[k].y &amp;&amp; data[j] == num[k].x)) flag = 1; &#125; if(flag == 0)&#123; num[start].x = data[i]; num[start++].y = data[j]; &#125; break; &#125; else if(data[i]-data[j] &gt; T)&#123; left = j+1; right = (j+1+right)/2; &#125; else&#123; right = j-1; &#125; &#125; &#125;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int data[N]; int n ,T; scanf(&quot;%d%d&quot;,&amp;n,&amp;T); if(T &lt; 0) T= -T; for(int i = 0;i &lt; n;i++)&#123; scanf(&quot;%d&quot;,&amp;data[i]); &#125; qsort(data,n,sizeof(int),cmp); func(data,n,T); printf(&quot;%d\\n&quot;,start); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://sean10.github.io/tags/数据结构/"}]},{"title":"数据筛选——第k小的数","slug":"数据筛选——第k小的数","date":"2016-01-07T06:52:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/01/07/数据筛选——第k小的数/","link":"","permalink":"https://sean10.github.io/2016/01/07/数据筛选——第k小的数/","excerpt":"","text":"总时间限制: 10000ms 单个测试点时间限制: 5000ms 内存限制: 3000kB 描述 小张需要从一批数量庞大的正整数中挑选出第k小的数，因为数据量太庞大，挑选起来很费劲，希望你能编程帮他进行挑选。 输入 第一行第一个是数据的个数n(10&lt;=n&lt;=106)，第二个是需要挑选出的数据的序号k(1&lt;=k&lt;=105)，n和k以空格分隔； 第二行以后是n个数据T(1&lt;=T&lt;=109)，数据之间以空格或者换行符分隔。 输出 第k小数（如果有相同大小的也进行排序，例如对1,2,3,8,8，第4小的为8，第5小的也为8）。 样例输入 12310 51 3 8 20 2 9 10 12 8 9 样例输出 18 这道题，由于提供的内存限制，1M的记录，都为整型，就达到了4M超出了3M的限制，必须要分组进行排序 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;#define N 200010int data[N];int cmp(const void* a,const void* b)&#123; return *(int *)a-*(int *)b;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int n,k; scanf(&quot;%d%d&quot;,&amp;n,&amp;k); for(int i = 0;i &lt; k;i++)&#123; scanf(&quot;%d&quot;,&amp;data[i]); &#125; qsort(data,k,sizeof(int),cmp); n-=k; while(n&gt;0)&#123; if(n&gt;k)&#123; for(int i = k;i&lt;2*k;i++)&#123; scanf(&quot;%d&quot;,&amp;data[i]); &#125; qsort(data,2*k,sizeof(int),cmp); n-=k; &#125; else&#123; for(int i = k;i &lt; n+k;i++) scanf(&quot;%d&quot;,&amp;data[i]); qsort(data,k+n,sizeof(int),cmp); n-=n; &#125; &#125; printf(&quot;%d\\n&quot;,data[k-1]); return 0;&#125; 参考资料 [1].http://blog.csdn.net/u010663294/article/details/37612219","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"排序","slug":"排序","permalink":"https://sean10.github.io/tags/排序/"}]},{"title":"距离排序","slug":"距离排序","date":"2016-01-06T08:56:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2016/01/06/距离排序/","link":"","permalink":"https://sean10.github.io/2016/01/06/距离排序/","excerpt":"","text":"总时间限制: 1000ms 内存限制: 65536kB 描述 给出三维空间中的n个点（不超过10个）,求出n个点两两之间的距离,并按距离由大到小依次输出两个点的坐标及它们之间的距离。 输入 输入包括两行，第一行包含一个整数n表示点的个数，第二行包含每个点的坐标(坐标都是整数)。点的坐标的范围是0到100，输入数据中不存在坐标相同的点。 输出 对于大小为n的输入数据，输出n*(n-1)/2行格式如下的距离信息： (x1,y1,z1)-(x2,y2,z2)=距离 其中距离保留到数点后面2位。 (用cout输出时保留到小数点后2位的方法:cout&lt;&lt;fixed&lt;&lt;setprecision(2)&lt;&lt;x) 样例输入 1240 0 0 1 0 0 1 1 0 1 1 1 样例输出 123456(0,0,0)-(1,1,1)=1.73(0,0,0)-(1,1,0)=1.41(1,0,0)-(1,1,1)=1.41(0,0,0)-(1,0,0)=1.00(1,0,0)-(1,1,0)=1.00(1,1,0)-(1,1,1)=1.00 代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cmath&gt;typedef struct point&#123; int x,y,z;&#125;Point;typedef struct data&#123; int a,b; double len;&#125;Data;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int n; Point data[11]; Data len[110]; scanf(&quot;%d&quot;,&amp;n); for(int i = 0;i &lt; n;i++)&#123; scanf(&quot;%d%d%d&quot;,&amp;data[i].x,&amp;data[i].y,&amp;data[i].z); &#125; int start = 0; double length; int k; for(int i = 0;i &lt; n-1;i++)&#123; for(int j = i+1;j &lt; n;j++)&#123; length = sqrt((data[i].x-data[j].x)*(data[i].x-data[j].x) +(data[i].y-data[j].y)*(data[i].y-data[j].y) +(data[i].z-data[j].z)*(data[i].z-data[j].z)); for(k = 0;k &lt; start &amp;&amp; length-len[k].len &lt;= 1e-10;k++); for(int l = start;l &gt; k;l--) len[l] = len[l-1]; len[k].a = i; len[k].b = j; len[k].len = length; start++; &#125; &#125; for(int i = 0;i &lt; start;i++)&#123; printf(&quot;(%d,%d,%d)-(%d,%d,%d)=%.2f\\n&quot;,data[len[i].a].x,data[len[i].a].y,data[len[i].a].z, data[len[i].b].x,data[len[i].b].y,data[len[i].b].z,len[i].len); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"排序","slug":"排序","permalink":"https://sean10.github.io/tags/排序/"}]},{"title":"leetcode 319","slug":"leetcode-319","date":"2015-12-19T12:51:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/leetcode-319/","link":"","permalink":"https://sean10.github.io/2015/12/19/leetcode-319/","excerpt":"","text":"123int bulbSwitch(int n) &#123; return (int)sqrt(n);&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"leetcode 260","slug":"leetcode-260","date":"2015-12-19T12:27:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/leetcode-260/","link":"","permalink":"https://sean10.github.io/2015/12/19/leetcode-260/","excerpt":"","text":"12345678910111213141516171819202122/** * Return an array of size *returnSize. * Note: The returned array must be malloced, assume caller calls free(). */int* singleNumber(int* nums, int numsSize, int* returnSize) &#123; int xor = 0; for(int i = 0;i &lt; numsSize;i++) xor ^= nums[i]; int temp = xor; temp &amp;= ~temp+1; int ansX = 0; for(int i = 0;i &lt; numsSize;i++) if(nums[i]&amp;temp)//这一行还有点纳闷，如果换成(nums[i]&amp;temp == temp)就会WA ansX ^= nums[i]; int ansY = ansX^xor; *returnSize = 2; int *ans; ans = malloc(sizeof(int)*2); ans[0] = ansX; ans[1] = ansY; return ans;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"leetcode 226","slug":"leetcode-226","date":"2015-12-19T11:45:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/leetcode-226/","link":"","permalink":"https://sean10.github.io/2015/12/19/leetcode-226/","excerpt":"","text":"12345678910111213141516171819/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * struct TreeNode *left; * struct TreeNode *right; * &#125;; */struct TreeNode* invertTree(struct TreeNode* root) &#123; struct TreeNode* temp; if(root == NULL) return NULL; else&#123; temp = root-&gt;left; root-&gt;left = invertTree(root-&gt;right); root-&gt;right = invertTree(temp); return root; &#125;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"leetcode 100","slug":"leetcode-100","date":"2015-12-19T11:24:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/leetcode-100/","link":"","permalink":"https://sean10.github.io/2015/12/19/leetcode-100/","excerpt":"","text":"1234567891011121314/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * struct TreeNode *left; * struct TreeNode *right; * &#125;; */bool isSameTree(struct TreeNode* p, struct TreeNode* q) &#123; if(p == NULL || q == NULL) return p == q; else return p-&gt;val == q-&gt;val &amp;&amp; isSameTree(p-&gt;left,q-&gt;left) &amp;&amp; isSameTree(p-&gt;right,q-&gt;right);&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"leetcode 283","slug":"leetcode-283","date":"2015-12-19T11:17:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/leetcode-283/","link":"","permalink":"https://sean10.github.io/2015/12/19/leetcode-283/","excerpt":"","text":"123456789101112void moveZeroes(int* nums, int numsSize) &#123; //int zeros = 0; for(int i = numsSize-1;i &gt;= 0;i--)&#123; if(nums[i] == 0)&#123; for(int j = i;j &lt; numsSize-1;j++)&#123; nums[j] = nums[j+1]; &#125; nums[numsSize-1] = 0; //zeros++; &#125; &#125;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"leetcode 237","slug":"leetcode-237","date":"2015-12-19T07:12:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/leetcode-237/","link":"","permalink":"https://sean10.github.io/2015/12/19/leetcode-237/","excerpt":"","text":"12345678910111213/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * struct ListNode *next; * &#125;; */void deleteNode(struct ListNode* node) &#123; struct ListNode* temp = node-&gt;next; node-&gt;val = node-&gt;next-&gt;val; node-&gt;next = node-&gt;next-&gt;next; free(temp);&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"leetcode 104","slug":"leetcode-104","date":"2015-12-19T07:06:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/leetcode-104/","link":"","permalink":"https://sean10.github.io/2015/12/19/leetcode-104/","excerpt":"","text":"1234567891011121314151617/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * struct TreeNode *left; * struct TreeNode *right; * &#125;; */int maxDepth(struct TreeNode* root) &#123; if(root == NULL) return 0; int x = maxDepth(root-&gt;left); int y = maxDepth(root-&gt;right); if(x&gt;y) return x+1; else return y+1;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"leetcode 258","slug":"leetcode-258","date":"2015-12-19T07:02:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/leetcode-258/","link":"","permalink":"https://sean10.github.io/2015/12/19/leetcode-258/","excerpt":"","text":"123int addDigits(int num) &#123; return (num != 0 &amp;&amp; num%9 == 0)?9:num%9;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"leetcode292","slug":"leetcode292","date":"2015-12-19T06:50:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/leetcode292/","link":"","permalink":"https://sean10.github.io/2015/12/19/leetcode292/","excerpt":"","text":"这道题传统递归在leetcode上会超时，不过我觉得传统思路还是可以保留的。 数学方法 123bool canWinNim(int n) &#123; return n%4;&#125; 传统递归 1234567bool canWinNim(int n) &#123; if(n &gt; 0 &amp;&amp; n &lt;= 3) return true; if(canWinNim(n-1)&amp;&amp;canWinNim(n-2)&amp;&amp;canWinNim(n-3)) return false; else return true;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://sean10.github.io/tags/leetcode/"}]},{"title":"poj 2752 前后缀匹配","slug":"poj-2752-前后缀匹配","date":"2015-12-19T06:16:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/19/poj-2752-前后缀匹配/","link":"","permalink":"https://sean10.github.io/2015/12/19/poj-2752-前后缀匹配/","excerpt":"","text":"kmp才能保证不超时 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;#include &lt;stack&gt;#include &lt;iostream&gt;using namespace std;void getNext(int next[],char str[])&#123; int j = 0; next[0] = -1; int k = -1; int len = strlen(str); while(j &lt; len)&#123; if(k == -1 || str[k] == str[j])&#123; next[++j] = ++k; &#125; else k = next[k]; &#125;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); char str[400001]; int next[400001]; int j; while(scanf(&quot;%s&quot;,str) != EOF)&#123; memset(next,0,strlen(str)); getNext(next,str); stack &lt;int&gt; q; j =strlen(str); while(j != 0)&#123; q.push(j); j = next[j]; &#125; while(!q.empty())&#123; printf(&quot;%d &quot;,q.top()); q.pop(); &#125; printf(&quot;\\n&quot;); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"kmp","slug":"kmp","permalink":"https://sean10.github.io/tags/kmp/"}]},{"title":"Hdu 4018 正则表达式（简单）","slug":"Hdu-4018-正则表达式（简单）","date":"2015-12-18T15:32:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/18/Hdu-4018-正则表达式（简单）/","link":"","permalink":"https://sean10.github.io/2015/12/18/Hdu-4018-正则表达式（简单）/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); char str[100]; char ch[100]; int n; scanf(&quot;%d&quot;,&amp;n); for(int j = 1;j &lt;= n;j++)&#123; scanf(&quot;%s&quot;,str); for(int i = 0;str[i+2] != &apos;\\0&apos;;i++)&#123; if(str[i] == &apos;/&apos;)&#123; if(str[i+1] == &apos;/&apos;)&#123; strcpy(ch,&amp;str[i+2]); break; &#125; &#125; &#125; for(int i = 0;ch[i] != &apos;\\0&apos;;i++)&#123; if(ch[i] == &apos;/&apos; || ch[i] == &apos;:&apos;)&#123; ch[i] = &apos;\\0&apos;; break; &#125; &#125; printf(&quot;Case #%d: %s\\n&quot;,j,ch); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"正则","slug":"正则","permalink":"https://sean10.github.io/tags/正则/"}]},{"title":"Hdu 1039 字符串","slug":"Hdu-1039-字符串","date":"2015-12-18T15:08:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/18/Hdu-1039-字符串/","link":"","permalink":"https://sean10.github.io/2015/12/18/Hdu-1039-字符串/","excerpt":"","text":"本来以为是正则，结果只是字符串水题 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;#include &lt;iostream&gt;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); char str[22]; char vowel[26]=&quot;aeiou&quot;; char consonants[26]=&quot;bcdfghjklmnpqrstvwxyz&quot;; while(scanf(&quot;%s&quot;,str) &amp;&amp; strcmp(str,&quot;end&quot;))&#123; int tag[3]; tag[0] = 0; int len = strlen(str); for(int i = 0;i &lt; len;i++)&#123; for(int j = 0;j &lt; 5;j++)&#123; if(str[i] == vowel[j])&#123; tag[0] = 1; break; &#125; &#125; &#125; //char ch[3]; //ch[0] = str[0]; tag[1] = 1; int flag[3] = &#123;1,1,1&#125;; for(int i = 0;i &lt; len-2;i++)&#123; flag[0] = 0; for(int j = 0;j &lt; 21;j++)&#123; if(str[i] == consonants[j]) flag[0] = 1; &#125; flag[1] = 0; for(int j = 0;j &lt; 21;j++)&#123; if(str[i+1] == consonants[j]) flag[1] = 1; &#125; flag[2] = 0; for(int j = 0;j &lt; 21;j++)&#123; if(str[i+2] == consonants[j]) flag[2] = 1; &#125; if(flag[0] == 1 &amp;&amp; flag [1] == 1 &amp;&amp; flag[2] == 1) tag[1] = 0; &#125; for(int i = 0;i &lt; len-2;i++)&#123; flag[0] = 0; for(int j = 0;j &lt; 5;j++)&#123; if(str[i] == vowel[j]) flag[0] = 1; &#125; flag[1] = 0; for(int j = 0;j &lt; 5;j++)&#123; if(str[i+1] == vowel[j]) flag[1] = 1; &#125; flag[2] = 0; for(int j = 0;j &lt; 5;j++)&#123; if(str[i+2] == vowel[j]) flag[2] = 1; &#125; if(flag[0] == 1 &amp;&amp; flag [1] == 1 &amp;&amp; flag[2] == 1) tag[1] = 0; &#125; //char ch = str[0]; tag[2] = 1; for(int i = 1;i &lt; len;i++)&#123; if(str[i-1] == str[i]) if(str[i] != &apos;e&apos; &amp;&amp; str[i] != &apos;o&apos;) tag[2] = 0; //ch = str[i]; &#125; if(tag[0] == 1 &amp;&amp; tag[1] == 1 &amp;&amp; tag[2] == 1) printf(&quot;&lt;%s&gt; is acceptable.\\n&quot;,str); else printf(&quot;&lt;%s&gt; is not acceptable.\\n&quot;,str); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"水题","slug":"水题","permalink":"https://sean10.github.io/tags/水题/"}]},{"title":"《starting over重启人生》","slug":"《starting-over重启人生》","date":"2015-12-15T15:48:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/15/《starting-over重启人生》/","link":"","permalink":"https://sean10.github.io/2015/12/15/《starting-over重启人生》/","excerpt":"###starting over重启人生 这是这一个月来看的第一本质量感觉不错的轻小说。 初看完，我觉得从小说的方向上来说是引起我们对自己人生的反思的，我之前看过的《我将死去，你将重生》感觉和这本类似的感觉，同样值得一看。","text":"###starting over重启人生 这是这一个月来看的第一本质量感觉不错的轻小说。 初看完，我觉得从小说的方向上来说是引起我们对自己人生的反思的，我之前看过的《我将死去，你将重生》感觉和这本类似的感觉，同样值得一看。 每个人多少应该都怀有那么些后悔，觉得「当初要是那么做就好了」。人生就是伴随着后悔，「如果人生可以重來，誰都想以第一人生的反省、教訓或是記憶，期待更加美好的第二人生。」 主角却恰恰相反，选择了看似与众不同的道路。他对第一人生的幸福已经万分满足，没有再来一次进行更加美好的人生的欲望，因而在这个「多余的事」的第二人生选择了模仿第一人生。 这个时候，主角并不知道自己其实是被掩藏了一部分记忆的，否则就会感谢这样的机会了吧。 主角认为这样的机会多余，实际并不多余。「所谓的机会，永远都是给那些不企求机会的人。」这句话其实从另一个角度已经解释了机会的出现，记得以前看到过这么一说，上帝给你机会让你凤凰涅槃，你却任凭机会逝去，只为等待上帝让你一步登天。当你不企求机会的时候，才是真正抓住了机会。 在这里，主角现在得到了重来的机会，虽然他还没有意识到其意义，这并不意味着这个机会没有意义。 「总而言之，我不管做任何事都很认真地在放水。」为了重现第一人生，主角坚持对任何事都不尽力，这样的选择会带来什么样的结局？我们都很清楚，环境的影响力是不可忽视的。不过假如我们同主角一般，带着10年的记忆回来，生活没有了一丝难度，失去了挑战的乐趣，也没有找到新的爱好，如此一直懈怠下去。假如，忽然你遭遇了意料之外的挫折，在曾经的记忆中如同呼吸一般顺理成章的发展在第二人生却改变了，你会如何呢？ 主角在第二人生懈怠了5年之后遭遇了这样的事。「举几个例子来说，对了，就是被第一人生中的好朋友欺负，被第一人生中的女朋友狠狠甩了，没考上第一人生中念的高中……这种感觉。」这里作者让主角联想到的是蝴蝶效应，似乎是这样的原因，自己的变化影响了周围的一切，让原本可能实现的第一人生的未来彻底从自己的人生中消失了。 主角因而颓废了高中3年，这样的发展很正常吧。在颓废中，他没有放弃思考对他来说最重要的第一人生的女朋友甩了他的原因，为了试图找到挽回的机会，他在最后一年找回了曾经的学习的状态，最终考上了第一人生中的那所和女友一同念的大学。这点其实还是值得参考的，拥有努力过的记忆，如果拥有年轻的身体，好好学习还是可能做到的。 来吧，故事进入了大学，也就是拥有的记忆的最后2年，出现了新的角色。出现了所谓的「分身」，拥有和主角在第一人生中同样特质的人出现了，在第二人生中取代了那个位置，身边的女生则是主角一直在追寻的被甩的「女友」。 主角这时候受到什么样的打击都无可厚非吧，但他发现那个「分身」和曾经的自己完全相同之后，试图以消灭那个人来让其他人注意到自己这个本尊的存在。当然，在最后的最后，这所谓的「分身」和「本尊」都不存在意义，因为都是现实存在的人，不存在满足主角取代想法的美好幻想。 在跟踪计划中，来到了这10年的最后几个月，主角发现了一个现实，在他身旁，从初中开始，一直互相以对方作为最后的孤独同伴的女生——柊，其实是他带着第一人生的记忆回来的女友。而与此同时，主角在最后的最后找回了在第一人生的最后的故事的记忆，第一人生的他们在圣诞之夜出了车祸。 主角在这里觉悟了，虽然心里很平静。** 「这样啊，那两个人要死了吗？」只是这样。** 「因为他们一直以来可以过着那么幸福的人生，不如说，能在幸福的顶点死去也是一种幸福吧。」 「因为我们就算再怎么等下去，亚弥也不会变成我的，常叶也不会变成你的。加上我们只要一看到那两个人，就算不情愿也会想起第一人生的事，因而落入不停执著于过去的窘境。既然如此，亚弥和常叶干脆都消失了还比较好。」 主角只是为了让自己不后悔，心里虽然那么安慰自己，但还是希望能够拯救这一人生的那一对「分身」，拉着柊冲向之后本将发生车祸的路口，在夜晚停电时维护交通状况。 10年的记忆也只到这里，主角接下来要在没有记忆的干扰的情况下，和柊一起开始新的人生。故事就此结束了。 其实，故事也没有什么特别的感悟，仅仅只是主角追寻与女主的羁绊，颓废之后发现真相，以拯救曾经的自己的行动弥补自己的无意义的10年，让自己能够无后悔的开展新的人生。 其实从一定角度，作者三秋缒老师的后记更值得一看。 三秋缒老师只为了以自己期待的方式完成自己期待的故事，以最大的努力完成了这本书。老实说我感觉我很喜欢，能够将人生道理赋予现实，我做不到，所以我很钦佩。尤其在老师的第二本书中，更是凸显无疑。当下火热的《我的青春恋爱物语果然有问题》是他的第二本书，八幡大老师的人生道理在各式弹幕站上都是十分热门的。 总的来说，好评无误。 插一张小说的图 img","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"轻小说","slug":"轻小说","permalink":"https://sean10.github.io/tags/轻小说/"},{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/日本/"},{"name":"书评","slug":"书评","permalink":"https://sean10.github.io/tags/书评/"},{"name":"治愈向","slug":"治愈向","permalink":"https://sean10.github.io/tags/治愈向/"}]},{"title":"huffman编码实现压缩与解压缩","slug":"huffman编码实现压缩与解压缩","date":"2015-12-13T13:23:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/13/huffman编码实现压缩与解压缩/","link":"","permalink":"https://sean10.github.io/2015/12/13/huffman编码实现压缩与解压缩/","excerpt":"","text":"题目：将任意一个指定的文件进行哈夫曼编码，并以真正的二进制位生成一个二进制文件（压缩文件）；反过来，可将一个压缩文件解码还原为原来的文件。 以下是编码过程中需要注意的地方 1.读入字符 这里需要明白fread的运用。这段代码要实现的功能是对各类型文件进行转码，所以文本输入的方式fscanf不能在这里使用，只能用fread. 读入过程中需要记录文件中总计的单字节字符数量n，后面需要写入编码的文件中用于后续解码时判断是否已经到了最后一个字符的编码处，跳过补充的0代码段的解码。 2.统计字符出现频次 这里需要统计实际的哈弗曼树的叶子节点的数量，即不同的字符数量。 3.通过2的过程已经得到了每个字符的权值，即前nReal项已经输入完毕，可以开始建树 首先通过Select函数从已经得到的字符中提取最小的2个字符的权值，然后进行循环建树。这里的过程就是常规的建立静态分配空间以后的哈夫曼树的过程。 4.建树完毕，接下来开始进行编码操作 主体编码的流程是左子树为0，右子树为1，如果该节点两个孩子节点均指向0,,则该节点编码完毕，将临时分配的cd空间内的字符存入哈夫曼树中。 5.编码完毕，接下来直接输出即可 重新按照文件的字符出现的顺序，找到该字符对应的编码，按每8位完成一个编码写入文件，当抵达最后一个字符的时候，如果不足8位，补充编码，后面解码的时候的n就是用在这里跳过补充的编码的。 注意：这里并不能直接输出 如果直接以char型写入，输出的并没有起到压缩的作用，最多只能算是转码，所以这里需要追加一个过程，使得输出的0、1为确实的单比特输出，而不是1个字节的字符型输出。 并且这里char型与unsigned char型在首位也是存在差别的，所以建议转换类型为unsigned char。 下面解码 虽然说哈弗曼编码运用了前缀编码的原理，编码不会发生无法解码的过程，但是其终究是建立在具有了哈弗曼树的前提下才可进行解码。假如没有哈夫曼树，因为文件内部的二进制码是没有间断点的，如果一个一颗成形的哈夫曼树，我们并不能判断是否已经到了这个字符的编码结束的位置。假如迭代暴力解码，间断点的可能性有(n-1)!种，相当于o(n^n)级的复杂度，不可行。 所以我们在这里在编码时就将整棵树输出到解码文件的首部，解码时通过读取此树，再根据这棵树进行解码。 1.首先，读取nReal，动态分配足够的空间给接下来建立的树，读取文件中关于树的data和权值。 2.建树完毕，读取二进制编码，根据01决定左、右子树，如果抵达叶子节点，则其左右子树均为0，存入输出字符串即可。 这里对于补充的编码长度如何写入呢？ 程序优化： 可以对哈夫曼树进行压缩 参考资料: [1].http://blog.csdn.net/u013275340/article/details/38778497?utm_source=tuicool&amp;utm_medium=referral [2].http://zzh87615.blog.163.com/blog/static/1178207282009516271866 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;#define MAX 99999999typedef struct node&#123; unsigned char data; int weight; int parent,lchild,rchild; //unsigned char *bit; unsigned char *bit;&#125;HuffmanNode,HuffmanTree[512];/*typedef struct bit&#123;//设立位域，用于解码进行数字比对 unsigned a:1; unsigned b:6; unsigned c:1;&#125;Bit;*/void Select(HuffmanTree HT,int k,int &amp;s1,int &amp;s2)&#123;//选取最小的两个未链入哈弗曼树中的节点 int minHuf1 = MAX,minHuf2 = MAX; s1 = 99999999,s2 = 99999999; for(int i = 1;i &lt;= k;i++)&#123; if(HT[i].weight &lt; minHuf1 &amp;&amp; HT[i].parent == 0)&#123; minHuf2 = minHuf1; s2 = s1; minHuf1 = HT[i].weight; s1 = i; &#125;else if(HT[i].weight &lt; minHuf2 &amp;&amp; HT[i].parent == 0)&#123; s2 = i; minHuf2 = HT[i].weight; &#125; &#125;&#125;void Encode(HuffmanTree HT,int nReal)&#123;//进行字符编码 unsigned char *cd; cd = (unsigned char*)malloc(nReal*sizeof(unsigned char)); cd[nReal-1] = &apos;\\0&apos;; for(int i = 1;i &lt;= nReal;i++)&#123; int start = nReal-1; for(int curr = i,parent = HT[i].parent;parent != 0 &amp;&amp; 0 &lt; parent &amp;&amp; parent &lt;= 2*nReal-1;curr = parent,parent = HT[parent].parent)&#123; if(curr == HT[parent].lchild) cd[--start] = &apos;0&apos;; else cd[--start] = &apos;1&apos;; &#125; HT[i].bit = (unsigned char*)malloc((nReal-start+1)*sizeof(unsigned char)); int x = 0; do&#123; HT[i].bit[x++] = cd[start++]; &#125;while(cd[start-1] != &apos;\\0&apos;); HT[i].bit[x] = &apos;\\0&apos;; //strcpy(HT[i].bit,&amp;cd[start]); &#125; free(cd); /* if(nReal == 1) HT[1].bit[0] = &apos;0&apos;; */&#125;void Init(FILE *fpR,HuffmanTree &amp;HT,int &amp;nReal,int &amp;n)&#123;//初始化哈夫曼树 nReal = 0; HuffmanNode *p; int i; unsigned char ch; for(p = HT,i = 1;i &lt;= 511;i++,p++) *p = &#123;&apos;\\0&apos;,0,0,0,0&#125;; int start = 1; while(true)&#123; fread(&amp;ch,1,1,fpR); if(feof(fpR)) return; int tag = 0; n++; for(int j = 1;j &lt;= nReal;j++)&#123; if(ch == HT[j].data)&#123; HT[j].weight++; tag = 1; break; &#125; &#125; if(tag == 0)&#123; HT[start].data = ch; HT[start++].weight++; nReal++; &#125; &#125;&#125;void BuildTree(HuffmanTree &amp;HT,int nReal)&#123;//建树 int m = 2*nReal-1; for(int i = nReal+1;i &lt;= m;i++)&#123; int s1,s2; Select(HT,i-1,s1,s2); HT[s1].parent = i; HT[s2].parent = i; HT[i].lchild = s1; HT[i].rchild = s2; HT[i].weight = HT[s1].weight + HT[s2].weight; &#125;&#125;void Decode(HuffmanTree &amp;HT,int &amp;n,int &amp;nReal,FILE *fpR,FILE *fpW)&#123;//解码 int sup; fread(&amp;sup,sizeof(int),1,fpR); fread(&amp;n,sizeof(int),1,fpR); fread(&amp;nReal,sizeof(int),1,fpR); int i; HuffmanNode *p; for(p = HT,i = 1;i &lt;= 511;i++,p++) *p = &#123;&apos;\\0&apos;,0,0,0,0&#125;; for(i = 1;i &lt;= 2*nReal-1;i++)&#123; fread(&amp;HT[i].data,sizeof(unsigned char),1,fpR); fread(&amp;HT[i].weight,sizeof(int),1,fpR); &#125; BuildTree(HT,nReal); unsigned char c; unsigned char str; int root = 2*nReal-1; //i = 0; int length = 0;//对字符读取数量的计数，判断是否已经结束一次字符串读取 int flagSup = 0; while(true)&#123; fread(&amp;c,1,1,fpR); if(feof(fpR)) return; //fseek(fpR,len,SEEK_CUR); for(int k = 0;k &lt; 8;k++)&#123; if(HT[root].lchild == 0 &amp;&amp; HT[root].rchild == 0)&#123;//哈弗曼树不存在度为1的节点，故用and或者or均可 //if(HT[root].data == &apos;\\0&apos;) // fprintf(stderr,&quot;Error str\\n&quot;); str = HT[root].data; root = 2*nReal-1; fwrite(&amp;str,1,1,fpW); length++; &#125; if(length == n) break; if((c&amp;128) == 0) root = HT[root].lchild; else if((c&amp;128) == 128)&#123; root = HT[root].rchild; &#125; c = c &lt;&lt; 1; if(length == n) flagSup++; &#125; &#125;&#125;void EncodeOutput(HuffmanTree HT,FILE *fpR, FILE *fpW,int n,int nReal)&#123;//输出编码 fseek(fpW,4,SEEK_SET); fwrite(&amp;n,sizeof(int),1,fpW); fwrite(&amp;nReal,sizeof(int),1,fpW); for(int i = 1;i &lt;= 2*nReal-1;i++)&#123; fwrite(&amp;HT[i].data,sizeof(unsigned char),1,fpW); fwrite(&amp;HT[i].weight,sizeof(int),1,fpW); &#125; int length = 0; unsigned char c = 0;//编码变量 unsigned char ch;//输入字符变量，作为文件顺序参照 int sup = 0; int start = 0; fseek(fpR,0,SEEK_SET); for(int i = 0;i &lt; n;i++)&#123;//进行逐个字符编码写入 fread(&amp;ch,1,1,fpR); for(int j = 1;j &lt;= nReal;j++)&#123;//进行逐个匹配，寻找对应字符哈弗曼节点 if(HT[j].data == ch)&#123; int StrLen = 0; while(HT[j].bit[StrLen] != &apos;\\0&apos;)//计算该节点字符的编码比特数 StrLen++; //fprintf(fpW,&quot;%s&quot;,HT[j].bit); for(int k = 0;k &lt; StrLen;k++)&#123; if(HT[j].bit[k] == &apos;0&apos;) c = c &lt;&lt; 1; else if(HT[j].bit[k] == &apos;1&apos;) c = (c &lt;&lt; 1)|1; else fprintf(stderr,&quot;Bit output error!\\n&quot;); length++; if(i == n-1 &amp;&amp; length % 8 != 0)&#123;//最后一个节点需要记录补充编码数 while(length%8!=0)&#123; c = c &lt;&lt; 1; length++; sup++; &#125; &#125; if(length % 8 == 0 &amp;&amp; length &gt; 0) fwrite(&amp;c,1,1,fpW); &#125; //fwrite(HT[i].bit,1,sizeof(HT[i].bit),fpW); &#125; &#125; &#125; fseek(fpW,0,SEEK_SET); //fwrite(&amp;length,sizeof(int),1,fpW); fwrite(&amp;sup,sizeof(int),1,fpW); //fwrite(str,sizeof(unsigned char),length,fpW);&#125;void InterfaceFile(char *infile,char *outfile)&#123; fprintf(stdout,&quot;***Welcome to the Huffman Encoding/Decoding System:***\\n&quot;); fprintf(stdout,&quot;*** ***\\n&quot;); fprintf(stdout,&quot;Please input the input file name(including the postfix):&quot;); gets(infile); fprintf(stdout,&quot;Please input the output file name(including the postfix):&quot;); gets(outfile);&#125;void InterfaceNum(int &amp;num)&#123; fprintf(stdout,&quot;***Please choose which operation you&apos;d like to do:****\\n&quot;); fprintf(stdout,&quot;*** ***\\n&quot;); fprintf(stdout,&quot;***1_Encoding 2_Decoding ***\\n&quot;); while(fscanf(stdin,&quot;%d&quot;,&amp;num) &amp;&amp; (num != 1 &amp;&amp; num != 2))&#123; fprintf(stdout,&quot;The number is out of range.\\nPlease input again:&quot;); &#125;&#125;int main()&#123; FILE *fpR,*fpW; char infile[255],outfile[255]; InterfaceFile(infile,outfile); if((fpR = fopen(infile,&quot;ab+&quot;)) == NULL)&#123; fprintf(stderr,&quot;File_Read open error!\\n&quot;); exit(1); &#125; if((fpW = fopen(outfile,&quot;wb+&quot;)) == NULL)&#123; fprintf(stderr,&quot;File_Write open error!\\n&quot;); exit(2); &#125; HuffmanTree HT; //unsigned char ch;//编码字符 int n = 0,nReal = 0;//文件中字符数量n，哈弗曼节点数量nReal int num = 0;//选择方案 InterfaceNum(num); switch(num)&#123; case 1: Init(fpR,HT,nReal,n); BuildTree(HT,nReal); Encode(HT,nReal); EncodeOutput(HT,fpR,fpW,n,nReal); break; case 2: Decode(HT,n,nReal,fpR,fpW); break; &#125; fclose(fpR); fclose(fpW); return 0;&#125;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Huffman","slug":"Huffman","permalink":"https://sean10.github.io/tags/Huffman/"},{"name":"压缩","slug":"压缩","permalink":"https://sean10.github.io/tags/压缩/"}]},{"title":"用先序递归过程建立二叉树","slug":"用先序递归过程建立二叉树","date":"2015-12-13T13:21:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/13/用先序递归过程建立二叉树/","link":"","permalink":"https://sean10.github.io/2015/12/13/用先序递归过程建立二叉树/","excerpt":"","text":"用先序递归过程建立二叉树 (存储结构：二叉链表) 输入数据按先序遍历所得序列输入，当某结点左子树或右子树为空时，输入‘*’号，如输入abc**d**e**得到的二叉树如下： 123 a b ec d 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;typedef struct tree&#123;//二叉树结构 char data; struct tree *lc,*rc;&#125;BitNode,*BitTree;typedef struct queu&#123;//先序序列存储队列，包含&apos;*&apos; char data; struct queu *next;&#125;QueueNode,*Queue;Queue head = NULL,rear = head;void enqueue(Queue &amp;head, Queue &amp;rear,char ch)&#123;//入队 Queue p = (Queue)malloc(sizeof(QueueNode)); p-&gt;data = ch; p-&gt;next = NULL; if(head == NULL)&#123; head = p; rear = p; &#125; else&#123; rear-&gt;next = p; rear = p; &#125; return ;&#125;Queue Del(Queue head)&#123;//删除节点操作 Queue temp = head -&gt; next; free(head); return temp;&#125;char dequeue(Queue &amp;head)&#123;//出队 if(head == NULL) return NULL; char ch = head-&gt;data; head = Del(head); return ch;&#125;void BuildTree(BitTree &amp;root)&#123;//根据带&apos;*&apos;先序序列建树 char ch = dequeue(head); if(ch == &apos;*&apos; || ch == &apos;\\0&apos;)//遇到&apos;*&apos;，直接返回 return; root = (BitTree)malloc(sizeof(BitNode)); root-&gt;data = ch; root-&gt;lc = NULL; root-&gt;rc = NULL; BuildTree(root-&gt;lc); BuildTree(root-&gt;rc); return ;&#125;void PreOrder(BitTree root)&#123;//先序遍历输出 printf(&quot;%c&quot;,root-&gt;data); if(root-&gt;lc) PreOrder(root-&gt;lc); if(root-&gt;rc) PreOrder(root-&gt;rc);&#125;void MidOrder(BitTree root)&#123;//中序遍历输出 if(root-&gt;lc) PreOrder(root-&gt;lc); printf(&quot;%c&quot;,root-&gt;data); if(root-&gt;rc) PreOrder(root-&gt;rc);&#125;void AftOrder(BitTree root)&#123;//后续遍历输出 if(root-&gt;lc) AftOrder(root-&gt;lc); if(root-&gt;rc) AftOrder(root-&gt;rc); printf(&quot;%c&quot;,root-&gt;data);&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); //freopen(&quot;out.txt&quot;,&quot;w&quot;,stdout); char ch[10000]; scanf(&quot;%s&quot;,ch); for(int i = 0;ch[i] != &apos;\\0&apos;;i++) enqueue(head,rear,ch[i]); BitTree root; BuildTree(root); PreOrder(root); printf(&quot;\\n&quot;); MidOrder(root); printf(&quot;\\n&quot;); AftOrder(root); printf(&quot;\\n&quot;); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://sean10.github.io/tags/二叉树/"},{"name":"数据结构","slug":"数据结构","permalink":"https://sean10.github.io/tags/数据结构/"}]},{"title":"蒙特卡洛算法（简单理解）","slug":"蒙特卡洛算法（简单理解）","date":"2015-12-09T09:23:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/09/蒙特卡洛算法（简单理解）/","link":"","permalink":"https://sean10.github.io/2015/12/09/蒙特卡洛算法（简单理解）/","excerpt":"","text":"###蒙特卡洛算法(Monte Carlo Algorithm) 在这本书里面，前面我们已经学到的算法都是属于确定性算法。有这样一种情况，一个确定性算法不得不仔细判断大量的甚至指数级的可能事件。在这种情况下，我们用到了下面现在我们要学习的一种特殊类的概率算法。该算法在不同的运行步数下提供随机性的选择，在应对决策问题的情况下，这种算法叫做蒙特卡洛算法。 A Monte Carlo algorithm for a decision problem uses a sequence of tests. The probability that the algorithm answers the decision problem correctly increases as more tests are carried out. At each step of the algorithm, possible responses are “true,” which means that the answer is “true” and no additional iterations are needed, or “unknown,” which means that the answer could be either “true” or “false.” After running all the iterations in such an algorithm, the final answer produced is “true” if at least one iteration yields the answer “true,” and the answer is “false” if every iteration yields the answer “unknown.” If the correct answer is “false,” then the algorithm answers “false,” because every iteration will yield “unknown.” However, if the correct answer is “true,” then the algorithm could answer either “true” or “false,” because it may be possible that each iteration produced the response “unknown” even though the correct response was “true.” We will show that this possibility becomes extremely unlikely as the number of tests increases. 决策问题只有“对”与“错”两种答案。在每一步迭代中，如果决策是“对”，意味着回答是“对”，并且与算法的其他迭代无关；也可能回应“未知”，意味着答案可能是“对”也可能是“错”。在全部均迭代过后，如果至少有一次迭代中生成了结果“对”，那么结果就为”对“；如果每个重复生成的回答都是”未知“，那么结果就为”错“。 然而，如果正确答案是”对“，而算法可以回答”对“或”错“，有可能所有的迭代均得到的回答是”未知“。（这就是其中的小概率的错误概率。） （这一段是我对书上的翻译，我理解下来，这段描述的其实是拉斯维加斯算法吧，是不是我理解错了，希望明白的人能指正一下） 对于蒙特卡洛算法，是实验样例越多，得到的结果也就愈发靠近正确的结果。 与蒙特卡洛算法相对的另一种随机算法，叫做拉斯维加斯算法，同样是随机抽样，样本数越多，这个算法增加的只有找到正确结果的概率，他得到的只有对与错，没找到正确的结果就没有意义。 参考其他资料对蒙特卡洛算法的理解是，蒙特卡洛算法是利用一种满足平均分布的随机抽样达成的计算数学期望的方法。其主要计算的是近似真值。也就是说他主要是从样本数中找对的结果，然后计算”对“的结果占全部样本数的概率，其方法重点是在于抽样的过程。 Ps.果然《离散数学》里面的各方面内容都只是各领域最简单的内容，关于蒙特卡洛算法，这里连抽样(sample)的单词都并没有用到，用了一些常用（多义）的单词，不看其他资料，完全不能理解呀。 参考资料： [1]http://www.zhihu.com/question/20254139 [2]http://www.cnblogs.com/daniel-D/p/3388724.html [3]https://en.wikipedia.org/wiki/Monte_Carlo_method","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/离散数学/"}]},{"title":"HDU2004","slug":"HDU2004","date":"2015-12-03T07:43:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/03/HDU2004/","link":"","permalink":"https://sean10.github.io/2015/12/03/HDU2004/","excerpt":"","text":"123456789101112131415161718192021#include &lt;cstdio&gt;#include &lt;cstdlib&gt;int main()&#123; int x; while(scanf(&quot;%d&quot;,&amp;x)!=EOF)&#123; if(x &gt;= 90 &amp;&amp; x&lt;= 100) printf(&quot;A&quot;); else if(x &gt;= 80&amp;&amp; x&lt;=89) printf(&quot;B&quot;); else if(x &gt;= 70 &amp;&amp; x &lt;= 79) printf(&quot;C&quot;); else if(x &gt;= 60 &amp;&amp; x &lt;= 69) printf(&quot;D&quot;); else if(x &gt;= 0 &amp;&amp; x &lt;= 59) printf(&quot;E&quot;); else printf(&quot;Score is error!&quot;); printf(&quot;\\n&quot;); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"水题","slug":"水题","permalink":"https://sean10.github.io/tags/水题/"}]},{"title":"HDU2003","slug":"HDU2003","date":"2015-12-03T07:39:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/03/HDU2003/","link":"","permalink":"https://sean10.github.io/2015/12/03/HDU2003/","excerpt":"","text":"123456789101112#include &lt;cstdio&gt;#include &lt;cstdlib&gt;int main()&#123; double x; while(scanf(&quot;%lf&quot;,&amp;x)!=EOF)&#123; if(x&lt;0) x=-x; printf(&quot;%lf\\n&quot;,x); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"水题","slug":"水题","permalink":"https://sean10.github.io/tags/水题/"}]},{"title":"HDU2002","slug":"HDU2002","date":"2015-12-03T07:31:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/03/HDU2002/","link":"","permalink":"https://sean10.github.io/2015/12/03/HDU2002/","excerpt":"","text":"严格来说，到最后我还是没找到为什么我本机的CB运行出来就是0，上传就能AC的原因。 12345678910111213#include &lt;stdio.h&gt;#include &lt;math.h&gt;#define PI 3.1415927int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); double r; while(scanf(&quot;%lf&quot;,&amp;r)!=EOF)&#123; printf(&quot;%.3lf\\n&quot;,4.0/3.0*PI*r*r*r); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"水题","slug":"水题","permalink":"https://sean10.github.io/tags/水题/"}]},{"title":"HDU2001","slug":"HDU2001","date":"2015-12-03T07:17:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/03/HDU2001/","link":"","permalink":"https://sean10.github.io/2015/12/03/HDU2001/","excerpt":"","text":"1234567891011#include &lt;stdio.h&gt;#include &lt;math.h&gt;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); double x1 = 0,x2 = 0,y1 = 0,y2 = 0; while(scanf(&quot;%lf %lf %lf %lf&quot;,&amp;x1,&amp;y1,&amp;x2,&amp;y2)!=EOF)&#123; printf(&quot;%.2lf\\n&quot;,sqrt((x1-x2)*(x1-x2)+(y1-y2)*(y1-y2))); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"水题","slug":"水题","permalink":"https://sean10.github.io/tags/水题/"}]},{"title":"HDU2000","slug":"HDU2000","date":"2015-12-03T07:04:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/03/HDU2000/","link":"","permalink":"https://sean10.github.io/2015/12/03/HDU2000/","excerpt":"","text":"自从那次校赛没过以后就一直没心思做题，现在连水题要注意的PE也交了6次再看了一份AC代码才想起来，多输出了空格再换行也是会PE的。 真的是代码打得太少了。 123456789101112131415161718192021222324252627282930313233343536#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;void swap(char *s,int j)&#123; char temp = s[j]; s[j] = s[j+1]; s[j+1] = temp;&#125;void Bubblesort(char *s)&#123; char temp = s[0]; for(int i = 0;i &lt; 3;i++)&#123; for(int j = 0;j &lt; 2;j++)&#123; if(s[j] &gt; s[j+1]) swap(s,j); &#125; &#125;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); char s[4]; while(scanf(&quot;%s&quot;,s)!=EOF)&#123; //getchar(); Bubblesort(s); for(int i = 0;i &lt; 2;i++)&#123; printf(&quot;%c&quot;,s[i]); printf(&quot; &quot;); &#125; printf(&quot;%c&quot;,s[2]); printf(&quot;\\n&quot;); &#125; //printf(&quot;\\n&quot;); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"水题","slug":"水题","permalink":"https://sean10.github.io/tags/水题/"}]},{"title":"条件概率","slug":"条件概率","date":"2015-12-02T13:19:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/02/条件概率/","link":"","permalink":"https://sean10.github.io/2015/12/02/条件概率/","excerpt":"","text":"定义1.假设\\(S\\)是一个有\\(n\\)个元素的集合，均匀分布分配给\\(S\\)的每个元素\\(\\frac1n\\)的概率。 定义2.事件\\(E\\)的概率是\\(E\\)中所有结果出现的概率之和。如下：\\[p(E)=\\sum_{s \\in E}p(s)\\]. （注意：当\\(E\\)是一个有限集合时，\\(\\sum_{s \\in E}p(s)\\)是一个收敛有限级数。） 这里事件的各个结果的概率计算依照拉普拉斯概率的计算即可。 从一个带有均匀分配（也可叫做一致分布）的样本空间中选择一个元素的实验叫做随机选取元素\\(S\\)。 在这个部分，带有数个结果的事件的补全概率的计算依旧遵循拉普拉斯的传统的计算。 \\[p(E_1 \\cup E_2)=p(E_1)+p(E_2)-p(E_1 \\cap E_2)\\]. 定理1.如果\\(E_1,E_2,\\dots\\) 是一序列成对出现的样本空间\\(S\\)中的不相交的事件，那么\\[p \\left(\\bigcup_i E_i \\right)=\\sum_i{p(E_i)}\\]. （注意这个定义在一序列事件\\(E_1,E_2,\\dots\\)是由有限或可数数量的成对不想交的事件组成的时候应用） ###条件概率 &gt;定义3.令\\(E\\)和\\(F\\)作为\\(p(F)&gt;0\\)的事件。给出条件\\(F\\)的\\(E\\)的条件概率写作\\(p(E|F),定义为\\)\\(p(E|F)=\\cfrac{p(E \\cap F)}{p(F)}\\)$. 依照这个公式，目前来看，还是比较容易计算的。 ###独立性 一个硬币被掷3次，告诉我们第一次是背面，3次中出现奇数次背面的概率是多少？从上面的条件概率的公式中，我们可以得到\\(\\cfrac{\\cfrac14}{\\cfrac48}=\\cfrac12\\).即便没有告诉我们第一次是背面，得到的概率同样也是\\(\\cfrac12\\)。这样概率并没有受到影响的两个事件，就叫做独立事件。 定义4.事件\\(E\\)和\\(F\\)是独立的，当且仅当\\(p(E \\cap F)=p(E)p(F)\\). 定义5.当且仅当对于所有对整数\\(i\\)和\\(j\\) \\(（1\\leq i \\leq j \\leq n)\\)有\\(p(E_i \\cap E_j)=p(E_i)p(E_j)\\)，事件\\(E_1,E_2,\\dots,E_n\\)是成对独立的。如果对于$i_j,j=1,2,,m $，是\\(1 \\leq i_1 \\leq i_2 \\leq \\dots \\leq i_m \\leq n\\) 和\\(m \\geq 2\\)的整数，那么\\(p(E_{i_1}\\cap E_{i_2}\\cap \\dots \\cap E_{i_m})=p(E_{i_1})p(E_{i_2})\\dots p(E_{i_m})\\)这些事件是相互独立的。 从定义5，我们可以看到每个\\(n\\)个相互独立事件的集合也是成对独立的。然而\\(n\\)个成对独立的时间并不一定是相互独立的。 （成对独立只对于两个事件之前，而相互独立是\\(n\\)个之间之间均独立，差别就在这里了） ###伯努利实验和二项分布（Bernoulli Trials and the Binomial Distribution) &gt;每个具有两个可能结果的实验表现称之为伯努利实验。 &gt;一般来说，伯努利实验的可能结果被称为成功或者失败. 定理2.实际上在\\(n\\)格独立伯努利实践中\\(k\\)个成功的概率，在成功的概率为\\(p\\)、失败的概率为\\(q=1-p\\)的条件下是\\[C(n,k)p^kq^{n-k}\\]. 我们也常写作\\(b(k;n,p)\\).我们把这个函数(为什么叫function，不太明白）叫做二项分布。 \\[\\sum^n_{k=0}C(n,k)p^kq^{n-k}=(p+q)^n=1.\\] ###随机变量 &gt;定义6.一个随机变量是一个从实验的样本空间映射到实数集合的函数。因此，一个随机变量分配一个实数到每个可能结果。 注意：随机变量并不是变量，也不随机。 &gt;定义7.在样本空间\\(S\\)中的随机变量\\(X\\)的分配是对所有\\(r \\in X(S),p(X=r)\\)是\\(X\\)取值\\(r\\)的概率的对\\((r,p(X=r))\\)的集合。（在这个分配中的对的集合是由对\\(r \\in X(S)\\)的概率\\(p(X=r)\\)决定的。） ####生日问题 生日问题是寻找房间里最少的人数使得至少有2个人同一天生日的概率大于\\(\\frac12\\). 答：首先，我们列出几条假设。我们假设在一个房间里的人们的生日均是独立的。更进一步，我们假设每个生日是等可能的并且一年里有366天。（实际上，在一年里更多的人出生在一年里的相同的一些日子里，比如包括新年在内的一些节日后的9个月里） 为了找到这个可能性，我们首先计算这些人有全部都有不同生日的概率\\(p_n\\)。然后，至少2个人有相同生日的概率为\\(1-p_n\\)。为了计算\\(p_n\\)，我们姑且认定\\(n\\)个人的生日是遵循一定顺序的。想象一下，他们在一个时刻一个个进入房间；我们将会计算每个人进入房间时与已经在房间里的人的生日不同的概率。 第一个进入房间的人的生日当然不会匹配到任何在房间里的人的生日。第二个人的生日不同于第一个人的概率是$因为当第二个人出生在除了第一个人的生日之外的\\(365\\)天里时，他们的生日是不同的。（这个对每个人出生在\\(366\\)天里任何一天等可能的假设保证了这个和后续步骤） 第三个人有不同生日的概率是\\(\\cfrac{364}{366}。延伸开来，对于第\\)j\\(个人(2 \\leq j \\leq 366)，有一个不同于其他\\)n-1\\(个人的生日的概率是\\)\\(\\cfrac{366-(j-1)}{366}=\\cfrac{367-j}{366}.\\)$ 因为已经假设在房间里的人的生日均是独立的，我们就可以得出结论这房间里的\\(n\\)个人有不同生日概率是\\[p_n=\\cfrac{365}{366}\\cfrac{364}{366}\\cfrac{363}{366}\\dots \\cfrac{367-n}{366}.\\] 随之，我们得到\\[1-p_n=1-\\cfrac{365}{366}\\cfrac{364}{366}\\cfrac{363}{366}\\dots \\cfrac{367-n}{366}.\\] 接下来为了找到最少的人数使得其概率大于\\(\\cfrac12\\)，我们逐渐带入增大的\\(n\\)来计算（虽然可以用微积分，但是这里不使用。话说怎么用？我忘了）。我们会发现\\(n=22,1-p_n \\approx 0.475;n=23,1-p_n \\approx 0.506\\)。因此我们得知最少只要23个人即可使得房间内的人至少有2个人的生日相同的概率为\\(\\cfrac12\\)。 哈希的重合概率计算和生日问题类似。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/离散数学/"},{"name":"概率","slug":"概率","permalink":"https://sean10.github.io/tags/概率/"}]},{"title":"有限概率（拉普拉斯概率）","slug":"有限概率（拉普拉斯概率）","date":"2015-12-02T11:44:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/02/有限概率（拉普拉斯概率）/","link":"","permalink":"https://sean10.github.io/2015/12/02/有限概率（拉普拉斯概率）/","excerpt":"","text":"###有限概率（拉普拉斯概率） 定义1.如果\\(S\\)是一个等可能结构的有限非空样本空间，\\(E\\)是一个作为\\(S\\)的子集的一个事件，那么\\(E\\)的概率为\\(p(E)=\\cfrac{|E|}{|S|}\\). 定理1.让\\(E\\)成为一个样本空间\\(S\\)中的一个事件。事件\\(\\overline{E}=S-E\\)发生的概率，即事件\\(E\\)的补全事件，由以下公式给出\\[p(\\overline{E})=1-p(E)\\]. ###事件补全、联合概率 &gt;定理2.让\\(E_1\\)和\\(E_2\\)成为样本空间\\(S\\)中的时间，那么\\(p(E_1 \\cup E_2)=p(E_1)+p(E_2)-p(E_1 \\cap E_2)\\). ###概率性原因 没什么内容，都是概率之前学过的基础，就下面这个问题比较有意思。 ####蒙提霍尔问题 &gt;蒙提霍尔问题就是在一个游戏中，有三扇门，一扇门背后是奖品，两扇门背后是山羊，参加者可以在上台前选择其中一扇门，上台之后，主持人会从剩下的两扇门中选择一扇背后没有奖品的门打开，然后给参加者一个更换选择的机会。 问：如果你更换，会不会有更大的概率拿到奖品。 这里的问题以前看到过流言终结者，那里面采用的方法是统计概率，得到的结果是2/3的中签率。 在更换之前的是先验概率，为1/3。 得到一扇门打开之后的是后验概率（条件概率）。 举个例子： 比如10个人抽一个人值日，这是一个事件，概率是1/10. 如果一个人打开了他的签，他并不值日，他的事件和你的事件是两回事，概率并不相关。 但如果你知道了他的未中签，给你再选择的机会，那就是1/9. （概率永远会变）变了一定是事件变了。 回到这个例子，如果你始终不更换你的选择，你的中签率就是1/3，这里就算主持人打开了门，但你不重新选择，所以你始终是1/3.这是不相关的两件事。 如果你会更改选择，那么简单地来说，因为事件改变为了剩下两个一扇奖品一扇山羊，这样你的概率一定会大于等于1/2. 假如我选两扇门，中奖概率一定是2/3.这是确定的事件，确定的概率。 不让你选择两个，其实换个角度，就是比如有ABC三扇门，我想选AB，我就先选C，然后主持人会在AB里选择一扇门，然后我就可以更换到AB中的那扇没被打开的门了。这样事件没有改变，很明显， 中奖概率都是2/3.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/离散数学/"},{"name":"概率","slug":"概率","permalink":"https://sean10.github.io/tags/概率/"}]},{"title":"二叉树——森林的带度数层次序列存储","slug":"二叉树——森林的带度数层次序列存储","date":"2015-12-01T10:09:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/12/01/二叉树——森林的带度数层次序列存储/","link":"","permalink":"https://sean10.github.io/2015/12/01/二叉树——森林的带度数层次序列存储/","excerpt":"","text":"题目链接 总时间限制: 1000ms 内存限制: 65536kB 描述 对于树和森林等非线性结构，我们往往需要将其序列化以便存储。有一种树的存储方式称为带度数的层次序列。我们可以通过层次遍历的方式将森林序列转化为多个带度数的层次序列。 例如对于以下森林： img 两棵树的层次遍历序列分别为：C E F G K H J / D X I 每个结点对应的度数为：3 3 0 0 0 0 0 / 2 0 0 我们将以上序列存储起来，就可以在以后的应用中恢复这个森林。在存储中，我们可以将第一棵树表示为C 3 E 3 F 0 G 0 K 0 H 0 J 0，第二棵树表示为D 2 X 0 I 0。 现在有一些通过带度数的层次遍历序列存储的森林数据，为了能够对这些数据进行进一步处理，首先需要恢复他们。 输入 输入数据的第一行包括一个正整数n，表示森林中非空的树的数目。 随后的 n 行，每行给出一棵树的带度数的层次序列。 树的节点名称为A-Z的单个大写字母。 输出 输出包括一行，输出对应森林的后根遍历序列。 样例输入 1232C 3 E 3 F 0 G 0 K 0 H 0 J 0D 2 X 0 I 0 样例输出 1K H J E F G C X I D 这道题，主要就是用队列存下根节点，根据其子节点数目判断是不是叶子。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;queue&gt;using namespace std;typedef struct node&#123; char data; struct node *child[26];&#125;BitNode,*BitTree;void Init(BitTree &amp;root, char ch)&#123; for(int i = 0;i &lt; 26;i++)&#123; root-&gt;child[i] = NULL; &#125; root-&gt;data = ch;&#125;void Create(BitTree &amp;root)&#123; queue &lt;BitTree&gt;qRoot; queue&lt;int&gt;qSeq; BitTree temp,tempHead; char ch; int i = 0; int degree = 0;//树的度 int childNum; cin &gt;&gt; ch &gt;&gt; childNum; root = (BitTree)malloc(sizeof(BitNode)); Init(root,ch); qRoot.push(root); qSeq.push(childNum); while(!qRoot.empty())&#123; while(degree == i)&#123; if(qRoot.empty()) return ; degree = qSeq.front(); qSeq.pop(); tempHead = qRoot.front(); qRoot.pop(); i = 0; &#125; cin &gt;&gt; ch &gt;&gt; childNum; temp = (BitTree)malloc(sizeof(BitNode)); Init(temp,ch); qRoot.push(temp); qSeq.push(childNum); tempHead-&gt;child[i] = temp; i++; &#125;&#125;void AftTranverse(BitTree root)&#123; for(int i = 0;i &lt; 26 &amp;&amp; root-&gt;child[i];i++) AftTranverse(root-&gt;child[i]); cout &lt;&lt; root-&gt;data &lt;&lt; &apos; &apos;;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); BitTree root; int n; cin &gt;&gt; n; while(n--)&#123; Create(root); AftTranverse(root); &#125; cout &lt;&lt; &apos;\\n&apos;; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://sean10.github.io/tags/二叉树/"},{"name":"树","slug":"树","permalink":"https://sean10.github.io/tags/树/"}]},{"title":"大学物理实验 考点总结","slug":"大学物理实验-考点总结","date":"2015-11-30T14:42:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/30/大学物理实验-考点总结/","link":"","permalink":"https://sean10.github.io/2015/11/30/大学物理实验-考点总结/","excerpt":"","text":"大物实验 考点总结 误差 测量误差可以用绝对误差，也可以用相对误差表示： \\[绝对误差=测量结果-真值\\] \\[相对误差=\\cfrac{绝对误差}{真值}\\] 误差分类： (1)系统误差(2)随机误差(3)粗大误差 测量结果的评价 评价测量结果，反应测量误差大小，常用到精密度、正确度和准确度3个概念。 精密度反映随机误差大小的程度，它是对测量结果的重复性的评价。精密度高是指测量的重复性好，各次测量值的分布密集，随机误差小。但是，精密度不能反映系统误差的大小。精密度反映测量值离散程度。 正确度反映系统误差大小的程度。正确度高是指测量数据的算术平均值偏离真值较小，测量的系统误差小。但是正确度不能确定数据分散的情况，即不能反映随机误差的大小。 准确度反映系统误差与随机误差综合大小的程度。准确度高是指测量结果既精密又正确，即随机误差与系统误差均小。 常用的测量方法有异号法、交换法、替代法、对称法。 服从正态分布的随机误差 服从正态分布的随机误差具有下列特点： (1)单峰性——绝对值小的误差比绝对值大的误差出现的概率答； (2)对称性——大小相等而符号相反的误差出现的概率相同； (3)有界性——在一定的测量条件下，误差的绝对值不超过一定的限度； (4)抵偿性——误差的算术平均值随测量次数\\(n\\)的增加而趋于零。 当测量次数无穷多或足够多时，测量值的误差分布才接近正态分布，但是当测量次数较少时（例如，少于10次，物理实验教学中一般取\\(n=6\\sim 10\\)次），测量值的误差分布将明显偏离正态分布，而遵从\\(t\\)分布，又称为学生分布。\\(t\\)分布曲线与正态分布曲线的形状类似，但是\\(t\\)分布曲线的峰值低于正态分布；而且\\(t\\)分布曲线上部较窄，下部较宽。 为什么置信概率取0.95 不确定度的\\(A\\)类（采用统计方法评定的\\(A\\)类不确定度）分量用\\(u_A(x)\\)表示。物理实验中\\(u_A(x)\\)一般用多次测量平均值的标准偏差\\(s(\\overline{x})\\)与\\(t\\)因子\\(t_p\\)的乘积来估算，即\\[u_A(x)=t_ps(\\overline x)\\] 式中，\\(t\\)因子\\(t_p\\)是与测量次数\\(n\\)和对应的置信概率\\(p\\)有关，当置信概率为\\(p=0.95\\)，测量次数\\(n=6\\)时，我们可以查到\\(t_{0.95}/\\sqrt{n} \\approx 1\\)，则有\\[u_A(x)=s(x)\\] 即在置信概率为\\(0.95\\)的前提下，测量次数\\(n=6\\)，\\(A\\)类不确定度可以直接用测量值的标准偏差\\(s(x)\\)估算。 因此，在未加说明时，普遍采取置信概率\\(p=0.95\\)。 测量不确定度和结果的表达 不确定度由两类不确定度合成 1. A类不确定度：采用统计方法评定的不确定度，即对多次测量的数据进行处理而得到的不确定度，以\\(u_A(x)\\)表示。 2. B类不确定度：采用非统计方法评定的不确定度，即\\(u_A(x)\\),常常用仪器误差\\(\\Delta_仪\\)来表示。 （一般来说这个仪器误差会给出，所以不需要背） 合成不确定度与测量结果的表达 下式就是不确定度的合成公式： \\[u(x)=\\sqrt{u^2_A(x)+u^2_B(x)}\\tag {1.1}\\] 完整的数据处理结果，标准形式如下： \\[\\begin{cases}x=\\overline {x} \\pm u(x) \\\\\\\\ u_r=\\cfrac{u(x)}{\\overline {x}} \\times 100\\% \\end{cases}\\tag{1.2}\\] 式中，\\(\\overline x\\)为多次测量的平均值，\\(u(x)\\)为合成不确定度，\\(u_r\\)是两者的比值，称为测量的相对不确定度。 不确定度的求解 直接测量不确定度的求解过程 1.单次测量 因为我们的实验过程都是指定的，并不需要我们自己来构思实验过程，所以对于测量单次或者多次无需判断，这部分不在考点内。 当遇到测量结果是单次测量时，我们的不确定度只有\\(u_B(x)\\)一项。它的取值有两种，一种是仪器标定的最大误差限（暂时没遇到，如果有应该会在型号说明那把），第二种是实验室给出的最大允许误差\\(u(x)=u_B(x)=\\Delta_仪\\)。如果两种都有，取较大者。 2.多次测量 多次测量时，不确定度一般按照下列过程进行计算： * 求多次的测量数据的平均值\\(\\overline{x}=\\sum \\frac{x_i}{n}\\); * 修正已知系统误差，得到测量值，例如，已知螺旋测微仪的零点误差为\\(d_0\\)，修正后的测量结果为\\(d=d_测-d_0\\)； * 用贝塞尔公式计算标准误差\\[s(x)=\\sqrt{\\cfrac{\\sum_{i=1}^{n} (x_i-\\overline{x})^2}{n-1}}\\] * 根据仪器标定的最大误差限，或实验室给出的最大允许误差，确定\\(u_B(x)\\)； * 根据$u_A(x)和u_B(x)求合成不确定度 \\[u(x)=\\sqrt{u^2_A(x)+u^2_B(x)}$ ； * 计算相对不确定度$u_r(x)=\\cfrac{u(x)}{\\overline {x}} \\times 100 \\%$; * 给出测量结果\\]\\begin{cases}x=u(x) \\\\ u_r=100 % \\end{cases}$$ 间接测量的不确定度 在实际测量中，我们遇到的往往是间接测量，因此间接测量具有非常重要的意义。假设物理量\\(F\\)是\\(n\\)个独立的直接测量量\\(x,y,z,\\cdots\\)的函数，即\\(F=f(x,y,z,\\cdots)\\)，如果它们相互独立，则\\(F\\)的不确定度可由各直接测量量的不确定度合成，即\\[u(F)=\\sqrt{\\left(\\cfrac {\\partial{f}}{\\partial {x}}\\right)^2 u^2 (x)+\\left(\\cfrac {\\partial{f}}{\\partial {y}}\\right)^2 u^2 (y)+\\left(\\cfrac {\\partial{f}}{\\partial {z}}\\right)^2 u^2 (z)+\\cdots}\\] 式中，\\(u(x),u(y),u(z)\\)为各直接测量量\\(x,y,z,\\cdots\\)的不确定度。 当\\(F=f(x,y,z,\\cdots)\\)中各观测量之间的关系是乘、除或方幂时，采用相对不确定度的表达方式，可以大大简化合成不确定度的运算。 方法是先取自然对数，然后作不确定度的合成，即 \\[u(F)=\\sqrt{\\left(\\cfrac{\\partial{lnf}}{\\partial x}\\right)^2u^2 (x)+\\left(\\cfrac{\\partial{lnf}}{\\partial y}\\right)^2u^2 (y)+\\left(\\cfrac{\\partial{lnf}}{\\partial z}\\right)^2u^2 (z)+\\cdots}\\] 间接测量不确定度的计算过程类似直接测量的计算过程，这里就不写了，只是将\\(u(x)\\)替换成\\(u(F)\\)。 ### 有效数字及其运算法则 #### 有效数字 对于有效数字注意以下几点即可 有效数字位数多少的计算是从测量结果的第一位（最高位）非零数字开始，到最后一位数。 数字结尾的0不应随便取舍，因为它与有效数字密切相关。例如，\\(103000\\)与\\(1.03\\times 10^5\\)不一样，前者有6位有效数字，而后者只剩下3位。 常用数学常数的有效位数（即\\(e\\)、\\(\\pi等\\))，可根据需要进行取舍，一般取位应比参加运算各数中有效位数最多的数再多一位。 在仪器上直接读取测量结果时，有效数字的多少是由被测量的大小及仪器的精度决定。正确的读数，应在仪器最小分度以下再估读一位，除非有特殊说明该仪器不需要估读。如千分尺等指针式器具，加上我们估读的那位，才读到千分位。而精密数字显示仪器和游标仪器就不用估读。 有效数字的近似运算法则 在加减法运算中，有效数字取决于参与运算的数字中末位位数最高的那个数。 乘除法运算的有效位数取决于参与运算数字中有效位数最少的那个数，必要时可多取一位。(当两个乘数的第一位数相乘大于10，则多取一位） 四则运算的基本原则与以上相同。 特殊函数的运算（三角函数、对数） 这里一定是个考点。 例：已知角度为\\(15^\\circ21’\\)，求\\(sinx\\)。 答：在x的最后一位数上取1个单位作为\\(x\\)的不确定度，即\\(u_{min}=\\Delta=1&#39;\\)，将它化为弧度有\\(\\Delta x=0.000\\ 29rad\\)；设\\(y=sinx\\),并对其求微分，得\\(\\Delta y=cosx\\Delta x \\approx 0.000\\ 28\\)，不准确位是小数点后的第4位，因此\\(sin x\\)应取到小数点后的第4位，即\\(sinx=0.264\\ 7\\)。 如果上述角度是\\(15^\\circ21&#39;10&#39;&#39;\\),则\\(\\Delta x=1&#39;&#39;=0.000\\ 004\\ 85 rad\\)，可算出\\(u(y)=cosx \\Delta x \\approx 0.000\\ 004\\ 7\\),不准确位是小数点后第6位，因此\\(sinx\\)应取到小数点后的第6位，即\\(sinx = 0.264\\ 761\\)。 例：已知\\(x=57.8\\),求\\(lg\\ x\\)。 答：设\\(y=lg\\ x\\),已知\\(u_{min}=\\Delta x=0.1\\),有\\(\\Delta y=\\Delta(ln\\ x/ln\\ 10)=0.434\\ 3\\Delta x /x \\approx0.000\\ 75\\),因此\\(lg\\ x\\)应取到小数点后第4位，即\\(lg\\ x =1.761\\ 9\\)。 综上所述，总结如下： 加、减法运算，以参加运算各量中有效数字末位最高的为准，并与之对齐； 乘、除法运算，以参加运算各量中有效数字最少的为准，必要时可多取一位。(当两个乘数的第一位数相乘大于10，则多取一位） 混合四则运算按以上原则进行； 特殊函数运算，通过微分关系进行； 数据的修约和测量结果的表述 不确定度的有效位数在一般情况下，保留一位，至多不超过两位。 具体：如果不确定度有效位数的第一位数小于或等于3，允许保留2位有效数字；如果不确定度有效位数的第一位数大于3，则只能保留一位有效数字 （在实际中经常会遇到测量结果与不确定度的有效位数发生矛盾的情况，原则是以不确定度的有效位数确定测量结果的有效位数，因此在计算测量结果时不要过早地将数字截断） 数据截断时，剩余的尾数按”小于5舍弃，大于5进位，等于5凑偶” 等于5凑偶的意思是当尾数等于5，且5后没有其他不为零的数字时，如果它前面的数是奇数，则加1，将其凑成偶数，如果是偶数则不变。 常用数据处理方法 作图法 1.选择合适的坐标分度值，确定坐标纸的大小: 坐标分度值的选取应能反映测量值的有效位数，一般以 1～2mm对应于测量仪表的最小分度值或对应于测量值的次末位数）。 2. 标明坐标轴： 用粗实线画坐标轴，用箭头标轴方向，标坐标轴的名称或符号、单位,再按顺序标出坐标轴整分格上的量值。 3.标实验点： 实验点可用“+”、 “\\(\\times\\)”、“\\(\\circ\\)”等符号标出（同一坐标系下不同曲线用不同的符号）。 4. 连成图线： 用直尺、曲线板等把点连成直线、光滑曲线。一般不强求直线或曲线通过每个实验点，应使图线线正穿过实验点时可以在两边的实验点与图线最为接近且分布大体均匀。图点处断开。 5.标出图线特征： 在图上空白位置标明实验条件或从图上得出的某些参数。如利用所绘直线可给出被测电阻R大小：从所绘直线上读取两点 A、B 的坐标就可求出 R 值。 6.标出图名： 在图线下方或空白位置写出图线的名称及某些必要的说明。 至此一张图完成 注意点 *问题：曲线太粗，不均匀，不光滑 应该用直尺、曲线板等工具把实验点连成光滑、均匀的细实线。 *问题：横轴坐标分度选取不当 横轴以3 cm 代表1 V，使作图和读图都很困难。实际在选择坐标分度值时，应既满足有效数字的要求又便于作图和读图，一般以1 mm 代表的量值是10的整数次幂或是其2倍或5倍。 图解法 实验曲线作出后，可由曲线求出经验公式及所含参数，称为图解法。物理实验中常见的有：直线，指数曲线，抛物线等。其中直线是最简单的一种。 建立经验公式的一般步骤： 第一步：根据曲线的形状判断曲线的类型； 第二步：由曲线的类型判断公式的特点，建立经验公式； *第三步：用实验数据来检验公式的准确度。 由曲线图直接建立经验公式是困难的，我们可以用变数置换法把曲线图改成直线图，再按建立直线方程的办法建立经验公式。 （1）确定直线图形的斜率和截距求测量结果 图线\\(y=kx+b\\)，可在图线上选取两点\\(P_1(x_1,y_1)\\)和\\(P_2(x_2,y_2)\\)（不能用原来测量的点）计算其斜率：\\[k=\\cfrac{y_2-y_1}{x_2-x_1}\\] \\(P_1\\)和\\(P_2\\)不要太靠近，以减小误差。其截距b是当\\(x=0\\)时的y值；或选取图上的任一点\\(P_3(x_3,y_3)\\)，带入\\(y=kx+b\\)中，并利用斜率公式得：\\[b=y3-\\cfrac{y_2-y_1}{x_2-x_1}x_3\\] 确定直线图形的斜率和截距以后，再根据斜率或截距求出所含的参量，从而得出测量结果。 （2）根据图线求出经验公式 这个就只是将函数适当转换成线性关系，不多说，这个初高中做得挺多的。 逐差法 在使用逐差法计算时，必须把测量数据分成高、低两组，对这两组实行对应项相减，不能采取逐项相减的办法处理数据。 为了保持多次测量的优点，体现出多次测量减小随机误差的目的，将一组等间隔连续测量数据（共\\(2n\\)次）按次序分成高低两组（两组次数应相同）。 一组为\\(x_0,x_1,\\cdots,x_n-1\\)，另一组为\\(x_n,x_{n+1},\\cdots,x_{2n-1}\\),取对应项的差值后再求平均值：\\[\\delta=\\frac 1n \\sum_{i=0}^{n-1}(x_{n+i}-x_i)\\] 标准偏差（即不确定度）为\\[s(\\delta)=\\sqrt{\\cfrac {\\sum_{i=0}^{n-1}[(x_{n+i}-x_i)-\\delta]^2}{n-1}}\\] 最小二乘法 设已知函数的形式为\\[y=bx+a\\] 式中，a和b为两个待定系数，成为回归系数；只有\\(x\\)为变量，由于只有一个变量，因此称为一元线性回归。 （1）回归系数的确定 回归系数a与b为\\[\\begin{cases} b=\\cfrac{\\overline{xy}-\\overline{x}\\overline{y}}{\\overline{x^2}-\\overline{x} ^2}\\\\\\\\ a=\\overline{y}-b\\overline{x} \\end{cases}\\] (2)相关系数的确定 为了判断所作的线性回归结果是否合理，引入线性回归相关系数的概念，相关系数以\\(r\\)表示，定义公式为\\[r=\\cfrac {\\overline{xy}-\\overline{x}\\overline{y}}{\\sqrt{(\\overline{x}^2-\\overline{x^2})(\\overline{y}^2-\\overline{y^2})}}\\] 相关系数\\(r\\)的取值范围为\\(-1&lt;r&lt;+1\\)。当\\(r&gt;0\\)时，回归直线的斜率为正，称为正相关。当\\(r&lt;0\\)时，回归直线的斜率为负，称为负相关。且\\(|r|\\)越接近1，说明数据点越靠近拟合曲线，即设定的回归方程越合理。 实验报告思考题 3.1示波器的使用 思考题： 1.如果波形不稳，总是向左或向右移动，该如何调节？ 答：检查触发源是否正确，如正确，调节触发电平，当Trig’D灯亮，波形稳定。 2.示波器“电平”旋钮的作用是什么？什么时候需要调节它？观察李萨如图时，能否用它把图形稳定下来？ 答：点评是使观测喜好在屏幕上稳定显示的电位器；波形在屏幕上左右滚动时，调节此电平，波形可稳定；观测李萨如图时不起作用。 3.如果打开示波器后，只看到一个或两个移动的点而没有扫描线，是什么原因？应如何调整？如果看到的是一个或两个固定不动的点呢？ 答：扫描速度较低，将扫描时间因数往快调；处于X-Y状态，调到扫描A状态即可。 3.2空气中的声速测定 思考题： 1.调整信号的频率和移动接受换能器的位置（振幅法）都是为了使接受换能器的输出达到极大，并且都被称为共振，它们是一回事吗？ 答：不是。调整频率达到共振是指探头的谐振频率，使探头有最大输出功率。移动接收换能器的位置达到共振是使超声波在两探头间形成驻波。 2.行波比较测量声速实验中，将发送换能器的信号输入到CH1通道，接受换能器的信号输入到CH2通道，此时，示波器的触发源应如何选择？ 答：选择CH1通道，因为发生换能器的信号更强，更稳定。 3.在振幅法中，示波器上看不到接受换能器的输出波形，但连线无误，仪器和导线（电缆）无故障，以下三种分析是否合理？如原因属实，应当如何处理？ （1）信号源的频率偏离换能器共振频率太远； （2）激励发生器的信号幅度太小； （3）VOLTS/DIV选择不当。 答： （1）合理。调整信号源频率，使换能器工作在谐振频率上。 （2）合理。增加信号源的输出电压。 （3）合理。可能电压分度值过高，改变接收换能器信号输出端的VOLTS/DIV，放大接收信号。 4.振幅法中，如果极大值振幅超过荧光屏显示范围，有人认为以下三种调节方法可使信号不超出范围，你认为可行吗？ （1）改变示波器VOLTS/DIV旋钮的档位； （2）调节信号发生器的输出幅度； （3）调节信号发生器的频率； 答：（1）、（2）可行，仍能保证实验数据的准确性。（3）不行，频率变化，幅度仍不变。 5.实验中，能否固定发射器与接收器之间的距离，利用改变频率测声速？ 答：不行，\\(v=f\\lambda\\),无法测出波长。 6.利用目前的仪器设备可以实现对移动距离的测量吗？ 答：可以 3.3惠斯通电桥测量中值电阻 思考题： 1.使用交换法测未知电阻时\\(R_1,R_2\\)的阻值在交换前后是否可以改变？为什么？例如交换前\\(R_1=R_2=100.0 \\Omega\\),交换后\\(R_1&#39;=R_2&#39;=500.0\\Omega\\)。 答：不可以改变。因为改变没有意义。由数据处理可知，交换法的优势在于：消除\\(R_1,R_2\\)对测量\\(R_x\\)的影响，使之只与\\(R_s、R_s&#39;\\)有关，以下证明： \\[R_x=\\frac{R_1}{R_2}R_s，R_x=\\frac{R_2}{R_1}R_s&#39; \\\\\\\\ \\Rightarrow R_x=\\sqrt{\\cfrac{R_1}{R_2} \\cdot \\cfrac{R_2}{R_1} \\cdot R_s \\cdot R_s&#39;}\\]. 如果改变\\(R_1,R_2\\)，生成\\(R_1&#39;,R_2&#39;\\),在计算\\(u(x)\\)时会加入新的元素，增大误差；即使保证\\(\\cfrac{R_1&#39;}{R_2&#39;}=\\cfrac{R_1}{R_2}\\)，既增大了复杂度，在交换过程中也可能出错。 2.\\(AC5/3\\)检流计的“电计”和“短路”键的作用是什么？调零键下方的锁扣在什么位置才可以进行调零和测量（说明是露出红点还是白点），使用后应置于什么位置（是露出红点还是白点）？ 答：“电计”键：按下后检流计接通，相当于检流计的开关。 “短路”键：可以将检流计的两端短路，增大电磁阻尼作用，使指针停止摆动。 露出红点时可以调零和测量，使用后露出白点。 3.说明测量电路中滑线变阻器的作用 答：实验中，电键闭合前将滑线变阻器调至最大，方便检流计调节平衡，待基本调节平衡，再逐渐将其阻值调零，使电路中电流增大，提高精确度。 4.下列因素是否会加大测量误差 （1）电源电压大幅下降 （2）电源电压稍有波动 （3）检流计零点没有调准 （4）检流计灵敏度不够高 答：（1）会。电源电动势越低，电桥灵敏度越低，误差越大。 （2）不会。稍有波动的电源电压对电桥灵敏度的影响可忽略。 （3）会。电桥没有到达平衡状态，测量读数会有较大误差 （4）会，因为电桥灵敏度与检流计灵敏度成正比，检流计灵敏度不高，电桥灵敏度也不高，误差较大。 5.用给出的仪器自组单臂电桥，并用其测量表头（微安表）内阻。要求： （1）画出线路图； （2）写出设计思想及表头内阻的计算公式。 仪器：0.1级电阻箱一个：电阻箱有四个接线柱分别标有：\\(0.9\\Omega\\),\\(9.9\\Omega\\),\\(99999.9\\Omega\\).滑线变阻器一个：\\(500\\Omega\\),允许\\(2A\\)电流。微安表一个：\\(100\\mu A\\)，1.5级，内阻约为\\(1000\\Omega\\)。电源：3V干电池。开关导线若干。 答：（1） ewb 无视滑线变阻器和电源上的参数吧，这是用ewb画的，不要介意。 （2）利用电阻箱结构，将电阻箱拆成3个桥臂电阻，设为\\(R_1,R_2,R_3\\)，微安表内阻为\\(r\\),使\\(R_1:R_2=1：10\\),再调整\\(R_3\\)使电桥平衡，则\\(r=\\frac{R_1}{R_2}R_3\\)。k开关变化时，\\(\\mu A\\)示数不变，则平衡。 3.4开尔文电桥测量低值电阻 思考题： 1.写出金、银、铜、铁等常见金属的电阻率，试判断我们测量的材料可能是哪一种？ 答：\\(\\rho_金=0.024\\mu \\Omega\\cdot m\\);\\(\\rho_银=0.0175\\mu \\Omega\\cdot m\\);\\(\\rho_铜=0.016\\mu \\Omega\\cdot m\\);\\(\\rho_铁=0.0978\\mu\\Omega\\cdot m\\); 所以可能是铁棒。 2.比较单臂电桥与双臂电桥有何不同，至少给出三处 答：（1）单臂电桥是两端钮接法；双臂电桥是四端钮接法； （2）单臂电桥测量中值电阻；双臂电桥测量低值电阻； （3）双臂电桥比单臂电桥多一组桥壁。 3.用双臂电桥测量\\(1\\Omega\\)以下电阻时，如被测电阻\\(R_x\\)的两电压端引线电阻较大，对测量结果有无影响？若电流端引线电阻较大，对测量结果有无影响？ 答：电压端引线电阻较大对测量结果有影响，电流端引线电阻较大无影响。 3.5霍尔元件测磁场 思考题： 1. 为什么霍尔元件要选用半导体材料制作？ 答：霍尔效应是磁敏效应。霍尔系数的大小也决定霍尔效应的明显程度，已知霍尔系数\\(K_H=\\cfrac1{nqd}\\)，若载流子密度\\(n\\)较大时，霍尔系数\\(K_H\\)较小，则发生霍尔效应不明显。由于金属材料的载流子密度较大，而半导体的载流子密度比金属要小得多，为了让霍尔效应更明显，故选择半导体材料制作霍尔元件。 2.为什么霍尔元件通常做成薄片状？ 答：霍尔系数\\(K_H=\\cfrac1{nqd}\\)，当霍尔元件的厚度\\(d\\)越小，则霍尔系数\\(K_H=\\cfrac1{nqd}\\)越大。霍尔系数越大，霍尔效应越明显。故霍尔元件通常做成薄片状。 3. 如何判断实验中所用的霍尔元件是N型还是P型半导体材料？ 答：实验中的霍尔元件是\\(N\\)型半导体材料制作的。在半导体材料中，\\(N\\)型半导体材料的载流子迁移率比\\(P\\)型半导体材料答。判断实验中所用的霍尔元件是\\(N\\)型还是\\(P\\)型半导体材料关键看载流子的迁移率。（有更好的，希望能说一下） 4.霍尔元件的摆放方向和位置对霍尔效应测磁场的结果会有何影响？ 答：霍尔效应测磁场只能测出垂直于电流方向的磁场。 所以，必须保证电流方向与磁场方向垂直，不然测出的磁场只是垂直于电流方向的分量，测量值偏小。 3.6集成霍尔传感器与简谐振动 思考题： 1.测量弹簧的变化量时，如何从加有反射镜的游标尺上正确读数？ 答：调整底脚螺钉使实验装置铅直，调节砝码盘指针靠近游标卡尺的反射镜，读数时使反射镜上的刻线和砝码盘指针及其像重合，加减砝码应该保持砝码盘水平。 2.为使周期的测量更准确，测量时应注意什么？ 答： (1)测弹簧振子振动50次所用的时间，不再是10次。 (2)拉的时候一定要竖直向下，以保证弹簧振子只在竖直方向震动。 (3)调节霍尔片与磁钢之间的距离，尽量减小振动系统的震动幅度。 (4)保证振动过程中小灯泡交替亮、灭。 3.集成霍尔传感器有哪两种类型？其输出特点有什么不同？ 答：集成霍尔传感器按输出特点分为开关型输出和线性输出。 开关型输出其输出信号只有两种状态， 高电平或低电平。 线性输出指其输出信号的电压值随着磁场极性以及强度的变化而变化。 3.12液压拉伸法测量弹性模量 思考题： 1.如果实验中钢丝直径加倍，而其他条件不变，弹性模量将变为原来的几倍？ 答：直径加倍，弹性模量不变，因为弹性模量只与材料本身属性有关。 2.测量时，光杠杆的后脚应放在什么位置？ 答：测量时，光杠杆的后脚应置于与钢丝固定的圆形托盘上。 3.为什么实验中对不同的物理量采用不同的长度测量仪器来进行测量？ 答:不同的物理量大小范围不同，精度也不同，故物理量应寻找合适的测量仪器进行测量 4.能否用光杠杆法测量一块薄金属片的厚度？试作图说明。 答：如图所示，OA为平面镜，OB在平面上，OA与OB相固定，可绕O在竖直方向转动，\\(OB=S\\)，M点处有一光源，经平面镜反射到P点，\\(ON=L\\),在B下方未知金属片，其未知厚度d. 得如图关系。 \\(L、X、S\\)已知，则\\(tan2\\alpha=\\frac XL\\)，\\(2\\alpha \\to 0\\) \\(\\alpha = \\frac X{2L}\\),so\\(d=S tan\\alpha=s\\alpha=\\cfrac{XS}{2L}\\). 3.15分光计的调整和使用 思考题： 1.调节望远镜光轴与分光计的中心轴相垂直，应该调节哪些螺钉？如何判断望远镜光轴与分光计的中心轴已经垂直？ 答：用望远镜通倾角调平螺钉和载物台调平螺钉进行调节。 若望远镜光轴与分光计中心轴垂直，光学平行平板或三棱镜两个光学面反射的亮十字像，都能与望远镜分划板叉丝刻线上焦点重合。 2.调整平行光管能够发出平行光，应调节哪些螺钉？如何判断平行光管已经发出平行光？ 答：松开夹缝套筒锁紧螺钉，前后移动狭缝筒，能看到清晰地狭缝像。 3.调节载物台法线方向与分光计中心轴平行时，三棱镜为什么要按照下图在载物台上摆放？说明理由。 答：因为需要达到调整一个光学面的法线方向时，尽量不对另一个光学面的倾斜度产生影响。调节螺钉Z，改变光学面AB的法线方向，对光学面AC的法线方向无影响。调节螺钉X可改变光学面AC的法线方向而不会对光学面AB的倾斜度产生影响。 4.调节望远镜光轴与分光计的中心轴相垂直时，如果只在一个光学面观察到十字像，如何调节？ 答：当望远镜光轴和载物台都倾斜，但望远镜的光轴垂直或大致垂直于光学平行平板的镜面时，从望远镜中可观察到反射的十字像。将光学平行平板随载物台转过\\(180^\\circ\\)后，望远镜的光轴与光学平行平板不再有垂直或大致垂直的关系，反射的十字像则可能无法进入望远镜。因此，只能观察到一个光学平面反射的十字像。（粗调） 根据望远镜、光轴和载物台的倾斜方向，可分别判断反射的为进入望远镜的十字像，是在望远镜筒外的上方还是下方。由此，可决定进一步的调节方向，或者重新进行粗调。 5.为什么分光计采用双游标度数？两个度数之间有什么关系？ 答：为消除度盘与分光计中心轴轴之间的偏心差，两个游标相差约\\(180^\\circ\\). 6.三棱镜的分光原理是什么？ 答：根据入射光的不同波长，三棱镜的折射率不同，不同波长的出射光线的偏向角不同，因而形成色散光谱，达成分光。 4.9用非线性电路研究混沌现象 思考题： 1.如何理解“混沌是确定系统中的随机性行为”？ 答：混沌现象是指发生在确定性系统中的貌似随机的不规则运动，一个确定性理论描述的系统，其行为却表现为不确定性，即不可重复、不可预测性。 2.产生混沌的条件是什么？产生混沌现象有几种途径？ 答：产生混沌的必要条件是系统具有非线性因素，充分条件是描述系统的状态方程若是非自治的，则为二阶的；若自治，则至少需要3个以上变量。 产生途径：(1)倍周期分叉进入混沌 (2)阵发性途径 (3)准周期途径 3.通过本实验尝试阐述倍周期分叉、混沌、奇怪吸引子等概念的物理意义。 答：倍周期分叉：倍周期分叉是一个映射的稳定的周期，随着参数增大而加分叉的现象，是从周期窗口进入混沌的一种“方式”（老师划了条线，不知道什么意思） 混沌：确定的宏观的非线性系统在一定条件下所呈现的不确定的或不可预测的随机现象。 奇怪吸引子：把相空间中一定体积的点都取为初值时，这个区域的形状在演化过程中虽然改变可使体积不变。耗散的系统不同，相体积在演化过程中不断收缩，最终趋向于名为“吸引子”的某一局域空间内。 4.混沌现象的特征 答：(1)初值敏感性、长时间不可预测性：对具有内在随机性的混沌系统而言，从两个非常接近的初值出发的两个轨线在经过长时间演化之后，可能相距极远。一个细微的变化，可能系统的运动轨迹就会有大的变化，表现出其对初值的极度敏感、长时间不可预测性。 (2)内在随机性：从非线性系统变化的图像观察他们在混沌区的行为表现出随机不确定性。然而这种不确定性不是来源于外部环境的随机因素对系统运动的影响，二是由系统自发产生的。 (3)非规则的有序：混沌不是纯粹的无序，而是另一种类型的有序运动，混沌区的系统行为往往体现在无穷嵌套自相似（分形），这种不同层次上的结构相似性是标度变换下的不变形，体现出混沌运动的规律。 以上是个人的答案 原本在页面源码里的彩蛋放出来了。 &lt;彩蛋：链接: http://pan.baidu.com/s/1qW29mAK 密码: ag63&gt;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"物理","slug":"物理","permalink":"https://sean10.github.io/tags/物理/"}]},{"title":"非递归判断完全二叉树！递归？No answer!","slug":"非递归判断完全二叉树！递归？No-answer","date":"2015-11-29T10:56:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/29/非递归判断完全二叉树！递归？No-answer/","link":"","permalink":"https://sean10.github.io/2015/11/29/非递归判断完全二叉树！递归？No-answer/","excerpt":"","text":"判断完全二叉树。 完全二叉树的定义是，只有第n行将所有子节点元素集中在最左以外（可以不满），其余行所有节点均为满。 结构 1234typedef struct tree&#123; char data; struct tree *lc,*rc;&#125;BitNode,*BitTree; 1.采用层次遍历 通过建立一个队列，将节点an层次入队列。当队列首节点为空时，之后的节点应当均为空，出现非空，则为非完全二叉树 123456789101112131415161718192021222324bool JudgeComplete(BitTree root)&#123; queue&lt;BitTree&gt; q; if(NULL == root) return true; q.push(root); BitTree cur = NULL; bool flag = false; while(!q.empty()) &#123; cur = q.front(); q.pop(); if(cur) &#123; if(flag) return false; q.push(cur-&gt;lc); q.push(cur-&gt;rc); &#125; else flag = true; &#125; return true;&#125; 2.递归判断的方法 如果要使用最原始的递归，那么根据分形的原则，完全二叉树并没有处处分形（自相似），所以是肯定不能使用最原始的递归方法，即只传递一个根节点进入的。下面两种传统的递归方法都有漏洞。 那么，可不可以通过追加其他的形参比如层次、深度、左右子树标记来达成目的呢？ 假设有一个深度为3的子树，追加这三项是可以判断出的，然而如果深度为100呢？仅一个标记已经无法判断这颗子树的位置，也就无法判断完全二叉树了。 所以，我认为对于完全二叉树的判断，只能采用队列层次遍历的方法 12345678910bool JudgeComplete(BitTree root)&#123; if(root != NULL)&#123; if(root-&gt;rc != NULL &amp;&amp; root-&gt;lc == NULL) return false; JudgeComplete(root-&gt;lc); JudgeComplete(root-&gt;rc); &#125; return true;&#125; 存在一个问题，对于同时存在左右子树，不过是在倒数第二行的右子树上同时存在2个子树，而同行的左子树无子树，这种情况也会被判断为完全二叉树 另外还有一个不同的递归算法，同样有比较大的问题 1234567891011bool JudgeComplete(BitTree root) //采用递归算法来实现判断是否为完全二叉树&#123; if(root == NULL) return true; if(root-&gt;lc == NULL &amp;&amp; root-&gt;rc == NULL) return true; if(root-&gt;lc == NULL &amp;&amp; root-&gt;rc != NULL || root-&gt;lc != NULL &amp;&amp; root-&gt;rc == NULL) return false; return JudgeComplete(root-&gt;lc) &amp; JudgeComplete(root-&gt;rc); &#125; 这个算法里就是完全把存在左子树，不存在右子树作为了反例了的，实际上是存在一个这样的二叉树的。","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://sean10.github.io/tags/二叉树/"},{"name":"递归","slug":"递归","permalink":"https://sean10.github.io/tags/递归/"}]},{"title":"偏序集、格","slug":"偏序集、格","date":"2015-11-28T15:44:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/28/偏序集、格/","link":"","permalink":"https://sean10.github.io/2015/11/28/偏序集、格/","excerpt":"","text":"####重新看一下关于格的知识 具有极值性质的偏序集元素有许多重要应用。 其中偏序集的一个元素叫做极大的，当它不小于这个偏序集的任何其他元素，即在偏序集中是极大的。 这里有个问题，什么叫做极大的？偏序集难道只有大小关系吗，不是说关系是任意的吗。难道说这个偏序集的大小关系其实就是是否满足这个偏序集所指定的关系，满足即为大，不满足即为小？这样的话又有一个问题，之前定义也说到了，满足即称为可比的，不满足即称为不可比的，那么在这里要求极大元素时，不可比的两个元素怎么说呢？ 这里所说的极大，其实就是在这个偏序集中不存在第二个元素可以使得他作为被处理的关系，即关系的受者。这样的元素称为该偏序集的极大元素。 使用Hasse图可以很容易找到极大元素和极小元素，因为他们是这个图的顶和底。 那么为什么呢？通过这个图，我们得到的是一个各关系之间的比较，所以，图底的元素是已经消除了所有多余的必定存在的环和传递线的，剩下的既然他作为底或顶，就意味着他已经是唯一的运算的主体或完全的运算的客体存在的了。 这里又出现了两个新的名词，最大元素和最小元素。这两个元素的出现有什么意义呢？这两个名词限定了一个性质，那就是这两个人最大和最小都一定是唯一的，如果在Hasse图中在最高层次和最低层次出现了两个及以上的数量的元素，那么这个偏序集就不存在最大元素和最小元素了。 这里保留一个问题，最大元素和最小元素的存在价值？ 上界和下界是完全不一样的，首先从关键性质上就已经发生了偏差。最大元素和最小元素有个性质是必定要是唯一的才行，而上界和下界就完全没有这样的性质，完全可以存在好多个，只要满足对该子集中所有的元素都满足关系，就可以称之为其上界和下界。 其次从范围上，有所区别，比如最大元素和最小元素其实在定义中并没有提到可以用到偏序集的子集当中，而这里上界和下界主要就是用在偏序集的子集中。 接下来，出现了两个关键新名词，最小上界和最大下界。 而最大下界和最小上界就是意味着，在上界和下界中进行比较，其中最小的称之为最小上界，以此类推，最大的就称之为最大下界了。 最小上界和最大下界估计接下来会有很大的作用，因为在这里书上给了他一个定义GLB(A)和LUB(A) ####好啦，接下来整章中最重要的BOSS登场了，格。 格的首先的性质就要求一个偏序集中的每对元素存在最小上界和最大下界。这里有个很重要的修饰词——每对，任意对元素的集合都必须得存在最小上界和最大下界。 以字母序排列的偏序集长得我觉得就比较像格。 这里稍微说道，格在布尔代数中起到了非常重要的性质。 这里可以让我们保留一下期盼。（待以后看到了补充） 书上分析是否是格，出现了一个没见过的判断，用到的原因是说3个元素的任意一个的在这个偏序集中的序都不大于另两个。 这里的序是不是就是所谓的链接的大小关系呢？就是说因为他们三个元素与他们以下的元素都形成了相等的3条线，故三者相等，不存在其中一个大于另两个之说，也就导致了最小上界不存在。故不为格？ 这是一个猜想，姑且保留先。 ####信息流的格模型 在许多设置中，从一个人或计算机程序到另一个人或计算机程序的信息流要受到限制，这可以通过安全权限来实现。 我们可以使用格的模型来表示不同的信息流策略。 （这句话是什么意思，不能理解，什么叫做策略，又怎么来表示） 例如，一个通用的信息流策略是用于政府或军事系统中的多级安全策略。为每组信息分配一个安全级别，并且每个安全级别用一个对（A,C）表示，其中A是权限级别，C是种类，然后允许人和计算机程序从一个被特别限制的安全类的集合中访问信息。 （感觉这里并咩有说清楚，A和C是如何形成了一个偏序集的） 在美国政府中，使用的典型的权限级别是不保密（0）、秘密（1）、机密（2）和绝密（3）。在安全级别中使用的种类是一个集合的子集，这个集合含有与一个特定行业领域相关的所有的分布。每个分部表示一个指定的对象域。 （分部和对象域又是什么？完全没有提到） 例如，如果分部的集合是{间谍，鼹鼠，双重间谍}，那么存在8种不同的分类，分部集合有8个子集，对于每个子集有一类，例如{间谍，鼹鼠} （这里应该是根据关系进行了任意的组合，但是也没有说道这两个种类之间的关系） 我们可以对安全类排序，规定 。信息允许从安全类（A1，C1}流向安全类（A2，C2）当且仅当（A1，C1）对(A2，C2)满足那个关系。例如，信息允许从安全类（机密，{间谍，鼹鼠}）流向安全类{绝密，{间谍，鼹鼠，双重间谍}}。反之，信息不允许从安全类（绝密，{间谍，鼹鼠}）流向安全类（机密，{间谍，鼹鼠，双重间谍}）或（绝密，{间谍}）； （暂时还是不理解） ####拓扑排序 假设一个项目由20个任务构成。某些人武只能在其他任务结束后完成。如何找到这些任务的顺序（感觉这个有点像路径了，比如CPM） 定义，如果只要aRb就有a与b满足那样的关系，则称一个全序 与偏序R是相容的（相容又是一个新名词）。 从一个偏序构造一个相容的全序叫做拓扑排序，我们需要使用引理。（引理看起来很重要）","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/离散数学/"}]},{"title":"《沉默的大多数》跳出手掌心","slug":"《沉默的大多数》跳出手掌心","date":"2015-11-27T15:56:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/27/《沉默的大多数》跳出手掌心/","link":"","permalink":"https://sean10.github.io/2015/11/27/《沉默的大多数》跳出手掌心/","excerpt":"","text":"近来读了C．P．斯诺的《两种文化》。这本书里谈到的事倒是不新鲜，比方说，斯诺先生把知识分子分成了科学知识分子和文学（人文）知识分子两类，而且说，有两种文化，一种是科学文化，一种是文学（人文）文化。现在的每个知识分子，他的事业必定在其中一种之中。 我要谈到的事，其实与斯诺先生的书只有一点关系，那就是，我以为，把两种文化合在一起，就是人类前途所系。这么说还不大准确，实际上，是创造了这两种文化的活动——人类的思索，才真正是人类前途之所系。尤瑟纳尔女士借阿德里安之口云，当一个人写作或计算时，就超越了性别，甚至超越了人类——当你写作和计算时，就是在思索。思索是人类的前途所系，故此，思索的人，超越了现世的人类。这句话讲得是非常之好的，只是讲得过于简单。实际上，并不是每一种写作或计算都可以超越人类。这种情况并不多见，但是非常的重要。 现在我又想起了另一件事，乍看上去离题甚远：八十年代，美国通过了一个计划，拨出几百亿美元的资金，要在最短时间之内攻克癌症。结果却不令人满意，有些人甚至说该计划贻人笑柄，因为花了那么多钱，也没找出一种特效疗法。这件事说明，有了使不尽的钱，也不见得能做出突破性的发现。实际上，人类历史上任何一种天才的发现都不是金钱直接作用的结果。金钱、权力，这在现世上是最重要的东西，是人类生活的一面，但还有另一面。说到天才的发现，我们就要谈到天才、灵感、福至心灵、灵机一动等等，决不会说它们是某些人有了钱、升了官，一高兴想出来的。我要说的就是：沉默地思索，是人类生活的另外一面。就以攻克癌症为例，科学家默默地想科学、做科学，不定哪一天就做出一个发现，彻底解决了这个问题。但是，如果要约定一个期限，则不管你给多少钱也未必能成功。对于现代科技来说，资金设备等等固然重要，但天才的思想依然是最主要的动力。一种发现或发明可以赚到很多钱，但有了钱也未必能造出所要的发明。思索是一道大门，通向现世上没有的东西，通到现在人类想不到的地方。以科学为例，这个道理就是明明白白的。 科学知识分子很容易把自己的工作看作超越人类的事业，但人文知识分子就很难想到这一点。就以文学艺术为例，我们这里要求它面向社会、面向生活，甚至要求它对现世的人有益，弘扬民族文化等等，这样就越说越小了。诚然，文学艺术等等，要为现世的人所欣赏，但也不仅限于此。莎士比亚的戏现在还在演，将来也要演。你从莎翁在世时的英国的角度出发，绝想象不到会有这样的事。自然科学的成果，有一些现在的人类已经用上了，但据我所知，没用上的还很多。倘若你把没用上的通通取消，科学就不成其为科学。我上大学时，有一次我的数学教授在课堂上讲到：我现在所教的数学，你们也许一生都用不到，但我还要教，因为这些知识是好的，应该让你们知道。这位老师的胸襟之高远，使我终生佩服。我还要说，像这样的胸襟，在中国人文知识分子中间很少见到。 倘若我说，科学知识分子比人文知识分子人品高尚，肯定是不对的。科学知识分子里也有卑鄙之徒，比方说，前苏联的李森科。但我未听到谁对他的学说说过什么太难听的话，更没有听到谁做过这样细致的分析：李森科学说中某个谬误，和他的卑鄙内心的某一块是紧密相连的。倘若李森科不值得尊敬，李森科所从事的事业——生物学——依旧值得尊重。在科学上，有错误的学说，没有卑鄙的学说；就是李森科这样卑鄙的人为生物学所做的工作也不能说是卑鄙的行径。这样的道德标准显然不能适用于现在中国的艺术论坛，不信你就看看别人是怎样评论贾平凹先生的《废都》的。很显然，现在在中国，文学不是一种超越现世、超越人类的事业。我们评论它的标准，和三姑六婆评价身边发生的琐事的标准，没有什么不同。贾先生写了一部《废都》，就如某位大嫂穿了旗袍出门，我们不但要说衣服不好看，还要想想她的动机是什么，是不是想要勾引谁。另外哪位先生或女士写了什么好书，称赞他的话必是功在世道人心，就如称赞哪位女士相夫教子、孝敬公婆是一样的。当然，假如我说现在中国对文艺只有这样一种标准，那就是恶毒的诽谤。杜拉斯的《情人》问世不久，一下就出了四种译本（包括台湾的译本），电影《辛德勒的名单》国内尚未见到，好评就不绝于耳。我们说，这些将是传世之作，那就不是用现世的标准、道德的标准来评判的。这种标准从来不用之于中国人。由此得到一个结论，那就是在文学艺术的领域，外国人可以做超越人类的事业，中国人却不能。 在文学艺术及其他人文的领域之内，国人的确是在使用一种双重标准，那就是对外国人的作品，用艺术或科学的标准来审评；而对中国人的作品，则用道德的标准来审评。这种想法的背后，是把外国人当成另外一个物种，这样对他们的成就就能客观地评价；对本国人则当作同种，只有主观的评价，因此我们的文化事业最主要的内容不是它的成就，而是它的界限；此种界限为大家所认同，谁敢越界就要被群起而攻之。当年孟子如此来评价杨朱和墨子：“无君无父，是禽兽也。”现在我们则如此地评价《废都》和一些在国外获奖的电影。这些作品好不好可以另论，总不能说人家的工作是“禽兽行”，或者是“崇洋媚外”。身为一个中国人，最大的痛苦是忍受别人“推己及人”的次数，比世界上任何地方的人都要多。我要说的不是自己不喜欢做中国人（这是我最喜欢的事），我要说的是，这对文化事业的发展很是不利。 我认为，当我们认真地评价艺术时，所用的标准和科学上的标准有共通之处，那就是不依据现世的利害得失，只论其对不对（科学）、美不美（艺术）。此种标准我称为智慧的标准。假设有一种人类之外的智能生物，我们当然期望它们除了理解人类在科学上的成就之外，还能理解人类在艺术上的成就，故此，智慧就超越了人类。有些人会以为人类之外的东西能欣赏人类的艺术是不可能的，那么我敢和你打赌，此种生物在读到尤瑟纳尔女士的书时，读到某一句必会击节赞赏，对人类拥有的胸襟给予肯定；至于它能不能欣赏《红楼梦》，我倒不敢赌。但我敢断言，这种标准是存在的。从这种标准来看，人类侥幸拥有了智慧，就该善用它，成就种种事业，其中就包括了文学艺术在内。用这样的标准来度量，小说家力图写出一本前所未有的书，正如科学家力图做出发现，是值得赞美的事。当然，还有别的标准，那就是念念不忘自己是个人，家住某某胡同某某号，周围有三姑六婆，应该循规蹈矩地过一生，倘有余力，就该发大财，当大官，让别人说你好。这后一种标准是个人幸福之所系，自然不可忘记，但作为一个现代知识分子，前一种标准也该记住一些。 一个知识分子在面对文化遗产时，必定会觉得它浩浩洋洋，仰之弥高。这些东西是数千年来人类智慧的积累，当然是值得尊重的。不过，我以为它的来源更值得尊重，那就是活着的人们所拥有的智慧。这种东西就如一汪活水，所有的文化遗产都是它的沉积物。这些活水之中的一小份可以存在于你我的脑子里，照我看来，这是世界上最美好的事情。保存在文化遗产里的智慧让人尊敬，而活人头脑里的智慧更让人抱有无限的期望。我喜欢看到人们取得各种成就，尤其是喜欢看到现在的中国人取得任何一种成就。智慧永远指向虚无之境，从虚无中生出知识和美；而不是死死盯住现时、现事和现在的人。我认为，把智慧的范围限定在某个小圈子里，换言之，限定在一时、一地、一些人、一种文化传统这样一种界限之内是不对的；因为假如智慧是为了产生、生产或发现现在没有的东西，那么前述的界限就不应当存在。不幸的是，中国最重大的文化遗产，正是这样一种界限，就像如来佛的手掌一样，谁也跳不出来；而现代的主流文化却诞生在西方。 在中国做知识分子，有一种传统的模式，可能是孔孟，也可能是程朱传下来的，那就是自己先去做个循规蹈矩的人，做出了模样，做出了乐趣，再去管别人。我小的时候，从小学到中学，班上都有这样的好同学，背着手听讲，当上了小班长，再去管别人。现在也是这样，先是好好地求学，当了知名理论家、批评家，再去匡正世道人心。当然，这是做人的诀窍。做个知识分子，似乎稍嫌不够；除了把世道和人心匡得正正的，还该干点别的。由这样的模式，自然会产生一种学堂式的气氛，先是求学，受教，攒到了一定程度，就来教别人，管别人。如此一种学堂开办数千年来，总是同一些知识在其中循环，并未产生一种面向未来、超越人类的文化——谁要骂我是民族虚无主义，就骂好了，反正我从小就不是好同学——只产生了一个极沉重的传统，无数的聪明才智被白白消磨掉。倘若说到世道人心，我承认没有比中国文化更好的传统——所以我们这里就永远只有世道人心，有不了别的。 总之，说到知识分子的职责，我认为还有一种传统可循：那就是面向未来，取得成就。古往今来的一切大智者无不是这样做的。这两种知识分子的形象可以这样分界，前一种一世的修为，是要做个如来佛，让别人永世跳不出他的手掌心；后一种是想在一生一世之中，只要能跳出别人的手掌心就满意了。我想说的就是，希望大家都做后一种知识分子，因为不管是谁的手掌心，都太小了。 我们可能算得上是未来的知识分子，现在至少我自认认识的还远远不够多。我们的最大的价值确实是在于思考，现在我在努力养成的习惯正是无时无刻的思考。 在博客园里的大部分人想必都是已经达到了一定的水平的程序员（我是少部分还在学习中的层次），我们其实也算得上是科学方面的知识分子，我们都是科技的受利者，在使用当下的科技谋生。在互联网产业中，如同乔布斯的创业者其实也可以算得上是在试图引发时代的变革、进化吧，工作确实算得上是超越人类的事业。而人文，对于理工科的我们，感受到的恐怕最为明显的只有精神的放松的作用了罢，于没有闲情逸致消遣人文的人，对于人文的超越性确实会很难理解了。 对于人文的理解，我看的书还不够深，我也不太理解，这点期待其他人的想法。 对于知识分子智慧的标准，我们虽然追求第一个标准，不想遵循粗鄙的第二个标准。然而第二个标准却是生活必然，超然于第二个标准实在需要一定的物质、精神高度才可。 于程序员的世界，求学是永久的，我们始终面向未来，在不断的跳出其他人的手掌心，可能也会让其他人进入自己的手掌心，我们不正进入了Linus等人的手掌吗？如来佛也只是佛之一种，在我们的世界，并不存在万佛之祖，即便是Linus也是在其他人手中学习着的。 话虽如此，环境虽然面向未来，我们依旧要时刻保持虚心的态度学习，否则恐怕就会成为悟空，只不过是被自己的五指山镇压。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"书评","slug":"书评","permalink":"https://sean10.github.io/tags/书评/"},{"name":"王小波","slug":"王小波","permalink":"https://sean10.github.io/tags/王小波/"},{"name":"思考","slug":"思考","permalink":"https://sean10.github.io/tags/思考/"}]},{"title":"《沉默的大多数》序言","slug":"《沉默的大多数》序言","date":"2015-11-26T10:09:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/26/《沉默的大多数》序言/","link":"","permalink":"https://sean10.github.io/2015/11/26/《沉默的大多数》序言/","excerpt":"","text":"年轻时读萧伯纳的剧本《芭芭拉少校》，有场戏给我留下了深刻的印象：工业巨头安德谢夫老爷子见到了多年不见的儿子斯泰芬，问他对做什么有兴趣。这个年轻人在科学、文艺、法律等一切方面一无所长，但他说自己有一项长处：会明辨是非。老爷子把自己的儿子暴损了一通，说这件事难倒了一切科学家、政治家、哲学家，怎么你什么都不会，就会一个明辨是非？我看到这段文章时只有二十来岁，登时痛下决心，说这辈子我干什么都可以，就是不能做一个一无所能，就能明辨是非的人。因为这个原故，我成了沉默的大多数的一员。我年轻时所见的人，只掌握了一些粗浅（且不说是荒谬）的原则，就以为无所不知，对世界妄加判断，结果整个世界都深受其害。直到我年登不惑，才明白萧翁的见解原有偏颇之处；但这是后话——无论如何，萧翁的这些议论，对那些浅薄之辈、狂妄之辈，总是一种解毒剂。 萧翁说明辨是非难，是因为这些是非都在伦理的领域之内。俗话说得好，此人之肉，彼人之毒；一件对此人有利的事，难免会伤害另一个人。真正的君子知道，自己的见解受所处环境左右，未必是公平的；所以他觉得明辨是非是难的。倘若某人以为自己是社会的精英，以为自己的见解一定对，虽然有狂妄之嫌，但他会觉得明辨是非很容易。明了萧翁这重意思以后，我很以做明辨是非的专家为耻——但这已经是二十年前的事了。当时我是年轻人，觉得能洁身自好，不去害别人就可以了。现在我是中年人——一个社会里，中年人要负很重的责任：要对社会负责，要对年轻人负责，不能只顾自己。因为这个原故，我开始写杂文。现在奉献给读者的这本杂文集，篇篇都在明辨是非，而且都在打我自己的嘴。 伦理问题虽难，但却不是不能讨论。罗素先生云，真正的伦理原则把人人同等看待。考虑伦理问题时，想替每个人都想一遍是不可能的事，但你可以说，这是我的一得之见，然后说出自己的意见，把是非交付公论。讨论伦理问题时也可以保持良心的清白——这是我最近的体会；但不是我打破沉默的动机。假设有一个领域，谦虚的人、明理的人以为它太困难、太暧昧，不肯说话，那么开口说话的就必然是浅薄之徒、狂妄之辈。这导致一种负筛选：越是傻子越敢叫唤——马上我就要说到，这些傻子也不见得是真的傻，但喊出来的都是傻话。久而久之，对中国人的名声也有很大的损害。前些时见到个外国人，他说：听说你们中国人都在说“不”？这简直是把我们都当傻子看待。我很不客气地答道：物以类聚，人以群分。你认识的中国人都说“不”，但我不认识这样的人。这倒不是唬外国人，我认识很多明理的人，但他们都在沉默中，因为他们都珍视自己的清白。但我以为，伦理问题太过重要，已经不容我顾及自身的清白。 伦理（尤其是社会伦理）问题的重要，在于它是大家的事——大家的意思就是包括我在内。我在这个领域里有话要说，首先就是：我要反对愚蠢。一个只会明辨是非的人总是凭胸中的浩然正气做出一个判断，然后加上一句：难道这不是不言而喻的吗？任何受过一点科学训练的人都知道，这世界上简直找不到什么不言而喻的事，所以这就叫做愚蠢。在我们这个国家里，傻有时能成为一种威慑。假如乡下一位农妇养了五个傻儿子，既不会讲理，又不懂王法，就会和人打架，这家人就能得点便宜。聪明人也能看到这种便宜，而且装傻谁不会呢——所以装傻就成为一种风气。我也可以写装傻的文章，不只是可以，我是写过的——“文革”里谁没写过批判稿呢。但装傻是要不得的，装开了头就不好收拾，只好装到底，最后弄假成真。我知道一个例子是这样的：某人“文革”里装傻写批判稿，原本是想搞点小好处，谁知一不小心上了《人民日报》头版头条，成了风云人物。到了这一步，我也不知他是真傻假傻了。再以后就被人整成了“三种人”。到了这个地步，就只好装下去了，真傻犯错误处理还能轻些呀。 我反对愚蠢，不是反对天生就笨的人，这种人只是极少数，而且这种人还盼着变聪明。在这个世界上，大多数愚蠢里都含有假装和弄假成真的成分；但这一点并不是我的发现，是萧伯纳告诉我的。在他的《匹克梅梁》里，息金斯教授遇上了一个假痴不癫的杜特立尔先生。息教授问：你是恶棍还是傻瓜？这就是问：你假傻真傻？杜先生答：两样都有点，先生，凡人两样都得有点呀。在我身上，后者的成分多，前者的成分少；而且我讨厌装傻，渴望变聪明。所以我才会写这本书。 在社会伦理的领域里我还想反对无趣，也就是说，要反对庄严肃穆的假正经。据我的考察，在一个宽松的社会里，人们可以收获到优雅，收获到精雕细琢的浪漫；在一个呆板的社会里，人们可以收获到幽默——起码是黑色的幽默。就是在我呆的这个社会里，什么都收获不到，这可是件让人吃惊的事情。看过但丁《神曲》的人就会知道，对人来说，刀山剑树火海油锅都不算严酷，最严酷的是寒冰地狱，把人冻在那里一动都不能动。假如一个社会的宗旨就是反对有趣，那它比寒冰地狱又有不如。在这个领域里发议论的人总是在说：这个不宜提倡，那个不宜提倡。仿佛人活着就是为了被提倡。要真是这样，就不如不活。罗素先生说，参差多态乃是幸福的本源——弟兄姐妹们，让我们睁开眼睛往周围看看，所谓的参差多态，它在哪里呢。 在萧翁的《芭芭拉少校》中，安德谢夫家族的每一代都要留下一句至理名言。那些话都编得很有意思，其中有一句是：人人有权争胜负，无人有权论是非。这话也很有意思，但它是句玩笑。实际上，人只要争得了论是非的权力，他已经不战而胜了。我对自己的要求很低：我活在世上，无非想要明白些道理，遇见些有趣的事。倘能如我所愿，我的一生就算成功。为此也要去论是非，否则道理不给你明白，有趣的事也不让你遇到。我开始得太晚了，很可能做不成什么，但我总得申明我的态度，所以就有了这本书——为我自己，也代表沉默的大多数。 王小波 1997年3月20日 明辨是非确实不值得自称，正如作者所说，是非与社会伦理相关，受环境影响，辨出的是非是与视野确切相关的。 当下的我们大部分人还年轻，阅历并不能算是很丰富，可能看了不少书、电影、段子，即便这些都是建立在真实之上的，那也只是真实的局部，我们认识的与亲身经历的往往相差甚远。往往通过网络看到一些时事时，看到结果与自己的判断差不多，自以为自己辨别的不错。其实都是假象，其中一个原因，就是人总会自觉的美化自己。就像看答案做作业，你总会觉得这些题好简单，很容易就写出来；而实际脱离答案时，建立的思路却远不上道。辨别是非并不是像我们当下想象的那么简单地能力，正如作者所言，年轻时还是少言是非多做自己的事为好。 必须着重强调一下的是，少言是非。少言并不是对一切保持沉默，即便是自己该发言的时候。少言仅仅只是指不要对不关自己的事情，不切身的事情，妄下评论。对于与自己相关之事，单纯发表真实的想法并不为过。 而在相关、且并非时下不正常的时候，不发表自己的真实想法，以装傻糊弄他人占些便宜，这就是在损伤自己的良心了。仅从我们个人自身来谈，对于并非聪明绝顶的、我们这样的普通人来说，装傻装着装着习惯了，贪小便宜习惯了，那可就真的习惯了装傻的思维方式了。至少于我，装傻是不可行的，否则我必定会习惯局限性的思考，忘记了探索思维的深度。而且吧，如果是真傻，那还只是自己的思维的广度不足，对某些事真的不懂，学着学着就不傻了。假傻，那可就没辙了，时间会让你习惯成真傻的。 对无趣这段，所幸当下的我们的社会其实还是不错的了，至少对于网上的我们，还是能做些越矩的事的。 有态度，慢慢做，做到哪收获到哪，对我来说，当下也足够了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"书评","slug":"书评","permalink":"https://sean10.github.io/tags/书评/"},{"name":"王小波","slug":"王小波","permalink":"https://sean10.github.io/tags/王小波/"}]},{"title":"并查集——HDU1213","slug":"并查集——HDU1213","date":"2015-11-26T08:02:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/26/并查集——HDU1213/","link":"","permalink":"https://sean10.github.io/2015/11/26/并查集——HDU1213/","excerpt":"","text":"第一次做并查集的题，选了道比较简单的。 用数组很简单，不多说了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;cstdio&gt;#include &lt;cstdlib&gt;int a[1010];void Init(int N)&#123; for(int i = 1;i &lt;= N;i++) a[i] = i;&#125;int Find(int x)&#123; while(x != a[x]) x = a[x]; return x;&#125;void Union(int x, int y)&#123; int x1 = Find(x); int y1 = Find(y); if(x1 != y1) a[y1] = x1; return ;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int T; scanf(&quot; %d&quot;,&amp;T); while(T--)&#123; int N,M; scanf(&quot; %d%d&quot;,&amp;N,&amp;M); Init(N); for(int i = 0;i &lt; M;i++)&#123; int x,y; scanf(&quot;%d%d&quot;,&amp;x,&amp;y); Union(x,y); &#125; int ans = 0; for(int i = 1;i &lt;= N;i++)&#123; if(i == a[i]) ans++; &#125; printf(&quot;%d\\n&quot;,ans); //getchar(); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"并查集","slug":"并查集","permalink":"https://sean10.github.io/tags/并查集/"}]},{"title":"二叉树——Huffman树求最短路径和","slug":"二叉树——Huffman树求最短路径和","date":"2015-11-26T06:25:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/26/二叉树——Huffman树求最短路径和/","link":"","permalink":"https://sean10.github.io/2015/11/26/二叉树——Huffman树求最短路径和/","excerpt":"","text":"题目链接 总时间限制: 1000ms 内存限制: 65536kB ####描述 构造一个具有n个外部节点的扩充二叉树，每个外部节点Ki有一个Wi对应，作为该外部节点的权。使得这个扩充二叉树的叶节点带权外部路径长度总和最小： Min( W1 * L1 + W2 * L2 + W3 * L3 + … + Wn * Ln) Wi:每个节点的权值。 Li:根节点到第i个外部叶子节点的距离。 编程计算最小外部路径长度总和。 ####输入 第一行输入一个整数n，外部节点的个数。第二行输入n个整数，代表各个外部节点的权值。 2&lt;=N&lt;=100 ####输出 输出最小外部路径长度总和。 样例输入 1241 1 3 5 样例输出 117 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;typedef struct tree&#123; int weight; int lc ,rc, parent;&#125;HufNode,*HufTree;int GetMin(HufTree H,int k)&#123; int i = 0,min,minWeight; while(H[i].parent != -1)&#123; i++; &#125; min = i; minWeight = H[i].weight; for(;i&lt;k;i++)&#123; if(minWeight &gt; H[i].weight &amp;&amp; H[i].parent == -1)&#123; minWeight = H[i].weight; min = i; &#125; &#125; H[min].parent = 1; return min;&#125;HufTree Create(HufTree &amp;H,int *s,int n)&#123; int total = 2*n-1; H = (HufTree)malloc(total*sizeof(HufNode)); for(int i = 0;i &lt; n;i++)&#123; H[i].weight = *s; H[i].lc = -1; H[i].rc = -1; H[i].parent = -1; s++; &#125; for(int i = n;i &lt; total;i++)&#123; H[i].weight = 0; H[i].lc = -1; H[i].rc = -1; H[i].parent = -1; &#125; int min1,min2; for(int i = n;i &lt; total;i++)&#123; min1 = GetMin(H,i); min2 = GetMin(H,i); H[min1].parent = i; H[min2].parent = i; H[i].lc = min1; H[i].rc = min2; H[i].weight = H[min1].weight+H[min2].weight; &#125; return H;&#125;int Trans(HufTree H,int n)&#123; int ans = 0; for(int i = 0;i &lt; n;i++)&#123; int deepth = 0; int temp = i; while(H[i].parent != -1)&#123; deepth++; i = H[i].parent; &#125; i = temp; ans += deepth *H[i].weight; &#125; return ans;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int n; scanf(&quot;%d&quot;,&amp;n); int s[1000]; for(int i = 0;i &lt; n;i++)&#123; scanf(&quot;%d&quot;,&amp;s[i]); &#125; HufTree H = Create(H,s,n); printf(&quot;%d\\n&quot;,Trans(H,n)); return 0;&#125; 参考资料： [1]http://blog.csdn.net/ns_code/article/details/19174553","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"Huffman","slug":"Huffman","permalink":"https://sean10.github.io/tags/Huffman/"},{"name":"二叉树","slug":"二叉树","permalink":"https://sean10.github.io/tags/二叉树/"}]},{"title":"二叉树——文本二叉树","slug":"二叉树——文本二叉树","date":"2015-11-26T01:25:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/26/二叉树——文本二叉树/","link":"","permalink":"https://sean10.github.io/2015/11/26/二叉树——文本二叉树/","excerpt":"","text":"总时间限制: 1000ms 内存限制: 65536kB ####描述 img 如上图，一棵每个节点都是一个字母，且字母互不相同的二叉树，可以用以下若干行文本表示: 12345678A-B--*--C-D--E---*---F 在这若干行文本中： 每个字母代表一个节点。该字母在文本中是第几行，就称该节点的行号是几。根在第1行 每个字母左边的’-’字符的个数代表该结点在树中的层次（树根位于第0层） 若某第 i 层的非根节点在文本中位于第n行，则其父节点必然是第 i-1 层的节点中，行号小于n,且行号与n的差最小的那个 若某文本中位于第n行的节点(层次是i) 有两个子节点，则第n+1行就是其左子节点，右子节点是n+1行以下第一个层次为i+1的节点 若某第 i 层的节点在文本中位于第n行，且其没有左子节点而有右子节点，那么它的下一行就是 i+1个’-‘字符再加上一个’*’ 给出一棵树的文本表示法，要求输出该数的前序、后序、中序遍历结果 ####输入 第一行是树的数目 n 接下来是n棵树，每棵树以’0’结尾。’0’不是树的一部分 每棵树不超过100个节点 ####输出 对每棵树，分三行先后输出其前序、后序、中序遍历结果 两棵树之间以空行分隔 ####样例输入 12345678910111213142A-B--*--C-D--E---*---F0A-B-C0 ####样例输出 1234567ABCDEFCBFEDABCAEFDABCBCABAC 递归不太会用，这道题是参照解题报告，用迭代来建树的。 这道题的关键点在于建一个栈，存储节点的目录，用于寻找当前节点的父节点，以及节点是否是叶子节点（如果是叶子节点，因为与下一个节点不成父子节点，直接出栈）。 算法的关键是对两种节点情况的处理。 1.有左右子树尚未链接上，进行左右判别，从栈里找到它的父节点（判断父节点的方法就是树的深度相差为1），链接； 2.左右子树链接完了，出栈，进行同深度右子树的链接。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;stack&gt;#include &lt;cstring&gt;using namespace std;typedef struct node&#123; int deepth; int dir; char data; struct node *lc,*rc;&#125;BitNode,*BitTree;BitTree Create()&#123; BitTree p1,p2,head; char s[100]; scanf(&quot;%s&quot;,s); head = (BitTree)malloc(sizeof(BitNode)); head-&gt;data = s[0]; head-&gt;deepth = 0; head-&gt;dir = 0; head-&gt;lc = NULL; head-&gt;rc = NULL; stack&lt;BitTree&gt;temp; temp.push(head); //p2 = temp.top(); while(scanf(&quot;%s&quot;,s))&#123; if(s[0] == &apos;0&apos;)&#123; return head; &#125; p1 = (BitTree)malloc(sizeof(BitNode)); p1-&gt;deepth = strlen(s)-1; p1-&gt;data = s[p1-&gt;deepth]; p1-&gt;lc = NULL; p1-&gt;rc = NULL; p1-&gt;dir = 0; p2 = temp.top(); if(p1-&gt;data == &apos;*&apos;)&#123; p2-&gt;dir++; continue; &#125; while(p1-&gt;deepth - p2-&gt;deepth != 1)&#123; temp.pop(); p2 = temp.top(); &#125; if(p2-&gt;dir == 0)&#123; p2-&gt;lc = p1; p2-&gt;dir++; &#125; else if(p2-&gt;dir == 1)&#123; p2-&gt;rc = p1; p2-&gt;dir++; &#125; if(p2-&gt;dir == 2)&#123; temp.pop(); &#125; temp.push(p1); &#125; //return head;&#125;void PreOrder(BitTree root)&#123; cout &lt;&lt; root-&gt;data; if(root-&gt;lc) PreOrder(root-&gt;lc); if(root-&gt;rc) PreOrder(root-&gt;rc);&#125;void MidOrder(BitTree root)&#123; if(root-&gt;lc) MidOrder(root-&gt;lc); cout &lt;&lt; root-&gt;data; if(root-&gt;rc) MidOrder(root-&gt;rc);&#125;void AftOrder(BitTree root)&#123; if(root-&gt;lc != NULL) AftOrder(root-&gt;lc); if(root-&gt;rc != NULL)&#123; AftOrder(root-&gt;rc); &#125; cout &lt;&lt; root-&gt;data;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int t; BitTree head; cin &gt;&gt; t; while(t--)&#123; head = Create(); PreOrder(head); cout &lt;&lt; endl; AftOrder(head); cout &lt;&lt; endl; MidOrder(head); cout &lt;&lt; endl; cout &lt;&lt; endl; &#125; return 0;&#125; 参考资料： [1]http://www.cnblogs.com/zl0372/articles/C_01.html [2]http://blog.sina.com.cn/s/blog_6ae9d6c70101bf8p.html","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://sean10.github.io/tags/二叉树/"}]},{"title":"二叉树——实现堆结构","slug":"二叉树——实现堆结构","date":"2015-11-23T01:46:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/23/二叉树——实现堆结构/","link":"","permalink":"https://sean10.github.io/2015/11/23/二叉树——实现堆结构/","excerpt":"","text":"题目链接 总时间限制: 3000ms 内存限制: 65535kB 描述 定义一个数组，初始化为空。在数组上执行两种操作： 1、增添1个元素，把1个新的元素放入数组。 2、输出并删除数组中最小的数。 使用堆结构实现上述功能的高效算法。 输入 第一行输入一个整数t，代表测试数据的组数。 对于每组测试数据，第一行输入一个整数n，代表操作的次数。 每次操作首先输入一个整数type。 当type=1，增添操作，接着输入一个整数u，代表要插入的元素。 当type=2，输出删除操作，输出并删除数组中最小的元素。 1&lt;=n&lt;=100000。 输出 每次删除操作输出被删除的数字。 样例输入 123456789101112251 11 21 32241 51 11 72 样例输出 123121 提示 每组测试数据的复杂度为O(nlgn)的算法才能通过本次，否则会返回TLE(超时) 需要使用最小堆结构来实现本题的算法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;int heap[100010];int len;//int maxsize;void Init()&#123; //maxsize = 0; len = 0;&#125;void Insert(int x)&#123; //heap[len] = x; len++; int i = len -1; while(i &gt; 0)&#123; int j = (i-1)/2; if(x &gt; heap[j]) break; heap[i] = heap[j]; i = j; &#125; heap[i] = x;&#125;int Del()&#123; if(0 == len)&#123; exit(1); &#125; int temp = heap[0]; len--; if(0 == len)&#123; return temp; &#125; int x = heap[len]; int i = 0; int j = 2*i+1; while(j &lt;= len-1)&#123; if((j &lt; len-1)&amp;&amp; (heap[j] &gt; heap[j+1]))&#123; j++; &#125; if(x &lt; heap[j])&#123; break; &#125; heap[i] = heap[j]; i = j; j = 2*i+1; &#125; heap[i] = x; return temp;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int t,n,type,x; scanf(&quot;%d&quot;,&amp;t); while(t--)&#123; scanf(&quot;%d&quot;,&amp;n); //struct node p; Init(); while(n--)&#123; scanf(&quot;%d&quot;,&amp;type); if(type == 1)&#123; scanf(&quot;%d&quot;,&amp;x); Insert(x); &#125; else if(type == 2) printf(&quot;%d\\n&quot;,Del()); &#125; &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://sean10.github.io/tags/二叉树/"},{"name":"堆","slug":"堆","permalink":"https://sean10.github.io/tags/堆/"}]},{"title":"二叉树——由中根序列和后根序列重建二叉树","slug":"二叉树——由中根序列和后根序列重建二叉树","date":"2015-11-22T13:48:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/22/二叉树——由中根序列和后根序列重建二叉树/","link":"","permalink":"https://sean10.github.io/2015/11/22/二叉树——由中根序列和后根序列重建二叉树/","excerpt":"","text":"题目链接 总时间限制: 500ms 内存限制: 65535kB 描述 我们知道如何按照三种深度优先次序来周游一棵二叉树，来得到中根序列、前根序列和后根序列。反过来，如果给定二叉树的中根序列和后根序列，或者给定中根序列和前根序列，可以重建一二叉树。本题输入一棵二叉树的中根序列和后根序列，要求在内存中重建二叉树，最后输出这棵二叉树的前根序列。 用不同的整数来唯一标识二叉树的每一个结点 中根序列是9 5 32 67 后根序列9 32 67 5 前根序列5 9 67 32 输入 两行。第一行是二叉树的中根序列，第二行是后根序列。每个数字表示的结点之间用空格隔开。结点数字范围0～65535。暂不必考虑不合理的输入数据。 输出 一行。由输入中的中根序列和后根序列重建的二叉树的前根序列。每个数字表示的结点之间用空格隔开。 样例输入 129 5 32 679 32 67 5 样例输出 15 9 67 32 关键在于利用通过后序找到每个子树的根节点，以此为界找到左、右子树，从而进行递归。 链式算法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;#define N 65536typedef struct node&#123; int data; struct node * lc,*rc;&#125;BitNode,*BitTree;int sLDR[N],sLRD[N];BitTree BuildTree(int coStart,int coEnd,int loStart, int loEnd)&#123; BitTree root = (BitTree)malloc(sizeof(BitNode)); root-&gt;data = sLRD[loEnd]; root-&gt;lc = NULL; root-&gt;rc = NULL; int i; if(coStart == coEnd) return root; for(i = 0;i &lt;= coEnd-coStart;i++)&#123; if(sLDR[coStart+i] == sLRD[loEnd]) break; &#125; if(i&gt;=1) root-&gt;lc = BuildTree(coStart,coStart+i-1,loStart,loStart+i-1); if(coEnd&gt;=coStart+i+1) root-&gt;rc = BuildTree(coStart+i+1,coEnd,loStart+i,loEnd-1); return root;&#125;int visit(BitTree T)&#123; printf(&quot;%d &quot;,T-&gt;data); return T-&gt;data;&#125;int PreTranverse(BitTree T)&#123; if(T)&#123; visit(T); if(T-&gt;lc) PreTranverse(T-&gt;lc); if(T-&gt;rc) PreTranverse(T-&gt;rc); &#125; return 1;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int s[N]; int order = 0; int ch; while((scanf(&quot;%d&quot;,&amp;ch))!=EOF)&#123; s[++order] = ch; &#125; for(int i = 1;i &lt;= order/2;i++) sLDR[i] = s[i]; for(int i = 1;i &lt;= order/2;i++) sLRD[i] = s[order/2+i]; BitTree root = BuildTree(1,order/2,1,order/2); PreTranverse(root); printf(&quot;\\n&quot;); return 0;&#125; 顺序算法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;#define N 65536typedef struct node&#123; int data; struct node * lc,*rc;&#125;BitNode,*BitTree;int sLDR[N],sLRD[N];int tree[N];void BuildTree(int coStart,int coEnd,int loStart, int loEnd,int k)&#123; //BitTree root = (BitTree)malloc(sizeof(BitNode)); tree[k] = sLRD[loEnd]; tree[2*k] = 0; tree[2*k+1] = 0; //root-&gt;lc = NULL; //root-&gt;rc = NULL; int i; if(coStart == coEnd) return ; for(i = 0;i &lt;= coEnd-coStart;i++)&#123; if(sLDR[coStart+i] == sLRD[loEnd]) break; &#125; if(i&gt;=1) BuildTree(coStart,coStart+i-1,loStart,loStart+i-1,2*k); if(coEnd&gt;=coStart+i+1) BuildTree(coStart+i+1,coEnd,loStart+i,loEnd-1,2*k+1); //return root;&#125;int visit(int i)&#123; printf(&quot;%d &quot;,tree[i]); return tree[i];&#125;int PreTranverse(int i)&#123; if(tree[i])&#123; visit(i); if(tree[2*i]) PreTranverse(2*i); if(tree[2*i+1]) PreTranverse(2*i+1); &#125; return 1;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int s[N]; int order = 0; int ch; while((scanf(&quot;%d&quot;,&amp;ch))!=EOF)&#123; s[++order] = ch; &#125; for(int i = 1;i &lt;= order/2;i++) sLDR[i] = s[i]; for(int i = 1;i &lt;= order/2;i++) sLRD[i] = s[order/2+i]; BuildTree(1,order/2,1,order/2,1); PreTranverse(1); printf(&quot;\\n&quot;); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://sean10.github.io/tags/二叉树/"}]},{"title":"二叉树——UVA122","slug":"二叉树——UVA122","date":"2015-11-22T11:23:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/22/二叉树——UVA122/","link":"","permalink":"https://sean10.github.io/2015/11/22/二叉树——UVA122/","excerpt":"","text":"二叉树的层次遍历 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;queue&gt;#include &lt;cstdio&gt;#include &lt;vector&gt;#include &lt;cstring&gt;using namespace std;struct Node&#123; bool have_value; int v; struct Node* left,*right; Node():have_value(false),left(NULL),right(NULL)&#123;&#125;&#125;;const int maxn = 256;bool failed;char s[10000];Node *root = NULL;Node* newnode()&#123; return new Node();&#125;void addnode(int v,char *s)&#123; int n = strlen(s); Node* u = root; for(int i = 0;i &lt;n;i++) if(s[i] == &apos;L&apos;)&#123; if(u-&gt;left == NULL) u-&gt;left = newnode(); u = u-&gt;left; &#125; else if(s[i] == &apos;R&apos;)&#123; if(u-&gt;right == NULL) u-&gt;right = newnode(); u = u-&gt;right; &#125; if(u-&gt;have_value) failed = true; u-&gt;v = v; u -&gt;have_value = true;&#125;bool bfs(vector&lt;int&gt;&amp; ans)&#123; queue&lt;Node*&gt; q; ans.clear(); q.push(root); while(!q.empty())&#123; Node * u = q.front(); q.pop(); if(!u-&gt;have_value) return false; ans.push_back(u-&gt;v); if(u-&gt;left != NULL) q.push(u-&gt;left); if(u-&gt;right != NULL) q.push(u-&gt;right); &#125; return true;&#125;bool read()&#123; failed = false; root = newnode(); for(;;)&#123; if(scanf(&quot;%s&quot;,&amp;s) != 1) return false; if(!strcmp(s,&quot;()&quot;)) break; int v; sscanf(&amp;s[1],&quot;%d&quot;,&amp;v); addnode(v,strchr(s,&apos;,&apos;)+1); &#125; return true;&#125;void remove_tree(Node *u)&#123; if(u == NULL) return ; remove_tree(u-&gt;left); remove_tree(u-&gt;right); delete u;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); char s[maxn]; while(1)&#123; if(!read()) break; vector&lt;int&gt;ans; if(!failed &amp;&amp; bfs(ans))&#123; int len = ans.size(); for(int i = 0;i &lt; len;i++) printf(&quot;%d%c&quot;,ans[i],i == len-1?&apos;\\n&apos;:&apos; &apos;); &#125;else printf(&quot;not complete\\n&quot;); &#125; remove_tree(root); return 0;&#125; 参考资料： [1].《算法竞赛入门经典（第二版）》 [2].http://blog.csdn.net/u014800748/article/details/44733017","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://sean10.github.io/tags/二叉树/"}]},{"title":"二叉树——UVA679","slug":"二叉树——UVA679","date":"2015-11-22T08:45:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/22/二叉树——UVA679/","link":"","permalink":"https://sean10.github.io/2015/11/22/二叉树——UVA679/","excerpt":"","text":"用二叉树来模拟的算法会TLE,只能找规律来过 画图会发现，当I为奇数时，都会掉到左子树去，偶数则右。然后判断一下何时到叶子节点就可以了 TLE的算法 12345678910111213141516171819202122232425262728#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;#include &lt;string.h&gt;#define N 1048577int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int n,x,y,li ; int a[N]; scanf(&quot;%d&quot;,&amp;n); while(~scanf(&quot;%d&quot;,&amp;x))&#123; int k; li = (1&lt;&lt;x) -1; if(x == -1) break; scanf(&quot;%d&quot;,&amp;y); for(int j = 1;j &lt;= li;j++) a[j] = 0; for(int j = 1;j &lt;= y;j++)&#123; for(k = 1;2*k &lt;= li;)&#123; a[k] = !a[k]; k = a[k]==0?(2*k+1):(2*k); &#125; &#125; printf(&quot;%d\\n&quot;,k); &#125; return 0;&#125; AC 12345678910111213141516171819202122232425262728#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cstdlib&gt;using namespace std;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int n,D,I; scanf(&quot;%d&quot;,&amp;n); while(~scanf(&quot;%d&quot;,&amp;D))&#123; int k = 1; if(D== -1) break; long long li = (1&lt;&lt;D)-1; scanf(&quot;%d&quot;,&amp;I); for(k = 1;k &lt;=li;)&#123; if(I%2)&#123; I=I/2+1; k*=2; &#125; else&#123; I=I/2; k=2*k+1; &#125; &#125; printf(&quot;%d\\n&quot;,k/2); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"二叉树","slug":"二叉树","permalink":"https://sean10.github.io/tags/二叉树/"}]},{"title":"线性表——约瑟夫问题（递推未完）","slug":"线性表——约瑟夫问题（递推未完）","date":"2015-11-22T05:43:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/22/线性表——约瑟夫问题（递推未完）/","link":"","permalink":"https://sean10.github.io/2015/11/22/线性表——约瑟夫问题（递推未完）/","excerpt":"","text":"题目链接 总时间限制: 1000ms 内存限制: 65536kB 描述 有n只猴子，按顺时针方向围成一圈选大王（编号从1到n），从第1号开始报数，一直数到m，数到m的猴子退出圈外，剩下的猴子再接着从1开始报数。就这样，直到圈内只剩下一只猴子时，这个猴子就是猴王，编程求输入n，m后，输出最后猴王的编号。 输入 输入包含两个整数，第一个是n，第二个是m (0 &lt; m,n &lt;=300)。 输出 输出包含一行，即最后猴王的编号。 样例输入 112 4 样例输出 11 这道题是有好几种解法的。 首先是数组。 1.链表模拟 分析：建立一个循环链表，递推，一个个删除直到只剩下一个，输出即可。 2.静态链表模拟 分析：用数组模拟链表，就是数组里存的是下一个位置的下标。 以上两种的时间复杂度均为O(n*m); 3.数组模拟 分析：先初始化整个数组为1，接下来在循环中只对数值为1的进行计数，满n置0，最后遍历最后一个数值为1的数，输出其下标。 这种的时间复杂度最大，为O(n^2); 4.递推算法 待考试周过去后写 1.链表遍历算法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define N 10000typedef struct node&#123; int data; struct node* next;&#125;node,*nodePtr;void Create(nodePtr head, int n )&#123; nodePtr temp, last = head; for(int i = 1;i &lt;= n;i++)&#123; temp = (nodePtr)calloc(1,sizeof(node)); if(temp == NULL) return ; temp -&gt; data = i; last -&gt; next = temp; //printf(&quot;%p\\t%p\\t%p\\t%p\\n&quot;,NULL,head,last,last-&gt;next); last = temp; //printf(&quot;%d\\n&quot;,last-&gt;data); &#125; last -&gt; next = head -&gt; next; //printf(&quot;%p\\t%p\\t%p\\t%p\\n&quot;,NULL,head,last,last-&gt;next);&#125;void Del(nodePtr prev, nodePtr &amp;curr)&#123; nodePtr temp = curr; prev-&gt;next = curr -&gt; next; curr = prev; free(temp);&#125;nodePtr Josephus(nodePtr head,int m)&#123; nodePtr temp = head,prev = NULL; while(head-&gt;next != head)&#123; for(int i = 0;i &lt; m;i++)&#123; prev = head; head = head -&gt; next; //printf(&quot;%p\\t%p\\n&quot;,prev,head); &#125; //printf(&quot;%d\\n&quot;,head-&gt;data); Del(prev,head); &#125; free(temp); return head;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int n,m; while(~scanf(&quot;%d%d&quot;,&amp;n,&amp;m))&#123; nodePtr head = NULL; head = (nodePtr)malloc(sizeof(node)); head -&gt; next = NULL; Create(head, n); printf(&quot;%d\\n&quot;,Josephus(head,m)-&gt;data); &#125; return 0;&#125; 2.静态链表算法 123456789101112131415161718192021222324252627#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define N 10000int main()&#123; int a[N]; int n,m; scanf(&quot;%d%d&quot;,&amp;n,&amp;m); for(int i = 0;i &lt; n;i++)&#123; a[i] = i+1; &#125; a[n] = 1; int k = 0; int prev; while(a[k] != k)&#123; for(int i = 1;i &lt;= m;i++)&#123; prev = k; k = a[k]; &#125; a[prev] = a[k]; &#125; printf(&quot;%d\\n&quot;,k); return 0;&#125; 3.数组模拟算法 1234567891011121314151617181920212223242526272829303132333435#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define N 350int main()&#123; int n,m; scanf(&quot;%d%d&quot;,&amp;n,&amp;m); int a[N]; int cnt = 0; int times = 0; for(int i = 1;i &lt;= n;i++) a[i] = 1; int i = 1; while(times!=n-1)&#123; while(1)&#123; if(a[i++] == 1)&#123; cnt++; if(cnt &gt; 0 &amp;&amp; cnt%m == 0) break; &#125; if(i &gt; n) i = i%n; &#125; a[i-1] = 0; if(i &gt; n) i = i%n; times++; &#125; for(i = 1;i&lt;=n;i++) if(a[i] == 1) break; printf(&quot;%d\\n&quot;,i); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"线性表","slug":"线性表","permalink":"https://sean10.github.io/tags/线性表/"}]},{"title":"栈——HDU1022","slug":"栈——HDU1022","date":"2015-11-19T02:37:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/19/栈——HDU1022/","link":"","permalink":"https://sean10.github.io/2015/11/19/栈——HDU1022/","excerpt":"","text":"题目是栈的模拟进出。 先用数组来模拟一下栈的指针移动。 12345678910111213141516171819202122232425262728293031323334#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); int a[1000]; char c[1000]; char s1[1000],s2[1000]; int n; //scanf(&quot;%d&quot;,&amp;n); while(scanf(&quot;%d %s%s&quot;,&amp;n,s1,s2)!=EOF)&#123; int m = 0,j = 0,k = 0; for(int i = 0; i &lt; n;i++)&#123; a[j++] = 1; c[k++] = s1[i]; while(c[k-1] == s2[m]&amp;&amp; k &gt;= 0)&#123; a[j++] = -1; m++; k--; &#125; &#125; if(k &lt;= 0)&#123; printf(&quot;Yes.\\n&quot;); for(int i = 0;i &lt; j;i++)&#123; if(a[i] == 1) printf(&quot;in\\n&quot;); else if(a[i] == -1) printf(&quot;out\\n&quot;); &#125; &#125;else printf(&quot;No.\\n&quot;); printf(&quot;FINISH\\n&quot;); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"栈","slug":"栈","permalink":"https://sean10.github.io/tags/栈/"}]},{"title":"栈——出栈序列统计","slug":"栈——出栈序列统计","date":"2015-11-18T06:36:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/18/栈——出栈序列统计/","link":"","permalink":"https://sean10.github.io/2015/11/18/栈——出栈序列统计/","excerpt":"","text":"题目链接 总时间限制: 100ms 内存限制: 64kB 描述 栈是常用的一种数据结构，有n个元素在栈顶端一侧等待进栈，栈顶端另一侧是出栈序列。你已经知道栈的操作有两种：push和pop，前者是将一个元素进栈，后者是将栈顶元素弹出。现在要使用这两种操作，由一个操作序列可以得到一系列的输出序列。请你编程求出对于给定的n，计算并输出由操作数序列1，2，…，n，经过一系列操作可能得到的输出序列总数。 输入 就一个数n(1≤n≤15)。 输出 一个数，即可能输出序列的总数目。 样例输入 13 样例输出 15 提示 先了解栈的两种基本操作，进栈push就是将元素放入栈顶，栈顶指针上移一位，等待进栈队列也上移一位，出栈pop是将栈顶元素弹出，同时栈顶指针下移一位。 用一个过程采模拟进出栈的过程，可以通过循环加递归来实现回溯：重复这样的过程，如果可以进栈则进一个元素，如果可以出栈则出一个元素。就这样一个一个地试探下去，当出栈元素个数达到n时就计数一次(这也是递归调用结束的条件)。 这道题一开始想到的就是出栈序列公式，即catalan数公式，不过传统的公式中间数过大，在12的时候就爆了。 网上搜了一下，用了代码里的那个公式。 123456789101112#include&lt;cstdio&gt;using namespace std;int main()&#123; int n, a = 1; scanf(&quot;%d&quot;, &amp;n); for(int i=2; i&lt;=n; i++) a = (4 * i - 2) * a / (i + 1); printf(&quot;%d\\n&quot;, a); return 0;&#125; 下面还有一种用递归模拟进出栈的 1234567891011121314151617181920#include &lt;cstdio&gt;int num = 0;int n;void Stack(int inWait,int outWait,int outs)&#123; if(n == outs)&#123; num++; return ; &#125; if(inWait &gt; 0) Stack(inWait-1,outWait+1,outs); if(outWait &gt; 0) Stack(inWait,outWait-1,outs+1);&#125;int main()&#123; scanf(&quot;%d&quot;,&amp;n); Stack(n, 0, 0); printf(&quot;%d\\n&quot;,num); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"栈","slug":"栈","permalink":"https://sean10.github.io/tags/栈/"}]},{"title":"栈——密码翻译","slug":"栈——密码翻译","date":"2015-11-18T04:43:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/18/栈——密码翻译/","link":"","permalink":"https://sean10.github.io/2015/11/18/栈——密码翻译/","excerpt":"","text":"题目链接 总时间限制: 1000ms 内存限制: 65536kB 描述 在情报传递过程中，为了防止情报被截获，往往需要对情报用一定的方式加密，简单的加密算法虽然不足以完全避免情报被破译，但仍然能防止情报被轻易的识别。我们给出一种最简的的加密方法，对给定的一个字符串，把其中从a-y,A-Y的字母用其后继字母替代，把z和Z用a和A替代，则可得到一个简单的加密字符串。 输入 第一行是字符串的数目n。 其余n行每行一个字符串。 输出 输出每行字符串的加密字符串。 样例输入 121Hello! How are you! 样例输出 1Ifmmp! Ipx bsf zpv! 最近重新开始练算法了，好多基础用法都忘了，现在重新熟悉一下，先从OpenJudge做起。 这道题严格意义上应该题目叫简单凯撒密码翻译。题目理解很简单，不过对于scanf的用法需要注意，在%s格式时，遇到空格就会结束输入，这里可以用gets()和scanf(“%[^\\n]”,h)来解决这个问题。 123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); char h[1000]; int n; scanf(&quot; %d&quot;,&amp;n); getchar(); for(int k = 0;k &lt; n;k++)&#123; //getchar(); gets(h); //printf(&quot;%s\\n&quot;,h); int len=strlen(h); for(int i = 0;i &lt; len;i++)&#123; if((h[i] &gt;= &apos;a&apos; &amp;&amp; h[i] &lt; &apos;z&apos;) ||( h[i] &gt;= &apos;A&apos; &amp;&amp; h[i] &lt; &apos;Z&apos;))&#123; h[i]+=1; &#125; else if(h[i] == &apos;z&apos;)&#123; h[i] = &apos;a&apos;; &#125; else if(h[i] == &apos;Z&apos;)&#123; h[i] = &apos;A&apos;; &#125; &#125; printf(&quot;%s\\n&quot;,h); &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"栈","slug":"栈","permalink":"https://sean10.github.io/tags/栈/"}]},{"title":"关于Warshall、Roy对寻找传递闭包方法的不同表达的探讨","slug":"关于Warshall、Roy对寻找传递闭包方法的不同表达的探讨","date":"2015-11-17T11:23:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/17/关于Warshall、Roy对寻找传递闭包方法的不同表达的探讨/","link":"","permalink":"https://sean10.github.io/2015/11/17/关于Warshall、Roy对寻找传递闭包方法的不同表达的探讨/","excerpt":"","text":"一、引言 在计算机科学中，Floyd-Warshell-Roy算法是用于在有向图或负权图中寻找最短路径的一种算法。运行一次能够找到所有两个顶点间的最短路径，不过并不输出所有路径。该算法同时也可以被用于寻找关系R的传递闭包。 Floyd-Warshell算法是一个动态规划的例子，在1962年为Robert Floyd发表。然而，在1959年，相同的算法已经被Bernard Roy发表。同年，Stephen Warshell发表了找到传递闭包的这个算法。三人被认定为独立发现这个算法。 该算法的主要作用是将常规算法的时间复杂度由Θ(n4)降低到了Θ(n3). 本文中，我们出于寻找Roy、Warshall的算法被认定为独立发现的的缘由对两人的算法进行分析。 二、分析与讨论 1. Warshall 算法 1234567procedure Warshall (MR : n × n zero–one matrix)W : = MRfor k : = 1 to n for i : = 1 to n for j : = 1 to n w_ij : = w_ij ∨ (w_ik)∧ w_kj )return W&#123;W = [w_ij] is MR∗&#125; essay_ essay_ essay 三、结论 虽然Bernard Roy 提出该算法在Robert Floyd和Stephen Warshall之前，但他论文的主体依旧是以对图的定义为主，而Warshall 和Floyd两人同年发表了成文的简单算法。所以，可能这是一部分影响单独发表的原因。 四、展望 根据[1]，我们知道了Roy的传递闭包计算方法是采用了Kleene已经提出了的深层技术，而Warshall和Floyd则是采用了第三个参数。不过基于时间以及水平原因，并没有能够找到这两者之间所说的深层技术，也并没能确定是否Warshall和Floyd所采用的关键技术是在于中间点k。因而，可以沿这个方向继续接下去进行查询发掘。 五、参考文献 [1]. Jeff Erickson, Kleene-Roy-Floyd-Warshall. [https://courses.engr.illinois.edu/cs498dl1/sp2015/notes/22-apsp.pdf] [2]. Warshall, Stephen (January 1962). “A theorem on Boolean matrices”. Journal of the ACM 9 (1): 11–12. doi:10.1145/321105.321107 . [3]. Roy, B. “Transitivité et connexité.” C. R. Acad. Sci. Paris 249, 216-218, 1959. [http://gallica.bnf.fr/ark:/12148/bpt6k3201c] [4]. Bouyssou, D., Jacquet-Lagrèze, E., Perny, P., Slowiński, R., Vanderpooten, D., Vincke, P,《Aiding Decisions with Multiple Criteria: Essays in Honor of Bernard Roy》,24,2001. [5]. Wikipedia. [https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm] [6]. Purdom, Paul, Jr. “A Transitive Closure Algorithm.” Bit 10, no. 1 (March 1970): 76–94. doi:10.1007/BF01940892.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/离散数学/"}]},{"title":"离散数学——hamming码最小距离","slug":"离散数学——hamming码最小距离","date":"2015-11-14T16:12:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/15/离散数学——hamming码最小距离/","link":"","permalink":"https://sean10.github.io/2015/11/15/离散数学——hamming码最小距离/","excerpt":"","text":"1：给定H(读取文件方式，第一行两个整数m,n，第二行 m(n-m)个0或1，也就是矩阵H的上半部分，下半部单位矩阵自行生成)，计算群码编码函数e_H。计算该编码函数能检测到多少位错误，交互输出字的码字。 输入文件：in.txt，示例：第一行两个整数，第二行累计mxr个整数。所有整数都用一个空格分隔。 3 5 1 0 1 0 0 1 无输出文件。 2：针对(8,12)编码e，找出最小距离最大的群码编码函数，输出H及最小距离。 无输入文件 输出文件：out.txt，示例，矩阵按行输出 1 1 0 0 0 0 1 0 …. 0 1 0 1 (以上总共256行，此行为说明，程序不输出) H的最小距离是：3 以下是代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;int int_pow(int x,int e)&#123; int ans = 1; while(e--) ans*=x; return ans;&#125;void GetBinary(int* mb,int m, int i)&#123; for(int j = m;j &gt;= 1;j--)&#123; mb[j] = i%2; i/=2; &#125;&#125;void CntBinary(int *mb, int n ,int &amp;min)&#123; int cnt = 0; for(int i = 1;i &lt;= n;i++)&#123; if(mb[i] == 1) cnt++; &#125; if(cnt &lt; min) min = cnt;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); FILE *fp = fopen(&quot;in.txt&quot;,&quot;r&quot;); if(fp == NULL) printf(&quot;ERROR OPEN.\\n&quot;); int m,n; int ma[100][100]; fscanf(fp,&quot; %d %d&quot;,&amp;m,&amp;n); for(int i = 1;i &lt;= m;i++)&#123;//行列互换 for(int j = 1;j &lt;= n-m;j++)&#123; fscanf(fp,&quot; %d&quot;,&amp;ma[i][j]); &#125; &#125; /* for(int i = 1;i &lt;= m;i++)&#123; for(int j = 1;j &lt;= n-m;j++) printf(&quot;%d&quot;,ma[i][j]); printf(&quot;\\n&quot;); &#125; */ int mb[100]; int mc[100]; int min = m; for(int i = 1;i &lt; int_pow(2,m);i++)&#123; GetBinary(mb,m,i); for(int j = m+1;j &lt;= n;j++) mc[j] = 0; for(int j = 1;j &lt;= m;j++) mc[j]=mb[j]; for(int j = m+1;j &lt;= n;j++)&#123; for(int k = 1;k &lt;= m;k++)&#123; mc[j] += mb[k]*ma[k][j-m]; &#125; mc[j] %= 2; &#125; CntBinary(mc,n,min); &#125; printf(&quot;The minimum hamming distance is:%d\\n&quot;,min); for(int i = 1;i &lt;= m;i++) scanf(&quot; %d&quot;,&amp;mb[i]); for(int i = 0;i &lt;= n;i++) mc[i] = 0; for(int i = 1;i &lt;= m;i++) mc[i]=mb[i]; for(int i = m+1;i &lt;= n;i++)&#123; for(int j = 1;j &lt;= m;j++)&#123; mc[i] += mb[j]*ma[j][i-m]; &#125; mc[i] %= 2; &#125; printf(&quot;The code word is:&quot;); for(int i = 1;i &lt;= n;i++) printf(&quot;%d&quot;,mc[i]); printf(&quot;\\n&quot;); return 0;&#125; 第二题这里，依照以下定理自己手算奇偶校验矩阵就比较简单了，最小距离最大的充要条件是奇偶校验矩阵任意两行线性无关。 定理是(n,k)线性分组码的最小Hamming距离为d的充要条件是，H矩阵中任意d-1列线性无关。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#define N 256int int_pow(int x,int e)&#123; int ans = 1; while(e--) ans*=x; return ans;&#125;void GetBinary(int* mb,int m, int i)&#123; for(int j = m;j &gt;= 1;j--)&#123; mb[j] = i%2; i/=2; &#125;&#125;void CntBinary(int *mb, int m ,int &amp;min)&#123; int cnt = 0; for(int i = 1;i &lt;= m;i++)&#123; if(mb[i] == 1) cnt++; &#125; if(cnt &lt; min) min = cnt;&#125;int main()&#123; FILE *fp=fopen(&quot;out.txt&quot;,&quot;w&quot;); int m = 8,n = 12; int ma[N][5]=&#123;&#123;0,0,0,0,0&#125;, &#123;0,1,1,0,0&#125;, &#123;0,0,1,1,0&#125;, &#123;0,1,1,0,1&#125;, &#123;0,1,1,1,0&#125;, &#123;0,1,0,0,1&#125;, &#123;0,0,1,0,1&#125;, &#123;0,1,0,1,0&#125;, &#123;0,0,0,1,1&#125;&#125;; /* for(int i = 0;i &lt; 8;i++)&#123; for(int j = 0;j &lt; 4;j++)&#123; printf(&quot;%d&quot;,H[i][j]); &#125; printf(&quot;\\n&quot;); &#125; */ int mb[N]; int mc[N]; int min = m; for(int i = 1;i &lt; int_pow(2,m);i++)&#123; GetBinary(mb,m,i); for(int j = m+1;j &lt;= n;j++) mc[j] = 0; for(int j = 1;j &lt;= m;j++) mc[j]=mb[j]; for(int j = m+1;j &lt;= n;j++)&#123; for(int k = 1;k &lt;= m;k++)&#123; mc[j] += mb[k]*ma[k][j-m]; &#125; mc[j] %= 2; &#125; for(int j = m+1;j &lt;= n;j++) fprintf(fp,&quot;%d\\t&quot;,mc[j]); fprintf(fp,&quot;\\n&quot;); CntBinary(mc,n,min); &#125; fprintf(fp,&quot;The maximum of all the minimum distance is:%d\\n&quot;,min); return 0;&#125;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/离散数学/"},{"name":"校验码","slug":"校验码","permalink":"https://sean10.github.io/tags/校验码/"}]},{"title":"十二年小说、游戏杂忆","slug":"十二年小说、游戏杂忆","date":"2015-11-13T16:24:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/14/十二年小说、游戏杂忆/","link":"","permalink":"https://sean10.github.io/2015/11/14/十二年小说、游戏杂忆/","excerpt":"","text":"##十二年小说、游戏杂忆 还留有印象的小说，应该是预备班时看的了。那时，似乎是刚尝试用电脑看小说，那个时候看的第一本书应该是心梦无痕的《七界传说》。现在脑海里还留有一个印象，那时相当懵懂的我看到里面男主和女主的交流就很害羞，快速跳过。现在想来，那个时代的我们还真是单纯。现在再看，这类的文字过眼即忘了。 虽说印象里只剩下初中看的书了，不过小学的时候去图书馆也很频繁，那个时候记得一天差不多要去图书馆3、4次，除了图书管理员的任务之外，经常去借各种各样的书。印象里还有一本翻了整整一系列，当时最后好像也没看懂的小说《头重脚轻》。 虽然当时的图书馆拥有的书量相比现在去的图书馆数百乃至数千个书架不能比，记得图书馆只有8个书架，不过对于小时候的我来说足够看很久了。印象最深的就是有一个月因为上课也在偷偷的看书，一天要去借好几次，一次3本，最终月借书量达到了红色警戒线（150左右吧）。（貌似也因为这个，学校的大队长第一次和我聊了会，印象颇深呢！） 很可惜初中虽然图书库存不少，不过对于学生的开放实在是不人性。图书室开放时间只有工作日的中午20分钟，加上初中很注重抓紧中午时间上课讲题，也就不再有机会去图书馆了。也就在那个时候，似乎网络游戏开始流行了，原本那时看书似乎就只是为了打磨时间，作为一种休闲，自然游戏在初中替代了我心目中书的地位。 印象里，在小学的时候在同学的带领下玩过一段时间的QQ幻想，不过因为点卡要收费，也没玩多久。 初中看不了纸质书以后，有空就在电脑上看小说。一次看小说时，一个游戏的广告始终停留在页首，然后就去玩了《昆仑世界》（那个时候还叫《昆仑》），似乎玩了整整一两年，最后还是被迫离开（因为注册时还没有验证邮箱、验证密保之说，最后账号密码被人修改，无法找回）。 因为游戏数年的努力都化成飞灰，无心重头再来，毕竟所在服务器大家也都是养老休闲的了。大家都是熟人了。没什么新颖的花样了。我便转投了同平台的《三国风云》，同样持续了一年多的样子。这次的离开是因为玩了好多个新区了，对于游戏模式摸得比较清楚了，对RMB的作用无力了之后离开的。 最后一个网页策略游戏，是腾讯的七雄争霸了。之前的游戏里因为可接触游戏的工作时间只有周末，经常被同期的人甩开很多，时间和RMB都不如其他人，自然毫无竞争力。在这个游戏里，因为支持手机网页登陆进行操作，我似乎一直坚持玩到了高一。最后的战绩也还算是不错的，进入了同服务器的次强的联盟。那个时候早上玩一次，晚上玩一次，投入的时间毕竟不少。 在玩网页游戏的过程中也去接触了不少腾讯的客户端游戏（因为懒，熟悉的平台的游戏最方便了），DNF。现在想来，自己的游戏经历还真是挺丰富的，可惜唯一真正投入去研究发展攻略、甚至写过游戏攻略的只有第一、第二个网页游戏了。后面就没有用过心了。 回到书，初中因为硬性条件的不支持，加上外界的吸引，就远离了书。而电子书（那时不懂有pdf扫描本，主要看的就是网络小说），接触的倒也不能算是多。 严格来说，接触最多的时间应该是高中的时候了，那个时候似乎智能手机渐渐开始普及，在移动终端上看小说的网页阅读器似乎也被完成了。我就在手机上看了各式各样的网络小说。当时起点、红袖添香等小说网站的排行榜、完本小说榜等等数十页目录喜欢的都被刷尽了。 不过，这些小说的内容都极其雷同。即便是现在的小说的内容，其实和3、4年前也完全没有什么成长。唯一的变化恐怕就是内容的细节变得更加丰满了吧，添加了越来越多的设定。比如，宿敌的猪队友呀，高智商的宿敌呀。 因为剧情比较简单，内容之间唯一的衔接也就是时间和地点了。并没有太多的伏笔。 当时看的比较多的是玄幻、奇幻、游戏之类的小说。玄幻、奇幻这两本小说的基本内容都是升级练功、扮猪吃虎、男主智商最高呀之类的。从正常的小说的角度来说，围绕着主角来描写内容，剧情主线这样发展是无可厚非的。 我看过的三少、西红柿、辰东等人的书都是这般。现在想来，这些小说并没有太多的泪点，对自己可以说是一点经验都没有收获了。 那个时候，无人引领，在庞杂的书海中肆意，丢失的时间实在是太多了。 话虽如此，现在依旧偶尔会在做自己的事的时候刷一下同人小说。 小说仿佛一股瘾，开始了便停不下来。 尤其，我还挺喜欢看动漫的，现在看动漫同人小说，好多都能满足我希望在原作中看到的剧情（顺带一提，因为我看到喜欢的动漫，剧情不全的话，基本我都会去看他的轻小说本，没有轻小说就去看看漫画本）。也有不少动漫是游戏改编的，没有时间去体验游戏，便藉由其他专业的宅的小说中体会剧情了。 基于这样的原因下，我恐怕也只能克制一下阅读的频率和时间，把重心放在学习上了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"小记","slug":"小记","permalink":"https://sean10.github.io/tags/小记/"}]},{"title":"数据结构之稀疏矩阵——稀疏矩阵加法和乘法","slug":"数据结构之稀疏矩阵——稀疏矩阵加法和乘法","date":"2015-11-11T14:47:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/11/数据结构之稀疏矩阵——稀疏矩阵加法和乘法/","link":"","permalink":"https://sean10.github.io/2015/11/11/数据结构之稀疏矩阵——稀疏矩阵加法和乘法/","excerpt":"","text":"题目：假设稀疏矩阵A和B均以三元组表作为存储结构，试写出矩阵相加和相乘的算法，另设三元组表C存放结果矩阵。 要求： 从键盘输入稀疏矩阵A和B 检测A和B能否相加/相乘 如能，做矩阵相加和相乘运算，并打印运算结果 如不能，应显示出原因 这里主要就是三元组的运用，比较基础，详情见代码中的注释。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define OK 1 //函数结果状态#define ERROR 0#define MAX 100typedef int Status;//函数结果状态类型typedef struct&#123; int i,j; //三元组的行号、列号； int e; //三元组的值;&#125;Triple;typedef struct&#123; Triple data[MAX];//非零元三元组表示 int rpos[MAX]; //稀疏矩阵三元组各行起始坐标 int mu,nu,tu; //矩阵的行数、列数和非零元个数&#125;Matrix;void Input(Matrix *M,Matrix *N);Status CreateMatrix(Matrix *M);Status PrintMatrix(Matrix M);Status PlusMatrix(Matrix M, Matrix N, Matrix *D);Status MultMatrix(Matrix M, Matrix N, Matrix *Q);int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); //freopen(&quot;output.txt&quot;,&quot;w&quot;,stdout); Matrix M,N,D,Q; Input(&amp;M,&amp;N); if(!PlusMatrix(M,N,&amp;D)) printf(&quot;They cannot be added.\\n&quot;); if(!MultMatrix(M,N,&amp;Q)) printf(&quot;They cannot be multiplied.\\n&quot;); return 0;&#125;void Input(Matrix *M,Matrix *N)&#123; printf(&quot;Please input the rows and cols and number of the nonzero element:&quot;); if(!CreateMatrix(M)) printf(&quot;Error Create M!\\n&quot;); PrintMatrix(*M); printf(&quot;Please input the rows and cols and number of the nonzero element:&quot;); if(!CreateMatrix(N)) printf(&quot;Error Create N!\\n&quot;); PrintMatrix(*N);&#125;Status CreateMatrix(Matrix *M)&#123;//创建稀疏矩阵，采取三元组存储 int num[MAX]=&#123;0&#125;; //对应行非零元个数 int flag[MAX][MAX]=&#123;0&#125;;//标记对应位置是否已有非零元 int i,j,e; //非零元三元组的临时存储变量 scanf(&quot; %d%d%d&quot;,&amp;M-&gt;mu,&amp;M-&gt;nu,&amp;M-&gt;tu); while(M-&gt;mu &lt; 0 || M-&gt;nu &lt; 0 || M-&gt;tu &gt; M-&gt;mu * M-&gt;nu)&#123;//判断矩阵行数、列数和非零元个数是否合法 printf(&quot;The rows,cols and number of nonzero element is out of normal range!!\\n&quot;); printf(&quot;Please input again:&quot;); scanf(&quot; %d%d%d&quot;,&amp;M-&gt;mu,&amp;M-&gt;nu,&amp;M-&gt;tu); &#125; if(!M-&gt;tu) return OK;//全部为零元素，直接返回 for(int k = 1;k &lt;= M-&gt;tu;k++)&#123;//输入非零元 printf(&quot;Please input the row,col,and data of element:&quot;); scanf(&quot; %d%d%d&quot;,&amp;i,&amp;j,&amp;e); while(i &lt;= 0 || i &gt; M-&gt;mu || j &lt;= 0 || j &gt; M-&gt;nu)&#123;//判断输入非零元行号、列号合法 printf(&quot;The row,col and data of element is out of normal range!!\\n&quot;); printf(&quot;Please input again:&quot;); scanf(&quot; %d%d%d&quot;,&amp;i,&amp;j,&amp;e); &#125; while(!e)&#123;//判断是否非零元 printf(&quot;Zero element occurs!\\n&quot;); scanf(&quot; %d&quot;,&amp;e); &#125; if(!flag[i][j])&#123;//判断该位置是否已有非零元 flag[i][j] = 1; &#125; else&#123; printf(&quot;Here exists!\\n&quot;); continue; &#125; int l,m; //寻找该三元组的位置 if(k==1)&#123; M-&gt;data[k].i = i; M-&gt;data[k].j = j; M-&gt;data[k].e = e; continue; &#125; for(l = 1;l &lt; k &amp;&amp; (i &gt; M-&gt;data[l].i || (i == M-&gt;data[l].i &amp;&amp; j &gt; M-&gt;data[l].j));l++); for(m = k-1;m &gt;= l;m--)&#123;//依次向后移动 M-&gt;data[m+1] = M-&gt;data[m]; //printf(&quot;%d\\n&quot;,M-&gt;data[m+1].i); &#125; //保存数据 M-&gt;data[l].i = i; M-&gt;data[l].j = j; M-&gt;data[l].e = e; //printf(&quot;%d\\t%d\\t%d&quot;,M-&gt;data[k].i,M-&gt;data[k].j,M-&gt;data[k].e); //printf(&quot;%d\\n&quot;,k); &#125; //求各行非零元起始位置 if(M-&gt;tu)&#123;//判断非零元个数是否为0 for(int m = 1;m &lt;= M-&gt;tu;m++) ++num[M-&gt;data[m].i];//求M中每行非零元素个数 M-&gt;rpos[1] = 1;//起始位置赋值 for(int m = 2;m &lt;= M-&gt;tu;m++) M-&gt;rpos[m] = M-&gt;rpos[m-1] + num[m-1]; &#125; return OK;&#125;Status PlusMatrix(Matrix M, Matrix N, Matrix *D)&#123;//求稀疏矩阵的和Q=M+N if(M.mu != N.mu || M.nu != N.nu)//检查稀疏矩阵M和N的行数和列数是否对应相等 return ERROR; int i = 1,j = 1,k = 1;//各矩阵三元组移动临时变量 D-&gt;mu = M.mu; D-&gt;nu = M.nu; D-&gt;tu = 0; if(M.tu*N.tu == 0)//零矩阵，直接返回 return OK; while(i &lt;= M.tu &amp;&amp; j &lt;= N.tu)&#123;//M和N均不为空 if(M.data[i].i &lt; N.data[j].i || (M.data[i].i == N.data[j].i &amp;&amp; M.data[i].j &lt; N.data[j].j))&#123;//以行为主序，M中的节点在N前 D-&gt;tu++; D-&gt;data[k++] = M.data[i++];//结构体赋值 &#125; else if(M.data[i].i == N.data[j].i &amp;&amp; M.data[i].j == N.data[j].j)&#123;//M和N节点对应 if(M.data[i].e+N.data[j].e)&#123;//M和N相加之和不为0 D-&gt;data[k].i=M.data[i].i; D-&gt;data[k].j=M.data[i].j; D-&gt;data[k++].e=M.data[i].e+N.data[j].e; D-&gt;tu++; //printf(&quot;%d\\n&quot;,D-&gt;data[k-1].e); &#125; i++; j++; &#125; else if(M.data[i].i &gt; N.data[j].i ||(M.data[i].i == N.data[j].i &amp;&amp; M.data[i].j &gt; N.data[j].j))&#123;//N节点在M前 D-&gt;tu++; D-&gt;data[k++] = N.data[j++]; &#125; &#125; while(i &lt;= M.tu)&#123;//将矩阵N的剩余元素插入矩阵 D-&gt;tu++; D-&gt;data[k++] = M.data[i++]; &#125; while(j &lt;= N.tu)&#123;//将矩阵M的剩余元素插入矩阵 D-&gt;tu++; D-&gt;data[k++] = N.data[j++]; &#125; //printf(&quot;%d\\n&quot;,k); printf(&quot;Matrix A plus Matrix B is D:\\n&quot;); PrintMatrix(*D); return OK;&#125;Status MultMatrix(Matrix M, Matrix N, Matrix *Q)&#123;//进行矩阵M和N相乘 int arow,brow,ccol,ctemp[MAX]; int p,q,tp,i,t;//p,q,i为中间变量；tp,t分别为M的各行位置上限 if(M.nu != N.mu)//判断M的列数和N的行数是否相等 return ERROR; Q-&gt;mu = M.mu; Q-&gt;nu = N.nu; Q-&gt;tu = 0; if(M.tu*N.tu == 0)//判断矩阵是否为非零矩阵 return OK; for(arow = 1;arow &lt;= M.mu;arow++)&#123;//处理M的每一行 for(i = 1;i &lt;= N.nu;i++)//元素累加清零 ctemp[i] = 0; Q-&gt;rpos[arow] = Q-&gt;tu+1;//起始坐标赋值 if(arow &lt; M.mu)//找到该行移动次数上限 tp = M.rpos[arow+1]; else tp = M.tu+1; for(p = M.rpos[arow];p &lt; tp;p++)&#123;//求Q中第arow行的非零元 brow = M.data[p].j; if(brow &lt; N.mu)//找到N中该行移动次数上限 t = N.rpos[brow+1]; else t = N.tu+1; for(q = N.rpos[brow];q &lt; t;q++)&#123; ccol = N.data[q].j;//成绩元素在N中列号 ctemp[ccol] += M.data[p].e * N.data[q].e; &#125; &#125; for(ccol = 1;ccol &lt;= Q-&gt;nu;ccol++)&#123;//存储非零元 if(ctemp[ccol])&#123; Q-&gt;tu++; Q-&gt;data[Q-&gt;tu].i = arow; Q-&gt;data[Q-&gt;tu].j = ccol; Q-&gt;data[Q-&gt;tu].e = ctemp[ccol]; &#125; &#125; &#125; printf(&quot;Matrix A multiply Matrix B is Q:\\n&quot;); PrintMatrix(*Q); return OK;&#125;Status PrintMatrix(Matrix M)&#123;//打印矩阵 int i,j,k = 1;//临时中间变量 printf(&quot;The matrix is:\\n&quot;); for(i = 1;i &lt;= M.mu;i++)&#123;//遍历矩阵 for(j = 1;j &lt;= M.nu;j++)&#123; if(i == M.data[k].i &amp;&amp; j == M.data[k].j)&#123;//存在三元组匹配，输出 printf(&quot;%d\\t&quot;,M.data[k].e); k++; &#125; else printf(&quot;0\\t&quot;); &#125; printf(&quot;\\n&quot;); &#125; printf(&quot;The matrix has %d rows, %d cols ,and %d nonzero elements.\\n&quot;,M.mu ,M.nu, M.tu); return OK;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://sean10.github.io/tags/数据结构/"}]},{"title":"数据结构之链表——加里森的任务（循环链表）","slug":"数据结构之链表——加里森的任务（循环链表）","date":"2015-11-11T09:45:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/11/数据结构之链表——加里森的任务（循环链表）/","link":"","permalink":"https://sean10.github.io/2015/11/11/数据结构之链表——加里森的任务（循环链表）/","excerpt":"","text":"题目：加里森的任务 有n个加里森敢死队的队员要炸掉敌人的一个军火库，谁都不想去，队长加里森决定用轮回数数的办法来决定哪个战士去执行任务。规则如下：如果前一个战士没完成任务，则要再派一个战士上去。现给每个战士编一个号，大家围坐成一圈，随便从某一个编号为x的战士开始计数，当数到y时，对应的战士就去执行任务，且此战士不再参加下一轮计数。如果此战士没完成任务，再从下一个战士开始数数，被数到第y时，此战士接着去执行任务。以此类推，直到任务完成为止。 加里森本人是不愿意去的，假设加里森为1号，请你设计一程序为加里森支招，求出n,x,y满足何种条件时,加里森能留到最后而不用去执行任务;。 要求： 主要数据结构采用链式结构存储。 自拟1个实验实例验证程序正确性（即：n,x,y自拟）。 循环链表的运用，最常见的一种，时间复杂度是O(n^3). 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879//#include &quot;stdafx.h&quot;#include &lt;iostream&gt;#include &lt;cstdio&gt;#include &lt;cstdlib&gt;using namespace std;typedef struct node&#123; //加里森队员链表结构 int data; struct node* next;&#125;Linknode, *Link;Link ListCreate(int n)&#123; Link head = NULL, curr = NULL, last = NULL; while (n)&#123; //对n个成员进行创建链表并编号 head = (Link)calloc(1, sizeof(Linknode)); if (NULL == head) cout &lt;&lt; &quot;Error in calloc.&quot; &lt;&lt; endl; head-&gt;data = n; head-&gt;next = curr; curr = head; if (NULL == last)&#123;//保存最后一个节点的地址 last = head; &#125; n--; &#125; last-&gt;next = head;//进行首尾链接 return head;&#125;Link ListDel(Link prev)&#123; if (NULL == prev-&gt;next)&#123;//一种情况执行完毕，进行最后的节点空间释放。 free(prev); return NULL; &#125; Link curr = prev-&gt;next; prev-&gt;next = curr-&gt;next; free(curr); return prev;&#125;Link Josephus(Link head, int x, int y)&#123; Link prev = NULL; while (head-&gt;next-&gt;data != x)//进行遍历，直到指针的下一个节点的编号为x head = head-&gt;next; while (head != head-&gt;next)&#123;//循环直到只剩下一个节点 for (int i = 0; i &lt; y; i++)&#123; prev = head; head = head-&gt;next; &#125; head = ListDel(prev); &#125; head-&gt;next = NULL;//将无限循环单节点链表断开 return head;&#125;void ListPrintSol(Link head,int n, int i, int j)&#123; if (1 == head-&gt;data)&#123; cout &lt;&lt; &quot;The solution of &quot; &lt;&lt; n &lt;&lt; &quot; is: from &quot; &lt;&lt; i &lt;&lt; &quot; by &quot; &lt;&lt; j &lt;&lt; endl; //cout &lt;&lt; &quot;The last of the list is: &quot; &lt;&lt; head-&gt;data &lt;&lt; endl; &#125;&#125;int main()&#123; int n; //FILE *stream; //freopen_s(&amp;stream,&quot;op.txt&quot;, &quot;w&quot;, stdout); Link head = NULL; cout &lt;&lt; &quot;Please input the number of members n:&quot;; cin &gt;&gt; n; for (int i = 1; i &lt;= n; i++)&#123; for (int j = 1; j &lt;= n; j++)&#123; head = ListCreate(n);//创建链表 head = Josephus(head,i,j );//调用约瑟夫函数进行编号计数抽选，派遣队员，直到最后一人 ListPrintSol(head,n,i,j);//输出使加里森成为最后一人的x,y head = ListDel(head);//释放空间 &#125; &#125; return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://sean10.github.io/tags/数据结构/"}]},{"title":"数据结构之队列——回文字判断","slug":"数据结构之队列——回文字判断","date":"2015-11-11T09:43:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/11/数据结构之队列——回文字判断/","link":"","permalink":"https://sean10.github.io/2015/11/11/数据结构之队列——回文字判断/","excerpt":"","text":"题目：判别回文字符串 正读和反读都一样的字符串称为回文字符串。 编写程序，在键盘上输入一个字符串，以“#”作为结束标志，判别它是否为回文字符串。要求：采用栈和队列来实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define ERROR 0#define OK 1typedef struct node&#123; char data; struct node *next;&#125;queue,stack,*LinkQueue,*LinkStack;int push(LinkStack &amp;sHead, char ch)&#123;//入栈操作 LinkStack p = (LinkStack)calloc(1, sizeof(stack)); if (p == NULL)&#123; printf(&quot;Error calloc.\\n&quot;); return ERROR; &#125; p-&gt;data = ch; p-&gt;next = sHead; sHead = p; return OK;&#125;char pop(LinkStack &amp;sHead)&#123;//出栈 if (NULL == sHead) return ERROR; LinkStack temp = sHead; char ch = sHead-&gt;data; sHead = sHead-&gt;next; free(temp); return ch;&#125;int enqueue(LinkQueue &amp;qHead, LinkQueue &amp;qRear, char ch)&#123;//进入队列操作 LinkQueue p = (LinkQueue)calloc(1, sizeof(queue));//动态分配空间并初始化 if (p == NULL)&#123; printf(&quot;Error calloc_queue.\\n&quot;); return ERROR; &#125; p-&gt;data = ch; p-&gt;next = NULL; if (NULL != qRear) qRear-&gt;next = p; if (NULL == qHead) qHead = qRear; qRear = p; return OK;&#125;int queueDel(LinkQueue &amp;qHead)&#123;//进行队列删除 if (qHead == NULL) return OK; LinkQueue temp = qHead; qHead = qHead-&gt;next; free(temp); return OK;&#125;char dequeue(LinkQueue &amp;qHead)&#123;//进行出队列操作 char ch = qHead-&gt;data; LinkQueue temp = qHead; qHead = qHead-&gt;next; queueDel(temp); return ch;&#125;void input(LinkStack &amp;sHead, LinkQueue &amp;qHead,LinkQueue &amp;qRear,int &amp;len)&#123; char ch; printf(&quot;Please input the string which would be judged:&quot;); while (scanf(&quot;%c&quot;, &amp;ch) &amp;&amp; &apos;#&apos; != ch)&#123; push(sHead, ch);//推入栈 enqueue(qHead ,qRear, ch);//进入队列 len++; &#125;&#125;int compare(LinkStack &amp;sHead, LinkQueue &amp;qHead,int len)&#123; int cnt = 0; while (sHead != NULL &amp;&amp; qHead != NULL &amp;&amp; cnt &lt;= len/2)&#123;//判断一半的栈和队列是否已空 if (pop(sHead) != dequeue(qHead))//比较对应字符是否相同 return ERROR;//不同直接退出比较 cnt++; &#125; return OK;//始终相同，匹配&#125;void output(LinkStack &amp;sHead, LinkQueue &amp;qHead,int len)&#123; if (compare(sHead, qHead,len))//调用判断函数进行判断是否满足 printf(&quot;It is a plalindrome.\\n&quot;); else printf(&quot;It isn&apos;t a plalindrome.\\n&quot;);&#125;int main()&#123; //freopen(&quot;input.txt&quot;,&quot;r&quot;,stdin); //freopen(&quot;output.txt&quot;,&quot;w&quot;,stdout); int len=0; LinkStack sHead = NULL;//栈的头结点指针 LinkQueue qHead = NULL ,qRear = NULL;//队列的头结点和尾节点指针 input(sHead, qHead,qRear,len); output(sHead, qHead,len); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://sean10.github.io/tags/数据结构/"}]},{"title":"数据结构之栈——二进制转十进制","slug":"数据结构之栈——二进制转十进制","date":"2015-11-11T09:42:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/11/数据结构之栈——二进制转十进制/","link":"","permalink":"https://sean10.github.io/2015/11/11/数据结构之栈——二进制转十进制/","excerpt":"","text":"数据结构的作业，顺便就放上来吧 题目： 2/8进制转换器 编写程序，从终端输入一串0/1表示二进制数，以“#”结束，输出它的8进制表示形式。要求：采用栈来实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define ERROR 0#define OK 1typedef struct node&#123; int data; struct node* nextPtr;&#125;Stack,*LinkStack;int StackDel(LinkStack &amp;s)&#123; if (NULL == s) return ERROR;//判断栈是否出现了意外的空的状态 LinkStack temp = s;//定义一个存储即将被释放的空间的指针 s = s-&gt;nextPtr;// free(temp); return OK;&#125;int pop(LinkStack &amp;s)&#123; int e; if (NULL == s) return ERROR; e = s-&gt;data;//存储从栈中取出的值 StackDel(s);//删除已取出的栈的空间 return e;&#125;int push(LinkStack &amp;s, int e)&#123; LinkStack p = (LinkStack)calloc(1, sizeof(Stack));//动态分配空间并初始化 if (!p)&#123; printf(&quot;Error calloc_push&quot;); return ERROR; &#125; p-&gt;data = e; p-&gt;nextPtr = s;//将新数据链接到链表头部 s = p; return OK;&#125;void transform(LinkStack &amp;s)&#123; int e, temp = 0, pow = 1; while (NULL != s)&#123;//直到栈空 e = pop(s); temp += e*pow;//进行二进制转十进制的计算 pow *= 2;//进行位权的累乘 &#125; printf(&quot;The octonary answer is:(&quot;); printf(&quot;%o&quot;, temp);//输出八进制结果 printf(&quot;)8\\n&quot;);&#125;void input(LinkStack &amp;s)&#123; char ch; printf(&quot;Please input the binary string:&quot;); while (scanf(&quot;%c&quot;, &amp;ch) &amp;&amp; ch != &apos;#&apos;)&#123; push(s, ch - &apos;0&apos;);//将字符型二进制数以整型输入 &#125; return;&#125;int main()&#123; //freopen(&quot;input.txt&quot;,&quot;r&quot;,stdin); //freopen(&quot;output.txt&quot;,&quot;w&quot;,stdout); LinkStack s = NULL;//栈的头结点指针 input(s); transform(s); return 0;&#125;","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"栈","slug":"栈","permalink":"https://sean10.github.io/tags/栈/"},{"name":"数据结构","slug":"数据结构","permalink":"https://sean10.github.io/tags/数据结构/"}]},{"title":"《爱的艺术》人类超越了本能","slug":"《爱的艺术》人类超越了本能","date":"2015-11-07T16:10:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/08/《爱的艺术》人类超越了本能/","link":"","permalink":"https://sean10.github.io/2015/11/08/《爱的艺术》人类超越了本能/","excerpt":"","text":"第二章 爱情的理论 (一) 爱情是对人类生存问题的回答 爱情的每一个理论必须要以人的理论、人的生存理论为前提。我们所能看到的动物的爱情或者更确切地说动物身上类似爱情的东西，主要是动物的一部分本 能。在人身上只能看到这一本能的残余。人的存在的根本要点是人超越了动物界，超越了本能的适应性，脱离了自然-尽管人永远不可能完全脱离自然。人继续是自然的一部分，但又同自然分离，永远不可能再同自然合二为一。人从天堂里被赶出来后失去了同自然的和谐状态，带有火剑的天神就挡住了人的归路。人只能继续前进，不断发展人的理智，用一种新的，充满人性的和谐去取代永不复返的类人猿时代的和谐。 爱情的理论必须以人的理论、人的生存理论为前提，这时毋庸置疑的。唯有超越了本能的人类才能在超越了本能的范畴里讨论爱情。毕竟，假如在动物的本能的范畴内讨论爱情，那般的爱情就只是弗洛伊德所一直坚持着的性的爱。以性为根本的爱并不是本书所讨论的艺术的爱的范畴。 人的存在的根本要点是人超越了动物界，超越了本能的适应性，脱离了自然。为什么说脱离了自然呢？这句话的理解恐怕不能从常规的现实性的接触与否来理解脱离的含义，这里的脱离只是指人已经不再为自然所操控，不再完全只是听从本能而行动。这同时也解释了下一句，为什么说“尽管人永远不可能完全脱离自然。人继续是自然的一部分，但又同自然分离，永远不可能再同自然合二为一。” 人从天堂里被赶出来后失去了同自然的和谐状态。因为原本的动物性的人类遵循本能，而无需也不会考虑到寂寞、生存中的心灵的问题，以本能为心。而脱离了伊甸园无忧无虑本能状态的人类当前脱离了乌托邦，知道终究已经知道，不可能再回到无知的状态，火剑的天神就挡住了人的归路。人只有从另一个方向——全知的方向去找寻属于人类的新的和谐。 人一生下来-亦指种族和个人-就从一个确定的环境，如本能，被推到一个不确定的，完全开放的环境中去。人只了解过去，对未来-除了知道要以死亡告终外-一无所知。 人类离开已知的本能，来到了理智的世界。理智的世界便是所谓的未来，唯一的知晓仅是人终将体验到的死亡的经验。 不过这里，其实人类对于过去也并不了解。经历过的终究只有现在的一瞬间，过去了终究就是过去了，过去并不会停滞。唯一停滞于我们脑海中的只有过去的现在的那些印象。印象只是过去的部分展开。因而，人类对过去和未来一无所知。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/读书笔记/"},{"name":"爱的艺术","slug":"爱的艺术","permalink":"https://sean10.github.io/tags/爱的艺术/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/爱情/"}]},{"title":"栈——C语言模拟","slug":"栈——C语言模拟","date":"2015-11-05T05:37:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/05/栈——C语言模拟/","link":"","permalink":"https://sean10.github.io/2015/11/05/栈——C语言模拟/","excerpt":"","text":"##栈——C语言模拟 一、定义 根据wiki百科，栈(stack)，是一种特殊的串列形式的数据结构，是线性表的一种，一种_限制访问端口_的线性表。 栈的特殊之处在于只能在链接串列的一端，即栈顶(top)进行操作，在栈顶进行存入数据(push)，取出(pop). 推入:将数据放入栈的顶端，top+1. 弹出:将顶端数据资料输出，top-1. 也就是所谓的先进后出(LIFO，Last In First Out). stack 栈的存在价值 虽然说，栈实现的功能用数组和链表也可以实现，不过你不得不分神到考虑数组的下标增减、链表的指针指向等问题。 引用原作者的例子，就像我们明明有两只脚可以走路，算上游泳，理论上可以去到全球任何一个地方，那么为什么我们还要有汽车、火车、飞机一样。在向未来的发展过程中，我们需要考虑的更多的是在在抵达目的地之后的发展，这个抵达的过程已经成了我们继续发展的拖累。这时，优化移动方式就成了必然，让我们得以关注结果之后。 所以说，栈的引入简化了程序设计的问题，划分了不同关注层次，让人更聚焦于问题本身。比如C++，JAVA等的标准库都封装了栈的结构。 栈分为顺序栈和链式栈 两者的差别在哪里呢？为什么要特别用两种方法模拟呢？ 时间复杂度上，两者都没有任何其他的操作，均为O(1)； 而空间复杂度上，顺序栈只存储了数据和表头标记；而链式栈对每个数据都建立了一个节点，存储数据之外还存储了指向下一个节点的指针，空间较顺序栈多了一倍。 所以顺序栈优点，空间占用小，存取定位还是比较方便的，在使用小空间的；而链式栈可以 以下是栈的抽象数据类型的定义： 1234567891011121314151617181920212223242526272829303132333435363738394041ADT Stack&#123; 数据对象:D=&#123;ai|ai \\in ElemSet,i = 1,2,...,n, n &gt;= 0&#125; 数据关系:R1=&#123;&lt;a(i-1),ai&gt;|a(i-1),ai \\in D, i = 2,..,n&#125; 约定an端为栈顶，ai端为栈底. 基本操作: InitStack(&amp;S) 操作结果:构造一个空栈S Destroy(&amp;S) 初始条件:栈S已存在。 操作结果:栈S被销毁。 ClearStack(&amp;S) 初始条件:栈S已存在。 操作结果:将S清为空栈。 StackEmpty(S) 初始条件:栈S已存在。 操作结果:若栈S为空栈，则返回TRUE，否则FALSE。 StackLength(S) 初始条件:栈S已存在。 操作结果:返回S的元素个数，即栈的长度。 GetTop(S,&amp;e) 初始条件:栈S已存在且非空。 操作结果:用e返回S的栈顶元素。 Push(&amp;S,e) 初始条件:栈S已存在。 操作结果:插入元素e为新的栈顶指针。 Pop(&amp;S,&amp;e) 初始条件:栈S已存在且非空。 操作结果:删除S的栈顶元素，并用e返回其值。 StackTraverse(S,visit()) 初始条件:栈S已存在且非空。 操作结果:从栈底到栈顶依次对S的每个数据元素调用函数visit()。一旦visit()失败，则操作失效。&#125;ADT Stack 二、顺序栈 定义： 12345typedef struct&#123; SElemType *base; SElemType *top; int stacksize;&#125;SqStack; 接下来是顺序栈的模块说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#define STACK_INIT_SIZE 100 //存储空间初始分配量#define STACKINCREMENT 10 //存储空间分配增量#define ERROR 0#define OK 1#define OVERFLOW -1typedef struct&#123; SElemType *base; //在栈构造之前和压栈之后，base的值为NULL SElemType *top; //栈顶指针，指向栈顶的下一个位置 int stacksize; //当前已分配的存储空间，以元素为单位&#125;SqStack;//------基本操作的函数原型说明------Status InitStack(SqStack &amp;S);//构造一个空栈SStatus DestroyStack(SqStack &amp;S);//销毁栈S，S不再存在Status ClearStack(SqStack &amp;S);//把S置为空栈Status StackEmpty(SqStack S);//若栈S为空栈，则返回TRUE,否则返回FALSEint StackLength(SqStack S);//返回S的元素个数，即栈的长度Status GetTop(SqStack S,SElemType &amp;e);//若栈不空，则用e返回S的栈顶元素，并返回OK；否则返回ERRORStatus Push(SqStack &amp;S,SElemType e);//插入元素e为新的栈顶元素Status Pop(SqStack &amp;S,SElemType &amp;e);//若栈不空，则删除S的栈顶元素，用e返回其值，并返回OK；否则返回ERRORStatus StackTraverse(SqStack S,Stack (*visit()));//从栈底到栈顶一次对栈中每个元素调用函数visit().一旦visit()失败，则操作失败/***************基本操作的算法描述**********/Status InitStack(SqStack &amp;S)&#123; //构造一个空栈 S.base = (SElemType *)malloc(STACK_INIT_SIZE * sizeof(SElemType)); if(!S.base) exit(OVERFLOW); S.top = S.base; S.stacksize = STACK_INIT_SIZE; return OK;&#125;//InitStackStatus GetTop(SqStack S, SElemType &amp;e)&#123;//若站不空，则用e返回S的栈顶元素，并返回OK；否则返回ERROR if(S.top == S.base) return ERROR; e = *(S.top-1); return OK;&#125;//GetTopStatus Push(SqStack &amp;S,SElemType e)&#123;//插入元素e为新的栈顶元素 if(S.top-S.base &gt;= S.stacksize)&#123; //栈满，追加存储空间 S.base=(SElemType *)realloc(S.base,(S.stacksize+STACKINCREMENT)*sizeof(SElemType)); if(!S.base) exit(OVERFLOW);//存储分配失败 S.top=S.base+S.stacksize; S.stacksize+=STACKINCREMENT; &#125; *S.top++ = e; return OK;&#125;//push_backStatus Pop(SqStack &amp;S,SElemType &amp;e)&#123;//若栈不空，则删除S的栈顶元素，用e返回其值，并返回OK，否则返回ERROR if(S.top == S.base) return ERROR; e = * --S.top; return OK;&#125;//pop 顺序栈是为栈预先分配一个大小固定且较合适的空间，最常见的做法是Stack结构中含一个数组。 1234struct stack&#123; int data[10]; int top;&#125;; 以下是数组实现的各函数代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define STACK_POP_ERR 42#define stack struct Stack;struct Stack&#123; int val[10]; int top; //栈顶&#125;;/* 检查栈是否为空 */int empty(stack *stk) &#123; return stk-&gt;top == 0; &#125;/* 推入资料 */void push(stack *stk, int x)&#123; stk-&gt;top=stk-&gt;top+1; stk-&gt;val[stk-&gt;top]=x;&#125;/* 弹出并返回资料 */int pop(stack *stk) &#123; if(empty(stk)) return STACK_POP_ERR; // 不能弹出 else&#123; stk-&gt;top=stk-&gt;top-1; return stk-&gt;val[stk-&gt;top+1];//这里使用了复用技术 &#125;&#125;int main()&#123; // 宣告并初始化空间 stack stk; stk.top=0; // 推入四个 push(&amp;stk, 3); push(&amp;stk, 4); push(&amp;stk, 1); push(&amp;stk, 9); // 弹出三个 printf(\"%d \", pop(&amp;stk)); printf(\"%d \", pop(&amp;stk)); printf(\"%d \", pop(&amp;stk)); return 0;&#125; 三、链式栈 链式栈是定义一个结构体，去掉表头（表头是指一个空节点只带有一个指向存储栈顶数据的空间的指针，即首节点就开始存储数据） 链式栈这里我用二进制转八进制的程序来说明 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define ERROR 0#define OK 1typedef struct node&#123; int data; struct node* nextPtr;&#125;Stack,*LinkStack;int StackDel(LinkStack &amp;s)&#123; if (NULL == s) return ERROR;//判断栈是否出现了意外的空的状态 LinkStack temp = s;//定义一个存储即将被释放的空间的指针 s = s-&gt;nextPtr;// free(temp); return OK;&#125;int pop(LinkStack &amp;s)&#123; int e; if (NULL == s) return ERROR; e = s-&gt;data;//存储从栈中取出的值 StackDel(s);//删除已取出的栈的空间 return e;&#125;int push(LinkStack &amp;s, int e)&#123; LinkStack p = (LinkStack)calloc(1, sizeof(Stack));//动态分配空间并初始化 if (!p)&#123; printf(&quot;Error calloc_push&quot;); return ERROR; &#125; p-&gt;data = e; p-&gt;nextPtr = s;//将新数据链接到链表头部 s = p; return OK;&#125;void transform(LinkStack &amp;s)&#123; int e, temp = 0, pow = 1; while (NULL != s)&#123;//直到栈空 e = pop(s); temp += e*pow;//进行二进制转十进制的计算 pow *= 2;//进行位权的累乘 &#125; printf(&quot;The octonary answer is:(&quot;); printf(&quot;%o&quot;, temp);//输出八进制结果 printf(&quot;)8\\n&quot;);&#125;void input(LinkStack &amp;s)&#123; char ch; printf(&quot;Please input the binary string:&quot;); while (scanf(&quot;%c&quot;, &amp;ch) &amp;&amp; ch != &apos;#&apos;)&#123; push(s, ch - &apos;0&apos;);//将字符型二进制数以整型输入 &#125; return;&#125;int main()&#123; //freopen(&quot;input.txt&quot;,&quot;r&quot;,stdin); //freopen(&quot;output.txt&quot;,&quot;w&quot;,stdout); LinkStack s = NULL;//栈的头结点指针 input(s); transform(s); return 0;&#125; 四、栈的应用 1.表达式求值 2.由递归到非递归 3.深度优先搜索(bfs) 参考资料： [1].kelinlin.为什么要使用栈这种数据结构. [2][Wikipedia Definition.](https://zh.wikipedia.org/zh/%E5%A0%86%E6%A0%88) [3]《数据结构》，严蔚敏","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"栈","slug":"栈","permalink":"https://sean10.github.io/tags/栈/"}]},{"title":"读《弗洛伊德：作家与白日梦》","slug":"读《弗洛伊德：作家与白日梦》","date":"2015-11-04T10:31:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/04/读《弗洛伊德：作家与白日梦》/","link":"","permalink":"https://sean10.github.io/2015/11/04/读《弗洛伊德：作家与白日梦》/","excerpt":"","text":"##读《弗洛伊德：作家与白日梦》 在弗洛伊德的这篇论文中，我的理解的含义是作家的作品便是他们的幻想的一种表达，只是借小说等形式展露而不必为让其他人窥探自己的内心自我而感到害羞。在弗洛伊德看来，这种白日梦依旧是符合他对梦的解析的，这里的幻想就如同孩童时期的梦，只是通过外加刺激唤醒了孩童时期的记忆。 到文章最后，弗洛伊德将话题延伸至了对自我的分析，主体由第三者的作家转向了小说的读者——我们自己。他对于读者对小说的满足感的分析还只是处于找到方向、尚未完全深入的状态。至此，他提出了几种可能性。 作家提供给我们的所有美学快乐都具有”直观快乐“的性质，我们对一部富有想象力的作品的欣赏实际来自我们精神上紧张状态的消除。甚至有可能是，这种效果有相当一部分归因于作家能够使我们享受到自己的白日梦而又不必去自责或害羞。 以上是第一遍泛读得到的结论。 接下来我们细细地分析一下这篇论文。 我们这些门外汉总是以强烈的好奇心理去理解——恰如把类似的问题送给阿里奥斯托 [1]的那位红衣主教——与众不同的作家从哪处渊源发掘了他的素材，他又如何加工组织这些素材以至于使我们产生如此深刻的印象，在我们的心中激发起连我们自己都不曾料想的情感。 假如我们向作家讨教，他本人也难以解释，即使解释了也不会令我们满意，正因为如此，这便使我们产生更加浓厚的兴趣。即使我们都彻底了解作家是怎样选取素材的，了解创造想象形式的艺术的真谛，也不可能帮助我们把自己修炼成为作家。 即便是到了现在，作家加工组织素材的方式依旧是这般。因为各人的思想是不同的，借用弗洛伊德的名词，也就是自我是不同的。最终组织完成的作品终究不同。 用计算机术语来说，作家能够明确的说得出的只是他组织的一定的过程，至于是如何有了对素材那般这般的组织方式，即便是他自身也是不知道的。做后我们得知的仅仅只是每个模块的函数运行，完全不知道函数内部的源代码是如何，仅仅只是得到了一个个的黑盒。 既然无从得知，那么这篇文章的目的是让我们知道什么呢？ 如果我们至少在自身或在像自身的人们身上发现一种能动性与文学创作在某种方式上相类似，那该多么令人欣慰。检验这种能动性将使我们有希望对作家的创作做出解释。的确，这种情况的可能性是有的。作家自己也毕竟喜欢缩短他们自己的本性和人类的共性之间的距离；因此，他们一再鼓励我们相信，每一个人在心灵深处都是一位诗人。只要有人，就有诗人。 假如存在一种能动性与文学创作相类似，那么恐怕就能使得世界上充斥艺术的天才了。能动性是一种可以用理工科的方法进行理性分析的心理学产物，也就意味着存在一种可能性被进行编码分析的。 不过，这种可能也已经只是过去式了。人工智能（AI）假设使用模拟人脑的方式来进行编程，那么所需进行的计算量已经远远超出当今时代的计算机所能完成的计算量，即便程序的时间复杂度达到了最优，不过依旧是只有划时代的量子电脑或是尚未诞生的生物电脑、亦或是曾经被提出过的神经计算机才能完成的。而量子级、生物级尚且还太遥远，神经计算机则有些超想象。记得当时杂志上的介绍是这样的，神经计算机将完成人脑的全脑模型，不过神经计算机的制造前提也是仿人脑运行原理研制。要对人脑回路进行理性建模，尚且还在路上。 可以说人虽然存在，但心中的诗人可能永世不会醒来。 作家的本性与人类的共性至少在当下依旧只是一个无穷接近。 我们是不是应该在童年时代寻觅富于想象力的能动性的第一道轨迹呢？孩子最喜欢的最投入的活动是游戏(play)和玩耍(games）。难道我们不可以说每一个孩子在游戏时的表现行为俨然是一位作家吗？他在游戏中创造着一个属于自己的世界，或者说，是他在用自己喜爱的新方式重新组合他那个世界里的事物。如果认为他对待他那个世界的态度不够严肃，那就错了；恰恰相反，他在游戏时非常认真，并且在上面倾注了极大的热情。与玩耍相对的并不是严肃认真，而是实实在在。尽管他把情绪和精力投注于游戏世界，也还是能够很好地将游戏世界和现实世界区分开来的；他喜欢把想象中的物体和情境与现实世界中的有形的、看得见的事物联系起来。这种联系是区别孩子的“游戏”与“幻想”(phantasying)的根本依据。 弗洛伊德所说的能动性是能够通过人脑学习的，对于人的无穷可能性来说，还是相当现实的。 作家的工作与孩子游戏时的行为是一样的。他创造了一个他很当真的幻想世界——也就是说，这是一个他以极大的热情创造的世界——同时他又严格地将其与现实世界区分开来。语言保留了孩子们做的游戏和诗歌创作之间的这种关系。（在德语中）这种富有想象力的创作形式被称之为“Spiel”（游戏），这种创作形式与现实世界里的事物相联系，并具备表现能力。其作品称做“Lustspiel”或“Trauerspied”（“喜剧”或者“悲剧”，字面上可以叫做“快乐游戏”或“伤感游戏”），把那些从事表演艺术的人称做“Schauspieler”（“演员”字面上可以叫做“做游戏人”）。无论如何，作家幻想世界的非真实性对他的艺术技巧具有举足轻重的作用；因为许多事情就是这样，如果它们是真实的，就不能给人带来娱乐，在虚构的剧作中却能够带来娱乐。有许多动人心弦的剧情本身在实际上是令人悲伤的，但在一个作家的作品上演中，却能变成听众和观众的一个快乐的源泉。 幻想才能带来欢乐。 下面我们将从另一个角度，花更多些时间对现实世界与戏剧进行比较。当孩子长大成人不再做游戏时，在他经过几十年的劳作之后，以严肃的态度面对现实生活时，他或许在某一天会发现自己处于再次消除了戏剧与现实之间差别的心理情境（mental situation)之中。 作为成年人，他能够回想起童年时代游戏时所怀有的那种认真严肃的态度；如果把今天显然严肃的工作当成童年时代的游戏，他便可以抛却现实生活强加给的过于沉重的负担，从而通过幽默的方式得到大量的快乐 [2]。 由此所见，当人们长大后便停止了游戏，他们似乎也放弃了从游戏中所获得快乐的受益。但是不管是谁，只要他了解人类的心理，他就会知道，对一个人来说，如果让他放弃自己曾体验过的快乐那几乎比登天还难。事实上，我们从不放弃任何东西，我们只是用这一样东西去交换另外一样东西。看上去是被抛弃的东西实际上变成了代替物或代用品。同样，长大了的孩子当他停止游戏时，除去和真实事物的联系之外，他什么也没抛弃；代替游戏的是幻想。他在空中建造楼阁，去创造所谓的“白日梦”(day-dreaming)。我相信大多数人都在他们的生活中的某时某刻构造幻想。这是一个长期以来被忽视的事实，因此，它的重要性也就未被充分地认识到。 成年人以幻想来替代游戏？想来倒确实是这样。所谓的童心未泯恐怕就是偶尔将幻想化作现实，进行游戏。 观察人们的幻想比起观察儿童的游戏来困难得多。说真的，一个孩子要么独自游戏，要么以做游戏为目的而和其他孩子一起构成了一个封闭的精神系统；尽管在大人面前他们可能不做游戏，但在一方面，他们也从不在大人面前掩饰自己的游戏。与孩子相反，成年人却羞于表现自己的幻想，并且向其他人隐瞒自己的幻想。他珍爱自己的幻想恰如对待自己的私有财产那样。通常，他宁愿承认自己的不轨行为和过失，也不愿把自己的幻想向任何人透露。造成这种情况的原因可能是，他相信只有他创造了这样的幻想，岂不知在别人那里这种创造也相当普遍。做游戏的人和创造幻想的人在行为上的这种不同是由于两种活动的动机(motives)不同的缘故，然而它们却是互相依附的。 成年人封闭自己的内心，恐怕也正是因此当下的人们对通过行为表情等来分析对方的心理非常的感兴趣。 孩子的游戏是由其愿望所决定的：事实上是惟一的愿望(wish)——这个愿望在他的成长过程中起了很大的促进作用——希望长大成人。他总是做“已经长大”的游戏，在这种游戏中他模仿他所知道的年长者的生活方式，他没有理由掩饰这个愿望，而在成年人那里，情况就不同了，而应该在真实世界中去扮演某个角色；另一方面，他意识到把引起他幻想的一些愿望隐藏起来至关重要。于是，他就会为那些幼稚的不被允许的幻想而感到羞愧。 但是，你们会问，既然人们把他们的幻想搞得如此神秘，那么对这个问题我们又怎么会知道得如此之多呢？事情是这样的：人类中有这样一类，他们的灵魂里有一位严厉的女神(goddess)——必然性(necessity)——让他们讲述他们经受的苦难，说出给他们带来幸福 [3]的东西。他们是些神经性疾病(nervous illness)的受害者，他们不得不把自己的幻想讲出来，告诉医生，希望医生采用心理疗法(mental treatment)治愈他们的疾病。这是我们的最好的信息来源，我们据此找到了充分的理由假设；如果病人对我们守口如瓶，我们从健康人的口中也不可能有所闻。 现在，让我们来认识一下幻想的几个特征。我们可以断言，一个幸福的人从来不会去幻想，只有那些愿望难以满足的人才去幻想。幻想的动力是尚未满足的愿望，每一个幻想都是一个愿望的满足，都是对令人不满足的现实的补偿。这些充当动力的愿望因幻想者的性别、性格和环境的不同而各异；但它们又很自然地分成两大主要类别。他们要么是野心的愿望，这类愿望提高幻想者的人格；要么是性的愿望。在年轻的女子身上，性的愿望几乎总是占据主要地位，因为她们的野心通常都被性欲倾向所同化。在年轻的男子身上，自私的、野心的愿望和性的愿望相当明显地并驾齐驱。但是，我们不准备强调两种倾向之间的对立；我们更愿强调这样一个事实：它们经常结合在一块。正像在许多教堂祭坛后壁的装饰画中，捐献者的肖像可在画面的某个角落里看到一样，在大多数野心幻想中，我们也会在这个或那个角落里发 现一位女子，为了她，幻想的创造者表演了他的全部英雄行为，并把其所有的胜利果实堆放在她的脚下。大家看得出，在这样的幻想中，的确存在着想掩饰幻想的非常强烈的动机；受过良好教养的女子只允许有最低限度的性欲需求，青年男子必须学会压抑对自身利益的过分关注，以便在其他人也有着同样强烈要求的人际社会中找到可以适应自己的位置。 这一段就非常的贴合弗洛伊德的想法了，一切的本质原因都是本能的性。姑且不去探讨弗洛伊德的理论时下的正确性。幻想确实是愿望无法满足之后的产物，现实无法满足才不得进入梦的世界来实现。 我们不能认为这类想象活动的产物——各式各样的幻想，空中楼阁和白日梦——是已经定型或不可改变的东西。恰恰相反，它们随着幻想者对生活的理解的变换而变换，随着幻想者处境的每一个变化而变化，从每一个新鲜活泼的印象中去接受被称为“日戳”（date-mark）的印象。一般来说，幻想与时间之间的关系是至关重要的。我们可以说幻想似乎在三个时间之间徘徊——我们的想象经历三个时刻。心理活动与某些现时的印象相关联，和某些现时的诱发心理活动的事件有关，这些事件可以引起主体的一个重大愿望。心理活动由此而退回到对早年经历的记忆（通常是童年时代的经历），在这个时期该重大愿望曾得到过满足，于是在幻想中便创造了一个与未来相联系的场景来表现愿望满足的情况。心理活动如此创造出来的东西叫做白日梦或者是幻想，其根源在于刺激其产生的事件和某段经历的记忆。这样，过去，现在和未来就串联在一起了，愿望这根轴线贯穿于其中。 举一个非常普通的例子就可以把我所说的这些问题解释得很清楚。我们以一个贫穷孤儿为例，你已经给了他某个雇主的地址，他也许在那里能够找到一份工作。在去看雇主的路上，他可能沉湎于与产生与当时情景相适应的白日梦之中。他幻想的事情或许是这类事情：他找到了工作，并且得到新雇主对他的器重，自己成为企业里面举足轻重不可缺少的人物，既而被雇主的家庭所接纳，和这家的年轻而又妩媚迷人的女儿结了婚，随后又成为企业的董事，初始是作为雇主的合股人，而后就成了他的继承人。在这种幻想中，白日梦者重新获得他在幸福的童年时曾拥有的东西——庇护他的家庭，疼爱他的双亲以及他最初一见钟情的妙龄佳人。从这个例子中你可以看到，愿望利用一个现时的场合，在过去经历的基础上描绘出一幅未来的画面。 白日梦是随时变化的毫无疑问，为现实中某物所激发便随时可能增减内容。在此不去论证了。 关于幻想还有许多方面值得研究；但我将尽可能扼要地说明其中的某几点。如果幻想变得过于丰富多彩、强烈无比的话，那么神经症和精神病就处于待发作状态。另外，幻想是我们的病人经常抱怨的苦恼病状的直接心理预兆。它像一条宽敞的岔道伸向病理学范畴。 我不能略而不谈幻想与梦之间的关系。我们在夜里所做的梦就属此类幻想，这一点我们可以通过梦之分析来证实 [4]。很久以前语言就以其无与伦比的智慧对梦的本质问题下了定论，把漫无边际的幻想创造命名为“白日梦”。如果我们对我们的梦的意义总觉得含糊不清的话，那是因为夜间的环境使我们产生一些令自己羞惭的愿望；这些愿望我们必须对自己隐瞒，所以它们受到压抑，压入潜意识之中。这种受压抑的愿望及其派生物只允许以一种极其歪曲的形式表现出来。当科学工作已能成功地解释梦变形的这种因素时，就不难识别夜间的梦和白日梦——即我们非常了解的幻想一样，是愿望的满足。 梦的解析的问题姑且搁置。 关于幻想的问题就谈这些。现在来谈一下作家。我们真可以将富有想象力的作家和“光天化日之下的梦幻者” [5]做一比较，把他的创作和白日梦做比较吗？这里，我们必须先弄清楚一个问题。我们必须区分开这两类作家：像古代的史诗作家和悲剧作家那样接收现成题材的作家和似乎是由自己选择题材创作的作家。我们在进行比较时，将主要针对后一类作家，不去选择那些批评家顶礼推崇的作家，而是选择那些名气不十分大，但却拥有最广大、最热衷的男女读者的长篇小说，传奇文学和短篇小说的作者。在所有这些小说作者的作品中有一个特点我们肯定能看得出：每一部作品都有一个主角，这个主角是读者兴趣的中心，作家试图用尽一切可能的表现手法来使该主角赢得我们的同情，作者似乎将他置于一个特殊的神袛的庇护之下。假如在我的小说的某一章的结尾，我把主角遗弃，让他受伤流血，神志昏迷，那么我肯定在下一章的开头会读到他正得到精心的治疗护理，逐渐恢复健康；如果第一卷以他乘的船在海上遇到暴风雨而下沉为结尾，那么我还可以肯定，在第二卷的开头就会读到他奇迹般地获救——没有获救这个情节，小说将无法写下去。我带着安全感跟随主角走过他那危险的历程，这正是在现实生活中一位英雄跳进水中去拯救一个落水者时的感觉，或者是他为了对敌兵群猛烈攻击而把自己的身躯暴露在敌人的炮火之下时的感觉。这种感觉是真正英雄的感觉，我们一位最优秀的作家曾用一句盖世无双的话表达过：“我不会出事！” [6]然而，通过这种不受伤害、英雄不死的特性，我们似乎可以立即认出每场白日梦及每篇小说里的主角如出一辙 [7]，都是一个“惟我独尊的自我”。 这些自我中心小说在其它方面也表现出类似性。小说中的所有女人总是爱上了男主角，这一点，很难说是对现实的描写。但是，作为白日梦必要的构成因素却很容易被理解。同样，作者根本无视现实生活中所见到的人物性格的多样性，而将小说中的其他人物整齐地分成好人与坏人。“好人”是自我的助手，而“坏人”则成为自我的敌人和对手，这个自我就是故事的主角。 小说是围绕主角展开描写的，自然无法否认主角的好运。无论如何，都不得不承认对个人的自我的放大的小说读上去充斥着好运的感觉。 我们十分清楚，许多富于想象的作品和天真的白日梦模式相距甚远；但我仍不能消除这种怀疑：即使偏离白日梦模式最远的作品也可以通过不间断的，一系列的过渡事件与白日梦相联系。我注意到被人们称为“心理小说”(psychological novels)的作品中只有一个人物—就是那个通过内心描写的主角。作者好像坐在主人公的脑袋里，从外部来观察其他人物。毋庸置疑，一般来说心理小说之所以具有其特殊性，是因为现代作家倾向于凭借自我观察(self-observation) ,将他的主人公分裂成许多部分自我（part-egos),结果是作家把自己的心理生活中相冲突的几个倾向在几个主角身上体现出来。某些小说或许可称之为“怪诞”(eccentric)小说，似乎与白日梦的类型形成非常特殊的对比。在这些小说里，被作为主角介绍给读者的人物仅仅扮演着一个很小的角色，他犹如一位旁观者静观其他人的活动以及遭受的痛苦。 左拉的许多后期作品都属于这一类。但是我必须指出，通过对创造性的作家和在某些方面背离所谓规范的作家做个人精神分析，我们发现白日梦具有与“怪诞”小说类似的特点，即自我满足于充当旁观者的角色。 怪诞小说放大了对其他人的自我的猜测，从另一种角度形成了一种引领全书气氛的幻想。 如果我们想让富于想象力的作家和白日梦者、诗歌创作与白日梦之间的比较有某种价值的话，那就必须首先以某种方式表现出其有效性。譬如，我应试着对这些作者作品中所运用我们在前面论及的关于幻想、三个时间和贯穿三个时间的愿望之间的关系命题；借助于此我们还可以试着研究一下作者的生活与其作品之间的联系。一般来说，无人知晓在研究这个问题时应设想什么样的预期成果，而且人们常常把这种联系看得过于简单。借助于我们对幻想研究所得，我们应该预料以下的事态：现时的一个强烈经验唤起作家对早年某个经历（通常是童年时代）的记忆，在此记忆中又产生一个在其作品中可以得到满足的愿望。其作品本身能够显示出近期的诱发事件和旧时的记忆这些因素 [8]。 不要被这个程式的复杂性吓倒了。我猜想事实将会证明它是一种极为罕见的方式。然而，它或许包含着弄清事实真相的第一步；根据我所做的一些实验，我倾向于认为对于作品的这种研究方式不会是劳而无功的。你将不会忘记，对于作家生活中的童年时代的记忆的强调——这种强调或许令人莫名其妙——归根到底来自于这种假设：一篇具有创见性的作品像一场白日梦一样，是童年时代曾经做过的游戏的继续，也是这类游戏的替代物。 然而，我们不能忘记回到我们该认识的那类富有想象力的作品，这类作品并非是独创性的写作，而是现成的和熟悉的素材的改造加工。即使在这里，作家也拥有相当范围的自主权，这种自主权可表现在素材的遴选以及素材的千变万化上，这种变化的范围又相当广泛。不过就现有的素材来说，它来自流行的神话、传说及童话故事的宝库。对诸如此类民间心理构造的研究还远远够完善，但极有可能的是，诸如神话故事这类传说是所有民族充满愿望的幻想，也是人类年轻时期的尚未宗教化的梦幻歪曲后的残迹。 你会说，尽管在我的论文题目中我把作家放在首位，但我对作家的论述比对幻想的论述少得多。我意识到了这一点，但我这么做是有理由的，因为我推导出了我们现在所拥有的认识。我所能够做到的一切，就是提出一些鼓励和建议，从对于幻想的研究着手，导向作家选择其文学素材的问题的研究。至于另外的问题——作家采用什么手段来激发我们内心的感情效应——截止目前我们还根本没有涉及到这个问题。但我至少乐于向你指明一条从我们对幻想的讨论一直通向诗的效应问题的道路。 你会记得我曾论述过，白日梦幻者由于他感到有理由对自己创造的幻想而害羞，从而小心谨慎地向别人隐瞒自己的幻想。现在我应该补充说明，即使他打算把这些幻想告诉我们，这种倾诉也不会给我们带来任何快乐。我们听到这些幻想时会产生反感或者深感扫兴。但是当一位作家给我们献上他的戏剧或者把我们习惯于当作他个人的白日梦的故事时，我们就会体验到极大的快乐，这种快乐极有可能由许多来源汇集而产生。作家如何达到这一目的，那是他内心深处的秘密；诗歌艺术的精华存在于克服使我们心中感到厌恶的后果的技巧，这种厌恶感毫无疑问地与一个“自我”和其他“自我”之间产生的隔阂相联系。我们可以猜测到这种技巧的两个方法：作家通过改变和掩饰其利己主义的白日梦以软化它们的利己性质；他以纯形式的——即美学的——快感来收买我们这些读者。我们给这类快乐命名为“额外刺激”(incentive bonus)或“前期快乐”(fore pleasure)。作者向我们提供这种快乐是为了有可能从更深的精神源泉中释放出更大的快乐 [9]。从我的观点来讲，作家提供给我们的所有美学快乐都具有这种“直观快乐”的性质，我们对一部富有想象力的作品的欣赏实际来自我们精神上紧张状态的消除。甚至有可能是，这种效果有相当一部分归因于作家能够使我们享受到自己的白日梦而又不必去自责或害羞。这个认识成果就把我们引向新的、有刺激性的、复杂难懂的调查研究工作的门槛；但同时，至少是目前，它也把我们带到我们讨论的终点。 对最后这一部分的理解依旧与一开始相同。 阅读这类文字，看来思维能力还是有所欠缺，需要加大练习。 【1】红衣主教伊波里托·德埃斯特(Ippolito d’ Este)是阿里奥斯托的第一个保护人，阿里奥斯托(Ariosto)的《疯狂的奥兰多》就是献给他的。诗人得到的惟一报答是红衣主教提出的向题：“罗多维柯，你从哪儿找到这么多故事？” 【2】参阅弗洛伊德的《诙谐及其与潜意识的关系》（1905c）第七章第七节。 【3】这是指歌德的剧本《托夸多•诺索》最后一场中主角兼诗人所吟诵的诗句： 当人类在痛苦中沉默， 神让我讲述我的苦痛。 【4】 参阅弗洛伊德的《释梦》（1900a）。 【5】［Der Träumer am hellichten Tag］ 【6】“Es Kann dir nixg schehen！”“这句话出自弗洛伊德喜爱的维也纳剧作家安泽格鲁伯(Anzengruber)之口。参阅《对目前战争与死亡的看法》(1915b)标准版，第14卷，第296页。 【7】 参阅《论自恋》(1914c)，标准版，第14卷，第91页。 【8】弗洛伊德在1898年7月7日致弗利斯的信中讨论迈耶尔(C. F. Meyer)创作的短篇小说的主题时，已经提出过类似的观点（弗洛伊德，1950a，信92)。 【9】弗洛伊德把“前期快乐”和“额外刺激”的理论应用在《诙谐及其与潜意识的关系，（1905c）第四章最后一段中。在《性学三论》中，弗洛伊德又讨论了“前期快乐”的本质。 参考文献： 1.《作家与白日梦》，弗洛伊德，1908","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"梦","slug":"梦","permalink":"https://sean10.github.io/tags/梦/"}]},{"title":"《爱的艺术》爱的误解——对象，状态","slug":"《爱的艺术》爱的误解——对象，状态","date":"2015-11-04T03:04:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/04/《爱的艺术》爱的误解——对象，状态/","link":"","permalink":"https://sean10.github.io/2015/11/04/《爱的艺术》爱的误解——对象，状态/","excerpt":"","text":"当然，那并不是说人们认为爱不重要。人们渴望着爱，他们没完没了地观看有关换了和悲哀的爱情故事的电影，倾听很多毫无价值的爱情歌曲——爱呢日，几乎每一个人都认为，爱是没有什么可学的。 对于爱情的渴望，确实每个人都无可避免。不论是因为生理上的荷尔蒙，还是因为心理上对解脱寂寞的向往，爱情作为温柔乡，所有人都有着对理想的安神处的希望。不过，这样的渴望，毕竟正如上一段所说的，并不是所有人都能接受将其作为艺术来学习的。 这种特殊的态度基于几个前提，而这些前提往往分别地或共同地支持这种态度。__大多数人把爱只是简单地看成被爱的问题，而不是爱人及自己有无爱人的能力的问题。__因此，在他们看来，问题是怎样被爱，怎样得到爱，怎样变得可爱。为了追求这个目的，他们采用几条途径：其一，尽可能取得成功，取得与个人的社会地位相称的权利和财富，这条途径特别为男人所采用，其二，梳妆打扮、衣着华丽，使自己更富有吸引力，这条途径尤其为女人所采用。其它一些被男人和女人采用的、使自己富有吸引力的途径是养成令人愉快的生活习惯，谈笑风生，助人为乐，千寻而布帽烦别人。有很多让自己变得可爱的途径，类似于是自己取得成功的那些途径，如”赢得朋友，影响他人“。其实，在我们的文化观念中，大多数人所指的”可爱“基本上是时髦和性吸引力的混合物。 这个第一个前提，如何理解呢？ 从一定角度来说，其实他们地方法并没有做错。因为都是采取提高个人本身的固定价值来提高被关注率，相比只是提高自己追求的成功率的艺术的学习来说，可能这样的方法对于非主动的、以及并不知晓自己爱什么样的人、自己能爱什么样的人的人来说，更为恰当一些。 不过从弗洛姆的角度来理解的话，这些人都只是在选择发展让自己能吸引大量异性的方式，毕竟这样的方法可以让自己在更多的异性中拥有更好的印象，更容易吸引来自己喜欢的异性。当然，有方向的人明显不是属于这类人。 隐藏在“爱没有什么可学的态度“后面的第二个前提是：__爱的问题就是爱的对象问题，而不是爱的能力问题。__人们认为爱是简单地，但是要找到一个合适的爱的对象——或为其所爱——则是困难的。持这种态度有几个原因，它们同现代社会发展是密切相关的，其中之一是__20世纪对”爱的对象“的选择发生了巨大变化__。在维多利亚时代，爱，正如在很多传统文化中一样，通常来讲并不是一种自发的并导致婚姻的隐私经验；相反，婚姻是通过传统的风俗习惯确定的——要么通过双方家庭，要么通过一个媒人，或者不需要中间人的介绍。婚姻实在考虑社会需要的基础上最后做出的决定，一旦做出婚姻的决定，爱就理所当然地发展下去。在过去几代人中，浪漫式的爱的思想在西方世界中极为普遍。在美国，虽然并非完全不考虑传统的爱，但是人们在很大的程度上寻求的是”浪漫式“的爱，寻求导致婚姻的爱的隐私经验。在爱的方面，这种自由的新思想，同爱的作用相比，大大地增加了爱的对象的重要性。 确实，这个前提可以说是即便是到了现在，同样是作为最大的理由被人认所使用着。欧美可能在20世纪就已经结束了完全传统式的爱，而对于我们来说，可能80后90后才是渐渐在试图摆脱传统式的爱的人，所以可以说是这本书非但没有过时，而且非常的适合于我们这代人阅读。罗曼蒂克的爱情正在为不少人所追求，不过也已经经过了几年的浪漫，现在普遍大部分人都已经意识到了现实的残酷，现在正是处在传统与浪漫式的婚姻的交集诞生新的婚姻构成的时代。自由式的爱，之后对于对象可能会更为偏重了，可能将不再完全以传统的背景作为条件，更多的是考虑人本身，人本省的潜力以及远见等。 同这种爱的对象因素密切相关而又具有当代文化特色的另一个特点是，__我们的整个文化基于购买欲上，基于互利交易的观点上。__现代人的快乐就在于一股劲溜达商店，浏览商品橱窗，用现金或通过分期付款来购买它能支付得起的一切。他或她以同样的方式对待人。对男人来讲，具有吸引力的女人是他们所追求的极好的东西；对于女人来讲，具有吸引力的男人，是她们所追求的极好的东西。”吸引力“通常意味着在人格市场上被追求的流行的优质产品。特别使人富有吸引力的因素，无论在精神上或在物质上都是由时代风尚决定的。在20年代，一个酗酒、抽烟、泼辣、富有性感的女人是具有吸引力的；今天时代风尚更多地要求女性贤惠和羞怯。19世纪末二十世纪初，男人一定要雄心勃勃、富有进取心——今天他必须谙熟世故、善于交际、恢宏大度——以便成为一种具有吸引力的”产品“。在任何情况下，只有考虑到这种具有人性的商品不超过自己所能购买的范围，才常常会产生爱上一个人的感受。我只是一心为了交易。从社会价值来看，爱的对象应该是逞心如意的；同时爱的对象也考虑到我的全部财产和潜在能力而应该需要我。因此，两个人根据他们自己交换价值的条件，一旦在市场上发现有最好的对象，他们就产生了爱。象购买不动产一样，能发挥的潜力在这种交易中常常起相当大的作用。在市侩型意识流行的文化中，在物质上的成功具有特殊价值的文化中，人的爱情关系和条件商品市场与劳动力市场的交换，都遵循统一模式，这种现象是不足为奇的。 爱的对象的寻求确实已经可以称之为互利交易。一般来说，只有在物质、潜在能力相近的人之中才更能产生共同地想法，在婚姻之中也才更能具有互相理解的可能，为了未来的幸福，可以说是这样的互利交易的观点是最合适、最优的方案。 认为爱没有什么科学的第三个错误在于__混淆了”爱上“一个人的最初经验和对一个人”爱“的永久状态——或者我们不妨说”处于“爱一个人的永久状态。__假如两个素昧平生的陌生人，像我们大家一样，突然让两人之间的大墙dota，他们感到越来越近，最后成为一体，那么成为一体的一刹那是生活中经历最快乐最兴奋的时刻。对于已被隔绝，孤寂而没有爱的人来说，它更是美妙而神奇。这种意外的亲密奇遇，只要跟性的吸引和性的高潮结合起来，或者为性的吸引和性的高潮所驱动，常常是很容易产生的。但是，这种爱就其本性而言并不长久，只是昙花一现。这两个人渐渐熟悉，而亲密行为的神奇色彩却日渐褪去，直至最后他们地冲突、失望及相互间的厌烦把最初剩下的兴奋经验葬送殆尽。然而，开始时他们根本不知道这些，事实上，他们只是把相互间如痴如醉的迷狂状态当做双方强烈地爱的明证；与此同时，他也许仅仅表明他们以前孤独的程度。 爱的状态被误解是当下热恋的情侣分手的最普遍原因。这里稍稍提一下，第二个原因恐怕就是上一段所说的互利交易中最优的不满足。对于刚脱离孤寂时的充实感误认为是真实的双方之间的爱，将爱的情感的最高峰误认为是未来持久的爱的平均值，自然会对之后的爱的情感的滑坡感到不满，厌烦。从持久的角度来看，爱情理应是平和的，而非燃烧殆尽一般的瞬时的轰轰烈烈。不过，这里有一个问题。 什么样的轰轰烈烈是不正常的呢？对于在选择对象之时的突如其来的一种憧憬，同样也是一种强烈地情感，只是并未形成双方之间的关系，依旧只是单相思。这样的情感在双方之间建立桥梁之后，是否会形成真实平和的爱情呢？还是说，这只是一时的荷尔蒙原因，更需要做的是冷静，待一定时间之后便能明白自己真实的情感？ 尽管这种态度——再没有什么东西比爱更容易的了——得到截然相反的证明，可是它仍旧成为一种对爱流行的看法。几乎没有哪一种活动，哪一项事业会像爱那样一开始充满着希冀和期望，而最后又常常失败。如果在其它的活动中出现这种情况，人们也许会渴望知道失败的原因，渴望学会怎样做得更好一些，或者干脆放弃这种活动。既然在的问题上，人们要放弃爱是不可能的，那么似乎只有一种合适的办法来克服爱的失败，这种办法乃是探讨爱的失败的原因，进而探究爱的意义。 探究爱的原因，进而探讨爱的意义正是我们阅读这本书的目的。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/读书笔记/"},{"name":"爱的艺术","slug":"爱的艺术","permalink":"https://sean10.github.io/tags/爱的艺术/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/爱情/"}]},{"title":"商半群的计算总结","slug":"商半群的计算总结","date":"2015-11-03T12:06:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/03/商半群的计算总结/","link":"","permalink":"https://sean10.github.io/2015/11/03/商半群的计算总结/","excerpt":"","text":"##商半群的计算总结 看商半群的题看了好久，一直没看懂几个条件是什么意思，重头翻书，总算找到一些思路，是自己的基础没学好的缘故。 以下来分享以下我的计算方式，因为没有找到答案，我也不好说一定对。 首先，必须要明白商集的相关基础知识。 &gt; huafen huafen2 A的商集就是对集合A进行一个划分，所有划分的子集之间交集为空集，同时并集又为A。 看下图就能理解他是如何划分的了 example1 dingli1 explore 这两段讲的很清楚。 dingli2 example2 根据这个例子，我们理解了得到的集合的等价关系应该怎么写出来。 依据划分的块进行相关元素的全排列。 explore2 这个例子告诉了我们商集通过等价类应该如何表达。 &gt; example2 example3 接下来回到群的内容 definition3 这一段的(a)给了我们进行商半群的运算表的计算的条件。 等价类的二元运算就是先计算方括号内的，得到的等价类就是所求等价类 让我们来看一道题 question 在这里我们只做a题，b题暂时不涉及 我的答案是以下 &gt; ans 我对商半群的计算的认识就是以上的过程了。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/离散数学/"},{"name":"群论","slug":"群论","permalink":"https://sean10.github.io/tags/群论/"}]},{"title":"论勇气","slug":"论勇气","date":"2015-11-01T13:50:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/01/论勇气/","link":"","permalink":"https://sean10.github.io/2015/11/01/论勇气/","excerpt":"","text":"作为交英语作业前的一次头脑风暴，以中文来记录自己所暂时能想到的。 虽然本打算看完《存在的勇气》，再写的，时间不够，姑且量力而为了。 勇气，依据维基百科，是一种面对痛苦、危险、威胁、不定的选择和希望。 生理上的勇气是面对物理上的疼痛、困难、死亡抑或是死亡的威胁下的勇气，而心理上的勇气则是一种能够在面对流行的二元选择、羞愧、流言、气馁、个人损失下做出正确选择的能力。 在这里，我们考虑的更多的是心理上的广义范围内的勇气。 知道了定义，那么为什么勇气值得我们来探讨呢？ 勇气在哪些方面具有存在的价值呢？先从生命必须品的方向来说，勇气是生存必要的吗？并非生存必须品，所以它的价值对不同的人来说并不相同。 勇气，面对选择，能做出决断。 对于处在追求路上的人来说，毫无疑问，勇气是必须的。说的通俗，唯有勇气，方可乘风破浪。 反之，对于已经有所实现自身所需的人，已经只需要随性而为了。已经无需勇气来推动了。 回到实际，我们大部分人还是处在第一种，勇气自然是必备之物。那么，说的细致一些，我们应该怎么做呢？ 果断，在我看来，是最先需要具备的。当然，并非莽撞。在当下这个快节奏的大数据时代，时间是最充足的，但同样也是最紧缺的。在技术的支持下，传输、计算等硬性时间都已经得到了大幅度的缩减，人与非生命体最大的长处当前正可以得到最大限度的发挥。不过，技术的存在，也给人类的思维提供了更多的乌托邦，对我个人而言，网络的娱乐功能仿佛罂粟一般让人沉迷、无可自拔。原本膨胀的弹性时间也渐渐萎缩，仿佛统计回归一般。人的普遍成长是必须按部就班的，指数级提高的思维水平果然只是乌托邦吗。该放则放，当机立断，于我，是必须的。 其次，单纯，也必然需要作为元素之一。同样，基于信息时代，互联网的世界实在是丰富。在进入计算机专业之前，对互联网的了解，我仅仅只是基于世人都知道的，使得全世界达成了互连，可以在转瞬之间了解到世界对面的人的消息。然而，当时的我还是小看了数据。虽说当下距离互联网的诞生并没有多久，仅仅数十年罢，然而数据的累积早已不是个人之力可穷经其目录的了。如今，仅仅只是针对专业所及，所能学习的方面便已经多达数十种常用语言，而时间仅有那些，我一开始试图囫囵吞枣，太过贪心，一年一事无成，仅仅皆有所知。而其他人，虽然并不知晓其他方面的技术，但已经对一种语言的开发钻研至深。单纯的勇往直前，在如今繁杂的时代，不可或缺。否则，仅仅只能收获中庸。 当前，想来，要素并无需太多，唯二已经足够。 论勇气，当下只能想到这些了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"勇气","slug":"勇气","permalink":"https://sean10.github.io/tags/勇气/"}]},{"title":"《爱的艺术》爱是艺术吗？","slug":"《爱的艺术》爱是艺术吗？","date":"2015-10-31T16:00:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/11/01/《爱的艺术》爱是艺术吗？/","link":"","permalink":"https://sean10.github.io/2015/11/01/《爱的艺术》爱是艺术吗？/","excerpt":"##《爱的艺术》爱是艺术吗？ 上一次翻开这本书还是2年前了，是它引领了我进入哲学的世界，不知现在再翻开能不能有新的理解。","text":"##《爱的艺术》爱是艺术吗？ 上一次翻开这本书还是2年前了，是它引领了我进入哲学的世界，不知现在再翻开能不能有新的理解。 重读第一章 爱是一门艺术吗？如果爱是一门艺术，那就要求人们有这方面的知识并付出努力。或者爱仅仅是一种偶然产生的令人心荡神怡的感受，只有幸运儿才能“堕入”爱的情网呢？这本小册子以第一种假设为基础，而大多数人毫无疑问相信第二种假设。 假如爱是一门艺术，那么所有人就不得不进行学习，耗费心力。虽然可能可以换来一个成功的爱的概率，然而与不用耗费丝毫心力甚至时间、唯一的需求就只是听从天命等待运气的光临的第二种选择来说，毫无疑问的大部分人都会不经思考的、轻易地相信了第二种选择。 然而原因是什么呢？是因为人的本性吗，对于一些如同爱一般的非具象化的非显然必要存在于现实的元素，自然的惰性占据了优势吗？不深思相信爱是艺术与否的利弊，便做出了舍弃努力的可能的概率。 不过，仔细想来，其实这样的分析也是片面的。要知道，对于大部分人，只要没有陷入对娱乐等迷恋，能够提高自己的技能一定是不会轻易放弃的。恐怕，更大的原因只是，爱的因素毕竟不止是掌握了这门艺术与否，至少在深度掌握这门艺术之前，其他的如同外貌等不可掌控因素占据了更大的话语权。而一门艺术的高度掌握从来不是轻易可以达成的，是需要大量的努力的。一旦达成了一定的艺术的学习，然而却依旧没有得到爱，那般的打击下，便意味着短时间之内将无力改变。在未大成之际，失败的可能性更大的情况下，既然能够不去面对失败，大部分人理所当然会去选择躲避吧。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/读书笔记/"},{"name":"爱的艺术","slug":"爱的艺术","permalink":"https://sean10.github.io/tags/爱的艺术/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/爱情/"}]},{"title":"【Discrete Mathematics】Relations【2015.10.31更新】","slug":"【Discrete-Mathematics】Relations【2015-10-31更新】","date":"2015-10-29T13:22:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/10/29/【Discrete-Mathematics】Relations【2015-10-31更新】/","link":"","permalink":"https://sean10.github.io/2015/10/29/【Discrete-Mathematics】Relations【2015-10-31更新】/","excerpt":"","text":"【Discrete Mathematics】Relations 这是离散数学课的个人阶段性总结，如有纰漏，敬请指出，一起学习~太过简单，也请见谅Orz 使用教材为《离散数学及其应用》（第7版.英文版） 现在主要拉定义，加上个人理解= = Chapter 9.1 Relations and their properties Definition1. Let A and B be sets. A binary relation from A to B is a subset of A × B._ 二元关系就是序偶的集合R，记号为aRb，表示(a,b). 函数是关系的一种。对应于集合A的每一个元素，恰好有且仅有一个集合B中的元素与之对应。 Definition2. A relation on a set A is relation from A to A. Definition3. A relation R on a set A is called reflexive if (a, a)R for every element a A. Remark.我们看到a((a,a)R),那么集合上的关系是自反的。这里的论域是A中所有元素的集合。 Definition4. A relation R on a set A is called symmetric if(b,a) R whenever (a,b)R ,for all a,b A. A relation R on a set A such that for all a,b A, if (a,b) R and (b,a) R, then a = b is called antisymmetric. Remark.使用量词，可以看到如果a b((a,b) R -&gt; (b,a) R),则A上的关系R是对称的。类似的，如果a b(((a,b) R ^ (b,a) R)-&gt;(a=b),则A上的关系R是反对称的。 就是说，关系R是对称的，当且仅当如果a与b相关则b与a就相关，关系R是反对称的，当且仅当不存在由不同元素a和b构成的序偶使得a与b相关并且b与a也相关。对称与反对称的概念不是对立的，因为一个关系可以同时有这两种性质或者两种性质都没有。一个关系如果包含了某些形如(a,b)的对，其中a != b，这个关系就不可能同时是对称和反对称的。 Definition5. A relation R on a set A is called transitive if whenever (a,b) R and (b,c) R,then (a,c) R,for all a,b,c A. Remark.使用量词，我们可以看到在集合A上的关系R是传递的，如果a b c(((a,b)R ^(b,c)R)-&gt; (a,c)R). Definition6. Let R be a relation from a set A to a set B and S a relation from B to a set C.The composite of R and S is the relation consisting of ordered pairs(a,c),where aA,cC,and for which there exists an element b B such that (a,b) R and (b,c) S.We denote the composite of R and S by SR. Definition7. Let R be a relation on the set A.The powers R^n,n= 1,2,3…,are defined recursively by R^1=R and R^(n+1) = R^nR. Theorem1. The relation R on a set A is transitive if and only if R^n R for n = 1,2,3… Supplement A relation R on the set A is irreflexive if for every a A,(a,a) R.That is ,R is irreflexive if no element in A is related to itself. A relation R is called asymmetric if (a,b)R implies that (b,a) R. Let R be a relation from a set A to a set B.The inverse relation from B to A,denoted by R^-1 ,is the set of ordered pairs {(b,a)|(a,b)}.The complementary relation R is the set of ordered pairs{(a,b)|(a,b)R}. Chapter 9.2 n-ary relations and their applications Definition1. Let A1,A2,…An be sets.An n-ary relation on these sets is a subset of A1×A2×…×An.The sets A1,A2,…An are called the domains of the relation ,and n is called its degree. __*Supplement__ Relations used to represent databases are also called tables, because these relations are often displayed as tables. Each column of the table corresponds to an attribute of the database. For instance, the same database of students is displayed in Table 1. The attributes of this database are Student Name, ID Number, Major, and GPA. A domain of an n-ary relation is called a primary key when the value of the n-tuple from this domain determines the n-tuple. That is, a domain is a primary key when no two n-tuples in the relation have the same value from this domain. Records are often added to or deleted from databases. Because of this, the property that a domain is a primary key is time-dependent.Consequently, a primary key should be chosen that remains one whenever the database is changed. The current collection of n-tuples in a relation is called the extension of the relation. The more permanent part of a database, including the name and attributes of the database, is called its intension. When selecting a primary key, the goal should be to select a key that can serve as a primary key for all possible extensions of the database. To do this, it is necessary to examine the intension of the database to understand the set of possible n-tuples that can occur in an extension. Combinations of domains can also uniquely identify n-tuples in an n-ary relation. When the values of a set of domains determine an n-tuple in a relation, the Cartesian product of these domains is called a composite key. Definition2. Let R be an n-ary relation and C a condition that elements in R may satisfy. Then the selection operator sC maps the n-ary relation R to the n-ary relation of all n-tuples from R that satisfy the condition C. Definition3. The projection P(i1,i2,…,im) where i1 &lt; i2 &lt; · · · &lt; im, maps the n-tuple (a1, a2, . . . , an) to the m-tuple (a(i1), a(i2), . . . , a(im)), where m ≤ n. Definition4. Let R be a relation of degree m and S a relation of degree n. The join Jp(R, S), where p ≤ m and p ≤ n, is a relation of degree m + n − p that consists of all (m + n − p)-tuples (a1, a2, . . . , a(m−p), c1, c2, . . . , cp, b1, b2, . . . , b(n−p)), where the m-tuple (a1, a2, . . . , a(m−p), c1, c2, . . . , c(p)) belongs to R and the n-tuple (c1, c2, . . . , cp, b1, b2, . . . ,b(n−p)) belongs to S. Chapter 9.3 representing relations Representing relations using Matrices A relation between finite sets can be represented using a zero–one matrix. Suppose that R is a relation from A = {a1, a2, . . . , am} to B = {b1, b2, . . . , bn}. (Here the elements of the sets A and B have been listed in a particular, but arbitrary, order. Furthermore, when A = B we use the same ordering for A and B.) The relation R can be represented by the matrix MR = [mij], where m(ij)={1 if(ai,bj)R,0 if(ai,bj)R}. matrix Representing relations using Digraphs We have shown that a relation can be represented by listing all of its ordered pairs or by using a zero–one matrix. There is another important way of representing a relation using a pictorial representation. Each element of the set is represented by a point, and each ordered pair is represented using an arc with its direction indicated by an arrow. We use such pictorial representations when we think of relations on a finite set as directed graphs, or digraphs. __Definition1. A directed graph, or digraph, consists of a set V of vertices (or nodes) together with a set E of ordered pairs of elements of V called edges (or arcs). The vertex a is called the initial vertex of the edge (a, b), and the vertex b is called the terminal vertex of this edge. An edge of the form (a, a) is represented using an arc from the vertex a back to itself. Such an edge is called a loop. Chapter9.4 closures of relations The relation R = {(1, 1), (1, 2), (2, 1), (3, 2)} on the set A = {1, 2, 3} is not reflexive. How can we produce a reflexive relation containing R that is as small as possible? This can be done by adding (2, 2) and (3, 3) to R, because these are the only pairs of the form (a, a) that are not in R. Clearly, this new relation contains R. Furthermore, any reflexive relation that contains R must also contain (2, 2) and (3, 3). Because this relation contains R, is reflexive, and is contained within every reflexive relation that contains R, it is called the reflexive closure of R. Paths in Directed Graphs &gt;Definition1. A path from a to b in the directed graph G is a sequence of edges (x0, x1), (x1, x2), (x2, x3), . . . , (xn−1, xn) in G, where n is a nonnegative integer, and x0 = a and xn = b, that is, a sequence of edges where the terminal vertex of an edge is the same as the initial vertex in the next edge in the path. This path is denoted by x0, x1, x2, . . . , xn−1, xn and has length n. We view the empty set of edges as a path of length zero from a to a. A path of length n ≥ 1 that begins and ends at the same vertex is called a circuit or cycle. Theorem1. Let R be a relation on a set A. There is a path of length n, where n is a positive integer, from a to b if and only if (a, b) ∈ Rn. Definition2. Let R be a relation on a set A. The connectivity relation R* consists of the pairs (a, b) such that there is a path of length at least one from a to b in R. Because Rn consists of the pairs (a, b) such that there is a path of length n from a to b, it follows that R* is the union of all the sets Rn. In other words, formula1 Theorem2. The transitive closure of a relation R equals the connectivity relation R*. Lemma1. Let A be a set with n elements, and let R be a relation on A. If there is a path of length at least one in R from a to b, then there is such a path with length not exceeding n. Moreover, when a != b, if there is a path of length at least one in R from a to b, then there is such a path with length not exceeding n − 1. path Theorem3. Let MR be the zero–one matrix of the relation R on a set with n elements. Then the zero–one matrix of the transitive closure R* is formula2 Lemma2. algorithm Chapter9.5 Equivalence Relations Definition1. A relation on a set A is called an equivalence relation if it is reflexive, symmetric, and transitive. Definition2. Two elements a and b that are related by an equivalence relation are called equivalent. The notation a~b is often used to denote that a and b are equivalent elements with respect to a particular equivalence relation. Definition3. Let R be an equivalence relation on a set A. The set of all elements that are related to an element a of A is called the equivalence class of a. The equivalence class of a with respect to R is denoted by [a]R. When only one relation is under consideration, we can delete the subscript R and write [a] for this equivalence class. In other words, if R is an equivalence relation on a set A, the equivalence class of the element a is [a]R = {s | (a, s) ∈ R}. If b ∈ [a]R, then b is called a representative of this equivalence class. Any element of a class can be used as a representative of this class. That is, there is nothing special about the particular element chosen as the representative of the class. Theorem1. Let R be an equivalence relation on a set A. These statements for elements a and b of A are equivalent:(i) aRb (ii) [a] = [b] (iii) [a]∩[b] != 0 Theorem2. Let R be an equivalence relation on a set S. Then the equivalence classes of R form a partition of S. Conversely, given a partition {Ai | i ∈ I} of the set S, there is an equivalence relation R that has the sets Ai, i ∈ I, as its equivalence classes. a partition of a set S is a collection of disjoint nonempty subsets of S that have S as their union. In other words, the collection of subsets Ai, i ∈ I (where I is an index set) forms a partition of S if and only if Ai != 0 for i ∈ I, Ai ∩ Aj = 0 when i != j, and c Supplement A partition P1 is called a refinement of the partition P2 if every set in P1 is a subset of one of the sets in P2. Chapter9.6 Partial Orderings Definition1. A relation R on a set S is called a partial ordering or partial order if it is reflexive, antisymmetric, and transitive. A set S together with a partial ordering R is called a partially ordered set, or poset, and is denoted by (S, R). Members of S are called elements of the poset. Definition2. 4 Definition3. 3 Definition4. 2 Theorem1. 1 这一章就这样了，都是基础，摘录一下。找离散的符号太困难了，只能贴图了。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/离散数学/"},{"name":"关系","slug":"关系","permalink":"https://sean10.github.io/tags/关系/"}]},{"title":"《龙珠之复活的F》休闲的龙珠","slug":"《龙珠之复活的F》休闲的龙珠","date":"2015-10-25T12:14:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/10/25/《龙珠之复活的F》休闲的龙珠/","link":"","permalink":"https://sean10.github.io/2015/10/25/《龙珠之复活的F》休闲的龙珠/","excerpt":"稍稍温习了一下《龙珠之复活的F》，给我的印象就是现在出的龙珠的风格都已经趋于休闲了呢。《神与神》以及现在的这部，两部的剧情里都已经不再是以前的需要拼命才能拥有足够的战斗力了，现在已经偏向去日常化了，悟空的天真粗心的个性也愈发凸显了，虽说是主角，到了动漫的末期之后，配角反倒是和他拥有了同样的镜头率。","text":"稍稍温习了一下《龙珠之复活的F》，给我的印象就是现在出的龙珠的风格都已经趋于休闲了呢。《神与神》以及现在的这部，两部的剧情里都已经不再是以前的需要拼命才能拥有足够的战斗力了，现在已经偏向去日常化了，悟空的天真粗心的个性也愈发凸显了，虽说是主角，到了动漫的末期之后，配角反倒是和他拥有了同样的镜头率。 在这部中，弗利萨虽然复活了，然而这次他的身份却变成了丑角一般，只是在剧情中担任吐槽、被悟空、贝吉塔嘲讽的角色，感觉倒是略萌了。对于剧情中弗利萨半年就拥有了悟空整部龙珠Z经历之后的战斗力这点就不予评价了，龙珠的战斗力已经混乱了。在这里，悟空和贝吉塔两人都能轻松变身上一部中透露出的超级赛亚神变身之后的第一形态，秒杀弗利萨本不是问题，后面几十分钟真的只是日常的对话了，就像其他人说的，这一部剧场版的主旨在于凸显悟空的粗心大意，果不其然，剧情最后，弗利萨趁他们没注意，灭了地球，然后所幸一开始作者就已经给这个坑作了铺垫，维斯简单逆转时间，给他们提供了弥补的机会。不再让人后悔，也不再有紧张的气氛，整部动漫都沉浸在欢愉的气氛中。换个角度，也就是主角们已经不再有曾经的紧迫感提高实力，一切都只是消遣尔尔。 从原著者的角度，可能这样的发展是最好的，不是无止境的超4、超5下去，而是进入神的境界，体会自然。然而，从某种角度，合理同时也便是开始平凡的选择。想必大家也有同样的感觉罢，美好的结局永远不是能够想象到的，唯有留下一丝悬念的结局才能让人联想，并富有一丝完结的感伤。如今的龙珠原著，满满的日常化的风格，对我来说，已经只能是偶尔的娱乐了，相比，同人之作的《龙珠GT》给我的美好印象更为深刻了，最后悟空的别离，以及最后的以下下代的子孙重现悟空、贝吉塔的故事更为让人赞赏、让人意识到真的结束了，大家都成长了。至于其他的不断发掘宇宙本质、去其他宇宙找对手的同人就算了，虽说是遵循了主线，然而我作为观众，真的累了，看龙珠成长过来，如今大学了，希望的真的是结束了。 我对GT已经很满足了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/日本/"},{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/动漫/"},{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/影评/"}]},{"title":"Ubuntu+win7安装总结——查询不到win7分区问题","slug":"Ubuntu-win7安装总结——查询不到win7分区问题","date":"2015-10-24T12:01:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/10/24/Ubuntu-win7安装总结——查询不到win7分区问题/","link":"","permalink":"https://sean10.github.io/2015/10/24/Ubuntu-win7安装总结——查询不到win7分区问题/","excerpt":"","text":"这两天在学校计划装个linux以后用来写代码，windows下面就专心玩好了。 本来搜了下经验，以为很轻松（虽然事实上知道怎么弄，不出错就确实很轻松啦）。然后，就那么把原来的win7系统不自觉的全格了，直到花了1天半的时间之后，搜linux下怎么看不到win7的硬盘搜不到结果，忽然点开linux下的computer的property看了下之后，发现原本一直以为的linux只是在隔出来的50G下玩的，事实上是500G。 然后，明白了，数据全没了。（虽然已经备份，但是对于一些下载的计划看的资料丢了，也是比较难很快接受）。 OK，知道现在电脑里什么都没了以后，轻松了/ 因为觉得在Linux下装win7，事后的引导什么的可能会很麻烦，就依旧先刻个win7的U盘，在win7安装之后安装ubuntu。 这里的win7是从msdn里下载的应该说是最纯净的win7，因为连个网卡驱动都没有，还好周边有一台老式机，下载了一个拷过来才用上的网络。 接下来就是唯一导致这次安装错误的幕后黑手。 windows下准备好ultraiso刻录好的ubuntu的U盘。 开机进入选择启动（lenovo是F12进入，我电脑已经设置为Legacybios，所以不太了解win8双系统uefi该怎么设置） 进入ubuntu安装界面以后，之前都按continue就可以，到分区前一步，如果显示出已检测到win7系统，那么就说明你硬盘格式和标识都是正确的，下一步也就不会出现下一步不显示win7已经分好的磁盘的问题了。 如果没有显示检测出win7，现在按照我查的资料来理解。 安装win7的时候是MBR分区模式，安装ubuntu时，自动识别为GPT分区模式，执行以下命令就可以让Ubuntu以MBR执行。 在试用版里输入一下命令即可 &lt;pre class=“brush:bash”;&gt;sudo dd if=/dev/zero of=/dev/sda bs=1 count=8 seek=512 这会抹去 Primary GPT header 里的 GPT signature。请不要输错任何一个字，包括空格。 有其他人说也可以在bios设置里设置Legacyonly.我电脑没有这个选项，不确定在什么上有那个。 以上。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"app","slug":"app","permalink":"https://sean10.github.io/tags/app/"}]},{"title":"Ubuntu下安装xampp总结","slug":"Ubuntu下安装xampp总结","date":"2015-10-24T11:59:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/10/24/Ubuntu下安装xampp总结/","link":"","permalink":"https://sean10.github.io/2015/10/24/Ubuntu下安装xampp总结/","excerpt":"","text":"初用linux，对于指令还不太熟悉，在安装xampp过程中，一部分情况和其他教程不太符合，摸索着弄了一下。 在一开始没有用wget下载，在图形界面下下载的。 然后移动入opt文件夹，这里一开始始终弄不到管理员权限，不安装其他软件的情况下好像图形界面下取得不到管理员权限。 我用的是 &lt;pre class=“brush:bash”;&gt;然后用cd进入该文件夹 对文件权限设置可执行 &lt;pre class=“brush:bash”;&gt;chmod +x 文件名 然后启动文件 &lt;pre class=“brush:bash”;&gt;./opt/文件名 即可","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"app","slug":"app","permalink":"https://sean10.github.io/tags/app/"}]},{"title":"F.lux——自动调整屏幕亮度与颜色，降低蓝光","slug":"F-lux——自动调整屏幕亮度与颜色，降低蓝光","date":"2015-10-24T11:48:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/10/24/F-lux——自动调整屏幕亮度与颜色，降低蓝光/","link":"","permalink":"https://sean10.github.io/2015/10/24/F-lux——自动调整屏幕亮度与颜色，降低蓝光/","excerpt":"","text":"看电脑看的比较多，眼睛很容易干涩，这种方法，效果还不错。 linux下直接按照以下命令就可以了 sudo add-apt-repository ppa:kilian/f.lux sudo apt-get update sudo apt-get install fluxgui windows下进入以下网址下载即可 https://justgetflux.com/dlwin.html","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"App","slug":"App","permalink":"https://sean10.github.io/tags/App/"}]},{"title":"《六花的勇者》推理的勇者,黑化超凡or普通平淡","slug":"《六花的勇者》推理的勇者，黑化超凡or普通平淡","date":"2015-10-24T11:43:00.000Z","updated":"2018-10-08T15:11:42.000Z","comments":true,"path":"2015/10/24/《六花的勇者》推理的勇者，黑化超凡or普通平淡/","link":"","permalink":"https://sean10.github.io/2015/10/24/《六花的勇者》推理的勇者，黑化超凡or普通平淡/","excerpt":"新番刚出的时候，本以为是一部老套剧情讲述勇者组队刷魔王的故事。 而在最近看到其他人的推荐时，我才明白自己想错太多了。 剧情不复常见的勇者斗魔王，这仅仅只是一个从未漏出魔王对象的背景，真实的目的是开展一部杀人游戏。 从剧情角度的新颖来看，《六花的勇者》是和《魔王勇者》一般，对于针对性的受众——推理爱好者而言，是非常值得一看的。 《六花的勇者》的作者山形石雄在这之前写过《战斗司书》系列，早在07年已经被做成了动漫，可能是因为观看的平台少的缘故，之前并没有看到过这部的踪迹，单看百科的介绍，以人生化作的书为争夺中心，展开正方与反方的争夺，单单这样的设定，已经足以勾起我的兴趣。","text":"新番刚出的时候，本以为是一部老套剧情讲述勇者组队刷魔王的故事。 而在最近看到其他人的推荐时，我才明白自己想错太多了。 剧情不复常见的勇者斗魔王，这仅仅只是一个从未漏出魔王对象的背景，真实的目的是开展一部杀人游戏。 从剧情角度的新颖来看，《六花的勇者》是和《魔王勇者》一般，对于针对性的受众——推理爱好者而言，是非常值得一看的。 《六花的勇者》的作者山形石雄在这之前写过《战斗司书》系列，早在07年已经被做成了动漫，可能是因为观看的平台少的缘故，之前并没有看到过这部的踪迹，单看百科的介绍，以人生化作的书为争夺中心，展开正方与反方的争夺，单单这样的设定，已经足以勾起我的兴趣。 以下剧透 本部轻小说，围绕六花的6名天选勇者集合前往魔神领地沉默魔神背景，以自称地表上最强的男人与公主汇合、与半人半魔之女产生交际为铺垫，进入汇合之处，7人共同拥有勇者之六花，男主展开自己历经数年锻炼而来的综合能力，将真正的叛徒公主给成功的推理了出来。公主的真实想法是借牺牲50万人，实现永久的人与魔共存的和平。从长期高位的人来看，这样的想法其实相当合理，或者说这样的计划才是能有所成就者所会做的。作者如此的剧情可谓别出心裁，从中映射了高位决策者与低位小聪明者之间的大局观的差距，剧本中，是以大局者为之拒绝，始终在幕后执行自己的宏伟计划。而男主的单纯天真想法则在荧幕前作为主线展示。 在动漫的最后一幕，揭示了作者埋的一个大坑，真正的第6位六花登场了，动漫将这作为悬念遗留了下来，由此来看，该动画的制作公司还是有计划继续第二季的，不过当然这也是要看在观众群中的反响了。不过按照后续的轻小说的剧情来看，下一部的剧情恐怕也主要只会是男主在带领其他6人对抗魔神军三大统帅的过程中发现自己的真实身份——魔神三大统帅之一在人类中埋下的伏笔，然后男主继续斗智斗勇。并没有看过这部的轻小说，姑且凭经历猜测一下罢，按照动漫已知的铺垫来说，有2种最终结果的可能性。 第一种，也是我最不希望看到的，男主最后走上了一条最平淡也是最泛滥的道路，组队斗智斗勇打败了魔神中三大统帅之一也是他的身份的幕后黑手泰格纽。那么就确实完全没有什么必要出第二季了。 第二种，将公主的行动由幕后转向幕前，将男主的心理、眼界的成长确实的刻画出来，让男主成为一个黑化的人，不过这样的设定如果是同人，一定会有不少人欣赏，不过对于原著作者，这样舍弃自己的人物原本的设定，并不一定是一个好的选择，至少从我已有的经历来看，还从未看到过设定更改的动漫。比如大爱的《罪恶王冠》中，虽然男主和男配在剧情的中间实现了性格的黑化以及反转，然而在剧情的结束，还是以男主觉悟了、男配只是本性的展露作为结局。所以再看《六花》，作者只可能以第一种选择结束，想要看到第二种非主流路线，只可能在同人中找寻了。 再看轻小说与动漫的差异，本作动画化的构成、脚本作家是浦田达彦，《境界上的地平线》的脚本作家，暂时还感觉不到各集之间的剧情分配的不足之处，而人设上走了常见的勇者斗魔王的风格，粗旷不失细腻，对我来说还是感觉不错的了。 《六花的勇者》还是值得好评的。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/日本/"},{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/动漫/"},{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/影评/"}]}]}